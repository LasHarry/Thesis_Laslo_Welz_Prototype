{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e54965-b05c-4388-b8d3-283f1f026261",
   "metadata": {},
   "source": [
    "## RAG Prototype - Data Extraction and Processing\n",
    "First, multiple PDF documents are loaded, metadata extracted and irrelevant papers removed. Afterwards, the remaining papers are chunked into smaller pieces and assembled into a TSV format as the knowledge base for the retrieval model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff36e90-7f43-4a74-a9af-a4da223af3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python default libriaries\n",
    "import re\n",
    "import glob\n",
    "import csv\n",
    "import json\n",
    "\n",
    "# Python libraries for PDF (meta)data extraction and chunk generation\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257f7ae5-39c8-4bac-9ece-d300026d0064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metadata from PDF and return metadata items as dictionary \n",
    "def extract_metadata(file): \n",
    "    meta = PdfReader(file)\n",
    "\n",
    "    title_meta = meta.metadata.title\n",
    "    if meta.metadata.author == None:\n",
    "        author_meta = \"Unknown author\"\n",
    "    else:\n",
    "        author_meta = meta.metadata.author.strip()\n",
    "    date_meta = str(meta.metadata.creation_date.date())\n",
    "    subject_meta = meta.metadata.subject.split(',')[0]\n",
    "    if meta.metadata.subject == '':\n",
    "        doi_meta = \"No DOI available\"\n",
    "    else: \n",
    "        doi_meta = meta.metadata.subject.split(',')[1].strip()\n",
    "    try:\n",
    "        keywords_meta = str(list(meta.metadata.items())[7][1])\n",
    "    except:\n",
    "        keywords_meta = ''\n",
    "\n",
    "    keys = ['title', 'author', 'publish_date', 'subject', 'doi', 'keywords']\n",
    "    content = [title_meta, author_meta, date_meta, subject_meta, doi_meta, keywords_meta]\n",
    "\n",
    "    dict_metadata = dict(zip(keys, content))\n",
    "    return dict_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78e4680-9cc6-45b2-a960-8041590b9078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract plain text from PDF file and remove unnecessary text fragments\n",
    "def clean_document(file):\n",
    "    pdf = PdfReader(file)\n",
    "    text = \" \".join(page.extract_text() for page in pdf.pages)\n",
    "    # Remove newline characters and replace with a space\n",
    "    clean_text = text.replace('\\n', ' ')\n",
    "    \n",
    "    # Remove hyphen followed by space\n",
    "    clean_text = clean_text.replace('- ', '')\n",
    "\n",
    "    # Remove numeric references within square brackets\n",
    "    clean_text = re.sub(r'\\[\\d+(?:,\\s*\\d+)*\\]', '', clean_text)\n",
    "\n",
    "    # Remove hyperlinks\n",
    "    clean_text = re.sub(r'https?://\\S+', '', clean_text)\n",
    "    \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebae4a7-ff47-4c3b-9c60-1c520b5f28bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define chunk size and attach metadata to text chunk\n",
    "def chunk_documents(text, metadata):\n",
    "    custom_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=30,\n",
    "    length_function=len\n",
    "    )\n",
    "    \n",
    "    lib = custom_text_splitter.create_documents([text])\n",
    "    \n",
    "    for j in range(len(lib)):\n",
    "        lib[j].metadata.clear()\n",
    "        lib[j].metadata.update(metadata)\n",
    "\n",
    "    return lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f6722d-b33e-472e-a2e1-d367b5c4e7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    PATH = 'research/'\n",
    "    libs = []\n",
    "    metadata_list = []\n",
    "    for file in glob.glob('{}*.pdf'.format(PATH)):\n",
    "        meta = PdfReader(file)\n",
    "        title = meta.metadata.title\n",
    "        # Check for invalid publications\n",
    "        if title == None:\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Start processing: \" + str(title))\n",
    "            extracted_metadata = extract_metadata(file)\n",
    "            metadata_list.append(extracted_metadata)\n",
    "            cleaned_text = clean_document(file)\n",
    "            lib = chunk_documents(cleaned_text, extracted_metadata)\n",
    "            libs.append(lib)\n",
    "    \n",
    "    print('Chunks assembled!')\n",
    "\n",
    "    # Create JSON file for all publication metadata\n",
    "    with open('metadata.json', \"w\") as json_file:\n",
    "        json.dump(metadata_list, json_file, indent=4)\n",
    "    \n",
    "    print('Metadata saved as JSON!')\n",
    "\n",
    "    # Create TSV-file for the retrieval model\n",
    "    with open('kb/collection1024token.tsv', 'wt', encoding='utf-8') as out_file:\n",
    "        i = 0\n",
    "        for chunk in libs:\n",
    "            for line in chunk:\n",
    "                tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "                tsv_writer.writerow([i, line])\n",
    "                i += 1\n",
    "                \n",
    "    print('Collection created!')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4e20e2-d8be-402b-a7db-2ea9d719cf07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
