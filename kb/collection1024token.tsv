0	page_content='Personalizing Retrieval-Based Dialogue Agents Pavel Posokhov , Anastasia Matveeva ,O l e s i aM a k h n y t k i n a(B), Anton Matveev , and Yuri Matveev ITMO University, Saint Petersburg, Russia makhnytkina@itmo.ru Abstract. The development of various kinds of interactive assistants at present is highly in demand. In this ﬁeld, one critical problem is the per-sonalization of these dialog assistants seeking to increase user loyalty and involvement in a conversation, which may be a competitive advantage for enterprises employing them. This paper presents a study of retrieve models for a personalized dialogue agent. To train models the Persona Chat and Toloka Persona Chat Rus datasets are used. The study foundthe most eﬀective models among the retrieval models, learning strategies. Also, to solve one of the major limitations of the personalization of dialogue assistants—the lack of large data sets with dialogues containingperson characteristics—a text data augmentation method was developed that preserves' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
1	page_content='was developed that preserves individual speech patterns and vocabulary. Keywords: Personalized dialogue systems ·Retrieve models ·Text augmentation 1 Introduction Currently, due to the promising prospects for the practical use of dialogue systems in various ﬁelds, their development has become one of the most relevanttasks in NLP. Conversational systems, also known as chatbots, are in a high demand in industry and everyday life. According to a study by Business Insider, the chatbot market will grow from $2.6 billion in 2021 to $9.4 billion by 2024 at a compound annual growth rate (CAGR) of 29.7%. Currently, depending on the tasks being solved, it is common to separate goal-oriented models, the purpose of interaction with which is strictly deﬁned and aimed at solving a speciﬁc problem: ordering movie tickets, booking a hotel room, etc., usually the dialogue in this case is constricted to one subject area,which greatly simpliﬁes the interaction between the chatbot and a person and open-domain models which can' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
2	page_content='open-domain models which can operate in various subject areas, the goals of communication in this case can be diﬀerent, including phatic (idle-domestic).The latter are of the greatest interest due to their versatility, since ﬁne-tuning open-domain chatbots is more optimal than developing a new model to solve a speciﬁc problem. Also, it is clear that the construction of these types of models c/circlecopyrtSpringer Nature Switzerland AG 2022 S. R. M. Prasanna et al. (Eds.): SPECOM 2022, LNAI 13721, pp. 554–566, 2022. _47 Personalizing Retrieval-Based Dialogue Agents 555 is an important step necessary to create a strong AI. In addition, the task of open-domain communication, that is, without a strict goal-setting of a dialogue,on free topics, is also relevant, for example, less than ﬁve percent of Twitter posts are speciﬁc questions, while about 80 percent contain statements about a personal emotional state, thoughts or actions, represented by the so-called‘Me’-forms. Like all systems, open-domain systems have' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
3	page_content='open-domain systems have several disadvantages. For example, despite the rapid development of natural language processing, and the pres-ence of numerous dialogue studies in particular, caused by the success of the application of modern deep learning techniques to computational linguistics problems, modern dialogue systems are at the initial stage of their development.Human interactions with such models indicate the existence of numerous problems, such as lack of a coherent personality, lack of explicit long-term memory, a tendency to give vague and meaningless answers, these factors are the main reason for the decrease in the motivation of the second participant (human) to continue the communicative act. Often these problems are caused by the lackof direct information about the person and learning from the aggregate sample of dialogues of various people, which leads to the model adhering to a general, average personality, which can often lead to factual errors, inconsistencyor superﬁciality of the narrative.' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
4	page_content='of the narrative. It is possible to avoid such behavior of the model by creating personalized dialogue agents trained on datasets of people’s dialogues, extended by personality characteristics. Retrieval architectures, generative models, and hybrid models combining the ﬁrst two types in varied sequences are commonly used for the development of dialogue agents. This article proposes an approach to developing a personalizeddialogue agent using retrieval models. Currently, the ﬁeld of natural language processing is actively developing in the direction of improving the quality of solving problems via the emergenceof more complex and deep architectures of neural networks that require large datasets for training. The use of pre-trained models and additional ﬁne-tuning on target datasets also relies on the amount of data available. To increase the volume, data often are collected from multiple sources. This approach has signiﬁcant drawbacks for the development of virtual assistants, smart speakers,interactive' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
5	page_content='smart speakers,interactive robots, etc. since the data contains the speech of multiple people, each with its personal characteristics, which leads to a lack of cohesion in the responses, views, judgments, and style of communication. For handling this issue,augmentation of text data preserving individual speech patterns and vocabulary that is unique to the original text is relevant. This article presents a study on the inﬂuence of the use of augmentation methods that preserve style and vocab-ulary distinctive for a person on the performance of models for the automatic generation of replicas of a personalized dialogue agent. For producing high-quality models, it is critical to have large datasets. It is possible to increase the volume using successful dialogues between a bot and a user . However, at the stage of training neural networks, this approach is not applicable and the use of data augmentation methods is suggested. 556 P. Posokhov et al. 2 Related Work For building open-domain dialog systems, it is' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
6	page_content='dialog systems, it is common to distinguish two types of architectures [ 18,20]: retrieval search models which are based on the principle of ranking: choosing the most relevant answers to the input context from the selection of possible answers, and reﬁne models which are generator models that produce a system response token by token, based on the input context and, optionally, additional data necessary for generation, and also hybrid ensembles of those models, based on various strategies for their interaction. Non-goal-orienteddialogue systems have several features, including: 1. Models tend to produce generic, low-content answers. This problem is more characteristic of generative models, however, with a suﬃcient variety of can-didates in the data for retrieval models, this problem also occurs. The main reason for that is the lack of extensive extralinguistic knowledge of the model, which is why it produces answers containing as little factual information as possible, thus reducing the likelihood of making' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
7	page_content='the likelihood of making a mistake. 2. The conversational agents are not consistent in their responses which is reﬂected in contradictory statements following one another (for example, to the question “What do you like?” the model may answer “winter”, but the next answer to “What do you not like?” might be “cold and snow”). The mainreason for that is the lack of an explicit logical apparatus and reliance on a consistent personality of the agent, which, without additional personiﬁcation, is represented by an average set of all personalities in the training sample. 3. Dialogue models are not fully capable of grasping the context, primarily due to the lack of extralinguistic knowledge and the inability to personalize com-munication. One of the main approaches to solving these problems is the personalization and personiﬁcation of dialogue agents. Personalization is changing or modifyingthe responses of the model according to the information about another participant of the dialogue, passed to the model as an' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
8	page_content='passed to the model as an additional metadata vector. Some researchers ﬁnd this method unethical in certain cases, however, personalizationis more applicable to goal-oriented dialogue systems and is not included in this study. Personiﬁcation involves full-ﬂedged modeling of responses by the model in the context of the information about the persona of the sender. Person metadata can include various facts about the person (e.g., gender, age, hobbies, etc.) enabling a direct or indirect communication on behalf of the described person. Recent studies of retrieval models [ 5] show that the use of pre-trained BERT type transformer models as an embedding component of NLP models signiﬁcantly increases their eﬃciency in solving a wide range of problems, includingsolving ranking problems as encoders, which was also conﬁrmed in the ﬁrst phase of our study. Bidirectional Encoder Representations from Transformers (BERT) is the coding part of the transformer architecture, it uses the self-attention mech-anism and' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
9	page_content='self-attention mech-anism and multi-head attention to represent words, positional coding of tokens, which allows to achieve the eﬀect of a contextual representation of words. The eﬀectiveness of this approach is largely attributed to pre-training BERT on a Personalizing Retrieval-Based Dialogue Agents 557 large dataset with auto-labeling (MLM—masked word prediction, next sentence prediction, etc.), with the possibility of further ﬁne-tuning on the target datasetto improve the representation of the lexical meaning of words in the context of the problem under consideration. 1. Bi-Encoder [ 12] architecture is represented by a pair of independent BERT base models, which are initialized with the same parameters before the train-ing starts. Models receive context and candidate vectors as inputs, encoded using the WordPiece tokenizer, and process them independently. Dotprod is used to calculate an error. Negative sampling, where the distance value fordistractors can be partially masked, can also be used during' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
10	page_content='can also be used during training. 2. Cross-Encoder [ 12]—the architecture for ranking tasks which employs one instance of BERT, the input of which is a concatenated vector of context and candidates separated by a special token. The resulting vector is then compacted by weighted summation through a linear layer to obtain a scalarvalue that can be interpreted as the similarity between the candidate vector and the context. This approach allows the internal attention of the model to encode both vectors, which signiﬁcantly increases the eﬃciency of theirrepresentation, though signiﬁcantly increases the operating time and memory resources consumed. 3. Poly-Encoder [ 12]—the architecture that utilizes a pair of BERT embedders to represent contexts and candidates, similar to the Bi-Encoder model, but forthe calculation of the similarity of the candidate and context vectors, the latter passes through an attention block that has a collection of representations of the context initialized randomly and optimized during' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
11	page_content='randomly and optimized during training, where thecandidate vector is the query. Then the distance between the context and the candidates is calculated by multiplying their vectors. This approach allows to obtain contextual representations that are dependent both on the con-text and on the candidates, similar to how it happens in the Cross-Encoder architecture and improves the performance of the model. 4. Co-Encoder [ 30] similar to the Poly-Encoder architecture has two independent context and candidate representation blocks, but instead of the standard attention mechanism, it processes several stages of co-attention. This approach also produces extended views of the context. Additionally, the diffusion of information in this case extends to the representation of candidates,and the use of co-attention allows for incorporation of additional metadata vectors which are also used to expand the views. Generative architectures of conversational agents generate responses token by token using language modeling. Among' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
12	page_content='language modeling. Among the modern approaches to training generative models of personalized dialogue agents are: 1. GPT [ 7] is a Transformer-based architecture and training procedure for natural language processing tasks. Training follows a two-stage procedure. First, alanguage modeling objective is used on the unlabeled data to learn the initial parameters of a neural network model. These parameters are adapted to a target task using the corresponding supervised objective. 558 P. Posokhov et al. 2. Blenderbot [ 21] is a model created by the Facebook AI development team. It is built according to the standard architecture of the Seq2Seq transformermodel. It is created for user interaction but can also be used for many other text generation tasks. 3. Seq2Seq [ 16,24,28] is a tandem of two recurrent neural networks: encoder and decoder. These models can consist of several encoder and decoder blocks and a variable number of parameters. Also, such models employ an attention mechanism that solves the issue that' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
13	page_content='that solves the issue that the inﬂuence of previous block stateson the current one decreases exponentially with the distance between words. The layer of this mechanism is often implemented by a single-layer neural network that receives the hidden state of the encoder block and the context,which is represented by the previous hidden state of the decoder block, as input. A tremendous advantage of retrieval models over generative ones is the high volume of relevant content in the answers, allowing the dialogue to appear moremeaningful and realistic. Moreover, retrieval models have an objective advantage over generative ones since the former are evaluated by simple and eﬀective metrics such as top-k, which reﬂects the probability of ﬁnding the correct answerin the ﬁrst k ranks, R-precision k(equivalent to the value of recall for the k-th position), mrr(the reciprocal of the rank of the target response), etc. However, since automated evaluation metrics may not adequately reﬂect the quality of the dialogue system,' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
14	page_content='of the dialogue system, it is critical to evaluate the performance of the model by a person; as the study of dialogue systems shows, retrieval models are superiorto generative ones in this respect as well. Taking all of that into account, in this study, we focus on retrieval models. Also for producing high-quality models it is critical to have large datasets. It is possible to increase the volume using successful dialogues between a bot and au s e r[ 10], however, at the stage of training neural networks this approach is not applicable and the use of data augmentation methods is suggested. A set of the basic augmentation techniques is presented in the EDA algorithm [ 25], which consists of four operations: synonym replacement, random insertion, random permutation, and random deletion. When augmenting textualdata, it is important to preserve the meaning of the text; various dictionaries, for example, WordNet [ 8,25] or pre-trained language models such as BERT [ 26], GPT2 [ 15], Word2Vec [ 19], Glove [ 8],' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
15	page_content='Word2Vec [ 19], Glove [ 8], etc. are commonly used to replace words with synonyms. Work [ 19] considers several augmentation techniques similar to those in [ 8]: interpolation method, extrapolation method, adding random noise. The diﬀerence was the use of a pre-trained Word2Vec language model, unlike Glove in the previous work. The experiments were conducted for the problem of extractingtypes of contract elements from a text [ 3]. Various techniques for adding noise to word vector representations obtained using the Word2Vec model were reviewed in [ 29]: Gaussian noise, Bernoulli noise, Adversarial Noise, etc. Studies of adding noise to vector representations of words [ 8,19,29], in general, showed favorable results, however, the use of such Personalizing Retrieval-Based Dialogue Agents 559 augmentation methods involves embeddings of non-existing words, which can potentially lead to a mismatch in message class labels. Work [ 14] proposes a contextual augmentation approach based on the assumption that' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
16	page_content='based on the assumption that sentences are natural even if words in sentences are replaced by other words with paradigmatic relations. An alternative to generation of paraphrases is reverse translation. Reference  has studied the quality of reverse translation using deep neural networks, showing positive results. A study in [ 2] reviews the GECA (Good-Enough Compositional Data Augmentation) method, which is based on the idea that if two entities appear in a common environment, then any additional environment where one of the entitiesappears independently is also valid for another entity. Another non-trivial augmentation technique is presented in [ 9]w h e r et h e augmentation is performed via text shuﬄing using a neural network. Unfortunately, none of the methods above preserve the style and the vocabulary unique to the original message which is one of the most important issuesfor various applications such as the development of dialog assistants [ 17]s i n c e the personalization of dialog assistants is key' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
17	page_content='of dialog assistants is key to user loyalty. The method using the generative model LAMBADA [ 1] showed particular eﬃciency in text data augmentation. One of the main traits of this method is a phase for ﬁltering augmented data using the BERT classiﬁer. Also, this method is noteworthy for its supposed ability to preserve the speech characteristic of aperson. A signiﬁcant drawback of this method is the high demand for computing resources. Additionally, data from intermediate stages can not be immediately discarded due to the speciﬁcs of the algorithm, which leads to an increased usageof permanent (physical) memory. When modifying text data, transformations can lead to distortions in the text making it grammatically or semantically incorrect or stylistically distinctfrom the original text and it demands for techniques that can augment text preserving the style, vocabulary while maintaining syntactic integrity. There are also more advanced augmentation methods that have the ability to preserve the styles and' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
18	page_content='to preserve the styles and vocabulary of a text, for example, Paraphrases generator based on syntax trees transformation [ 4]. This method involves modifying a text by transforming the syntax tree based on syntactic grammars. Text augmentation via syntax trees with the generation of new data based on syntactic templates was also considered in [ 23,27]. 3 Methods 3.1 Models In the study, we consider retrieval and reﬁne models approaches for creation of personalized dialogue agents. 560 P. Posokhov et al. Retrieval Models. Numerous studies show that it is possible to improve the performance of nlp models in solving a wide range of tasks, including rankingtasks, by using pre-trained BERT-type transformer models as an embedding component. Bidirectional Encoder Representations from Transformers (BERT) is the encoding part of the transformer architecture. A self-attention mechanism,multi-head attention, and positional coding of tokens are employed for representing words in BERT, which allows obtaining of' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
19	page_content='which allows obtaining of contextual representation of words. Pre-training BERT on a large dataset with auto-labeling (MLM—maskedword prediction, next sentence prediction, etc.) is one of the main reasons for the eﬀectiveness of the method. As part of the study, we performed ﬁne-tuning of BERT models on target datasets to improve the representation of the lexicalmeaning of words within the scope of the problem under consideration. Within the scope of this study, we consider the following architectures based on BERT base models—Simple Bi-Encoder, Bi-Encoder with Coattention [ 11]. Text preprocessing includes only tokenization based on the Wordpiece [ 22] method. The following metrics are used to evaluate the performance of the models: (1) R@k—an interpretation of the recall for the ranking problem. The number of relevant responses from the k highest ranks divided by the total number of relevant responses. In the traditional form, the value k must match thenumber of relevant responses, thus R@k=acc (topk )/k,' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
20	page_content='thus R@k=acc (topk )/k, however, the number of highest ranks considered can be changed independently. Computing R@k requires knowledge of all documents relevant to the query (in the case of adialog system, k=1), then R@1 = acc (topk ). The sensitivity of the model can be analyzed by varying the number of ranks. (2) MRR or inverse rank, calculated by the formula MR R =1 /r,w h e r e ris the rank of the correct answer. This is a statistical measure for evaluating models that return responses sorted by probability of correctness. Unlike R@1, MRR can only be applied in the case of a single correct answer, and the metric itself is multiplicatively inverse. 3.2 Augmentation In this work, we present a new augmentation method that preserves the distinctive characteristics of a person’s speech (see Fig. 1). The idea for this augmentation method derives from the adapted data augmentation scheme shownin . The proposed method also includes the stage of extracting syntax trees. The stage of transformation and generation' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
21	page_content='transformation and generation of paraphrased data in this method is executed in a single process. Fig. 1. Schematic diagram of the augmentation process. Personalizing Retrieval-Based Dialogue Agents 561 Syntax tree extraction—in this stage, syntax trees are extracted for each replica using Stanford Core Nlp for the English language and SyntaxNet for theRussian language producing syntax trees of all replicas used by each person. (ROOT (SQ (VP (VB have) (NP (NP (DT any) (NNS pets)) (PP (IN at) (NP (NN home))))) (?))) The example of a syntax tree is produced from the original message “Do you have any pets at home?”. Creation of syntactic templates—the syntactic trees obtained at the previous stage are transformed to a uniform format by removingall the words of the original sentence from them and leaving only syntactic structural units. Further, duplicates and similar ones are removed from the set of obtained syntactic structures, and nmost frequently used ones are selected from the remaining ones. An example of' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
22	page_content='remaining ones. An example of a template is represented by formula (1). (ROOT (SQ (VP (VB )(NP (NP (DT )(NNS ))(PP (IN )(NP (NN )))))(?))) (1) where ROOT is the root of the sentence; SQ—inverted yes/no question, or main clause of a wh-question, following the wh-phrase in SBARQ ;VP—verb phrase; VB—verb, base form; NP—noun phrase; DT—determiner; NNS—noun, common, plural; PP—prepositional phrase; IN—preposition or subordinating conjunction; To these sets of templates obtained for each person we add commonfor OpenAttacker EOS line endings. Then, together with the original replica of the person, they are sent to the Syntactically Controlled Paraphrase Network (SCPN—encoder-decoder model for syntactically controlled generation of para-phrases) from the OpenAttaker framework [ 13] to generate augmented data. This way, each replica can be transformed in ndiﬀerent ways. Since only syntactic structures characteristic of a person are used for data augmentation, the syntac-tic features of a person’s speech are' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
23	page_content='of a person’s speech are preserved. Vocabulary and style are preserved since they remain almost unchanged as augmentation is based on transformation of the syntax tree. If any of the parts of speech is not present in the original replica, SCPN adds the necessary parts of speech (conjunctions, prepositions, particles) to maintain the syntactic coherence of the augmented replicas. If theremaining parts of speech are missing, they are added using a word generating LSTM. 4 Experiments 4.1 Datasets 1. PERSONA-CHAT is an English-language corpus of dialogues between two participants, reproducing artiﬁcial personas modeled based on 3–5 sentences 562 P. Posokhov et al. with a description (e.g. “I like to sk, “I am an artist”, “I eat sardines for breakfast daily”). This dataset consists of 8939 completed conversations and955 persons as a training set, 1000 dialogues and 100 persons for validation, and 968 dialogues and 100 persons for testing. To prevent word overlapping, information about persons after the collection' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
24	page_content='persons after the collection of dialogues was reworked,using paraphrasing, generalization, and concretization. 2. Toloka Persona Chat Rus is a dataset compiled at the Laboratory of Neural Systems and Deep Learning at the Moscow Institute of Physics and Tech-nology by each participant in the study modeling a certain speciﬁed person in dialogues. This dataset is packaged in two ﬁles: proﬁle.tsv containing lines with characteristics of 1505 diﬀerent persons, represented by 5 sentences suchas “I draw”, “I live abroad”, or “I have a snake”; dialogues.tsv containing 10,013 dialogues in Russian between study participants. Russian. 4.2 Retrieval Models Results In this study, we chose the most optimal conﬁgurations of ranking: Simple BiEncoder and CoBERT. In addition, for the modules, we employed a modiﬁedtraining method which involves the preliminary training of Siamese architectures, when the encoders of context and candidates are trained synchronously and then are separated and trained separately. One key' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
25	page_content='trained separately. One key condition for such learning methodis to prevent a complete optimization of the weights at the pre-learning stage because, having reached the clear minima of the error function, the Siamese encoders, when separated, will ﬁnd themselves in local minima, the escape fromwhich will require unreasonably large values of the learning step, which negates the beneﬁt of pre-learning. A comparison of the selected methods applied to the English Persona Chat dataset is presented in Table 1. Table 1. Performance of retrieval models Persona Chat. Strategy Model Persona Valid loss Valid acc Valid r1 Valid r5 Valid r10 Valid MRR 15/0 Cobert Mean 0.898 0.535 0.535 0.714 0.971 0.653 Cobert Concat 0.892 0.512 0.512 0.680 0.968 0.634 Simple Mean 0.911 0.509 0.509 0.686 0.963 0.629 Simple Concat 0.919 0.522 0.521 0.694 0.952 0.638 0/15 Cobert Mean 1.220 0.259 0.260 0.484 0.929 0.425 Cobert Concat 0.932 0.257 0.257 0.467 0.870 0.412 Simple Mean 1.298 0.253 0.254 0.474 0.919 0.418 Simple Concat 0.921' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
26	page_content='0.418 Simple Concat 0.921 0.352 0.352 0.490 0.949 0.489 5/10 cobert mean 0.874 0.539 0.539 0.716 0.972 0.656 Cobert Concat 0.890 0.533 0.533 0.712 0.970 0.653 Simple Mean 0.900 0.519 0.519 0.696 0.964 0.638 Simple Concat 0.995 0.519 0.519 0.699 0.962 0.642 Personalizing Retrieval-Based Dialogue Agents 563 According to the results of the comparison, the best result was achieved with the training with ﬁve epochs trained together and ten separately. With thisapproach to training, the most eﬀective was the CoBERT model. The performance results when using the Russian-language Toloka Persona Chat Rus dataset are presented in Table 2. Table 2. Performance of retrieval models Toloka Persona Chat Rus. Strategy Model Persona Valid loss Valid acc Valid r1 Valid r5 Valid r10 Valid r10 15/0 Cobert Mean 0.9 0.53 0.53 0.71 0.97 0.65 Cobert Concat 0.89 0.51 0.51 0.68 0.97 0.63 Simple Mean 0.91 0.51 0.51 0.69 0.96 0.63 Simple Concat 0.92 0.52 0.52 0.69 0.95 0.64 0/15 Cobert Mean 1.22 0.26 0.26 0.48 0.93 0.43 Cobert Concat' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
27	page_content='0.48 0.93 0.43 Cobert Concat 0.93 0.26 0.26 0.47 0.87 0.41 Simple Mean 1.3 0.25 0.25 0.47 0.92 0.42 Simple Concat 0.92 0.35 0.35 0.49 0.95 0.49 5/10 Cobert Mean 0.87 0.55 0.54 0.72 0.97 0.66 Cobert Concat 0.89 0.53 0.53 0.71 0.97 0.65 Simple Mean 0.9 0.52 0.52 0.7 0.96 0.44 Simple Concat 0.99 0.52 0.52 0.7 0.96 0.44 With Russian-language data, the best performance was achieved by the CoBERT and the 5/10 training approach. 4.3 Augmentation Results Examples of data augmented with syntactic paraphrasing are presented in Table 3. Table 3. Examples of data augmented with syntactic paraphrasing. Source text Dataset Result No I am not found a new girl at a wedding last weekPERSONA-CHAT i didn’t ﬁnd a girl at the wedding. L/yubl/yu /zheivotnyh ,prosto obo -/zhea/yu, kak i svo/yu rabotu )./Yaf a n Rustastiku l/yubl/yuToloka Persona Chat RusL/yubl/yu /zheivotnyh , prosto l/yubl/yu svo/yu rabotu i fan -tastiku . Training of retrieval models (simple Bi-encoder, CoBERT) was performed with three diﬀerent setups for data' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
28	page_content='diﬀerent setups for data augmentation. The option aug −prob =0 .0 corresponds to training without augmentations. With aug −prob =1 .0,e a c h statement is replaced by augmentation. The option augprob =0 .5where half of the statements are replaced by augmentation. Results of the experiments are presented in Table 4. 564 P. Posokhov et al. Table 4. Performance of retrievel models with augmentation. Augment Prob Language Model Valid acc Valid r1 Valid r5 Valid r10 Valid MRR 0.0 En Cobert 0.455 0.456 0.652 0.945 0.585 En Simple 0.405 0.406 0.6860 0.943 0.537 1.0 En Cobert 0.234 0.234 0.428 0.788 0.340 En Simple 0.290 0.290 0.522 0.874 0.407 0.5 En Cobert 0.463 0.463 0.655 0.942 0.593 En Simple 0.425 0.425 0.702 0.950 0.554 0.0 Ru Cobert 0.516 0.517 0.694 0.965 0.636 Ru Simple 0.520 0.520 0.699 0.959 0.440 1.0 Ru Cobert 0.234 0.234 0.429 0.765 0.338 Ru Simple 0.283 0.284 0.507 0.857 0.401 0.5 Ru Cobert 0.645 0.645 0.795 0.967 0.739 Ru Simple 0.629 0.629 0.785 0.967 0.728 5 Discussion and Conclusion Within the' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
29	page_content='and Conclusion Within the scope of this study, we analysed the modern types and architectures of dialogue systems, among which we identiﬁed the most eﬃcient type, namely, retrieval models. Among them, the best performance metrics were achieved by the CoBERT architecture when training ﬁve epochs together and ten others separately. Also in this paper, we propose a text data augmentation methodthat preserves individual speech patterns and vocabulary. We ﬁnd that data augmentation with the presented method produces an increase in performance at values of aug −prob < 1.0because in this case there is a chance that the original message remains unchanged. We observe a performance increase for diﬀerent models up to 12%. Acknowledgments. The research was ﬁnancially supported the Russian Science Foundations (project 22-11-00128). References 1. Anaby-Tavor, A., Carmeli, B., Goldbraich, E., Kantor, A., Kour, G., Shlomov, S., Tepper, N., Zwerdling, N.: Not enough data? deep learning to the rescue! (2019).  2. Andreas, J.:' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
30	page_content='(2019).  2. Andreas, J.: Good-enough compositional data augmentation (2019).  org/abs/1904.09545 3. Chalkidis, I., Androutsopoulos, I., Michos, A.: Extracting contract elements. In: Proceedings of the 16th Edition of the International Conference on Articial Intelli-gence and Law, pp. 19–28. ICAIL ’17, Association for Computing Machinery, New York, NY, USA (2017).  4. Coulombe, C.: Text data augmentation made simple by leveraging NLP cloud apis (2018).  Personalizing Retrieval-Based Dialogue Agents 565 5. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT: pre-training of deep bidirectional transformers for language understanding. In: Proceedings of the 2019 Conference of the North American Chapter of the Association for Com-putational Linguistics: Human Language Technologies, vol.1 (Long and Short Papers), pp. 4171–4186. Association for Computational Linguistics, Minneapolis, Minnesota (2019).  , org/N19-1423 6. Edunov, S., Ott, M., Auli, M., Grangier, D.: Understanding back-translation at scale. In:' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
31	page_content='at scale. In: Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 489–500. Association for Computational Linguis-tics, Brussels, Belgium (2018).  ,https:// aclanthology.org/D18-1045 7. Floridi, L., Chiriatti, M.: GPT-3: its nature, scope, limits, and consequences. Mind. Mach. 30(4), 681–694 (2020).  8. Giridhara, P.K.B., Mishra, C., Venkataramana, R.K.M., Bukhari, S.S., Dengel, A.R.: A study of various text augmentation techniques for relation classiﬁcationin free text. In: ICPRAM (2019) 9. Guo, H., Mao, Y., Zhang, R.: Augmenting data with mixup for sentence classiﬁcation: an empirical study (2019). arXiv:abs/1905.08941 10. Hancock, B., Bordes, A., Mazare, P.E., Weston, J.: Learning from dialogue after deployment: feed yourself, chatbot! pp. 3667–3684 (2019).  18653/v1/P19-1358 11. Humeau, S., Shuster, K., Lachaux, M., Weston, J.: Real-time inference in multisentence tasks with deep pretrained transformers (2019).  1905.01969 12. Humeau, S., Shuster, K., Lachaux, M.A.,' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
32	page_content='Shuster, K., Lachaux, M.A., Weston, J.: Poly-encoders: architectures and pre-training strategies for fast and accurate multi-sentence scoring. In: International Conference on Learning Representations (2020).  forum?id=SkxgnnNFvH 13. Iyyer, M., Wieting, J., Gimpel, K., Zettlemoyer, L.: Adversarial example generation with syntactically controlled paraphrase networks. In: Proceedings of the 2018 Conference of the North American Chapter of the Association for Computa-tional Linguistics: Human Language Technologies, vol. 1 (Long Papers), pp. 1875– 1885. Association for Computational Linguistics, New Orleans, Louisiana (2018).  , 14. Kobayashi, S.: Contextual augmentation: data augmentation by words with paradigmatic relations (2018). arXiv:abs/1805.06201 15. Kumar, V., Choudhary, A., Cho, E.: Data augmentation using pre-trained transformer models (2020). arXiv:abs/2003.02245 16. Lin, Z., Liu, Z., Winata, G.I., Cahyawijaya, S., Madotto, A., Bang, Y., Ishii, E., Fung, P.: XPersona: evaluating multilingual' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
33	page_content='evaluating multilingual personalized chatbot. In: Proceedings of the 3rd Workshop on Natural Language Processing for Conversational AI. pp.102–112. Association for Computational Linguistics, Online (2021).  org/10.18653/v1/2021.nlp4convai-1.10 , 17. Matveev, A., Makhnytkina, O., Matveev, Y., Svischev, A., Korobova, P., Rybin, A., Akulov, A.: Virtual dialogue assistant for remote exams. Mathematics 9(18) (2021).  , 2229 18. Ni, J., Young, T., Pandelea, V., Xue, F., Adiga, V., Cambria, E.: Recent advances in deep learning-based dialogue systems (2021) 566 P. Posokhov et al. 19. Papadaki, M., Chalkidis, I., Michos, A.: Data augmentation techniques for legal text analytics (2017) 20. Posokhov, P., Apanasovich, K., Matveeva, A., Makhnytkina, O., Matveev, A.: Personalizing dialogue agents for Russian: retrieve and reﬁne, vol. 2022, pp. 245–252 (2022).  21. Roller, S., Dinan, E., Goyal, N., Ju, D., Williamson, M., Liu, Y., Xu, J., Ott, M., Smith, E.M., Boureau, Y.L., Weston, J.: Recipes for building an open-domain' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
34	page_content='for building an open-domain chatbot. In: Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pp. 300–325. Association for Computational Linguistics, Online (2021).  eacl-main.24 , 22. Sennrich, R., Haddow, B., Birch, A.: Neural machine translation of rare words with subword units. CoRR abs/1508.07909 (2015),  23. Shen, T., Lei, T., Barzilay, R., Jaakkola, T.S.: Style transfer from non-parallel text by cross-alignment (2017). arXiv:abs/1705.09655 24. Sugiyama, H., Mizukami, M., Arimoto, T., Narimatsu, H., Chiba, Y., Nakajima, H., Meguro, T.: Empirical analysis of training strategies of transformer-based Japanesechit-chat systems (2021). arXiv:abs/2109.05217 25. Wei, J.W., Zou, K.: EDA: easy data augmentation techniques for boosting performance on text classiﬁcation tasks (2019). arXiv:abs/1901.11196 26. Wu, X., Xia, Y., Zhu, J., Wu, L., Xie, S., Fan, Y., Qin, T.: Mixseq: a simple data augmentation method for neural machine translation, pp.' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
35	page_content='machine translation, pp. 192–197 (2021). https:// doi.org/10.18653/v1/2021.iwslt-1.23 27. Yang, Z., Hu, Z., Dyer, C., Xing, E.P., Berg-Kirkpatrick, T.: Unsupervised text style transfer using language models as discriminators (2018). arXiv:abs/1805.11749 28. Zhang, S., Dinan, E., Urbanek, J., Szlam, A., Kiela, D., Weston, J.: Personalizing dialogue agents: I have a dog, do you have pets too? In: Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics(vol. 1: Long Papers), pp. 2204–2213. Association for Computational Linguistics, Melbourne, Australia (2018).  ,https:// aclanthology.org/P18-1205 29. Zhang, Z., Zweigenbaum, P.: Gneg: graph-based negative sampling for word2vec (2018).  30. Zhong, P., Sun, Y., Liu, Y., Zhang, C., Wang, H., Nie, Z., Miao, C.: Endowing empathetic dialogue systems with personas (2020). arXiv:abs/2004.12316' metadata={'title': 'Personalizing Retrieval-Based Dialogue Agents', 'author': 'Pavel Posokhov', 'publish_date': '2022-10-29', 'subject': 'Speech and Computer', 'doi': 'doi:10.1007/978-3-031-20980-2_47', 'keywords': 'Personalized dialogue systems; Retrieve models; Text augmentation'}
36	page_content='An Interactive Artiﬁcial Intelligence System for Inventive Problem-Solving Stelian Brad1(B)and Emil S ,tetco2 1Technical University of Cluj-Napoca, Memorandumului 28, 400445 Cluj-Napoca, Romania stelian.brad@staff.utcluj.ro 2Zetta Cloud, Govora 16A, 400535 Cluj-Napoca, Romania emil.stetco@zettacloud.ro Abstract. There is a vast space of potentiality for inspiration in the design and engineering of technical systems that are poorly valorized; the cyberspace that stores and daily adds high volumes of global collective intelligence. This spacecould be more productively tackled with the assistance of Artiﬁcial Intelligence algorithms led by Natural Language Processing (NLP) models. We investigate the application of Structured Activation V ertex Entropy (SA VE) method in combina-tion with Question Answering Machine (QAM) algorithms to explore information that is stored in big datasets, accessible within unstructured dataspaces. The SA VE method is transformed with the assistance of TRIZ into a set of' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
37	page_content='of TRIZ into a set of searchingmeta-terms or meta-concepts. Taking off from a clear description of the problem, target results, and the current (eco)system, meta-terms, and concepts are incorporated into a spiral searching-answering process called ‘D-SIT-SIT-C’, driven by a Retrieval Augmented Generation (RAG) model to create an “intelligent” Natural Language Processing pipeline, with inserting the human in the loop at each itera-tion. We have found that the proposed pipeline based on a RAG model brings new valences to the creative thinking process and unleashes new dimensions of investigations that lead to higher quality solutions than those formulated with limitedresources. Keywords: Artiﬁcial Intelligence (AI) ·Natural Language Processing (NLP) · Question Answering Machine (QAM) ·Deep Learning (DL) ·Theory of Inventive Problem Solving (TRIZ) ·Structured Activation of V ertex Entropy (SA VE) ·Retrieval Augmented Generation (RAG) ·Humans in the Loop (HL) · Interactive AI systems 1 Introduction With the' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
38	page_content='1 Introduction With the development of algorithms for text mining that use regular expressions [ 1], as well as considering the improvements in natural language processing models (NLP) [ 2], researchers, scientists and engineers beneﬁt a lot for searching in a smarter way within dataspaces for speciﬁc information. This is more than using search engines and key words to display a list of sources, such as the case of Google or other similar web search © IFIP International Federation for Information Processing 2022 Published by Springer Nature Switzerland AG 2022R. Nowak et al. (Eds.): TFC 2022, IFIP AICT 655, pp. 165–177, 2022. _15 166 S. Brad and E. S ,tetco engines [ 3]. In inventive-problem solving frameworks we count on previous knowledge, discoveries, and inventions (e.g., patents, solutions published in scientiﬁc papers, etc.) toinspire us to solve a new problem. TRIZ explicitly encourages engineers to investigate knowledge bases at a given step in the problem-solving process [ 4], mostly databases with' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
39	page_content='[ 4], mostly databases with patents, where information is well-structured. Case-based reasoning (CBR) is another approach to search for inspiration in problemsolving [ 5]. It is a model from the ﬁeld of artiﬁcial intelligence (AI) and cognitive science that deﬁnes reasoning patterns to solve new problems by retrieving ‘cases’ that are storedin knowledge bases. In CBR, previous problem-solving experiences are extracted and adapted to ﬁt new needs. CBR incorporates in the searching process a model of human reasoning as a mechanism to constructing intelligent systems [ 6]. Combinations of semantic models (which go beyond simple ontologies) and TRIZ have been considered to develop expert systems to search for ideas in structured patent databases and to make various analytics in the process of idea generation for a new problem. A representative technological development in this direction is PatentInspiration [ 7]. Semantic models with TRIZ inventive principles are embedded in another technology called InnovationQ' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
40	page_content='technology called InnovationQ Plus [ 8] that is designed to search in massive databases of patents and IEEE indexed scientiﬁc papers (over 100 million documents in all). Matching and extraction of relevant knowledge from patent documents to be integrated within Inventive Design Method is another research contribution to support creative design [ 9]. In the same line, there are some other researches. Thus, our investigation in the mainstream databases with scientiﬁc publications (e.g., Clarivate Analytics, SCO-PUS) revealed a research work about Artiﬁcial Intelligence (AI) driven inventions [ 10]. The authors cited in [ 10] articulate the idea that automating inventions look interesting, but they consider that AI will rather complement the intelligence of engineers and scien-tists, rather than replace it. They also present a semantic model that can form the basis of future AI approaches. As part of their work, over eight million patents and scientiﬁc publications have been screened with NLP techniques to' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
41	page_content='with NLP techniques to extract semantic concepts. Anotherrelevant research is about reproducing TRIZ reasoning through the Deep Learning (DL) on a large number of transdisciplinary patent sets [ 11]. The investigation of online data sources for pairing engineering problems with knowledge of physics for classiﬁcation have also recently been published [ 12]. The last reference with relevance in relation to the topic considered in this paper is about the use of DL NLP-related models (Doc2vec andCosine Similarity) for automatic information retrieval and introduction into an Inverse Problem Graph (IPG) process (note: IPG is a lean-based method for deﬁning problems in the initial analysis phase of the inventive design process) [ 13]. The above-mentioned researches indicate a growing interest of the scientiﬁc community in introducing AI algorithms, mostly NLP DL-related ones, for smarter searching in databases on information and knowledge to support the inventive design process. How-ever, our inquiry in mainstream' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
42	page_content='our inquiry in mainstream databases of scientiﬁc papers does not indicate relevant research in the ﬁeld of automating idea proposals for problem solving. This niche is going to be further elaborated on in the next sections of this paper. We consider thelatest developments in artiﬁcial intelligence, speciﬁcally Question Answering Machine An Interactive AI System for Inventive Problem-Solving 167 (QAM) algorithms [ 14] in combination with the inventive principles promoted by Structured Activation of V ertex Entropy (SA VE) method [ 15] to assist the ideation process for engineering problems. This is about neuro-symbolic models of AI. 2 Methodology Our aim is to investigate the application of Structured Activation V ertex Entropy (SA VE) method in combination with Question Answering Machine (QAM) algorithms to explore information that is stored in big knowledge/information/datasets (in a large number ofdocuments of various formats), accessible within structured or unstructured dataspaces (e.g., open Internet)' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
43	page_content='(e.g., open Internet) and formulate an inventive solution to a problem. The SA VE method is transformed with the assistance of TRIZ into a set of searching meta-terms or meta-concepts. Thus, by applying TRIZ contradiction matrix on the SA VE method in conjunction with QAM, the conﬂict is: how to transform SA VE for an easy operation (parameter 33 in TRIZ) without losing essential information (parameter 24 inTRIZ). This leads to the following set of TRIZ inventive principles (IP): asymmetry (IP 4); preliminary action (IP 10); cheap short-living objects (IP 27); turn harm into a beneﬁt (IP 22). IP 27 inspired us to covert the ten vertexes of SA VE into key words, key actions,and target-related key words. IP 4 inspired us to include as many as possible synonyms to the key words. IP 10 encourages organizing the key words into some semantics. IP 22 was not considered in this research. With these indications, the results are as follows: VERTEX 1: Activation of resonance [capable to resonate, work at the same' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
44	page_content='to resonate, work at the same frequency]. Vertex 1 associated key words : {resonance, resonant, reverberate, reverberation, harmony, harmonize, agreement, agreed, accord, consensus, unity, vibrate, vibrant, resonate, alignment, placement, conﬁguration, positioning, pact, congruence, converge, conver-gence, synchronize, synchronization, pulsate, pulsating}. Vertex 1 related key actions : {capable, able} {work, operate, act, perform} +{resonant, same, similar, harmonic, natural} +{intervention, opinion, frequency, vibration}. VERTEX 2: Introduction of neutral elements [capable to annihilate; activate a new path]. Vertex 2 associated key words : {annihilate, defeat, crush, overwhelm, overpower}; {path, trail, track, way, trajectory, direction, route, road, pathway}. Vertex 2 related key actions : {capable, able} +{annihilate, cancel, overwhelm, overpass, overcome}; {activate, work, create, generate, make} +{(new) +path, trajectory, direction, way, route, pathway}. VERTEX 3: Action against the wolf-pack spirit' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
45	page_content='against the wolf-pack spirit [operate and reach a target with nosupport from other systems; operate and reach a target with a fully volunteer support from other systems]. Vertex 3 associated key words : {operate, reach, target, aim, objective, volunteer, support, system, structure, ﬁeld, domain, no, without, other, external, single, alone, against}. Vertex 3 related key actions : {operate, activate, reach}; {target, goal, aim, desire, dream}; {(no, against, without) +support, assistance, help, guidance}; {alone, single}; {(full, entire, complete, big, large) +(volunteer, open, disinterest) + support, assistance, help, guidance}; {(other, outer, external) +system(s), domain(s), structure(s), ﬁeld(s)}.VERTEX 4: Activation of centrifugal forces [beneﬁt from the dynamics of individual elements]. Vertex 4 associated key words : {beneﬁt, advantage, activation, generation}; 168 S. Brad and E. S ,tetco {speed, rotational, centrifugal, centripetal, dynamics}. Vertex 4 related key actions : {activate, generate,' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
46	page_content=': {activate, generate, create, combine, produce} +{dynamics, element(s), force(s), ﬁeld(s), motivation, (new) +(interest(s), attractor(s), inﬂuence(s))}. VERTEX 5: Application of multi-level connections [act in alignment and synergy with other systems]. Vertex 5 associated key words : {action}; {synergy, alignment}; {multiple, external, other}; {system(s), module(s)}. Vertex 5 related key actions : {act, do, perform, execute, operate, align} +{synergy} +{system(s), unit(s), element(s), person(s), people, object(s), part(s), module(s)}. VERTEX 6: Application of asymmetry [counterbalance a much bigger system]. Vertex 6 associated key words : {asymmetry, counterbalance}; {super-system, system}; {larger, bigger, wider, higher, longer, greater, comprehensive}. Vertex 6 related key actions : {equilibrate, leveraging, counterbalancing} +{activity, system, part, module, unit}. VERTEX 7: Harmonization of individual goals with collective goals [aligned to a higherlevel target]. Vertex 7 associated key words :' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
47	page_content='7 associated key words : {harmonization, alignment}; {performance, goal}; {improvement, radical}. Vertex 7 related key actions : {harmonize, aggregate, align} +{target, performance, goal} +{individual, collective}. VERTEX 8: Transformation for value-added [can provide more outputs than before, using the same inputs]. Vertex 8 associated key words : {value-added, efﬁciency}; {inputoutput, transformation}. Vertex 8 related key actions : {transform, generate, create} + {efﬁciency, value-added}. VERTEX 9: Application of prisoner paradox [use only the existing local resources; rearrangement, and utilization of local resources]. Vertex 9 associated key words : {reconﬁguration, combination, rearrangement, reorganization}; {tool(s), material(s), element(s), resource(s)}; {local, limited}. Vertex 9 related key actions : {reconﬁgure, rearrange, combine, reorganize} +{local, limited, existent} +{resource(s), mean(s), tool(s), element(s), material(s), system(s)}. VERTEX 10: Application of shipwrecked paradox [transform' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
48	page_content='paradox [transform some local negative factors into positive factors, identify hidden resources]. Vertex 10 associated key words : {transformation, identiﬁcation, disclosure, revealing}; {negative, positive}; {local, lim-ited, existent}; {resource(s), factor(s)}. Vertex 10 related key actions : {dig, mining, discover, explore, investigate, search, identify, unhide, disclose, reveal, display, show}; {convert, transform, modify} +{negative, positive} +{factor(s), resource(s)}. In addition, we consider the target-related key words representative for the particular use case. For the use case introduced in the Sect. 4of this paper, the particular target-related key words are: {common, same, aligned} +{goal(s), interest(s)}; {no, low, missing, absent, irrelevant, little} +{obstacle(s), barrier(s), conﬂict(s), stress(es), tension(s), struggle(s), ﬁght(s), impediment(s), problem(s), difﬁculty, complication(s), barricade(s), blockage(s)}. To combine SA VE with QAM, we propose an algorithm that uses the problem, the' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
49	page_content='that uses the problem, the system, and the target result in a series of transformative processes led by the SA VE vertexes and embedded in the QAM model. The algorithm is named D-SIT-SIT-C, meaning: DESCRIBE 1. Describe the problem, including synonyms for the keywords. An Interactive AI System for Inventive Problem-Solving 169 2. Describe the system, including synonyms for the keywords. 3. Describe the target result, including synonyms for the key target words. PROCESS FOR EACH VERTEX STEP 1: SEARCH 1. Search using the mix “system-problem” 2. Search using the mix “problem – target result” STEP 2: INVESTIGA TE (WITH HUMAN-IN-THE-LOOP) 1. Investigate the extracted information – if it does not deliver acceptable solutions move to the next step STEP 3: TRANSFORM 1. Add to the system vertex-associated keywords 2. Add to the problem key actions STEP 4: SEARCH 1. Search using the mix “transformed systemtransformed problem” 2. Search using the mix “transformed problem – target result” STEP 5: INVESTIGA TE (WITH' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
50	page_content='STEP 5: INVESTIGA TE (WITH HUMAN-IN-THE-LOOP) 1. Investigate the extracted information – if it does not deliver acceptable solutions move to the next step STEP 6: TRANSFORM (WITH HUMAN-IN-THE-LOOP) 1. Create an intermediary solution by best possible use of the information collected in the previous steps 2. Make a new description of the TRANSFORMED system (intermediary solution) CONTINUE OR END 1. Take the next vertex and continue the process As one can see, in the proposed algorithm human expert is present in the loop to analyze the results and to introduce additional inputs that would facilitate the progress 170 S. Brad and E. S ,tetco in problem resolution. Human-in-the-loop (HITL) is met in NLP , including QAM algorithms [ 16]. HITL in this paper is inspired from traditional online HITL, but it follows a different path. We do not consider HITL for improving the training dataset. We make corrections to the given answer and introduce the corrected answer in the QAM’s loop without altering the training and' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
51	page_content='altering the training and testing datasets, and the trained model. 3 Results and Discussions For our experiments we decided to use the recent advances in NLP domain with apre-trained long form question answering system [ 17], which engages a question (engineering problem) and transformed with the assistance of SA VE method, fetches couple of relevant passages from the dataspace (e.g., in our case from Wikipedia snapshot), andwrites a generated multi-sentence answer based on the question and retrieved passages. In particular, for our experiments we used the pre-trained ELI5 model from Hugging Face Model Repository [ 18], a model that was trained using the ELI5 dataset described in , and the Wiki Snippets Indexes [ 20] generated using the Wiki-40B: Multilingual Language Model Dataset [ 21] loaded from Hugging Face Datasets [ 22]. To implement the algorithm, we wrote the code in Python, using eli5_utils.py, lfqa_utils.py speciﬁc modules, as well as some general libraries such as faiss_gpu, nlp, transformers,' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
52	page_content='faiss_gpu, nlp, transformers, and torch. The running environment was Jupyter Notebook, and for faster computation we used GPU resources (note: import torch; torch.cuda.is_available()). As example, we selected a situation from the ﬁeld of oil industry. Oil is deposited in huge reservoirs (e.g., 6 m height, 10 m radius or even bigger). Residuals settle overtime to the bottom of these reservoirs and cover the heating pipes. To clean tanks from these residuals, oil must be extracted and deposited into new reservoirs. In this context, we can formulate an engineering challenge as follows: The problem: how to clean the oil tanks from residuals collected on the tank’s ﬂoor without extracting the oil from the tank, and without working manually to complete thiskind of job. The system at start: oil tank, hole on the top of the tank, height of the tank, area of the ﬂoor, area of the hole, hole on the bottom side of the tank.The target result: An automatic installation capable to enter a small hole on the top or bottom' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
53	page_content='hole on the top or bottom of the oil tank and cover a large surface on the ﬂoor of the tank to extract residuals. First, we will use ARIZ [ 23] to ﬁnd a solution to this problem. After that we will apply the proposed AI-driven algorithm to see the results. Discussions around results with the two approaches (a traditional one and one driven by AI for searching within the space of collective intelligence) will be also considered. ARIZ recommends separating the opposite properties over time. The characteristics to be considered are: “12. Shape” (seen as the robot conﬁguration in this case), which conﬂicts with: “8. The volume of the static object”. The following inventive principlesresult: “7. Nest-in-nest: an object is placed inside another object, etc.; through a cavity, an object passes into another object”; “2. Extraction: extracts, removes, or separates a An Interactive AI System for Inventive Problem-Solving 171 part or property from the object that is bothering it”; “35. Transforming object properties:' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
54	page_content='object properties: changing the degree of ﬂexibility”. Results are shown in Fig. 1. Fig. 1. Solution generated with indications from ARIZ application. Now, we consider the D-SIT-SIT-C algorithm for the same problem. Intentionally, we will not consider all resources in system description to see how the D-SIT-SITC algorithm is dealing with. This means, we will intentionally exclude from system description the hole from the bottom side of the tank just to be somehow aligned withthe solution proposed in Fig. 1, with the help of ARIZ method. We expect that the AI model will search in the database for other resources, including those excluded by us. DESCRIBE Describe theproblem , including synonyms for the key words : how to [clean, suction, extraction] the [oil, petroleum, gasoline] [tanks, reservoir] from [residuals, waste] [col-lected, deposited] on the [ﬂoor, bottom] without [extracting, emptying] the oil from the tank, and without working manually. Describe thesystem , including synonyms for the key words :' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
55	page_content='synonyms for the key words : height of the tank, area of the ﬂoor, area of the hole, robot structure, robot joints, robot arm. Describe thetarget result , including synonyms for the target key words : A [robot, technology, mechanism, device] capable to enter a [small, tiny] [hole, hollow, cavity] onthe [top] of an oil tank and cover a large surface on the ﬂoor of the tank. STEP 1: SEARCH 172 S. Brad and E. S ,tetco Search using the mix “system-problem”. Question : the text from “Describe the problem” +the text from “Describe the system”. The Wiki top 10 support documents retrieved by the system are not included here because of space considerations, but we can reveal the areas indicated in these documents: mud agitator, desander solids control, triplex-style plunger pumps & compressed-air-powered double-diaphragm pumps, industrial extraction with centrifugal systems, artiﬁcial lift with rod less pumping & continuous belt transportation, electrostatic coalescer, automated tank cleaning machine from chemical' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
56	page_content='machine from chemical industry, Petrosix oil extraction pro-cess, artiﬁcial lift with hybrid gas and rod pump, artiﬁcial lift with electric submersible pumps (ESP). [eli5 +Wiki] automatic answer 1 : “Y ou don’t need to suction the oil out of the tank, you just need to remove the oil from the tank. Y ou can do this by using a pump to suck up the oil, and then you can pump the oil back into the tank with a pump attachment. The pump attachment is a bit more complicated, but the basic idea is the same.” We want to highlight the clear, human-like answer automatically formulated by the AI-driven model. This is in our opinion a step forward in helping the creative problemsolving of untrained people in structured innovation. Search using the mix “problem – target result”. Question : the text from “Describe the problem” +the text from “Describe the target result”. The Wiki top 10 support documents reveal two new indications: multi-stage gas extractor, and enhanced stripping methods from glycol dehydration. [eli5' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
57	page_content='glycol dehydration. [eli5 +Wiki] automatic answer 2 : “There are a lot of different ways to do it, but the most common is to pump the oil out of the tank or reservoir, and then pump it back into the tank/reservoir. Y ou can also pump it into the reservoir, but that’s more expensive than just pumping it out. There are also ways to remove the oil from the reservoir andpump it out, but those are more expensive.” STEP 2: INVESTIGA TE (WITH HUMAN EXPERTS) Investigate the extracted information – if it does not deliver acceptable solutions move to the next step. In our case we decided to move to the next step just to explore the space of potentiality, even if relevant information has been revealed at STEP 1. STEP 3: TRANSFORM Add to the system SAVE vertex-associated key words (in this step VERTEX 1). Question: [eli5 +Wiki] automatic answer 1 +[resonance, harmony, vibrate, conﬁguration, positioning, converge]. The Wiki top 10 support documents retrieved in addition to the previous information other new directions of' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
58	page_content='other new directions of investigation: ﬂuid coupling with scoop control, multistage centrifugal pumps & centrifugal pumps for solids control & magnetically coupled pumps, hit-and-miss engine, velocity triangle & vertical centrifugal pumps & frothpumps, hot-bulb engine, ﬂuidyne engine. [eli5 +Wiki] automatic answer 3 : The answer retrieved is identical with answer 1. It looks that the system is not capable to provide additional insights. Add key actions in conjunction to problem. Question : the text from “Describe the problem” +[activate, generate, create, combine, produce] +[dynamics, element(s), force(s), ﬁeld(s), (new) +(interest(s), attractor(s), inﬂuence(s))]. An Interactive AI System for Inventive Problem-Solving 173 The Wiki top 10 support documents retrieved by the system indicates other new directions of investigation: Lurgi–Ruhrgas process, RDF-power station, petroleummicrobiology, Carabobo ﬁeld. [eli5 +Wiki] automatic answer 4 : “Y ou don’t need to do any of those things. Y ou just need to be able' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
59	page_content='Y ou just need to be able to get the oil out of the tank or reservoir. It’s not like you have to doanything to get it out, it’s just a matter of getting it out fast enough that it doesn’t build up to the point where it’s a problem.” With the indications from the last answer, we made some transformations to the level of the answer and the problem. This process is required by the SA VE algorithm, in order to move forward with the investigation. Transformed answer : It’s just a matter of getting the residuals fast enough that it doesn’t build up to the point where it’s a problem. Transformed problem : Is there a robot that cleans an oil tank from residuals without extracting the oil? STEP 4: SEARCH Search using the mix “transformed systemtransformed problem”. Question : “Is there a robot that cleans an oil tank from residuals without extracting the oil? It’s just a matter of getting the residuals fast enough that it doesn’t build up to the point where it’s a problem.” The Wiki top 10 support documents retrieved' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
60	page_content='support documents retrieved by the system indicates other new directions of investigation: hydropneumatic suspension, bioclogging, green nanotechnology for cleaning up oil spills, dry milling and fractionation of grain, oily water separator (marine), Alberta Taciuk process. It looks like the deeper we investigate the problem indications move towards chemical processes rather than mechanical systems. This is a paradigm shift from the initial way of setting up the target result. This means, the AI system was not bordered by the limited perception (phycological inertia) of the team. It is also interesting the answer generatedby the system. [eli5 +Wiki] automatic answer 5 : “Yes, there is (about the robot). It’s called a scrubber , and it’s used to remove the residuals from the oil tank. The problem is that scrubbers don’t remove all of the oil. Some of it is still in the tank, and the scrubber can’t get rid of all of it, so it builds up to the point where it’s a problem.” Thus, the system was able to “judge”' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
61	page_content='system was able to “judge” the relevance of having a pure mechanical solution and to “decide” that it is not necessarily the optimal one. Search using the mix “transformed problem – target result”. Question : “It’s just a matter of getting the residuals fast enough that it doesn’t build up to the point where it’sa problem [robot, technology, mechanism, device] capable to enter a [small, tiny] [hole, hollow] on the top of an oil tank and cover a large surface on the ﬂoor of the tank”. The Wiki top 10 support documents retrieved by the system indicates other new directions of investigation: Nokomis 3 process, rebreather with CO 2scrubber, artiﬁcial pressure, annular ﬂuidized bed with ﬁne particulates, Finnish pollution control vessel Louhi. [eli5 +Wiki] automatic answer 6 : “It’s not just a matter of getting the residuals fast enough that it doesn’t build up to the point where it’s a problem. The problem isthat there’s no way to get rid of it fast enough for it to be a problem, so it builds up 174 S. Brad and' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
62	page_content='it builds up 174 S. Brad and E. S ,tetco until it’s too big to be contained.” The answer shows that the system did not advance in “judgment”. This somehow indicates that the searched resources have been covered. STEP 5: INVESTIGA TE (WITH HUMAN-IN-THE-LOOP) Investigate the extracted information – if it does not deliver acceptable solutions move to the next step. In principle, for the problem exempliﬁed here, the system was able to reveal sufﬁcient advices and directions to think to a novel solution. However, we can investigate further, sometimes just for the sick of curiosity and consolidation of thedecision. STEP 6: TRANSFORM (WITH HUMAN-IN-THE-LOOP) Create an intermediary solution by best possible use of the information collected in the previous steps. In this case, the intermediary formulated solution is: “Pump the oil out of the bottom of the tank, ﬁlter it and then pump it back as quickly as possible into the tank from the top of it. The installation that cleans an oil tank from residuals without' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
63	page_content='tank from residuals without extracting the oil is called the scrubber [ 24].” Make a new description of the transformed system (intermediary solution). The new system includes scrubber, pump, handling unit, chemical reactions, ﬁlters, units that generate ﬁelds or forces. CONTINUE OR END Take the next SA VE vertex and continue the process. In the second cycle we have considered VERTEX 2. The detailed steps are not further described in the paper. In continuation we limit ourselves to present only the last relevant answer generated by the system. [eli5 +Wiki] automatic answer 7 : “Pumping the oil out of the bottom of the tank, ﬁltering it, and then pumping it back as quickly as possible into the tank from the top of it. The robot that cleans an oil tank is called the Crude Oil Washing (COW). The COW washing system, or COW system, is part of the cleaning process.” Now it’s the time to use the list of information and indication to ideate the solution to the problem. Actually, the last answer is a solution to the' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
64	page_content='answer is a solution to the problem, automatically indicated by the system. We have also considered additional indications from the listretrieved by the system. It cannot be disclosed here because of an ongoing research project with inventive mission. Comparing the solution generated with the help of ARIZ method and the one proposed by the system we can conclude that the ﬁrst one is novel in the series of solutions destinated to petroleum tank cleaning, whereas the second is extracted from the pool of knowledge already created by humans. However, the ﬁrst solution was generated witha huge creative contribution of human experts, and it is a pure mechanical one. In the case of the AI-driven approach we did not want to develop a new tool for ideation, but rather a tool that helps engineers in the application of ARIZ or similar algorithms forinventive problem. It is a more powerful form of CBR because it moves beyond just displaying existent solutions, meaning it suggests vectors of investigation, as actually' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
65	page_content='of investigation, as actually the TRIZ does, but with much more practical indications. These vectors of investigation are extracted from the documents retrieved in various steps of the proposed algorithm, as one already saw in the previous paragraphs of this section. They can be combinedusing morphological charts to help engineers thinking to various options for ideation. An Interactive AI System for Inventive Problem-Solving 175 4 Conclusions This research introduces a possibility to transform a human-like nonlinear pattern of deep thinking into a format that is suitable for implementation into AI NLP-driven algorithms that search throughout big information/data/knowledge sets and automaticallygenerate “intelligent” machine answers to a given problem. SA VE method is embedded in the algorithm to increase the search effectiveness and provoke the system in answer formulation. But there are no limitations to replace SA VE vertexes with TRIZ inventiveprinciples or to add them to the vertexes list. The single' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
66	page_content='the vertexes list. The single issue is the productivity of doing the job. The use case illustrated in the paper reveals a sign of encouragement, indicating that AI models of QAM can be a reliable assistant for experts in solving complex technical problems in shorter periods of time and at higher levels of performance. In fact, this research brings a new tool to the world of ARIZ, where the use of knowledge bases is required for documentation. Traditional software systems were limited in providing a massive pool of resources. Modern tools such as those cited in [ 7] and [ 8] better fulﬁll this job. In the case of our model, we claim that it brings something more, by also indicating basic solutions or clues towards the solution in a very natural language. Our research also indicates that there are still huge steps until the automatic systems will be able to replacehuman mind and become sufﬁcient creative. We see the current systems rather being more explorative and highly productive in doing this job than' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
67	page_content='in doing this job than people, and less creative in the sense of proposing out-of-the-box ideas. But they can help in indicating disruptivevectors of investigation, which is a relevant ﬁnding of this research. This means, we should not be limited in the short list of 40 generic inventive principles proposed by traditional TRIZ, and expand its pool of suggestions, moving towards the modern TRIZ. It is important to highlight the fact that the capacity of the AI system is limited by the pool of training data, and from this angle one area to support inventive problem solving is to work on a dataspace of information that collects as many as possible informationcreated by humankind (e.g., patents, open Internet, scientiﬁc papers, images, videos). Thus, new spaces for AI are open in this regard. Further effort is needed to expand these experiments on various knowledge bases and online resources, including scientiﬁc web databases or the unstructured open Internet, with making sure that not only the English language' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
68	page_content='not only the English language content is targeted but also other languages, as well. For this we would needto train our own dense models from within the knowledge base and also sequence-tosequence models which are built upon a BART architecture [ 25] domain and language speciﬁc. Our future researches in the direction opened by this paper are also to trainnew models capable to deal with managerial problems, as well as to reﬁne the algorithm in terms of formulating questions, etc. We also see a space of opportunity in testing some other tools of creativity in conjunction to QAM. Of course, the challenge to createa smarter system, capable to play with creative patterns is also in view for our future researches. References 1. Friedl, J.: Mastering Regular Expressions, 3rd edn. O’Reilly, Sebastopol (2006) 176 S. Brad and E. S ,tetco 2. Lane, H., Hapke, H., Howard, C.: Natural Language Processing in Action. Manning, New Y ork (2019) 3. Dwyer, D.: Top 12 Best Search Engines in the World (2016).' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
69	page_content='Engines in the World (2016).  2016/11/11/top-12-best-search-engines-in-the-world238 . Accessed 20 June 2022 4. Gadd, K.: TRIZ for Engineers. Wiley, Chichester (2011) 5. Schmidt, R., Montani, S., Bellazzi, R., Portinale, L., Gierl, L.: Cased-based reasoning for medical knowledge-based systems. Int. J. Med. Inform. 64, 355–367 (2001) 6. Lee, C.H., Chen, C.H., Li, F., Shie, A.J.: Customized and knowledge-centric service design model integrating case-based reasoning and TRIZ. Expert Syst. Appl. 143, 13062, 14 pp. (2020) 7. Dewulf, S., Childs, P .R.N.: Patent data driven innovation logic: textual pattern exploration to identify innovation logic data. In: Borgianni, Y ., Brad, S., Cavallucci, D., Livotov, P . (eds.) TFC 2021. IAICT, vol. 635, pp. 170–181. Springer, Cham (2021).  978-3-030-86614-3_14 8. Ip.com: Why Non-Patent Literature Can Make or Break Y our Business.  . Accessed 02 June 2022 9. Souilia, A., Cavallucci, D., Rousselot, F.: Natural Language Processing (NLP) a solution for knowledge extraction from' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
70	page_content='for knowledge extraction from patent unstructured data. Proc. Eng. 131, 635–643 (2015) 10. Kaliteevskii, V ., Deder, A., Peric, N., Chechurin, L.: Concept extraction based on semantic models using big amount of patents and scientiﬁc publications data. In: Borgianni, Y ., Brad,S., Cavallucci, D., Livotov, P . (eds.) TFC 2021. IAICT, vol. 635, pp. 141–149. Springer, Cham (2021).  11. Guarino, G., Samet, A., Cavallucci, D.: Patent specialization for deep learning information retrieval algorithms. In: Borgianni, Y ., Brad, S., Cavallucci, D., Livotov, P . (eds.) TFC 2021. IAICT, vol. 635, pp. 162–169. Springer, Cham (2021).  12. Boufeloussen, O., Cavallucci, D.: Bringing together engineering problems and basic science knowledge, one step closer to systematic invention. In: Borgianni, Y ., Brad, S., Cavallucci, D., Livotov, P . (eds.) TFC 2021. IAICT, vol. 635, pp. 340–351. Springer, Cham (2021). https:// doi.org/10.1007/978-3-030-86614-3_27 13. Haniﬁ, M., Chibane, H., Houssin, R., Cavallucci, D.: Problem' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
71	page_content='R., Cavallucci, D.: Problem formulation in inventive design using Doc2vec and cosine similarity as artiﬁcial intelligence methods and scientiﬁc papers.Eng. Appl. Artif. Intell. 109, 104661 (2022) 14. Hugging Face: What is Question Answering?.  wering . Accessed 04 June 2022 15. Brad, S.: Domain analysis with TRIZ to deﬁne an effective “Design for Excellence” framework. In: Borgianni, Y ., Brad, S., Cavallucci, D., Livotov, P . (eds.) TFC 2021. IAICT, vol. 635, pp. 426–444. Springer, Cham (2021).  16. Wang, Z.J., Choi, D., Xu, S., Yang, D.: Putting humans in the natural language processing loop: a survey.  (2021). Accessed 04 May 2022 17. Roy, A.: Progress and Challenges in Long-Form Open-Domain Question Answering. https:// ai.googleblog.com/2021/03/progress-and-challenges-in-long-form.html . Accessed 03 Apr 2022 18. Jernite, Y .: ELI5 Model from Hugging Face Model Repository.  rnite . Accessed 02 Feb 2022 19. Fan, A., Jernite, Y ., Perez, E., Grangier, D., Weston, J., Auli, M.: ELI5: Long Form Question' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
72	page_content='M.: ELI5: Long Form Question Answering.  (2019). Accessed 20 Jan 2022 20. Wikipedia: User scripts/Snippets.  ppets . Accessed 05 Apr 2022 An Interactive AI System for Inventive Problem-Solving 177 21. Guo, M., Dai, Z., Vrandeˇ ci´c, D., Al-Rfou, R.: Wiki-40B: multilingual language model dataset. In: Proceedings of the 12th Language Resources and Evaluation Conference, pp. 2440–2452. European Language Resources Association, Marseille, France (2020) 22. Hugging Face Data Sets.  . Accessed 05 Apr 2022 23. Cameron, G.: ARIZ Explored: A Step-by-Step Guide to ARIZ, the Algorithm for Solving Inventive Problems. Create Space, Scotts V alley (2015) 24. Wikipedia. Scrubber:  . Accessed 02 June 2022 25. Lewis, M., et al.: BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension.  (2019). Accessed 04 May 2022' metadata={'title': 'An Interactive Artificial Intelligence System for Inventive Problem-Solving', 'author': 'Stelian Brad', 'publish_date': '2022-09-19', 'subject': 'Systematic Innovation Partnerships with Artificial Intelligence and Information Technology', 'doi': 'doi:10.1007/978-3-031-17288-5_15', 'keywords': 'Artificial Intelligence (AI); Natural Language Processing (NLP); Question Answering Machine (QAM); Deep Learning (DL); Theory of Inventive Problem Solving (TRIZ); Structured Activation of Vertex Entropy (SAVE); Retrieval Augmented Generation (RAG); Humans in the Loop (HL); Interactive AI systems'}
73	page_content='To Answer or Not to Answer? Filtering Questions for QA Systems Paulo Pirozelli1,4(B), Anarosa A. F. Brand˜ ao2,4, Sarajane M. Peres3,4, and Fabio G. Cozman2,4 1Instituto de Estudos Avan¸ cados, S˜ ao Paulo, Brazil paulo.pirozelli.silva@usp.br 2Escola Polit´ ecnica, S˜ ao Paulo, Brazil {anarosa.brandao,sarajane,fgcozman }@usp.br 3Escola de Artes, Ciˆ encias e Humanidades, S˜ ao Paulo, Brazil 4Center for Artiﬁcial Intelligence (C4AI), S˜ ao Paulo, Brazil Abstract. Question answering (QA) systems are usually structured as strict conditional generators, which return an answer for every inputquestion. Sometimes, however, the policy of always responding to questions may prove itself harmful, given the possibility of giving inaccurate answers, particularly for ambiguous or sensitive questions; instead, it maybe better for a QA system to decide which questions should be answered or not. In this paper, we explore dual system architectures that ﬁlter unanswerable or meaningless questions, thus answering only a subset' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
74	page_content='thus answering only a subset ofthe questions raised. Two experiments are performed in order to evaluate this modular approach: a classiﬁcation on SQuAD 2.0 for unanswerable questions, and a regression on Pir´ a for question meaningfulness. Despite the diﬃculties involved in the tasks, we show that ﬁltering questions may contribute to improve the quality of the answers generated by QA systems. By using classiﬁcation and regression models to ﬁlter questions,we can get better control over the accuracy of the answers produced by the answerer systems. Keywords: Question answering ·Answer triggering ·Dual system · Question ﬁltering 1 Introduction A question answering (QA) system may be thought as conditional generator that predicts an answer given a question, often with the support of some context. In other words, for every input question, the system returns an answer. In practice,however, no QA system is able to answer any possible question, even over a This work was carried out at the Center for Artiﬁcial' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
75	page_content='at the Center for Artiﬁcial Intelligence (C4AI-USP), with support by the S˜ ao Paulo Research Foundation (FAPESP grant #2019/ 07665-4) and by the IBM Corporation. Fabio G. Cozman thanks the support of the National Council for Scientiﬁc and Technological Development of Brazil (CNPq grant #312180/2018-7). c/circlecopyrtThe Author(s), under exclusive license to Springer Nature Switzerland AG 2022 J. C. Xavier-Junior and R. A. Rios (Eds.): BRACIS 2022, LNAI 13654, pp. 464–478, 2022. _33 To Answer or Not to Answer? Filtering Questions for QA Systems 465 restricted domain, except when questions are restricted to a strict format. The reasons for this limitation are varied: from the lack of necessary information, tomalformed questions, ambiguity, and tacit assumptions. The policy of always answering questions may be a detrimental one in some contexts. This is particularly true for high-risk AI systems, where there are“signiﬁcant risks to the health and safety or fundamental rights of persons” [ 6]. In such domains,' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
76	page_content='[ 6]. In such domains, it is often better for a QA system to conﬁne itself to questions it is strongly certain of and avoid answering sensitive or dubious requests. Decidingwhich questions should move through the QA system is important to guarantee safety and factual grounding [ 23]. If it is the case that some questions should not be answered at all, then a QA system has to understand which questions should receive an answer and which should not. Two main approaches can be taken for that purpose. First, a QA system may be trained directly on datasets containing answerable and unanswerable questions, simultaneously learning when and what to respond. Second, a QA system may have a dual composition, in which a ﬁrst componentﬁlters inadequate questions and the other module answers the selected questions. In this paper, we investigate QA systems of the latter type; in particular, we analyze the connection, in those dual systems, of question ﬁltering and QAquality. Our aim is to understand: i) how accurate can a' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
77	page_content='i) how accurate can a classiﬁer/regressor be on question answerability and meaningfulness; and ii) how do ﬁltering systems aﬀect the quality of the answering system. Although end-to-end systems have producedstate-of-the-art results for answer triggering datasets [ 5,11,15], by identifying answerable questions as part of the training process, and have been under recent scrutiny as regards their self-evaluation awareness [ 9], our goal here is to quantify the relation between the level of answerability and meaningfulness of a question and the quality of the generated responses. By using a dual system architecture, in which a model previously identiﬁes inappropriate questions, it is possible tomodularize a critical step of a QA system, assuring a better control of what is being answered. This paper is organized as follows. Section 2provides an overview of the technical literature and describes the data used in our experiments. Two main tasks are conducted by us: ﬁrst, we consider a traditional (discrete) answer' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
78	page_content='traditional (discrete) answer triggeringapproach, in which the problem is to ﬁgure out which questions have an answer (Sect. 3); then, we explore a regression system in which we measure a question’s degree of meaningfulness (Sect. 4). In both cases, we explore the eﬀectiveness of ﬁltering systems and how they aﬀect the outcome of answerer models. In Sect. 5 we discuss the results of our investigation as well as limitations of the current approaches and future directions for research. Finally, we conclude with a fewremarks on dual QA systems (Sect. 6). 1 1In order to assure reproducibility, codes, dataset partitions, and trained models are made available at the project’s GitHub repository:  tree/main/Triggering . 466 P. Pirozelli et al. 2 Background Answer triggering is the task of deciding whether a question should be answered or not. By allowing some questions not to have an answer, models are required tolearn when they should answer a given question. In Sect. 2.1, we brieﬂy present the main architectures' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
79	page_content='the main architectures for QA systems, such as rule-based, end-to-end, and modular approaches. Section 2.2reviews the datasets available for answering triggering and related tasks. Section 2.3describes the two datasets used in our experiments, SQuAD 2.0 and Pir´ a. 2.1 Question Answering Systems QA systems can have many diﬀerent architectures. Before the popularization of deep learning, dialogue systems usually employed a mixture of rule-based approaches and feature-based classiﬁers, often intertwined in complex architec-tures, as in the Watson DeepQA system [ 7]. More recently, neural approaches came to dominate the ﬁeld, at least for research purposes. Popular among these are end-to-end systems, such as T5, and decoder (e.g., BERT [ 5]) and encoder-based models (e.g., GPT [ 3,16]), adapted for question answering tasks. There are also QA systems that combine diﬀerent specialized mechanisms within the same training process. It is the case,for example, of RAG (Retrieval-Augmented Generation) [ 13], which uses' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
80	page_content='Generation) [ 13], which uses a neural retriever, DPR [ 10], and a language generator, BART [ 12]. Finally, modular systems combine independent models that execute speciﬁc functions in the QA pipeline, without end-to-end training. DrQA [ 4], for instance, has a document retriever, based on bigram hashing and TF-IDF matching, anda document reader, which uses an achitecture of bidirectional LSTMs. In this paper, we study a modular architecture for QA systems with two components, which we refer to as dual system. It consists of a ﬁltering modelthat assess which questions should be answered and an answerer model that responds only to the selected questions. 2.2 Answer Triggering Answer triggering was ﬁrst deﬁned by Yang et al. [ 26], together with a purposefully-developed dataset, WikiQA. Questions in WikiQA were based on Bing query logs, and the summary of the associated Wikipedia pages were usedto determine if questions had an answer or not. SeqAL [ 8] was also based on Wikipedia, but using a larger number of' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
81	page_content='but using a larger number of questions from more domains and using the full entry pages. Answer triggering datasets grew out in popularitywith SQuAD 2.0 [ 18], which added a large number of unanswerable questions to the original reading compreenhsion SQuAD dataset [ 19]. More importantly, unanswerable questions in SQuAD 2.0 were deliberately produced to have puta-tive candidate answers. Although not a strict answer triggering dataset, Pir´ a brings a number of human assessment on question meaningfulness that has a similar shape. To Answer or Not to Answer? Filtering Questions for QA Systems 467 It is not always clear whether a question can be answered or not. Questions can be ambiguous or poorly structured, and whether or not a question has ananswer may lay on a gray area, depending on contextual information that is not readily available. Some reading comprehension datasets try to overcome this diﬃculty by including a third outcome signaling uncertainty. ReCO [ 24]i sa dataset of opinion-based queries in' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
82	page_content='of opinion-based queries in Chinese which uses three candidate answers for annotation: a positive one like Yes, a negative one like No, and an undeﬁned one in case the question cannot be answered with the given documents. QuAIL is a multi-choice dataset developed to include three degrees of certainty: answerable questions (given a context), unanswerable questions (even with context and world knowledge), and partially certain questions (when a good guesscan be made). 2.3 Datasets Two datasets are used in our experiments, SQuAD 2.0 and Pir´ a. Table 1depicts their main statistics. 2 Table 1. Number of QA sets for diﬀerent splits of SQuAD 2.0 and Pir´ a. Model # QA instance (%) Train Validation Test Total SQuAD 2.0 130319 (91.65%) 5936 (4.17%) 5937 (4.17%) 142192 (100%) Pir´a 1755 (80.28%) 215 (9.83%) 216 (9.88%) 2186 (100%) SQuAD 2.0. SQuAD 2.0 is an extractive reading comprehension dataset. It combines the original SQuAD dataset [ 19], a reading comprehension resource with 100K+ questions, with approximately' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
83	page_content='questions, with approximately 53K unanswerable questions (markedas empty strings). To produce the unanswerable questions, annotators were asked to create questions over paragraphs that could not be correctly answered from these texts only. To avoid that questions unrelated to the context were created, annotators were instructed to produce questions that were relevant to the context and which contained plausible answers in the paragraph (such as the name ofa person for a Who-type question). These plausible answers serve as eﬀective distractors to questions, making it harder to realize what questions are in fact unanswerable. In total, SQuAD 2.0 contains around 151K questions, of whichapproximately 35.5% do not have answers. Another aspect of the dataset is that answerable questions present multiple answers, made by diﬀerent annotators; for our experiments, we use only the ﬁrst answer for each question as the ground 2In Pir´a, only QA sets with meaningful evaluations were used. For the original dataset, the' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
84	page_content='For the original dataset, the numbers would be: train: 1896 (79.98%), validation: 225 (9.96%), test: 227 (10%), total: 2258 (100%). 468 P. Pirozelli et al. truth answer. The test set for this dataset is not publicly available; we thus break the original validation set into two equally-sized partitions to get our validationand test sets (which explains the smaller number of QA sets described in Table 1 as compared to the total number of QA sets of SQuAD 2.0). Pir´a.Pir´a is a bilingual question answering dataset on the ocean, the Brazilian coast, and climate change. QA sets in Pir´ a are based on two corpora of supporting texts: one composed of scientiﬁc abstracts on the Brazilian Coast,and the other of small excerpts of two United Nations reports on the ocean. The dataset generation process comprised an assessment phase in which QA sets were manually evaluated in a number of aspects. Among these evaluations,participants were asked as to whether the QA sets were meaningful, based on a Likert scale (1 Strongly' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
85	page_content='on a Likert scale (1 Strongly disagree, 2 Disagree, 3 Neither agree nor disagree, 4 Agree, 5 Strongly agree). Figure 1displays the distribution of QA instances in the test set by level of question meaningfulness. We also use the human validation answers produced in the assessments phase for our second experiment.Pir´a contains 2248 QA sets in total. To conduct the experiments described in this paper, the dataset was splitted into three random partitions: training (80%), validation (10%), and test (10%) sets. Fig. 1. Number of QA sets in the test set of Pir´ a by question meaningfulness level. As regards the experiments conducted in this paper, SQuAD 2.0 and Pir´ a diﬀer in important aspects. First, SQuAD 2.0 is an answering triggering dataset, meaning that some questions in it may have an answer while others may not, whereas in Pir´ a all questions are associated with answers. In addition, the former uses a qualitative ordinal (binary) variable, while the latter uses a numerical discrete variable (1–5).' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
86	page_content='discrete variable (1–5). Finally, SQuAD 2.0 is concerned with answerability whereasPir´a is concerned with question meaningfulness. Those diﬀerences will be relevant to the experiments described above. To Answer or Not to Answer? Filtering Questions for QA Systems 469 3 Answer Triggering As a ﬁrst contribution, we are interested in testing the usefulness of ﬁltering questions based on answerability. As our answerer system, we use a DistilBERT-base model [ 22], ﬁne-tuned on SQuAD 1.1 (a dataset where all questions have answers); context and question are concatenated and used as input. Three diﬀerent scenarios are compared to measure the eﬀects of question ﬁltering on answerquality: – questions from SQuAD 2.0 are passed indistinctly to the DistilBERT answerer system; – questions are ﬁrst grouped by answerability labels based on ground truth classiﬁcations and then passed to the answerer system; and – questions are ﬁrst grouped by answerability labels based on a classiﬁcation model and then passed to the' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
87	page_content='model and then passed to the answerer system. These three possibilities are illustrated in Fig. 2. When generated answers are compared to the actual, manually-created ones, the QA system achieves a F1-score of 38.70 in the full test set (Fig. 2a). 3Table 2 brings the results for this and the following tests. Furthermore, when onlyanswerable questions are selected (based on real labels), there is a considerable increase in the quality of answers, with the F1-score going up to 78.25, a gain of 102.19% (Fig. 2b). This diﬀerence is due to the attempt, in the ﬁrst case, to answer questions that have no answer whatsoever; when restricted solely to questions that do have answers, the average quality of answers improves. Table 2. F1-score for a DistilBERT answerer model ﬁne-tuned on SQuAD 1.1, when applied to the test set of SQuAD 2.0; the F1-score (0–100) is obtained by comparing the predicted answers to the (ﬁrst) ground truth answers. Real labels are obtained from theannotated SQuAD 2.0 dataset (where' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
88	page_content='SQuAD 2.0 dataset (where unanswerable questions are presented as empty strings); predicted labels are obtained from three classiﬁcation models: DistilBERT, RoBERTa, and ALBERT, all ﬁne-tuned on SQuAD 2.0. Results for real and predictedlabels are divided by answerable (Answ.) and unanswerable (Unansw.) questions. The F1-score of an empty answer (i.e., an unanswerable question) is by deﬁnition 0. In bold, the best result for answerable questions based on the predicted labels. Model Total Real label Predicted label Answ. Unansw. Answ. Unansw. DistilBERT 38.70 78.25 0 39.42 18.53 RoBERTa 46.08 33.13 ALBERT 63.54 6.81 Hence, a ﬁltering procedure that was able to ﬁlter answerable questions could in theory improve the quality of the answers generated by the answerer module. 3F1-score is implemented with the oﬃcial SQuAD script. Available at: https:// rajpurkar.github.io/SQuAD-explorer/ . 470 P. Pirozelli et al. Fig. 2. Diﬀerent tests performed for assessing the relation between answerability and answer quality.' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
89	page_content='and answer quality. From top to bottom: (a) questions are passed indistinctly to theanswerer model; (b) questions are ﬁrst grouped by answerability labels based on ground truth labels before going through the answerer model; and (c) questions are ﬁrst grouped by answerability labels obtained from a classiﬁer before going through theanswerer model. The answers generated with the answerer system are then compared to the actual answers from SQuAD 2.0 using F1-score as an agreement metric. In order to test this hypothesis, we perform a classiﬁcation task on SQuAD 2.0’s test set for question answerability. Three transformer models are used for thetask: DistilBERT [ 22], RoBERTa [ 15], and ALBERT [ 11]; all of them ﬁne-tuned on SQuAD 2.0 (since we want a model that already knows some information regarding answerability). A concatenation of context and question is used asinput. All models are trained for 8 epochs in the train set, and the best log is chosen based on the validation set. Accuracy and F1-score for the' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
90	page_content='Accuracy and F1-score for the three classiﬁers, as well as the number of predicted labels, are shown in Table 3. After training the classiﬁers, we predict answerability labels for the questions in the test set of SQuAD 2.0 based on each of the models. Next, we calculate the F1-score for answerable or unanswerable separately, according to the predicted labels (Fig. 2c). As can be seen from Table 2, there is a considerable diﬀerence To Answer or Not to Answer? Filtering Questions for QA Systems 471 Table 3. Left : Distribution of predicted labels for DistilBERT, RoBERTa, ALBERT, and ground truth in the test set (Answ. = Answerable, Unansw. = Unanswerable).Right : Accuracy and F1-score for DistilBERT, RoBERTa, ALBERT in the answer triggering task. Best result in bold. Model # Predicted labels Results Answ. Unansw. Accuracy F1-score DistilBERT 5731 (96.53%) 206 (3.47%) 51.03 37.90 RoBERTa 2553 (43.00%) 3384 (57.00%) 57.84 57.59 ALBERT 3337 (56.21%) 2600 (43.79%) 84.08 84.03 Test set 3001 (50.55%) 2936 (49.45%)' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
91	page_content='3001 (50.55%) 2936 (49.45%) in the quality of answers when answerability is taken into account.4When only questions that are predicted to have an answer are considered, the F1-score goes up to 39.42 (+1.87%) with DistilBERT, to 46.08 (19.07+%) with RoBERTa, and to 63.54 with ALBERT (64.19+%); as regards to questions predicted ashaving no answer, F1-score goes down to 18.53 ( −52.12%), 33.13 ( −14.39%), and 6.18 ( −82.38%), respectively. The unintuitive fact that RoBERTa achieves better results than DistilBERT in both answerable and unanswerable questions is explained by a base rate problem: the DistilBERT model classiﬁes the majority of questions as answerable (96.53%), whereas the other two models classify only43.00% and 56.21% of the questions as answerable, respectively; a statistics closer to actual percentage of answerable questions in the test set (50.55%). 4 Continuous Answering Triggering Traditionally, answering triggering is understood as in our previous experiment: a binary classiﬁcation task on' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
92	page_content='binary classiﬁcation task on whether a question can be answered or not. Inreality, though, the answerability of a question is often a complex aﬀair. Although many questions can be undoubtedly categorized as having an answer or not, others lay on the middle part of the spectrum. Therefore, as a second contribution, we explore whether more ﬁne-grained information on questions can help to achieve better QA systems. For this task, we work with the English part of Pir´ a, a reading comprehension dataset on the ocean and the Brazilian coast (cf. Sect. 2.3). Contrary to answer triggering datasets tout court (cf. Sect. 2.2), Pir´a does not possess explicit features indicating unswerability or certainty degrees. Instead, we use its manual evaluationson question meaningfulness as proxies for answerability: questions with a low value for meaningfulness are treated as having a lower degree of answerability. 4Both the classiﬁers described in this section and the regressors trained in the next use random initializations' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
93	page_content='use random initializations that may resul in slightly diﬀerent predictions. To ensure the consistency of results, we repeated the same experiment 10 times each. The results described here are, therefore, representative of the trained models. 472 P. Pirozelli et al. The Likert scale (1–5) scores used in the assessments provide a detailed level of analysis of answerability, more so than a binary or three-point alternative; evenbetter, it permits us to treat question meaningfulness as an ordinal variable. Based on that, we reframe our answer triggering problem as a regression task, in which we aim to predict the degree of meaningfulness of a question in a 1 to5 scale. To see whether our meaningfulness regressor is indeed useful, we pair it again with a QA system. In theory, a QA system that only answers high-quality ques-tions should give superior answers overall. Thus, we conduct a number of experiments to measure the quality of the QA system when questions are ﬁltered by their degree of meaningfulness. First,' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
94	page_content='of meaningfulness. First, we ﬁne-tune a DistilBERT, ALBERT,and RoBERTa models on Pir´ a, using a concatenation of question and context as input. Models were trained for a total of 8 epochs in the training set, and evaluations were performed on the validation test. Similarly to the previous experiment, the ALBERT-based approach achieved the smallest loss and Root Mean Square Error in the validation set; for this reason, it was chosen as ourregressor system. For the QA systems, we use two DistilBERT models ﬁne-tuned for question answering on SQuAD 1.1 and SQuAD 2.0, respectively. After training the regressor models, we predict the degree of meaningfulness for the questions in the test set. Questions are then grouped in 10 progressively smaller partitions, based on the predictions made with the regressor. For our ﬁrst test, we measure the quality of the answers given by the QA system forthese diﬀerent partitions. As smaller partitions select questions evaluated better according to our regressor, we expect that' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
95	page_content='our regressor, we expect that the answers generated for them to be comparatively better. To measure the quality of answers, we rely again onF1-score; the original answer in Pir´ a serves as the ground truth. Figure 3(a) shows the results for both QA models. The two graphs exhibit a similar trend. In both cases, F1-score goes up when smaller partitions of thetest set feed the QA system. In this as in other tests, results for both QA models are similar—something expected, given that the F1-score between the answers generated with these two models is 70.03. Furthermore, as in the other tests discussed above, the F1-score for SQuAD 1.1 is usually higher than for SQuAD 2.0. Finally, the high spike in the last partitions may not be as signiﬁcant as itappears; rather, it is likely due to randomness, given its small size, with only 21 observations. F1-score is a metric based on the presence of the same tokens in the ground and predicted answers. It is well known, however, that automatic metrics may not correlate' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
96	page_content='metrics may not correlate well with human evaluations [ 14]. There is also a more straightforward shortcoming of F1-score: this metric is not able to identify subtler similarity phe-nomena between answers, involving paraphrasing. For this reason, we decided to check the similarity between predicted and ground truth answers based on vector representations. Embeddings for both the original and the generated answerwere produced with Sentence-BERT [ 20], and cosine dissimilarity (1 cosine distance) served as a measure of semantic similarity (rather than word similarity, as in the case of F1-score). To Answer or Not to Answer? Filtering Questions for QA Systems 473 Fig. 3. Left: F1-score for diﬀerent partitions of the test set (based on the predicted values of a RoBERTa regressor), comparing the ground truth answers in Pir´ aw i t h answers generated by two DiltilBERT models ﬁne-tuned on SQuAD 1.1 and SQuAD 2.0, respectively. Right: osine dissimilarity for diﬀerent partitions of the test set (based on the' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
97	page_content='of the test set (based on the predicted values of a RoBERTa regressor), comparing the ground truth answersin Pir´ a with answers generated by two DiltilBERT models ﬁne-tuned on SQuAD 1.1 and SQuAD 2.0, respectively. Figure 3(b) shows the results for both QA models. Answer dissimilarity, as measured by the cosine distance of sentence embeddings, tends to fall for smallerpartitions; in other words, answers get better when more meaningful questions are selected, similarly to what was observed for F1-score. As was the case for F1-score, SQuAD 1.1 performs better than SQuAD 2.0. The results obtained here are considerably worse than the results of the original SQuAD 1.1 and SQuAD 2.0 datasets. As reported in the original papers, a F1-score of 51 can be achieved with a strong logistic regression model forSQuAD 1.1 [ 19], and neural models can achieve a F1-score of 86 on SQuAD 1.1 and 66 on SQuAD 2.0 [ 18]. What explains the worse results for Pir´ a 2.0? Part of the gap may be explained by the non-extractive nature' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
98	page_content='by the non-extractive nature of its answers and thetechnical nature of the supporting texts. Another hypothesis is that our regressor is unable to detect levels of answerability. In order to test this possibility, we used the ground truth evaluations of question meaningfulness from Pir´ a to partition the dataset, instead of the predictions based on the regressor. Although this information is never present in real applications, this analysis may point to shortcomings derived from our prediction process. Figure 4(a) shows the results in F1-score for both QA models, for each level of meaningfulness. It seems counter-intuitive that lower quality questions (according to the annotators’ evaluations) achieve higher F1-scores. One reason for that may be a problem with human evaluations, perhaps due to a ﬂawed instruction process. Nonetheless, we must also consider the small number of examples of low mean-ingful questions (cf. Fig. 1). One of the reasons our regressor may perform badly is because our regression' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
99	page_content='is because our regression model did not have access to many questions with a low degree of meaningfulness. For the larger group of questions evaluated from3 to 5, F1-score seems to work more or less as expected. 474 P. Pirozelli et al. Fig. 4. Left: Average F1-score for each level of question meaningfulness (based on ground truth evaluations), comparing the original answers from Pir´ a and answers generated by two DistilBERT answerer models ﬁne-tuned on SQuAD 1.1 and SQuAD 2.0,respectively. Right: Average F1-score for each level of question meaningfulness (based on ground truth evaluations), comparing the original and validation answers from Pir´ a. As a ﬁnal test, we evaluated whether part of the explanation for the low F1-score we got was not also caused by limitations in answerer models. In order to assess that, we tested the agreement, measured by F1-score, between answersgiven in the QA creation phase and those given in the evaluation phase. Again, we used real assessments of question meaningfulness as' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
100	page_content='of question meaningfulness as the criterion for partitioning the test set. Figure 4(b) presents the results for this test. A few facts can be observed. First, F1-score is considerably higher here than in previous tests, in which the generated answers were taken into account. Second, except for a slight oscillation for intermediary values, the F1-score demonstrates a consistentbehavior, achieving larger values as the level of meaningfulness grows. 5 Discussion The two experiments run in this work have shown that ﬁltering out inadequate questions leads to better QA systems. Developing models that decide which questions to answer can help to achieve greater control over the quality of theanswers. Results, however, were less than ideal, as the two trained models—the classiﬁer and the regressor—were only relatively successful in selecting which questions should be passed to the answerer system. Therefore, if a dual systemis to be implemented, better ﬁltering models are highly needed. For our ﬁrst experiment on' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
101	page_content='For our ﬁrst experiment on classiﬁcation, the diﬃculty seems to derive from the nature of SQuAD 2.0, which has purposely-generated plausible unansweredquestions. Unswerability appears to involve subtle elements that are not always captured by language models restricted to word correlations. More generally, common causes that aﬀect the performance of answer triggering systems are To Answer or Not to Answer? Filtering Questions for QA Systems 475 related to syntactic bias (paying more attention to the structure of an answer than to its content); the presence of irrelevant information within the targetanswer; and lexical ambiguities [ 1]. As for the second experiment with Pir´ a, the limitations seem to be caused by a non-systematic annotation process. That feeling is strengthened by qualitativeanalysis of the dataset. In particular, when evaluating a question’s meaningfulness, a number of aspects were often conﬂated by annotators: grammaticality, answerability, and context. Our ﬁltering system has been focused' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
102	page_content='system has been focused on ﬁnding low-quality questions, understood as those questions that cannot be correctly answered or that are illformulated. This ﬁltering process, however, could be extended to a number ofother situations. In particular, developing question ﬁltering models is a real necessity for high-risk AI systems, since sensitive contexts demand that QA models avoid answering some questions. More importantly, these systems require a strict control over answer certainty. A separate module for ﬁltering questions may, thus, provide a modular and inspectable tool. Finally, as the small number of datasets available show, more answer triggering resources are needed. Particularly valuable would be datasets containing ﬁne-grained annotations beyond simple answerability (binary) labels, such asannotations focused on the sources of low-quality in questions—e.g., grammar issues, lack of contextual information, ambiguity. Furthermore, it is important to develop ﬁltering systems that can classify questions' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
103	page_content='that can classify questions with respect to featuresother than accuracy, such as language toxicity [ 25], or based on conversational attributes, such as sensibleness, speciﬁcity, and interestingness [ 23]. 6 Conclusion In this paper, we have explored whether ﬁltering models can contribute to control the quality of answers generated by answerer models. Two experiments wereconducted: a classiﬁcation task, with the aim of ﬁnding answerable questions; and a regression task, in which we predicted the degree of meaningfulness of questions. For both tasks, results showed a correlation between the ability toﬁlter some questions and the quality of the answers generated. The analysis conducted in this paper is a ﬁrst step in the attempt to investigate modular approaches to QA systems and, in particular, on detached modelsthat can select questions and control answer quality. In the future, we wish to expand this investigation in a number of directions. First, we want to develop better QA ﬁltering systems, perhaps with' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
104	page_content='systems, perhaps with the employment of speciﬁcally-developed architectures. Second, we want to train these models in multiple datasets, hoping that information from multiple sources can assist the task of discoveringmore general clues on answerability. Finally, we intend to explore ﬁltering system where the task is to avoid answering sensitive questions and where high conﬁdence in responses is needed. 476 P. Pirozelli et al. References 1. Acheampong, K.N., Tian, W., Sifah, E.B., Opuni-Boachie, K.O.-A.: The emergence, advancement and future of textual answer triggering. In: Arai, K., Kapoor, S., Bhatia, R. (eds.) SAI 2020. AISC, vol. 1229, pp. 674–693. Springer, Cham (2020).  50 2. Paschoal, A.F.A., et al.: Pir´ a: a bilingual portuguese-english dataset for questionanswering about the ocean. In: 30th ACM International Conference on Informa-tion and Knowledge Management (CIKM 2021) (2021).  3459637.3482012 3. Brown, T.B., et al.: Language models are few-shot learners. CoRR abs/2005.14165 (2020).  4. Chen, D.,' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
105	page_content='(2020).  4. Chen, D., Fisch, A., Weston, J., Bordes, A.: Reading Wikipedia to answer opendomain questions. In: Barzilay, R., Kan, M. (eds.) Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017, Vancouver,Canada, 30 July–4 August, Volume 1: Long Papers, pp. 1870–1879. Association for Computational Linguistics (2017).  5. Devlin, J., Chang, M., Lee, K., Toutanova, K.: BERT: pre-training of deep bidirectional transformers for language understanding. In: Burstein, J., Doran, C., Solorio, T. (eds.) Proceedings of the 2019 Conference of the North American Chapter ofthe Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, 2–7 June 2019, Volume 1 (Long and Short Papers), pp. 4171–4186. Association for Computational Linguistics (2019). 6. European-Commission: Proposal for a regulation laying down harmonised rules on artiﬁcial intelligence (artiﬁcial intelligence act) and amending certain union legislative acts' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
106	page_content='union legislative acts (2021).  uri=CELEX:52021PC0206&from=EN#footnote8 7. Ferrucci, D.A.: Introduction to “this is watson”. IBM J. Res. Dev. 56(3), 1 (2012).  8. Jurczyk, T., Zhai, M., Choi, J.D.: SelQA: a new benchmark for selection-based question answering. In: 28th IEEE International Conference on Tools with Artiﬁcial Intelligence, ICTAI 2016, San Jose, CA, USA, 6–8 November 2016, pp. 820–827. IEEE Computer Society (2016).  9. Kadavath, S., et al.: Language models (mostly) know what they know (2022).  10. Karpukhin, V., et al.: Dense passage retrieval for open-domain question answering. In: Webber, B., Cohn, T., He, Y., Liu, Y. (eds.) Proceedings of the 2020 Conferenceon Empirical Methods in Natural Language Processing, EMNLP 2020, Online, 16–20 November 2020, pp. 6769–6781. Association for Computational Linguistics (2020).  11. Lan, Z., Chen, M., Goodman, S., Gimpel, K., Sharma, P., Soricut, R.: ALBERT: a lite BERT for self-supervised learning of language representations. In: 8th International' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
107	page_content='In: 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, 26–30 April 2020. OpenReview.net (2020).  forum?id=H1eA7AEtvS 12. Lewis, M., et al.: BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. In: Jurafsky, D., Chai, J., Schluter, N., Tetreault, J.R. (eds.) Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, 5–10 July 2020, pp. To Answer or Not to Answer? Filtering Questions for QA Systems 477 7871–7880. Association for Computational Linguistics (2020).  18653/v1/2020.acl-main.703 13. Lewis, P.S.H., et al.: Retrieval-augmented generation for knowledge-intensive NLP tasks. In: Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., Lin, H. (eds.) Advances in Neural Information Processing Systems, vol. 33, Annual Conferenceon Neural Information Processing Systems 2020, NeurIPS 2020, 6–12 December 2020, virtual (2020) 14. Liu, C., Lowe, R., Serban, I.,' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
108	page_content='C., Lowe, R., Serban, I., Noseworthy, M., Charlin, L., Pineau, J.: How NOT to evaluate your dialogue system: an empirical study of unsupervised evaluation metrics for dialogue response generation. In: Su, J., Carreras, X., Duh, K. (eds.)Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP 2016, Austin, Texas, USA, 1–4 November 2016, pp. 2122– 2132. The Association for Computational Linguistics (2016).  18653/v1/d16-1230 15. Liu, Y., et al.: RoBERTa: a robustly optimized BERT pretraining approach. CoRR abs/1907.11692 (2019).  16. Radford, A., Narasimhan, K., Salimans, T., Sutskever, I., et al.: Improving language understanding by generative pre-training (2018) 17. Raﬀel, C., et al.: Exploring the limits of transfer learning with a uniﬁed text-totext transformer. J. Mach. Learn. Res. 21, 140:1–140:67 (2020).  papers/v21/20-074.html 18. Rajpurkar, P., Jia, R., Liang, P.: Know what you don’t know: unanswerable questions for squad. In: Gurevych, I., Miyao, Y. (eds.)' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
109	page_content='I., Miyao, Y. (eds.) Proceedings of the 56th AnnualMeeting of the Association for Computational Linguistics, ACL 2018, Melbourne, Australia, 15–20 July 2018, Volume 2: Short Papers, pp. 784–789. Association for Computational Linguistics (2018).  19. Rajpurkar, P., Zhang, J., Lopyrev, K., Liang, P.: Squad: 100, 000+ questions for machine comprehension of text. In: Su, J., Carreras, X., Duh, K. (eds.) Proceedingsof the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP, Austin, Texas, USA, 1–4 November 2016, pp. 2383–2392. The Association for Computational Linguistics (2016).  20. Reimers, N., Gurevych, I.: Sentence-BERT: sentence embeddings using Siamese BERT-networks. In: Inui, K., Jiang, J., Ng, V., Wan, X. (eds.) Proceedings ofthe 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLPIJCNLP 2019, Hong Kong, China, 3–7 November 2019, pp. 3980–3990. Associationfor Computational Linguistics' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
110	page_content='Computational Linguistics (2019).  21. Rogers, A., Kovaleva, O., Downey, M., Rumshisky, A.: Getting closer to AI complete question answering: a set of prerequisite real tasks. In: The Thirty-Fourth AAAI Conference on Artiﬁcial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artiﬁcial Intelligence Conference, IAAI 2020, The TenthAAAI Symposium on Educational Advances in Artiﬁcial Intelligence, EAAI 2020, New York, NY, USA, 7–12 February 2020, pp. 8722–8731. AAAI Press (2020).  22. Sanh, V., Debut, L., Chaumond, J., Wolf, T.: DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter. CoRR abs/1910.01108 (2019). http:// arxiv.org/abs/1910.01108 23. Thoppilan, R., et al.: LaMDA: language models for dialog applications (2022) 24. Wang, B., Yao, T., Zhang, Q., Xu, J., Wang, X.: ReCO: a large scale Chinese reading comprehension dataset on opinion. CoRR abs/2006.12146 (2020). https:// arxiv.org/abs/2006.12146 478 P. Pirozelli et al. 25. Welbl, J., et al.: Challenges in' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
111	page_content='J., et al.: Challenges in detoxifying language models. In: Findings of the Association for Computational Linguistics: EMNLP 2021, pp. 2447–2469. Association for Computational Linguistics, November 2021.  2021.ﬁndings-emnlp.210 26. Yang, Y., Yih, W.T., Meek, C.: WikiQA: a challenge dataset for open-domain question answering. In: Proceedings of the 2015 Conference on Empirical Methodsin Natural Language Processing, pp. 2013–2018. Association for Computational Linguistics, Lisbon, September 2015.' metadata={'title': 'To Answer or Not to Answer? Filtering Questions for QA Systems', 'author': 'Paulo Pirozelli', 'publish_date': '2022-11-14', 'subject': 'Intelligent Systems', 'doi': 'doi:10.1007/978-3-031-21689-3_33', 'keywords': 'Question answering; Answer triggering; Dual system; Question filtering'}
112	page_content='Text Data Augmentation for\xa0Deep Learning Connor Shorten* , Taghi M. Khoshgoftaar and Borko Furht  Introduction Nearly all the successes of Deep Learning stem from supervised learning. Supervised  learning describes the use of loss functions that align predictions with manually anno tated ground truth. Deep Learning can achieve remarkable performance through the  combination of this learning strategy and large labeled datasets. The problem is that  collecting these annotated datasets is very difficult at the scale required. For example,  one of the key Deep Learning applications for COVID-19 rapid response was question  answering . Tang et\xa0al.  constructed COVID-QA, a supervised learning dataset in  which articles are annotated with an answer span to a given question. The authors of the  paper describe working for 23 hours to produce 124 question-answer pairs. Fitting 124  question-answer annotations without overfitting is extremely challenging in the current  state of Deep Learning. In addition to question' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
113	page_content='In addition to question answering, Natural Language Process ing (NLP) researchers are also exploring the application of abstractive summarization in Abstract  Natural Language Processing (NLP) is one of the most captivating applications of Deep  Learning. In this survey, we consider how the Data Augmentation training strategy can  aid in its development. We begin with the major motifs of Data Augmentation summarized into strengthening local decision boundaries, brute force training, causality  and counterfactual examples, and the distinction between meaning and form. We  follow these motifs with a concrete list of augmentation frameworks that have been  developed for text data. Deep Learning generally struggles with the measurement of  generalization and characterization of overfitting. We highlight studies that cover how  augmentations can construct test sets for generalization. NLP is at an early stage in  applying Data Augmentation compared to Computer Vision. We highlight the key differences and' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
114	page_content='the key differences and promising ideas that have yet to be tested in NLP . For the sake of practical  implementation, we describe tools that facilitate Data Augmentation such as the use of  consistency regularization, controllers, and offline and online augmentation pipelines,  to preview a few. Finally, we discuss interesting topics around Data Augmentation in  NLP such as task-specific augmentations, the use of prior knowledge in self-supervised  learning versus Data Augmentation, intersections with transfer and multi-task learning,  and ideas for AI-GAs (AI-Generating Algorithms). We hope this paper inspires further  research interest in Text Data Augmentation. Keywords: Data Augmentation, Natural Language Processing, Overfitting, Big Data,  NLP , Text DataOpen Access © The Author(s), 2021. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits  use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
115	page_content='format, as long as you give appropriate credit to the original  author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third  party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the mate rial. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or  exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://   creat iveco mmons. org/ licen ses/ by/4. 0/.SURVEY PAPERShorten\xa0 et\xa0al. J Big Data           (2021) 8:101    *Correspondence:    cshorten2015@fau.edu  Florida Atlantic University,  777 Glades Road, Boca Raton,  FL 33431, USA Page 2 of 34 Shorten\xa0et\xa0al. J Big Data           (2021) 8:101  which a model outputs a novel summary from a collection of input documents. Cachola  et\xa0al.  were able' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
116	page_content='Cachola  et\xa0al.  were able to collect a dataset of 5.4K Too Long; Didn’t Read (TLDR) summaries  of 3.2K machine learning papers. This required employing 28 undergraduate students to  refine data bootstrapped from the OpenReview platform. These anecdotes are provided  to highlight the difficulty of curating annotated big data for knowledge-intensive NLP  tasks with millions of examples. The Deep Learning research community is currently exploring many solutions to the  problem of learning without labeled big data. In addition to Data Augmentation, selfsupervised learning and transfer learning have performed very well. Few and zero-shot  learning are categories of research gaining interest as well. In this survey, we explore  getting more performance out of the supervised data available with Data Augmentation.  Our survey additionally explores how Data Augmentation is driving key advances in  learning strategies outside of supervised learning. This includes self-supervised learning  from unlabeled datasets, and' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
117	page_content='from unlabeled datasets, and transfer learning from other domains, whether that data is  labeled or unlabeled. Data Augmentation describes a set of algorithms that construct synthetic data from an  available dataset. This synthetic data typically contains small changes in the data that the  model’s predictions should be invariant to. Synthetic data can also represent combina tions between distant examples that would be very difficult to infer otherwise. Data Aug mentation is one of the most useful interfaces to influence the training of Deep Neural  Networks. This is largely due to the interpretable nature of the transformations and the  window to observe how the model is failing. Preventing overfitting is the most common use case of Data Augmentation. Without  augmentation, or regularization more generally, Deep Neural Networks are prone to  learning spurious correlations and memorizing high-frequency patterns that are difficult  for humans to detect. In NLP , this could describe high frequency numeric' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
118	page_content='high frequency numeric patterns in  token embeddings, or memorizations of particular forms of language that do not gen eralize. Data Augmentation can aid in these types of overfitting by shuffling the particu lar forms of language. To overcome the noisy data, the model must resort to learning  abstractions of information which are more likely to generalize. Data Augmentation is a regularization strategy. Other regularization techniques have  been developed such as dropout  or weight penalties . These techniques apply  functional regularization by either adding noise to intermediate activations of the net work or adding constraints to the functional form. These techniques have found suc cesses, but they lack the power to express the esoteric concept of semantic invariance.  Data Augmentation enables an intuitive interface for demonstrating label-preserving  transformations. Our survey presents several strategies for applying Data Augmentation to text data.  We cluster these augmentations into symbolic or' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
119	page_content='into symbolic or neural methods. Symbolic methods  use rules or discrete data structures to form synthetic examples. This includes RuleBased Augmentations, Graph-Structured Augmentations, Feature-Space Augmenta tion, and MixUp. Neural augmentations use a deep neural network trained on a different  task to augment data. Neural augmentations surveyed include Back-Translation, Gen erative Data Augmentation, and Style Augmentation. In addition to symbolic vs. neuralbased augmentations, we highlight other distinctions between augmentations such as  Page 3 of 34  Shorten\xa0et\xa0al. J Big Data           (2021) 8:101    task-specific versus task-agnostic augmentations and form versus meaning augmenta tions. We describe these distinctions further throughout our survey. Generalization is the core challenge of Deep Learning. How far can we extrapolate  from the instances available? The same interface used to control the training data is also  useful for simulating potential test sets and distribution shifts. We can' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
120	page_content='distribution shifts. We can simulate distribu tion shift by applying augmentations to a dataset, such as adding random tokens to an  email spam detector or increasing the prevalence of tokens that lie on the long-tail of the  frequency distributions. These simulated shifts can also describe higher-level linguis tic phenomenon. This involves deeper fact chaining than what was seen in the training  set, or the ability to change predictions given counterfactual evidence. As our tools for  Generative Data Augmentation continue to improve, we will be able to simulate more  semantic distribution shifts. This looks like a very promising direction to advance gener alization testing. Our survey on Text Data Augmentation for Deep Learning builds on our work sur veying Image Data Augmentation for Deep Learning . In Computer Vision, this  describes applying transformations such as rotating images, horizontally flipping them,  or increasing the brightness to form augmented examples. We found that it is currently  much' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
121	page_content='that it is currently  much easier to apply label-preserving transformations in Computer Vision than NLP . It  is additionally easier to stack these augmentations in Computer Vision, enabling even  more diversity in the augmented set, which has been shown to be a key contributor to  success. Data Augmentation research has been more thoroughly explored in Computer  Vision than NLP . We present some ideas that have found interesting results with images,  but remain to be tested in the text data domain. Finally, we discuss the intersection of  visual supervision for language understanding and how vision-language models may  help overcome the grounding problem. We discuss the grounding problem in greater  detail under our Motifs Of Data Augmentation section. Our next section presents practical implementation decisions for text data augmen tation. We begin by describing the use of a consistency regularization loss to further  influence the impact of augmented data. Differently from consistency regularization,' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
122	page_content='consistency regularization,  contrastive learning additionally uses negative examples to structure the loss function.  The next key question is how to control the strength and sampling of each augmenta tion. Augmentation controllers apply a meta-level abstraction to the hyperparameters  of augmentation selection and the magnitude of the transformation. This is commonly  explored with an adversarial controller that aims to produce mistakes in the model. We  also describe controllers that search for performance improvements such as AutoAug ment , Population-Based Augmentation , and RandAugment . Although similar  in concept, we discuss the key distinction between augmentation controllers and cur riculum learning. Another important consideration for implementing Data Augmenta tion is the CPU to GPU transfer in the preprocessing pipeline, as well as the conceptual  understanding of offline versus online augmentation. Finally, we describe the application  of augmentation to alleviate issues caused by class' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
123	page_content='issues caused by class imbalance. Our Discussion section presents opportunities to explore text data augmentation.  We begin with task-specific augmentations describing how key NLP tasks such as  question answering differ from natural language inference, particularly with respect  to input length or the categorization as a knowledge-intensive task. We quickly  Page 4 of 34 Shorten\xa0et\xa0al. J Big Data           (2021) 8:101  previewed that self-supervised and transfer learning are also emerging solutions to  learning with limited labeled data. We discuss the use of Data Augmentation in selfsupervised learning and then recent works with transfer and multi-task learning.  Finally, we discuss AI-GAs, short for AI-generating Algorithms . This is a very  interesting idea encompassing papers such as POET , Generative Teaching Net works , and the Synthetic Petri Dish  which describe algorithms that learn  the environment to learn from. We present how this differs from augmentation con trollers or curriculum learning,' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
124	page_content='or curriculum learning, the idea of skill acquisition from artificial data, and  opportunities to test these ideas in NLP . Data Augmentation for NLP prevents overfitting, provides the easiest way to inject  prior knowledge into a Deep Learning system, and offers a view into the generaliza tion ability of these models. Our survey is organized as follows: • We begin with the key Motifs Of Data Augmentation that augmentations strive to  achieve. • We provide a list of Text Data Augmentations. This list can be summarized into  symbolic augmentations, using rules and graph-structured decomposition to form  new examples, and neural augmentations, that use auxiliary neural networks to  sample new data. • Following our list of available augmentations, we dive deeper into Testing Gener alization with Data Augmentation. • We continue with a comparison of Image versus Text Augmentation. • Returning to Text Data Augmentation, we describe Practical Considerations for  Implementation. • Finally, we present interesting' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
125	page_content='we present interesting ideas and research questions in our Discussion sec tion. • Our Conclusion briefly summarizes the motivation and findings of our survey. Background Data Augmentation has been a heavily studied area of Machine Learning. The  advancement of the prior knowledge encoded in augmentations is one of the key dis tinctions between previous works and now. As we will discuss in depth later in the  survey, the success of Data Augmentation in Computer Vision has been fueled by the  ease of designing label-preserving transformations. For example, a cat image is still a  cat after rotating it, translating it on the x or y axis, increasing the intensity of the red  channel, and so on. It is easy to brainstorm these semantically-preserving augmenta tions for images, whereas it is much harder to do this in the text domain. We believe our survey on text data augmentation is well-timed with respect to ques tions such as why now? What has changed recently? Recent advances in generative  modeling such as' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
126	page_content='generative  modeling such as StyleGAN for images, GPT-3 for text , and DALL-E unifying  both text and images , have been astounding. We summarize many exciting works  on the use of prompting for adapting language models for downstream tasks. As dis cussed in further detail later on, we believe these advances in generative modeling  Page 5 of 34  Shorten\xa0et\xa0al. J Big Data           (2021) 8:101    could be game changing for the way we store datasets and build Deep Learning mod els. More particularly, it could become common to use labeled datasets solely for the  sake of evaluation, rather than representation learning. Our survey has some similarities to Feng et\xa0al.  which has been published roughly  around the same time as ours. Both surveys seek a clear definition of Data Augmenta tion and aim to highlight key motifs. Additionally, both surveys narrate the development  of NLP augmentation around the successes of augmentation in Computer Vision and  how these may transfer. Feng et\xa0al.  provide a deeper' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
127	page_content='Feng et\xa0al.  provide a deeper enumeration of task-specific  augmentation than is covered in our survey. Our survey adds important concepts such  as the debate between Meaning versus Form, Counterfactual Examples, and the use of  prompts in Generative Data Augmentation. Many of the successes of Deep Learning stem from access to large labeled datasets  such as ImageNet . However, constructing these datasets is very challenging and  time-consuming. Therefore, researchers are looking for alternative ways to leverage data  without manual annotation. This is a large motivation behind the success of self-super vised language modeling with papers such as GPT-3  or BERT . Data Augmenta tion follows this same motivation as overcoming the challenge of learning with limited  labeled data and avoiding manually labeling data. For example, many of the surveyed  studies highlight the success of their algorithms when sub-setting the labeled data. Transfer Learning has been one of the most effective solutions to this' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
128	page_content='effective solutions to this challenge of  learning from limited labeled datasets . Transfer Learning references initialization  of the model for learning with the weights learned from a previous task. This previous  task usually has the benefit of big data, whether that data is labeled such as ImageNet or  unlabeled, as is used in self-supervised language models. There are many research ques tions around the procedure of Transfer Learning. In our Discussion section we discuss  opportunities with Data Augmentation such as freezing the base feature extractor and  training separate heads on the original and augmented datasets. Self-supervised learning describes a general set of algorithms that learn from unla beled data with supervised learning. This is done by algorithmically labeling the data.  Some of the most popular self-supervised learning tasks include generation, contrastive  learning, and pretext tasks. Generation describes how language models are trained. A  token is algorithmically selected to be' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
129	page_content='selected to be masked out and the masked out token is used  as the label for supervised learning. Contrastive learning aligns representations of data  algorithmically determined to be similar (usually through the use of augmentations),  and distances these representations from negatives (usually other samples in the minibatch). Pretext tasks describe ideas such as applying an augmentation to data and task ing the model to predict the transformation. The augmentation interface powers many  task constructions in self-supervised learning. Motifs of\xa0text data augmentation This section will introduce a unifying view of objective the augmentations presented in  the rest of the survey address. We introduce the key motifs of Text Data Augmentation  as Strengthening Decision Boundaries, Brute Force Training, Causality and Counterfac tual Examples, and the distinction between Meaning versus Form. These concepts dig  Page 6 of 34 Shorten\xa0et\xa0al. J Big Data           (2021) 8:101  into the understanding of Data' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
130	page_content='the understanding of Data Augmentation and their particular application to lan guage processing. Strengthening decision boundaries Data Augmentation is commonly applied to classification problems where class bounda ries are learned from label assignments. Augmented examples are typically only slightly  different from existing samples. Training on these examples results in added space  between the original example and its respective class boundary. Well defined class  boundaries result in more robust classifiers and uncertainty estimates. For example,  these boundaries are often reported with lower dimensional visualizations derived from  t-SNE [ 20] or UMAP . A key motif of Data Augmentation is to perturb data so that the model is more familiar  with the local space around these examples. Expanding the radius from each example in  the dataset will overall help the model get a better sense of the decision boundary and  result in smother interpolation paths. This is in reference to small changes to the origi' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
131	page_content='to small changes to the origi nal data points. In NLP this could be deleting or adding words, synonym swaps, or well  controlled paraphrases. The model becomes more robust to the local space and decision  boundary based on available labels simply by increased exposure. Brute force training Deep Neural Networks are highly parametric models with very high variance that can  easily model their training data. Fitting the training data is surprisingly robust to inter polation, or moving within the data points provided. What Deep Learning struggles  with, as we will unpack in Generalization Testing with Data Augmentation, is extrapo lating outside of data points provided during training. A potential solution to this is to  brute force the data space with the training data. The upper bound solution to many problems in Computer Science is to simply enu merate all candidate solutions. Brute force solutions rely on computing speed to over power the complexity of a given problem. In Deep Learning, this entails training' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
132	page_content='this entails training on an  exhaustive set of natural language sequences such that all potential distributions the  test set could be sampled from are covered in the training data. This way, even the most  extreme edge cases will have been covered in the training set. The design of brute force  training requires exhaustive coverage of the natural language manifold. A key question  is whether this idea is reasonable or not? It may be better to identify key regions that are  missing, although that it is challenging to probe for and define. Causality and\xa0counterfactual examples Vital to achieving the goals of Deep Learning, is to learn causal representations , as  opposed to solely representing correlations. The field of Causal Inference demonstrates  how to use interventions to establish causality. Reinforcement Learning is the most  similar branch of Deep Learning research in which an agent deliberately samples inter ventions to learn about its environment. In this survey, we consider how the results of' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
133	page_content='consider how the results of  interventions can be integrated into observational language data. This is also similar to  the subset of Reinforcement Learning known as the offline setting . Page 7 of 34  Shorten\xa0et\xa0al. J Big Data           (2021) 8:101    Many of the Text Data Augmentations described throughout the survey utilize the  terminology of Counterfactual Examples . These Counterfactual Examples describe  augmentations such as the introduction of negations or numeric alterations to flip the  label of the example. The construction of counterfactuals in language generally relies on  human expertise, rather than algorithmic construction. Although the model does not  deliberately sample these interventions akin to a randomized control trial, the hope is  that it can still establish causal links between semantic concepts and labels by observing  the result of interventions. Liu et\xa0al.  lay the groundwork for formal causal language in Data Augmentation.  This entails the use of structured causal models and' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
134	page_content='structured causal models and the procedure of abduction, action,  and prediction to generate counterfactual examples. These experiments rely on phrasal  alignment between sequences in neural machine translation to sample counterfactual  replacements. Their counterfactual augmentation improves on a baseline English to  French translation system from 26.0 to 28.92 according to the BLEU metric. It seems  possible that this phrasal alignment could be extended to other sequence-to-sequence  problems such as abstractive question answering, summarization, or dialogue systems.  This explicit counterfactual structure is different from most reviewed works that rather  use natural language prompts to automate counterfactual sampling. For example, DINO   generates natural language inference data by either seeding the generation with  “mean the same thing” or “are on completely different topics” . We think it is an interest ing research direction to see if rigorous causal modeling such as computing the condi tional' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
135	page_content='as computing the condi tional probabilities of the context removing the variable  will provide benefits over  prompts and large language models. Meaning versus\xa0form One of the most interesting ideas in language processing is the distinction between  meaning and form. Bender and Koller  introduced the argument, providing several  ideas and thought experiments. A particularly salient anecdote to illustrate this is known  as the octopus example. In this example, two people are stranded on separate islands,  communicating through an underwater cable. This underwater cable is intercepted by  an intelligent octopus who learns to mimic the speaking patterns of each person. The  octopus does this well enough that it can substitute for either person, as in the Turing  test. However, when one of the stranded islanders encounters a bear and seeks advice,  the octopus is unable to help. This is because the octopus has learned the form of their  communication, but it has not learned the underlying meaning of the world in' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
136	page_content='meaning of the world in which  their language describes. We will present many augmentations in this paper that aid in learning form. Similar to  the concept of strengthening decision boundaries, ideas like synonym swap or rotating  syntactic trees will help the octopus further strengthen its understanding of how lan guage is generally organized. With respect to achieving an understanding of meaning in  these models and defining this esoteric concept, many have turned to ideas in grounding  and embodiment. Grounding typically refers to pairing language with other modalities  such as vision-language or audio-language models. However, grounding can also refer to  abstract concepts and worlds constructed solely from language. Embodiment references  learning agents that act in their environment. Although Bender and Koller propose that  Page 8 of 34 Shorten\xa0et\xa0al. J Big Data           (2021) 8:101  meaning cannot be learned from form alone, many other works highlight different areas  of the language modeling task' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
137	page_content='of the language modeling task such as assertions  or multiple embedded tasks   that could lead to learning meaning. Another useful way of thinking about meaning ver sus form could be to look at recently developed benchmarks in language processing such  as the distinction between GLUE  and SuperGLUE  tasks that predominantly  test an understanding of form to knowledge-intensive tasks such as KILT  that bet ter probe for meaning. In our survey, we generally use the terms “understanding” and  “meaning” to describe passing black-box tests designed by humans. We believe that  drilling into the definition of these terms is one of the most promising pursuits in lan guage processing research. Text data augmentations We described Data Augmentation as a strategy to prevent overfitting via regularization.  This regularization is enabled through an intuitive interface. As we study a task or data set, we learn more about what kind of priors or what kind of additional data we need to  collect to improve the system. For' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
138	page_content='to improve the system. For example, we might discover characteristics about our  question answering dataset such as that it fails with symmetric consistency on compari son questions. The following list of augmentations describes the mechanisms we cur rently have available to inject these priors into our datasets. Symbolic augmentation We categorize these augmentations as “Symbolic Augmentations” in contrast to “Neural  Augmentations” . As stated earlier, the key difference is the use of auxiliary neural net works, or other types of statistical models, to generate data compared to using symbolic  rules to augment data. A key benefit of symbolic augmentation is the interpretability  for the human designer. Symbolic augmentations also work better with short transfor mations, such as replacing words or phrases to form augmented examples. However,  some information-heavy applications rely on longer inputs such as question answering  or summarization. Symbolic rules are limited in applying global transformations' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
139	page_content='global transformations such as  augmenting entire sentences or paragraphs. Fig. 1 Success of EDA applied to 5 text classification datasets. A key takeaway from these results is the  performance difference with less data. The gain is much more pronounced with 500 labeled examples,  compared to 5,000 or the full training set Page 9 of 34  Shorten\xa0et\xa0al. J Big Data           (2021) 8:101    Rule‑based augmentation Rule-based Augmentations construct rules to form augmented examples. This entails ifelse programs for augmentation and symbolic templates to insert and re-arrange exist ing data. Easy Data Augmentation from Wei et\xa0 al.  presents four augmentations.  Figure\xa0 1 highlights the performance improvement with EDA, note the smallest subset  of 500 labeled examples benefits the most. One of the main reasons to be excited about  Easy Data Augmentation is that it is relatively easy to use off-the-shelf. Many of the  Augmentations mentioned later in this survey, are still in the research phase, waiting  for' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
140	page_content='research phase, waiting  for large-scale testing and adoption. Easy Data Augmentation includes random swap ping, random deletion, random insertion, and random synonym replacement. Examples  of this are shown in Fig.\xa02. There are many opportunities to build on these augmentations. Firstly, we note that  with random swapping, the classification of the word is incredibly useful. From the Data  Augmentation perspective of introducing semantic invariances, “I am jogging” , is much  more similar to “I am swimming” than “I am yelling” . Further designing token vocabular ies with this kind of structure should lead to an improvement. Programs for Rule-based augmentation further encompass many of the adversarial  attacks that have been developed for NLP . Adversarial attacks are equivalent to aug mentations, differing solely in the intention of their construction. As an example of  a rule-based attack, Jin et\xa0 al.  present TextFooler. TextFooler first computes word  importance scores by looking at the change in output' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
141	page_content='at the change in output when deleting each word. Text Fooler then selects the words which most significantly changed the outputs for synonym  replacement. This is an example of a rule-based symbolic program that can be used to  organize the construction of augmented examples. Another rule-based strategy available is Regular Expression Augmentation. Regular  Expression filtering is one of the most common ways to clean data that has been scraped  from the internet, as well as several other data sources such as Clinical Notes . Regu lar Expressions describe matching patterns in text. This is usually used to clean data, but  it can also be used to find common forms of language and generate extensions that align  with a graph-structured grammar. For example, matching patterns like “This object is  adjective” and extending it with patterns such as, “and adjective” . Another strategy is to  re-order the syntactics based on the grammar such as “This object is adjective” to “ An  adjective object” . Min et\xa0 al.' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
142	page_content='object” . Min et\xa0 al.  propose rules for augmentation based on syntactic heuristics. This  includes Inversion, swapping the subject and object in sentences, and Passivization  Fig. 2 Examples of easy data augmentation transformations Page 10 of 34 Shorten\xa0et\xa0al. J Big Data           (2021) 8:101  where the hypothesis in premise-hypothesis NLI (Natural-Language Inference) pairs are  translated to the passive version of the sentence. An example of Inversion is the change  from “The lawyer saw the actor” to “The actor saw the lawyer” . An example of Passiviza tion is changing from “This small collection contains 16 El Grecos” to “This small col lection is contained by 16 El Grecos” . The authors show improvement applying these  augmentations on the HANS challenge set for NLI . Graph‑structured augmentation An interesting opportunity for text data augmentation is to construct graph-struc tured representations of text data. This includes relation and entity encodings in  knowledge graphs, grammatical structures' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
143	page_content='grammatical structures in syntax trees, or metadata grounding  language data, such as citation networks. These augmentations add explicit structural  information, a relatively new integration with Deep Learning architectures. The addi tion of structure can aid in finding label-preserving transformations, representation  analysis, and adding prior knowledge to the dataset or application. We will begin our  analysis of Graph-Structured Augmentation by unpacking the difference between  structured versus unstructured representations. Deep Learning operates by converting high-dimensional, and sometimes sparse,  data into lower-dimensional, continuous vector embedding spaces. The learned vec tor space has corresponding metrics such as L2 or cosine similarity distance func tions. This is a core distinction from topological spaces, in which distance between  points is not defined. A topological space is a more general mathematical space with  less constraints than Euclidean or metric spaces. Topological spaces' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
144	page_content='spaces. Topological spaces encode informa tion that is challenging to integrate in modern Deep Learning architectures. Rather  than designing entirely new architectures, we can leverage the power of structured  data through the Data Augmentation interface. One of the most utilized structures in language processing is the Knowledge Graph  . A Knowledge Graph is composed of (entity, relation, entity) tuple relations. The  motivation of the augmentation scheme is that paths along the graph provide infor mation about entities and relations which are challenging to represent without struc ture. Under the scope of Rule-based Augmentation, we presented the idea of synonym  swap. One strategy to implement synonym swap would be to use a Knowledge Graph  with “is equivalent” relationships to find synonyms. This can be more practical than  manually defining dictionaries with synonym entries. This is especially the case  thanks to rapid acceleration in automated knowledge graph construction from unla beled data.' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
145	page_content='from unla beled data. Knowledge Graphs often contain more fine-grained relations as well. Previously, we mentioned how random synonym replacement would benefit enor mously from the perspective of preserving the class label with better swaps. Improved  swaps describe transitions such as “I am jogging” to “I am running” compared to “I  am yelling” , or even “I am market” . Structured language in graph-form is a very useful  tool to achieve this augmentation capability. These kinds of graphs have been heavily  developed with notable examples such as WordNet , Penn Treebank , and the  ImageNet class label structure . Graphs such as WordNet describe words in rela tionship to one another through “synsets” . Page 11 of 34  Shorten\xa0et\xa0al. J Big Data           (2021) 8:101    Graphs are made up of nodes and edges. In WordNet, each node represents a word  such as “tiger” . The genius of WordNet is the simplification of which edges to connect.  In WordNet, the nodes are connected with the same edge type, a “synset”' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
146	page_content='same edge type, a “synset” relation ship. Synsets are loosely defined as words belonging to a similar semantic category.  The word “tiger” would have a synset relation with nodes such as “lion” or “jaguar” .  The word “tiger” may also have finer-grained synset relations with nodes that describe  more particular types of tigers. WordNet is an example of a Graph-Structured Aug mentation that builds on synonym replacement. WordNet describes a graph where  each node is related to another graph by being a “synset” . We additionally consider graphs that contain finer grained edge classifications, this  kind of graph is frequently referred to as a Knowledge Graph . As an example,  CoV-KGE  contains 39 different types of edges relating biomedical concept nodes  such as drugs or potential binding targets. Huang et\xa0al.  provide another interest ing example of constructing a knowledge graph from the long context provided as  input to abstractive summarization. This graph enables semantic swaps that preserve  global' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
147	page_content='swaps that preserve  global consistency. Another heavily studied area of adding structure to text data is known as syntactic  parsing. Syntactic parsing describes different tasks that require structural analysis of text  such as the construction of syntax or dependency trees. Recently, Glavas and Vulic   demonstrated that supervised syntactic parsing offered little to no benefit in the modern  pre-train, then fine-tune pipeline with large language models. The final use of structure for Text Data Augmentation we consider is to integrate meta data via structural information. For example, scientific literature mining has become a  very popular application of NLP . These applications could benefit from the underlying  citation network characterizing these papers, in addition to the text content of the papers  themselves. Particularly, network structure has played an enormous role in biology and  medicine. Li et\xa0al.  present many of these graphs in high-level application domains  such as molecules, genomics,' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
148	page_content='such as molecules, genomics, therapeutics, and healthcare. The integration of this struc ture with text data could be a key component to grounding text representations. In the theme of our survey, we note that these auxiliary graphs may benefit from aug mentation as well. Data Augmentation for explicitly graph-structured data is still in its  early stages. Zhao et\xa0 al.  propose an edge augmentation technique that “exposes  GNNs to likely (but nonexistent) edges and limiting exposure to unlikely (but exist ent) ones” . This graph augmentation leads to an average accuracy improvement  of 5% across 6 popular node classification datasets. Kong et\xa0 al.  further demon strate the effectiveness of adversarially controlled node feature augmentation on graph  classification. In the section, Practical Considerations for Implementation, we will present the use  of consistency regularization and contrastive learning to further enforce the use of aug mented data in training. Building on these ideas, we can use' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
149	page_content='on these ideas, we can use graph-structures to assign  nearest neighbor assignments and regularize embeddings. Neural Structured Learning   describes constructing a graph connecting instances that share fine-grained class  labels. This is used to penalize a misclassification of “golden retriever” less so than “ele phant” if the ground truth label is “labrador retriever” . Li et\xa0al.  similarly construct  Page 12 of 34 Shorten\xa0et\xa0al. J Big Data           (2021) 8:101  an embedding graph to enforce consistency between predictions of strong and weakly  augmented data. MixUp augmentation MixUp Augmentation describes forming new examples by meshing existing examples  together, sometimes blending the labels as well. As an example, MixUp may take half  of one text sequence and concatenate it with half of another sequence in the dataset to  form a new example. MixUp may be one of the best interfaces available to connect dis tant points and illuminate a path of interpolation. Most implementations of MixUp vary with' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
150	page_content='of MixUp vary with respect to the layer in which samples are  interpolated. Guo et\xa0al.  test MixUp at word and sentence levels. This difference is  shown in Fig.\xa0 3. Their wordMixup technique combines existing samples by averaging  embedding vectors at the input layer. The sentMixup approach combines existing sam ples by averaging sentence embeddings as each original sequence is passed through sia mese encoders. Their experiments find a significant improvement in reducing overfitting  compared to no regularization or using dropout. Feature space augmentation Feature Space Augmentation describes augmenting data in the intermediate representa tion space of Deep Neural Networks. Nearly all Deep Neural Networks follow a sequen tial processing structure where input data is progressively transformed into distributed  representations and eventually, task-specific predictions. Feature Space Augmentations  isolate intermediate features and apply noise to form new data instances. This noise  could be sampled from' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
151	page_content='noise  could be sampled from standard uniform or gaussian distributions, or they could be  designed with adversarial controllers. MODALS  presents a few strategies for feature space augmentations. Shown  in Fig.\xa0 4, these strategies describe how to move along class boundaries to form new  Fig. 3 Left, word-level mixup. Right, sentence-level mixup. The red outline highlights where augmentation  occurs in the processing pipeline Page 13 of 34  Shorten\xa0et\xa0al. J Big Data           (2021) 8:101    examples in the feature space. Hard example interpolation (a) forms a new example by  moving it in the direction of existing embeddings that lie on the decision boundary for  classification. Hard example extrapolation (b) describes moving existing examples along  the same angle they currently lie from the mean vector of the class boundary. Gauss ian noise (c) entails adding Gaussian noise in the feature space. Difference transform  (d) moves an existing sample in the directional distance calculated from two separate' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
152	page_content='calculated from two separate  points in the same class. As described as one of the general Motifs Of Data Augmenta tion, MODALS aims to strengthen decision boundaries. Research in Supervised Con trastive Learning , replacing the commonly used KL-divergence of logits and class  labels with contrastive losses such as NCE with positives and negatives formed based on  class labels, has been shown to improve these boundaries. It could be useful to explore  how this benefits the MODALS algorithm. We also consider Differentiable Data Augmentation  techniques to fall under the  umbrella of Feature Space Augmentation. Data Augmentation is a function f(x) that pro duces augmented examples x’ . Similar to any other layers in the network, we can treat  the beginning of the network as an augmentation module and backpropagate gradients  through it. We can also separate the augmentation function and add it to the inputs such  that the transformation is not too dramatic, akin to adding an optimized noise map to  the input.' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
153	page_content='noise map to  the input. Minderer et\xa0 al.  use this technique to facilitate self-supervised pretext  tasks. Neural augmentation The following augmentations rely on auxiliary neural networks to generate new train ing data. This entails using a model trained on supervised Neural Machine Translation  datasets to translate from one language to another and back to sample new instances,  or a model trained on generative language modeling to replace masked out tokens or  sentences to produce new data. We additionally discuss the use of neural style transfer in  NLP to translate from one writing style to another or one semantic characteristic such as  formal to casual writing. Back‑translation augmentation Back-translation describes translating text from one language to another and then back  from the translation to the original language. An example could be taking 1,000 IMDB  movie reviews in English and translating them to French and back, Chinese and back, or  Arabian and back. There has been an enormous interest' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
154	page_content='has been an enormous interest in machine translation. This has  Fig. 4 Directions for feature space augmentation explored in MODALS Page 14 of 34 Shorten\xa0et\xa0al. J Big Data           (2021) 8:101  resulted in the curation of large labeled datasets of parallel sentences. We can also imag ine the use of other text datasets such as translations between programming languages  or writing styles as we describe in more detail under Style Augmentation. Back-translation leverages the semantic invariances encoded in supervised translation  datasets to produce semantic invariances for the sake of augmentation. Also interest ingly, back-translation is used to train unsupervised translation models by enforcing  consistency on the back-translations. This form of back-translation is also heavily used  to train machine translation models with a large set of monolingual data and a limited  set of paired translation data. Outside of translation we could imagine structuring these  domain pairings such as scientific papers and' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
155	page_content='such as scientific papers and news articles or college-level and highlevel reading and so on. An interesting design question with this may be to weigh the importance of using a  high performance machine translation model for the back-translation. However, as  stated by Pham et\xa0al., the lesson has been “better translation quality of the pseudo-paral lel data does not necessarily lead to a better final translation model, while lower-quality  but diverse data often yields stronger results instead” . The curation of paired lan guages and domains could also impact the final performance. Exploring back-translation  augmentation for question answering Longpre et\xa0al. discuss “curating our input data and  learning regime to encourage representations that are not biased by any one domain or  distribution” . Style augmentation Finally, we present another augmentation strategy utilizing Deep Networks to augment  data for the training of other Deep Nets. In our previous survey of Image Data Augmen tation, we explored' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
156	page_content='Augmen tation, we explored works that use Neural Style Transfer for augmentation. Artistic style  transfers such as a picasso-themed dog image, may be useful as an OOD augmentation  in a Negative Data Augmentation framework, which we will present later. However, we  are more interested in styles within the dataset. This is an interesting strategy to prevent  overfitting to high-frequency features or blurring out the form of language such as to  focus on meaning. In the text data domain, this could describe transferring the writingstyle of one author to another for applications such as abstractive summarization or con text for extractive question answering. Data Augmentation is often deployed to focus models on semantics, rather than par ticular forms of language. These particular forms could emerge from one author’s writing  style or general tonality in the language such as an optimistic versus a pessimistic writer.  Style transfer offers an interesting window to extract semantic similarities between writ' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
157	page_content='similarities between writ ing styles. This could help with modeling contexts in question answering systems or doc uments for information retrieval. Generative data augmentation Generative Data Augmentation is one of the most exciting emerging ideas in Deep  Learning. This includes generating photorealistic facial images  or indistinguishable  text passages . These models have been very useful for Transfer Learning, but the  question remains: What is the killer application of the generative task? These generations  Page 15 of 34  Shorten\xa0et\xa0al. J Big Data           (2021) 8:101    are certainly interesting for artistic applications, but more importantly is their use for  representation learning and Data Augmentation. We note a core distinction in the use of generative models for Data Augmentation. A  popular use is to take a pre-trained language model of the shelf and optionally fine-tune  it further with the language modeling task. This is the standard operating procedure of  Transfer Learning. However, the' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
158	page_content='Learning. However, the fine-tuning is usually done with the Supervised Learn ing task, rather than additional language modeling. The pre-trained language models  have learned many interesting properties of language because they are trained on mas sive datasets. An interesting example that is publicly available is The Pile . The Pile is  800GB of text data spanning Wikipedia, comment forums, entire books, and many more  examples of data like this. Even though these models and datasets are very impressive,  additional benefits will likely be achieved by domain-tuning with additional language  modeling on the limited dataset. Language modeling is a very useful pre-training stage and we often have more data  for language modeling than a downstream task like question-answering. Whereas we  may only have 100 question-answer pairs, the question, answer, and surrounding context  could easily contain 300 words each, accounting for a total of 3,000 words for construct ing language modeling examples. A dataset size of' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
159	page_content='examples. A dataset size of 3,000 compared to 100 can make a  large difference in success with Deep Learning and is the prime reason for our interest  in Data Augmentation to begin with. Gururangan et\xa0al.  present an argument for this  use of language models since downstream performance is dramatically improved when  pre-training on a relevant dataset. This distinction of “relevant dataset” is in contrasting  reference to what is used to train models like GPT-3 . One of the most popular strategies for training a language model for Generative Data  Augmentation is Conditional BERT (C-BERT) . C-BERT augments data by replacing  masked out tokens of the original instance. The key novelty is that it takes an embed ding of the class label as input, such as to preserve the semantic label when replacing  masked out tokens. This targets the label-preserving property of Data Augmentation.  The C-BERT training strategy can be used when fine-tuning a model pre-trained on  another dataset or starting from a random' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
160	page_content='or starting from a random initialization. An emerging strategy to adapt pre-trained generative models to downstream tasks  is to re-purpose the interface of masking out tokens. This is known as prompting. The  output of language models can be guided with text templates for the sake of generating  or labeling new data. Testing the efficacy of prompting with respect to the objective of  learning from limited data, Scao and Rush  show that prompting is often worth 100s  of data points on SuperGLUE classification tasks . This is in direct comparison with  the more heavily studied paradigm of Transfer Learning, head-based fine-tuning. We  will present a few variants on implementing prompts, this includes in-context learning,  pattern-exploiting training, and prompt tuning. The first implementation of prompting we consider is in-context learning. In-context  learning became well known when demonstrated with GPT-3. The idea is to prepend  each input with a fixed task description and a collection of examples of the' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
161	page_content='collection of examples of the task. This  does not require any further gradient updates of the model. Brown et\xa0al.  show that  scale is crucial to making this work reporting significant performance drops from 175B  parameters to 13B and less. This technique has likely not yet hit its ceiling, especially  Page 16 of 34 Shorten\xa0et\xa0al. J Big Data           (2021) 8:101  with the development of transformer models that can in sequences longer than 512  tokens as inputs. Similar to excitement about retrieval-augmented modeling, this will  allow in-context learning models to process more demonstrations of the task. However,  due to limitations of scale, methods that continue with gradient updates are more practi cally useful. The next implementation of prompting we will present is prompt tuning. Prompt  tuning describes first embedding the prompt into a continuous space, and then opti mizing the embedding with gradient descent while keeping the rest of the network fro zen. Similarly to GPT-3, Lester et\xa0al.  show' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
162	page_content='to GPT-3, Lester et\xa0al.  show that scale improves performance with  prompt tuning and that prompt tuning significantly outperforms the in-context learning  results reported from Brown et\xa0al. . Performance can be further improved by ensem bling optimized prompts and running inference as a single batch of the input and the  appended prompts. Tuned prompt ensembling improves the average performance of the  prompts on SuperGLUE from 88.5, and the best performing individual prompt at 89.8, to  90.5. The authors further highlight that analysis of the optimized prompt embedding can  aid in task complexity and similarity metrics, as well as Meta-Learning. Prompt tuning  shares the same underlying concept of prepending context to the input of downstream  tasks to facilitate fine-tuning, however this technique is more in line with research on  Transfer Learning with minimal modifications. For example, adapter layers  aim to  introduce a small number of parameters to fine-tune a pre-trained Transformer. An emerging' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
163	page_content='Transformer. An emerging theme in the pre-train then fine-tune paradigm has been that domain  and task alignment tends to improve fine-tuned performance. Gururangan et\xa0 al.   demonstrate the effectiveness of data domain alignment and Zhang et\xa0 al.  dem onstrate effectiveness of task alignment in the proposed PEGASUS algorithm. In cor respondence with the lesson of alignment, Zhong et\xa0 al.  tune language models to  be better fitted to answer prompts. This is done by manually annotating 441 questions  across 43 existing datasets that map every task to a “Yes” or “No” answer. Measured by  AUC-ROC plots, the authors show that further fine-tuning on prompt specialization  improves these models and that this also benefits from scale. The authors call for the  organization of NLP datasets into unified formats that better aids in fine-tuning models  for answering prompts. Pattern exploiting training (PET)  uses the pre-trained language model to label  task-specific unlabeled data. This is done with manually-defined' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
164	page_content='is done with manually-defined templates that convert  the supervised learning task into a language modeling task. The outputs of the language  model are then mapped to supervised learning labels with a verbalizer. Gradient-descent  optimization is applied to verbalized outputs to fine-tune it with the same cross-entropy  loss function used to train classifiers. Schick and Shutze  demonstrated that the PET  technique enables much smaller models to surpass GPT-3 with 32 labeled examples  from SuperGLUE. Tam et\xa0al.  further developed the algorithm to ADAPET. ADA PET utilizes dense supervision in the labeling task, applying the loss to the entire vocab ulary distribution without a verbalizer and additional requiring the model to predict the  masked tokens in the context given the label, similarly to conditional-BERT. ADAPET  outperforms PET without the use of task-specific unlabeled data. A limitation to pattern-exploiting training, in-context learning, and prompt tun ing, is that they require retaining a large' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
165	page_content='require retaining a large language model for downstream tasks. Most  Page 17 of 34  Shorten\xa0et\xa0al. J Big Data           (2021) 8:101    applications are interested in compressing these models for the sake of efficiency. Under  the scope of Label Augmentation, we will present the use of knowledge distillation. For  now, we consider compression by generating data to train a smaller model with. This  approach is most similar to pattern-exploiting training, except that rather than use  the pre-trained language model to label data, we will instead use it to generate entire  examples. Drawing inspiration from the success of MixUp, which was presented in further detail  in MixUp Augmentation, Yoo et\xa0al. developed GPT3Mix . The input to GPT3Mix  begins with a Task Specification that defines the task such as, “Text Type T = movie  review, Label Type L = sentiment” . Akin to MixUp, the next inputs are examples of  the task formulated as “text type: example text k (label type: example label k)” , such as  “Example 1:' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
166	page_content='k)” , such as  “Example 1: The cat is running my mat. (negative)” . The final piece of the input is the  template to generate new examples. Further, the generated example is “soft-labeled” by  the generating probabilities of each token in the process of generating the new exam ple. GPT3Mix achieves massive performance improvements over no augmentation, Easy  Data Augmentation, and BackTranslation when subsetting available data to extreme lev els such as 0.1% and 0.3%. Schick and Shutze  also explore the strategy of generating data from language  models, presenting Datsets from Instructions (DINO). DINO uses a task description and  one example from the dataset to generate pairwise classification datasets. Interestingly,  they contrast task descriptions which entail the resulting label to decode language model  generation. For example, the task description could begin with “Write two sentences  that” and continue with either “mean the same thing” or “are on completely different  topics” . The generation' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
167	page_content='topics” . The generation accounts for the token another label description would gener ate. Evaluated on the STS text similarity dataset, representations learned from DINO  show improvements over state-of-the-art sentence embedding techniques trained with  supervised learning, such as Universal Sentence Encoders  and Siamese BERT and  RoBERTa models . While built on the same underlying concept, discrete versus continuous prompt  search diverge heavily from one another. Discrete prompt search has the benefit of inter pretability. For example, comparing different task descriptions and examples provided  by a human annotator offers insights into what the model has learned. However, prompt  optimization in the continuous embedding space fully automates the search. Continuous  prompt optimization is likely more susceptible to overfitting due to the freedom of the  optimization space. Another somewhat similar theme to prompting in NLP has been to augment knowl edge-enhanced text generation with retrieval. Popular' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
168	page_content='with retrieval. Popular models include Retrieval-Aug mented Generation (RAG) , and Retrieval-Augmented Language Model Pre-training  (REALM) . Shuster et\xa0 al.  show how retrieving information to prepend to the  input reduces the problem of hallucination in text generation. Once this retrieved infor mation is embedded into the continuous representation space of language models, it is a  similar optimization problem as prompt tuning. Another interesting idea is the intersection of Data Privacy and Generative Data Aug mentation. Can we store data in the parameters of models instead of centralized data bases? The idea of Federated Learning  is to send copies of the global model weights  Page 18 of 34 Shorten\xa0et\xa0al. J Big Data           (2021) 8:101  to a local database such as to avoid a centralized database. Which models should we  send to local databases? Classifiers or generative models? If we send a generative model,  we have the potential to cover more of the data distribution and learn more about gen eral' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
169	page_content='and learn more about gen eral data manifolds such as the use of language more broadly, however, we risk exposing  more critical information . Label augmentation Supervised Learning, describes fitting an input, x, to a label, y. Throughout this survey,  we have presented strategies for regularizing the x values. In this section, we explore  research looking to entertain the y class labels. The most successful example of this is  Knowledge Distillation . Knowledge Distillation describes transforming the tradi tional one-hot encoded y labels into a soft distribution by re-labeling xs with the logits of  another neural network’s prediction. This has been very influential in compression such  as DistilBERT , information retrieval , and achieving state-of-the-art classifica tion results in Computer Vision . In addition to Knowledge Distillation, several other strategies have been developed to  augment the label space. Label smoothing uses a heuristic adjustment to the density on  negative classes and has been' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
170	page_content='negative classes and has been highly influential for training classifiers  and genera tive adversarial networks . Another exciting approach is the use of a meta-controller,  similar to knowledge distillation, but massively different in that the Teacher is learning  from the gradients of the Student’s loss to update the label augmentation. Notable exam ples exploring this include Meta Pseudo Labels  and Teaching with Commentaries  . This ambitious idea of learning to augment data through outer-inner loop gradients  have also been explored in the data space, x, with Generative Teaching Networks .  As of the time of this writing, Generative Teaching Networks have only been applied  to image data. A similar idea is “Meta Back-Translation” , in this work, the authors  “propose a meta-learning framework where the back-translation model learns to match  the forward translation model’s gradients on the development data with those on the  pseudo-parallel data. ” Thakur et\xa0al.  present the Augmented SBERT to augment' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
171	page_content='Augmented SBERT to augment data labels for distilla tion. The authors note that the cross-encoder, although much slower and less efficient  than bi-encoders, tends to reach higher accuracy on pairwise classification tasks such  as ranking or duplicate question detection. The paper proposes to label data with the  cross-encoder and fit these augmented labels with the bi-encoder. Also worth mention ing is that the cross-encoder heavily outperforms the bi-encoder with less training data.  Thakur et\xa0al. find a significant benefit strategically selecting data to soft label with the  cross encoder. We have found this idea throughout experiments in Data Augmentation,  discussing it further in our Discussion section under Curriculum Learning. Testing generalization with\xa0data augmentation The holy grail of Machine Learning is to achieve out-of-distribution (OOD) generaliza tion. This is distinct from in-distribution generalization where the training and test sets  are sampled from the same data distribution. In order' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
172	page_content='data distribution. In order to measure OOD generalization,  we need to make assumptions about how the distribution will shift. As Arjvosky writes,  “if the test data is arbitrary or unrelated to the training data, then generalization is  Page 19 of 34  Shorten\xa0et\xa0al. J Big Data           (2021) 8:101    obviously futile” . Chollet further describes the relationship between system-centric  and developer-aware generalization, as well as levels of generalization such as absent,  local, broad, and extreme . We argue that Data Augmentation is the natural inter face to quantify the relationship between test and train data distributions and levels of  generalization. A classic tool to test for generalization is to simply report the difference in accuracy  between the training and test sets. However, as shown in papers such as Deep Double  Descent , the phenomenon of overfitting is generally poorly understood with largescale Deep Neural Networks. We believe it is more practical to study overfitting and' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
173	page_content='to study overfitting and  generalization in the data space. For example, the success of adversarial examples shows  that Deep Neural Networks cannot generalize to distributions added with adversarially  optimized noise maps. Jia and Liang  show that models trained on SQuAD cannot  generalize when adversarially optimized sentences are added to the context, an example  of this is shown in Fig.\xa0 5. In addition to adversarial attacks, many other datasets show  intuitive examples of distribution shifts where Deep Neural Networks fail to generalize. We present Data Augmentation as a black-box test for generalization. Check List  proposes a foundational idea for these kinds of tests in NLP . CheckList is  designed to test the linguistic capabilities of models such as robustness to negation,  vocabulary perturbations, or temporal consistency. We view this as introducing a dis tribution shift of linguistic phenomena in the test set. Clark et\xa0 al.  construct a  toy example for transformers to see how far they can' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
174	page_content='to see how far they can generalize fact chaining. In this  test, the training data requires the model to chain together more or less facts than are  tested in the test set. Again, the distribution shift is controlled with an intuitive inter face again to Data Augmentation. Finally, WILDS  is a collection of real-world dis tribution shifts. These real-world shifts can also be mapped to Data Augmentations. Kaushiik et\xa0al.  describes employing human-labelers to construct a set of coun terfactual movie reviews and natural language inference examples. The authors  construct an elegant annotation interface and task Mechanical Turk workers to  minimally edit examples such as to switch the label. For example, converting “The  world of Atlantis, hidden beneath the earth’s core, is fantastic” to “The world of Atlan tis, hidden beneath the earth’s core is supposed to be fantastic” . For movie reviews,  the authors group the workers’ revisions into categories such as recasting fact as  hoped for, suggesting sarcasm,' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
175	page_content='for, suggesting sarcasm, inserting modifiers, inserting phrases, diminishing  value qualifiers, differing perspectives, and changing ratings. For natural language  Fig. 5 Fooled by injected text. Image taken from Jia and Liang  Page 20 of 34 Shorten\xa0et\xa0al. J Big Data           (2021) 8:101  inference, the authors group the workers’ revisions into categories such as modifying/ removing actions, substituting entities, adding details to entities, inserting relation ships, numerical modifications, using/removing negation, and unrelated hypothesis.  These examples are constructed for testing generalization to these counterfactual  examples. Returning to our description of Generative Data Augmentation, are generative models  capable of making these edits? If GPT-3 was given an IMDB review with the task prompt  of “change this movie review from positive to negative” , it could probably manage it.  We leave it to future work to investigate the generalization shifts induced by humandesigned counterfactuals and' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
176	page_content='counterfactuals and generative models. To further motivate this study, the  authors note that their dataset construction came with a hefty price tag of $10,778.14.  Inference costs of generative models are unlikely to approach this cost, unless working  with extremely large models. Highlighting that a similar categorization of the changes  as Kaushik et\xa0al. use  could help us understand the linguistic phenomena underlying  this kind of generalization test. Generative Data Augmentation provides another lens to study generalization. Nak kiran et\xa0 al. propose a novel way of studying generalization in “The Deep Bootstrap  Framework” . The idea is to compare the Online test error to the Bootstrap test  error. The Online error describes the performance of a model trained on an infinite data  stream, i.e. without repeating samples. The Bootstrap test error describes the common  training setup in Deep Learning, repeating batches of the same data. The authors simu late the Online learning scenario by fitting a' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
177	page_content='scenario by fitting a generative model, in this particular case  a Denoising diffusion probabilistic model . The generative model is used to sample  6 million examples, compared to the standard 50,000 samples used to train CIFAR-10.  Garg et\xa0 al.  additionally propose RATT, a technique that analyzes learning curves  and generalization when randomly labeled unlabeled data is added to the training batch.  The augmentations described in this survey may be able to simulate this unlabeled data  and provide similar insights. To conclude, when is overfitting problematic? How much of a data distribution are  modern neural networks capable of covering? Deep Neural Networks have a remarkable  ability to interpolate within the training data distribution. A potential solution could be  to leverage Data Augmentation to expand the training distribution such that there are  no reasonable out-of-distribution shifts in the test sets. Even if all the potential distribu tions cannot be compressed into a single neural network,' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
178	page_content='into a single neural network, this interface can illuminate  where the model will fail. Image versus\xa0text augmentation Our survey on Text Data Augmentation for Deep Learning is intended to follow a simi lar format as our prior work on Image Data Augmentation for Deep Learning . We  note there are many similarities between the Easy Data Augmentations and basic geo metric and color space transformations used in Computer Vision. Most similarly, both  are easy to implement and complement nearly any problem working with text or image  data respectively. We have described how Easy Data Augmentation can easily interface  with text classification, pairwise classification, extractive question answering, abstrac tive summarization, and chatbots, to name a few. Similarly, geometric and color space  Page 21 of 34  Shorten\xa0et\xa0al. J Big Data           (2021) 8:101    transformations in Computer Vision are used in image classification, object detection,  semantic segmentation, and image generation. As described in the' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
179	page_content='As described in the beginning of our survey, Data Augmentation biases the model  towards certain semantic invariances. Image Data Augmentation has largely been suc cessful because it is easy to think semantic invariances relevant to vision. These include  semantic invariance to horizontal flips, rotations, and increased brightness, to name  a few. Comparatively, it is much harder to define transformations to text data that are  guaranteed to be semantically invariant. All of the augmentations described in Easy Data  Augmentation have the potential to perturb the original data such that it changes the  ground truth label, y. Another interesting trend is the integration of vision and language in recent mod els such as CLIP and DALL-E. For the sake of Data Augmentation, a notable example  is Vokenization from Tan and Bansal . The authors align tokens such as “humans”  with images of “humans” and so on, even for verbs such as “speaking” . The masked lan guage modeling task then uses the visual tokens as' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
180	page_content='uses the visual tokens as additional supervision for predicting  masked out tokens. There is some noise in this alignment such as finding a visual token  for words such as “by” or “the” . Tan and Basil report visual grounding ratios for tokens of  54.8%, 57.6%, and 41.7% on curated vision-language datasets compared to 26.6%, 27.7%,  and 28.3% for solely language corpora. Across the SST-2, QNLI, QQP , MNLI, SQuAD  v1.1 and v2.0, and SWAG benchmark tasks, Vokenization improves BERT-Large from  79.4 to 82.1 and RoBERTa-Large from 77.6 to 80.6. There are many interesting visionlanguage datasets labeled for tasks such as visual question answering, image captioning,  and text-image retrieval, to name a few. Vision-language Data Augmentation schemes  such as Vokenization look to be a very promising area of research. A recent trend in Image Data Augmentation has been its integration in the training  of generative models, namely generative adversarial networks (GANs) . The GAN  framework, similar to the ELECTRA model' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
181	page_content='similar to the ELECTRA model , consists of a generator and a discrimi nator. The generator transforms random noise into images and the discriminator clas sifies these images as either coming from the generator or the provided training set.  Following, we will describe why this does not work as well as autoregressive modeling  for text. Returning to how Data Augmentation has been used for GANs, this investi gation began with Zhang et\xa0 al. ’s work on consistency regularization . Consistency  regularization requires the discriminator to make the same classification on a real image  and an augmented view of that same image. Unfortunately, this led to the augmenta tions being “leaked” into the generated distribution such that the generator produces  augmented data as well. We will end this discussion by presenting some ideas from LeCun and Misra   on the key distinction between generative modeling between Images and Text. The key  issue stated in the article is handling uncertainty. As an example, take the masked' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
182	page_content='an example, take the masked token  completion task: “The mask chases the mask in the savana” . LeCun and Misra point out  that the language model can easily “associate a score or a probability to all words in the  vocabulary: high score for lion’ , ‘cheetah’ , and a few other predators, and low scores for  all other words in the vocabulary” . In comparison, applying this kind of density  on candidate images in highly intractable. The missing token can only be 1 of a typi cal 30,000 tokens, whereas a missing 8x8 RGB patch can take on a ridiculously large,  Page 22 of 34 Shorten\xa0et\xa0al. J Big Data           (2021) 8:101  255x8x8x3 values. Therefore, image models need to rely on energy-based models that  learn joint embedding spaces and assign similarity scores, rather than exactly modeling  the probability of each missing patch. Perhaps the GAN framework, or something simi lar, will take over in NLP once generative modeling expands its scope to sentence-level  or paragraph-level generation, such as the' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
183	page_content='generation, such as the pre-training task used for abstractive summa rization in PEGASUS . Another interesting success of Data Augmentation has been its application in Rein forcement Learning. This has been heavily studied with Robotic Control from Visual  Inputs and the Atari benchmark. One of the biggest bottlenecks with robotic learning,  and most deep reinforcement learning problems, is a lack of data. It is challenging to  restart a robot laundry folder back to the beginning of the unfolded shirt and collect  millions of trajectories. To solve this problem, researchers have turned to forming aug mented trajectories from collections in a replay buffer. Amongst many applications of  reinforcement learning with Text data that have been proposed, patient care control is  particularly exciting. Ji et\xa0al.  explore the use of model-based reinforcement learn ing for patient care of septic patients using the MIMIC-III dataset . The authors  use clinical notes to sanity check the model-based rollouts of' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
184	page_content='the model-based rollouts of physiological patient state  markers. A promising area of research will be to apply Text Data Augmentation to col lected clinical note trajectories to improve patient care and trajectory simulation. Practical considerations for\xa0implementation This section presents many details of implementing Text Data Augmentation that make  a large performance difference in terms of evaluation metrics and training efficiency. Consistency regularization Consistency regularization is a strong compliment to the priors introduced via Data  Augmentation. A consistency loss requires a model to minimize the distance in repre sentations of an instance and the augmented example derived from it. In line with the  motif of strengthening decision boundaries, consistency regularization enforces a con nection between original and augmented samples. This is usually implemented in a  multi-task learning framework where a model simultaneously optimizes the down stream task and a secondary consistency term.' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
185	page_content='a secondary consistency term. Consistency regularization has been successfully applied to translate between pro gramming languages by enforcing consistency on back-translations . Alberti et\xa0al.   use a slightly different form of consistency regularization to generate synthetic  question-answer pairs. Rather than minimizing the distance between representations  of original and augmented examples, the framework requires that the model outputs  the exact same answer when predicting from context, question inputs as when a sepa rate model generates the question from context, answer inputs. The original BERTLarge model achieves an F1 score of 83.1 when fine-tuned on the SQuAD2. Fine-tuning  BERT with an additional 7 million questions generated with the consistency condition  improves performance to 84.8. Consistency regularization is a common technique for self-supervised represen tation learning because unlabeled data should still have this property of consistent  Page 23 of 34  Shorten\xa0et\xa0al. J Big Data' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
186	page_content='J Big Data           (2021) 8:101    representations before and after augmentation. Xie et\xa0al.  deploy consistency reg ularization as shown in Fig.\xa0 6. This technique surpasses the previous state-of-the-arts  trained solely with supervised learning using significantly less data. These improvements  continue even in the extreme case of only 20 labeled examples. As an example of the per formance gain, the fine-tuned BERT model achieves a 6.5% error rate on IMDB review  classification, which is reduced to 4.2% with UDA. The multi-task loss formulation is  also fairly common in consistency regularization implementations. Contrastive learning Contrastive learning differs from consistency regularization by utilizing negative sam ples to normalize the loss function. This is a critical distinction because the negative  samples can provide a significant learning signal. We believe that the development of  Text Data Augmentation can benefit from adapting successful examples in Computer  Vision. The use of Data' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
187	page_content='Vision. The use of Data Augmentation to power contrastive self-supervised learning  has been one of the most interesting stories in Computer Vision. This involves frame works such as SimCLR , MoCo , SwAV , and BYOL , to name a  few. This training strategy should be well suited for information retrieval in NLP . Krishna et\xa0al.  propose contrastive REALM (c-REALM). The contrastive loss is used  to align the embedding of the question and supervised answer, and contrast the question  with other supervised answers from the mini-batch. However, this technique of contras tive learning is more akin to supervised contrastive learning , than frameworks such as  SimCLR. In SimCLR, Data Augmentation is used to form the positive pairs. This strategy  has not been heavily explored in information retrieval, likely due to the lack of augmenta tions. Hopefully, the list we have provided will help those interested pursue this idea. Gunel et\xa0al.  demonstrate significant improvements on GLUE benchmark tasks by  training with a' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
188	page_content='tasks by  training with a supervised contrastive loss in addition to cross-entropy loss on one-hot  encoded label vectors. The gain is especially pronounced when learning from 20 labeled  examples, while they do not report much of a difference at 1,000 labeled examples. In  addition to quantitative metrics, the authors highlight that the embeddings of classes are  much more spread out through the lens of a t-SNE visualization. Fig. 6 Unsupervised data augmentation schema. Image taken from Xie et al.  Page 24 of 34 Shorten\xa0et\xa0al. J Big Data           (2021) 8:101  Contrastive learning, similarly to consistency regularization, describes making the  representation of an instance and a transformation-derived pair similar. However, con trastive learning adds a negative normalization that additionally pushes these represen tations away from other instances in the samples mini-batch. Contrastive learning has  achieved large advances in representation Computer Vision such as SimCLR  and  MoCo . Using Data' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
189	page_content='and  MoCo . Using Data Augmentation for contrastive learning is a very promising area  of research with recent extensions to the information-retrieval language model REALM  . We refer interested readers to a report from Rethmeier and Augenstein  for  more details on early efforts to apply contrastive learning to NLP . Consistency regularization and contrastive learning are candidate solutions to a com mon problem found by inspecting model performance. For example, Thorne et\xa0al.   find that fact verification models achieve better accuracy when classifying if claims are  supported or refuted by the evidence when ignoring the evidence. Contrastive learning  would require the model to correctly associated supporting evidence by contrasting it  with refuting evidence. Consistency Regularization would more so describe having a  similar prediction when the evidence has been slightly perturbed, such as inserting a  random word or replacing it with a paraphrase that shares the same semantics. Negative data' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
190	page_content='same semantics. Negative data augmentation Negative Data Augmentation is a similar concept to the negative examples used in con trastive learning. However, a key difference is that contrastive learning generally uses  other data points as the negatives, whereas Negative Data Augmentation entails apply ing aggressive augmentations. These augmentations are not just limited to label cor ruptions, but may push the example out of the natural language distribution entirely.  Returning to the motif of Meaning versus Form  these augmentations may not be  useful for learning meaning, but they can help reinforce the form of natural language.  Sinha et\xa0al.  demonstrate how this can be used to improve contrastive learning and  generative adversarial networks. Augmentation controllers A large contributor to the success of Data Augmentation in Computer Vision is the  development of controllers. Controllers reference algorithms that optimize the strength  of augmentations throughout training. The strength of augmentations' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
191	page_content='The strength of augmentations describe the mag nitude of operation such as inserting 3 additional words compared to 15. Augmentation  strength also describes how many augmentations are stacked together such as random  insertion followed by deletion followed by back-translation and so on, described more  next. Successful controllers such as AutoAugment , Population-Based Augmentation  , or RandAugment  have not yet seen large-scale adoption in NLP . When applying Easy Data Augmentation, several hyperparameters arise. Hyperparam eter optimization is one of the active areas of Deep Learning research [115–117]. This  presents a perfect problem to find optimal values for random augmentation samplings,  as well as magnitudes such as: how many tokens to delete? SpanBERT , for exam ple, shows that instead of masking out single tokens for language modeling, masking out  multiple tokens at a time, known as spans, results in better downstream performance. Page 25 of 34  Shorten\xa0et\xa0al. J Big Data           (2021) 8:101' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
192	page_content='Data           (2021) 8:101    Adversarial augmentation Adversarial attacks and the use of adversarially optimized inputs for augmentation is  very similar to the previous discussion on controllers. The key differentiation is that  adversarially controllers target misclassifications whereas controllers generally try to  avoid misclassifications. Particularly, adversarial optimization aims to improve robust ness to high-frequency pattern shifts. Adversarial attacks on text data generally range  from introducing typos to swiping out individual or chunks of words. There is a great  deal of ambiguity with this since many of these perturbations would be cleaned and fil tered by the text data preprocessing techniques such as spell checkers, case normaliza tions, or regular expression filtering. TextAttack  is an open-source library implementing adversarial text attacks and  providing APIs for Data Augmentation. There are four main components of an attack in  the TextAttack framework, a goal function, constraints,' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
193	page_content='a goal function, constraints, transformations, and a search  method. This pipeline is illustrated in Fig.\xa0 7. The goal function defines the target out put, for example instead of solely flipping the predicted output we may want to target a  50-50 density. The constraints define how far the input can be changed. The transforma tion describes the tools available to change the input such as synonym swaps, deletions,  applying back-translation, and all the other techniques discussed previously. Finally, the  search method describes the algorithm for searching for the attack. Similar to our dis cussion of controllers there are many different ways to perform black-box searches such  as grid or random searches, bayesian optimization, and evolutionary search, to name a  few [ 115]. A key consideration with adversarial augmentation is how quickly we can construct  adversarial examples. Many adversarial example construction techniques such as Sze gedy et\xa0 al.  rely on iterative optimization such as L-BFGS to find the' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
194	page_content='such as L-BFGS to find the adversarial  example. This would be a significant bottleneck in Deep Learning training to wait for the  adversarial search at each training batch. Towards solving this issue, Wang et\xa0al.   reduce time consumption up to 60% with their DEAT algorithm. The high-level idea of  DEAT is to use batch replay to avoid repeatedly computing adversarial batches. Stacking augmentations Stacking augmentations is a strategy that has improved vision models but is less straight forward to apply to text data. One strategy for this is CoDA . CoDA introduces a  local consistency loss to make sure stacking augmentations has not overly corrupted the  sample, and a global loss to preserve local neighborhoods around the original instance. Fig. 7 Developing attacks in TextAttack  Page 26 of 34 Shorten\xa0et\xa0al. J Big Data           (2021) 8:101  Tokenization The preprocessing pipeline of tokenization presents a formidable challenge for imple menting Data Augmentations. It is common to tokenize, or convert' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
195	page_content='to tokenize, or convert word tokens to their  respect numeric index in a vocabulary-embedding lookup table offline before it reaches  the Data Loader itself. Applying Data Augmentations on these index lists could require  significantly more engineering effort. Even for simple synonym replacement, additional  code will have to be written to construct dictionaries of the synonyms index value for  swaps. Notably, researchers are exploring tokenizer-free models such as byT5  and  CANINE [ 124]. These models process byte-level sequences such as ASCII codes  and will require special processing to integrate these augmentations. Position embeddings Another more subtle detail of Transformer implementations are the use of position  embeddings. The original Transformer  uses sine and cosine functions to integrate  positional information into text sequences. Another subtle Data Augmentation could be  to explore perturbing the parameters that render these encodings. Augmentation on\xa0CPUs or\xa0GPUs? Another important aspect' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
196	page_content='Another important aspect of Data Augmentation is to understand the typical data pre processing pipeline from CPUs to GPUs. It has been standard practice to apply Data  Augmentation to data on the CPU before it is passed to the GPU for model training.  However, recent practice has looked at applying Data Augmentation directly on the  GPU. This is done in Keras, for example, by adding Data Augmentation as a layer in the  model immediately after the input layer. It is also worth noting clever schemes such as  Data Echoing from Choi et\xa0al.  that apply additional techniques to avoid idle time  between CPU data loading and GPU model training. Offline and\xa0online augmentation Similarly to the discussion of augmenting data on the CPU or on the GPU, another  important consideration is to make sure the Data Augmentation is happening online,  compared to offline. This refers to when the original instance is augmented in the data  pipeline. Offline augmentation refers to augmenting the data and storing the augmented' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
197	page_content='and storing the augmented  examples to the disk. Online augmentation describes augmenting the data as a new  batch of the original data is loaded for a training step. We note that Online augmenta tion is much more powerful than Offline augmentation. Offline augmentation offers the  slight benefit of faster loading times, but it does not really take advantage of the stochas ticity and diversity enabled with most of the described augmentations. Another important detail of this pipeline is augmentation multiplicity . Augmen tation multiplicity refers to the number of augmented samples derived from one original  example. Fort et\xa0 al.  and Hoffer et\xa0 al.  illustrate how increasing augmenta tion multiplicity can improve performance. This approach could introduce significant  memory overhead without an online augmentation pipeline. Additionally Wei et\xa0 al.   point out that examples are often augmented online such that the model never  actually trains with the original instances. Wei et\xa0al. propose separating the' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
198	page_content='et\xa0al. propose separating the model into  Page 27 of 34  Shorten\xa0et\xa0al. J Big Data           (2021) 8:101    two fine-tuning heads, one which trains solely on the unaugmented data and the other  trained on high magnitude augmentations. These works highlight the opportunity to  explore fine-grained details in augmentation pipelines. Curriculum learning Curriculum Learning describes having a human or meta-controller structured organi zation to the data batches. This includes varying the strength of Data Augmentation  throughout training. Kucnik and Smith  find that it is much more efficient to sub sample a portion of the dataset to be augmented, rather than augmenting the entire  dataset. Wei et\xa0 al.  demonstrate the efficacy of gradually introducing augmented  examples to original examples in the training of triplet networks for text classifica tion. We note this is very similar to our discussion of controllers for augmentation and  searching for optimal magnitude and chaining parameters. Thakur et\xa0 al.' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
199	page_content='parameters. Thakur et\xa0 al.  describe  that “selecting the sentence pairs is non-trivial and crucial for the success of the method” . Class imbalance A prevalent issue explored in classification models is Class Imbalance . In addition  to customized loss functions, sampling techniques are a promising solution to overcome  biases stemming from Class Imbalance. These solutions generally describe strategies  such as random oversampling or undersampling , in addition to interpolation  strategies such as synthetic minority oversampling technique (SMOTE) . SMOTE  is a general framework to oversample minority instances by averaging between them.  From the list of augmentations we have covered, we note that MixUp is very similar to  this technique and has been explored for text data. It may be useful to use other tech niques for oversampling to avoid potential pitfalls of duplicating instances. Discussion Task‑specific augmentation for\xa0NLP NLP encompasses many different task formulations. This ranges from text' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
200	page_content='This ranges from text classification  to paraphrase identification, question answering, and abstractive summarization, to name  a few. The off-the-shelf Data Augmentation prescribed in the previous section will need  slight adaptations for each of these tasks. For example, when augmenting the context in a  question answering dataset, it is important to be mindful of removing the answer. The larg est difference we have found between tasks from the perspective of Data Augmentation  is that they vary massively with respect to input length. Short sequences will have to be  more mindful of how augmentations change the original example. Longer sequences have  more design decisions such as how to sample nested sentences for back-translation and  so on. We refer interested readers to Feng et\xa0al.  who enumerate how Data Augmenta tion applies to summarization, question answering, sequence tagging, parsing, grammati cal error correction, neural machine translation, data-to-text natural language generation  (NLG),' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
201	page_content='language generation  (NLG), open-ended and conditional generation, dialogue, and multimodal tasks. Page 28 of 34 Shorten\xa0et\xa0al. J Big Data           (2021) 8:101  Self‑supervised learning and\xa0data augmentation In both the case of self-supervised learning and Data Augmentation, we are looking to  inject prior knowledge about a data domain. When a model is deployed, what is more  likely: the data distribution changes or the task the model is supposed to perform with  the data changes? In self-supervised learning, we look for ways to set up tasks and loss  functions for representation learning. In Data Augmentation, we look for priors to  manipulate the data distribution. A key advantage of Data Augmentation is that it is  much easier to stack priors than self-supervised learning. In order to utilize multiple  priors, self-supervised learning relies on highly unstable multi-task learning or costly  multi-stage learning. In contrast, Data Augmentation only requires random sampling  operations to integrate' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
202	page_content='operations to integrate multiple priors. We note that many of the key successes in self-supervised Learning rely on Data Aug mentation, or have at least been dramatically improved by Data Augmentation. For exam ple, the success of contrastive learning relies on Data Augmentation to form two views  of the original instance. The most data-efficient GAN frameworks achieve data-efficiency  through the use of Data Augmentation . Further, DistAug  even tests Data Aug mentation with large scale pixel autoregressive modeling in the ImageGPT model . Transfer and\xa0multi‑task learning Transfer learning has been one of the most successful approaches to training deep neu ral networks. This looks especially promising as more annotated datasets are collected  and unified in dataset hubs. A notable example of which is HuggingFace datasets ,  containing 884 datasets at the time of this publication. In addition to transfer learning,  researchers have additionally explored multi-task learning in which a model simulta neously' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
203	page_content='which a model simulta neously optimizes multiple tasks. This has been well explored in T5 , which con verts all tasks into language modeling. We believe there is room for Data Augmentation  experiments in this space, such as the use of MixUp to combine data from multiple tasks  or Back-Translation between curated datasets. Wei et\xa0al.  propose an interesting extension, named as Multi-Task View (MTV),  to the common practice of transfer learning to better utilize augmented subsets and  share information across distributions. Multi-Task View (MTV) trains separate heads  on augmented subsets and ensembles predictions for the final output. Geva et\xa0al.   have also shown utility in sharing a feature extractor base and training separate heads.  In this case, Geva et\xa0al. train each head with a different task and reformulate inputs into  unifying prompts for inference. Similar to the discussion of prompting under Generative  Data Augmentation, there remains a significant opportunity to explore transfer learning,' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
204	page_content='explore transfer learning,  multi-task learning, and Data Augmentation. AI‑GAs One of the most interesting ideas in artificial intelligence research is AI-GAs (AIgenerating algorithms) . An AI-generating algorithm is composed of three pillars,  meta-learning architectures, meta-learning the learning algorithms themselves, and  generating effective learning environments. We believe that Data Augmentation and  this interface to control data distributions will play a large role in the third pillar of  Page 29 of 34  Shorten\xa0et\xa0al. J Big Data           (2021) 8:101    generating learning environments. For example, embedding learning agents in teacherstudent loops in which the teacher controls augmentation parameters to render the  learning environment. Learning the learning environment itself has been successfully applied to bipedal walk ing control with neural networks in POET . POET is a co-evolutionary framework  of control parameters and parameters that render walking terrains. Data Augmentation  may be the' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
205	page_content='Data Augmentation  may be the most natural way of extending this framework to understanding language  in which the environment searches for magnitude parameters of augmentation or sub sets of data, as in curriculum learning. AI-GAs have been applied to vision problems  in examples such as Generative Teaching Networks  and Synthetic Petri Dish .  In GTNs, a teacher network generates training data for a student network. Notably, the  training data has high-frequency noise patterns that do not resemble natural image data.  It could be interesting to see how well GTNs could generate text embeddings similar to  the continuous optimization of prompt tuning. Conclusion In conclusion, this survey has presented several strategies for applying Data Augmenta tion in Text data. These augmentations provide an interface to allow developers to inject  priors about their task and data domain into the model. We have additionally presented  how Data Augmentation can help simulate distribution shift and test generalization.' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
206	page_content='and test generalization.  As Data Augmentation for NLP is relatively immature compared to Computer Vision,  we highlight some of the key similarities and differences. We have also presented many  ideas surrounding Data Augmentation, from practical engineering considerations to  broader discussions of the potential of data augmentation in building artificial intelli gence. Data Augmentation is a very promising strategy and we hope our discussion sec tion helps motivate further research interest. Acknowledgements We would like to thank the reviewers in the Data Mining and Machine Learning Laboratory at Florida Atlantic University.  Additionally, we acknowledge partial support by the NSF (IIS-2027890). Opinions, findings, conclusions, or recommendations in this paper are the authors’ and do not reflect the views of the NSF. Authors’ contributions CS performed the literature review and drafted the manuscript. TMK worked with CS to develop the article’s framework  and focus. TMK introduced this topic to CS. All' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
207	page_content='this topic to CS. All authors read and approved the final manuscript. Funding NSF RAPID (IIS-2027890). Availability of data and materials Not applicable. Declarations Ethics approval and consent to participate Not applicable. Consent for publication Not applicable. Competing interests The authors declare that they have no competing interests. Received: 22 June 2021   Accepted: 28 June 2021  Page 30 of 34 Shorten\xa0et\xa0al. J Big Data           (2021) 8:101  References  1. Shorten C, Khoshgoftaar T, Furht B. Deep learning applications for covid-19. J Big Data. 2021. https:// doi. org/ 10.  1186/ s4053702000392-9.  2. Tang R, Nogueira R, Zhang E, Gupta N, Cam P , Cho K, Lin J. Rapidly bootstrapping a question answering dataset for  covid-19. 2020. arXiv: 2004. 11339. Accessed Jul 2021  3. Cachola I, Lo K, Cohan A, Weld DS. TLDR: extreme summarization of scientific documents. 2020. arXiv: 2004. 15011.  Accessed Jul 2021  4. Srivastava N, Hinton G, Krizhevsky A, Sutskever I, Salakhutdinov R. Dropout: a simple way to' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
208	page_content='R. Dropout: a simple way to prevent neural net works from overfitting. J Mach Learn Res. 2014;15(1):1929–58 .  5. Kukačka J, Golkov V, Cremers D. Regularization for deep learning: a taxonomy 2017 . arXiv: 1710. 10686. Accessed  Jul 2021  6. Shorten C, Khoshgoftaar T. A survey on image data augmentation for deep learning. J Big Data. 2019;6:1–48.  7. Cubuk ED, Zoph B, Mane D, Vasudevan V, Le QV. AutoAugment: learning augmentation policies from data 2018.  arXiv: 1805. 09501. Accessed Jul 2021  8. Ho D, Liang E, Stoica I, Abbeel P , Chen X. Population based augmentation: efficient learning of augmentation  policy schedules 2019. arXiv: 1905. 05393. Accessed Jul 2021  9. Cubuk ED, Zoph B, Shlens J, Le QV. RandAugment: practical automated data augmentation with a reduced search  space 2019. arXiv: 1909. 13719. Accessed Jul 2021  10. Clune J. AI-GAs: AI-generating algorithms, an alternate paradigm for producing general artificial intelligence 2019.  arXiv: 1905. 10985. Accessed Jul 2021  11. Wang R, Lehman J,' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
209	page_content='2021  11. Wang R, Lehman J, Clune J, Stanley KO. Poet: Open-ended coevolution of environments and their optimized  solutions. In: Proceedings of the Genetic and Evolutionary Computation Conference. GECCO ’19, pp. 142–151.  Association for Computing Machinery, New York, NY, USA 2019. https:// doi. org/ 10. 1145/ 33217 07. 33217 99.  12. Such FP , Rawal A, Lehman J, Stanley KO, Clune J. Generative teaching networks: accelerating neural architecture  search by learning to generate synthetic training data 2019. arXiv: 1912. 07768. Accessed Jul 2021  13. Rawal A, Lehman J, Such FP , Clune J, Stanley KO. Synthetic petri dish: a novel surrogate model for rapid architecture search 2020. arXiv: 2005. 13092. Accessed Jul 2021  14. Brown TB, Mann B, Ryder N, Subbiah M, Kaplan J, Dhariwal P , Neelakantan A, Shyam P , Sastry G, Askell A, Agarwal  S, Herbert-Voss A, Krueger G, Henighan T, Child R, Ramesh A, Ziegler DM, Wu J, Winter C, Hesse C, Chen M, Sigler E,  Litwin M, Gray S, Chess B, Clark J, Berner C, McCandlish S,' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
210	page_content='J, Berner C, McCandlish S, Radford A, Sutskever I, Amodei D. Language models are  few-shot learners 2020. arXiv: 2005. 14165. Accessed Jul 2021  15. OpenAI: DALL.E: Creating Images from Text. OpenAI 2021. https:// openai. com/ blog/ dall-e/. Accessed Jul 2021  16. Feng SY, Gangal V, Wei J, Chandar S, Vosoughi S, Mitamura T, Hovy E. A Survey of Data Augmentation Approaches  for NLP . 2021;2105:03075.  17. Deng J, Dong W, Socher R, Li L-J, Li K, Fei-Fei L. Imagenet: A large-scale hierarchical image database. In: 2009 IEEE  Conference on Computer Vision and Pattern Recognition, pp. 248–255 2009. Ieee  18. Devlin J, Chang M-W, Lee K, Toutanova K. BERT: Pre-training of deep bidirectional transformers for language  understanding. In: Proceedings of the 2019 Conference of the North American Chapter of the Association for  Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp. 4171–4186.  Association for Computational Linguistics, Minneapolis, Minnesota 2019. https:// doi. org/' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
211	page_content='2019. https:// doi. org/ 10. 18653/ v1/ N191423.  19. Weiss K, Khoshgoftaar T, Wang D. A survey of transfer learning. J Big Data. 2016. https:// doi. org/ 10. 1186/  s405370160043-6.  20. van der Maaten L, Hinton G. Viualizing data using t-sne. J Mach Learn Res. 2008;9:2579–605.  21. McInnes L, Healy J, Melville J. UMAP: uniform manifold approximation and projection for dimension reduction  2018. arXiv: 1802. 03426. Accessed Jul 2021  22. Schölkopf B, Locatello F, Bauer S, Ke NR, Kalchbrenner N, Goyal A, Bengio Y. Towards causal representation learning  2021. arXiv: 2102. 11107. Accessed Jul 2021  23. Levine S, Kumar A, Tucker G, Fu J. Offline Reinforcement learning: tutorial, review, and perspectives on open prob lems 2020. arXiv: 2005. 01643. Accessed Jul 2021  24. Kaushik D, Hovy E, Lipton ZC. Learning the difference that makes a difference with counterfactually-augmented  data 2019. arXiv: 1909. 12434. Accessed Jul 2021  25. Liu Q, Kusner M, Blunsom P . Counterfactual data augmentation for neural machine' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
212	page_content='for neural machine translation. In: Proceedings  of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human  Language Technologies, pp. 187–197. Association for Computational Linguistics, Online 2021. https:// www.  aclweb. org/ antho logy/ 2021. naaclmain. 18. Accessed Jul 2021  26. Schick T, Schütze H. Generating Datasets with Pretrained Language Models 2021. arXiv: 2104. 07540. Accessed Jul  2021  27. Pearl J. Causality: models, reasoning, and inference. USA: Cambridge University Press; 2000.  28. Bender EM, Koller A. Climbing towards NLU: On meaning, form, and understanding in the age of data. In: Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 5185–5198. Association for  Computational Linguistics, Online 2020. https:// doi. org/ 10. 18653/ v1/ 2020. aclmain. 463.  29. Merrill W, Goldberg Y, Schwartz R, Smith NA. Provable limitations of acquiring meaning from ungrounded form:  what will future language models' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
213	page_content='will future language models understand? 2021. arXiv: 2104. 10809. Accessed Jul 2021  30. Weber L, Jumelet J, Bruni E, Hupkes D. Language modelling as a multi-task problem. In: Proceedings of the  16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pp.  2049–2060. Association for Computational Linguistics, Online 2021. https:// www. aclweb. org/ antho logy/ 2021.  eaclmain. 176. Accessed Jul 2021  31. Wang A, Singh A, Michael J, Hill F, Levy O, Bowman S. GLUE: A multi-task benchmark and analysis platform for  natural language understanding. In: Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and  Interpreting Neural Networks For NLP , pp. 353–355. Association for Computational Linguistics, Brussels, Belgium  2018. https:// doi. org/ 10. 18653/ v1/ W185446. Page 31 of 34  Shorten\xa0et\xa0al. J Big Data           (2021) 8:101     32. Sarlin P-E, DeTone D, Malisiewicz T, Rabinovich A. SuperGlue: Learning Feature Matching with Graph Neural Net works' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
214	page_content='with Graph Neural Net works 2019. arXiv: 1911. 11763. Accessed Jul 2021  33. Petroni F, Piktus A, Fan A, Lewis P , Yazdani M, Cao ND, Thorne J, Jernite Y, Karpukhin V, Maillard J, Plachouras V, Rock täschel T, Riedel S. KILT: a benchmark for knowledge intensive language tasks 2020. arXiv: 2009. 02252. Accessed Jul  2021  34. Wei J, Zou K. EDA: Easy data augmentation techniques for boosting performance on text classification tasks.  In: Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th  International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 6382–6388. Association for  Computational Linguistics, Hong Kong, China 2019. https:// doi. org/ 10. 18653/ v1/ D191670.  35. Jin D, Jin Z, Zhou J, Szolovits P . Is bert really robust? a strong baseline for natural language attack on text classification and entailment. Proc Conf AAAI Artif Intell. 2020;34:8018–25. https:// doi. org/ 10. 1609/ aaai. v34i05. 6311.  36. Spasic I, Nenadic G. Clinical' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
215	page_content='Spasic I, Nenadic G. Clinical text data in machine learning: systematic review JMIR. Med Inform. 2020. https:// doi.  org/ 10. 2196/ 17984.  37. Min J, McCoy RT, Das D, Pitler E, Linzen T. Syntactic data augmentation increases robustness to inference heuristics.  In: Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 2339–2352.  Association for Computational Linguistics, Online 2020. https:// doi. org/ 10. 18653/ v1/ 2020. aclmain. 212.  38. McCoy T, Pavlick E, Linzen T. Right for the wrong reasons: Diagnosing syntactic heuristics in natural language  inference. In: Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp.  3428–3448. Association for Computational Linguistics, Florence, Italy 2019. https:// doi. org/ 10. 18653/ v1/ P191334.  39. Ji S, Pan S, Cambria E, Marttinen P , Yu PS. A survey on knowledge graphs: representation, acquisition and applications 2020. https:// doi. org/ 10. 1109/ TNNLS. 2021. 30708 43.  40. Miller' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
216	page_content='2021. 30708 43.  40. Miller GA. Wordnet: a lexical database for english. Commun ACM. 1995;38(11):39–41. https:// doi. org/ 10. 1145/  219717. 219748.  41. Marcus MP , Marcinkiewicz MA, Santorini B. Building a large annotated corpus of english: the penn treebank. Comput Linguist. 1993;19(2):313–30.  42. Zeng X, Song X, Ma T, Pan X, Zhou Y, Hou Y, Zhang Z, Karypis G, Cheng F. Repurpose open data to discover therapeutics for COVID-19 using deep learning 2020. arXiv: 2005. 10831. Accessed Jul 2021  43. Huang L, Wu L, Wang L. Knowledge graph-augmented abstractive summarization with semantic-driven cloze  reward, 2020; pp. 5094–5107. https:// doi. org/ 10. 18653/ v1/ 2020. aclmain. 457  44. Glavaš, G., Vulić, I.: Is supervised syntactic parsing beneficial for language understanding tasks? an empirical investigation. In: Proceedings of the 16th Conference of the European Chapter of the Association for Computational  Linguistics: Main Volume, pp. 3090–3104. Association for Computational Linguistics, Online 2021.' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
217	page_content='Linguistics, Online 2021. https:// www.  aclweb. org/ antho logy/ 2021. eaclmain. 270. Accessed Jul 2021  45. Li MM, Huang K, Zitnik M. Representation learning for networks in biology and medicine: advancements, challenges, and opportunities 2021. arXiv: 2104. 04883. Accessed Jul 2021  46. Zhao T, Liu Y, Neves L, Woodford O, Jiang M, Shah N. Data augmentation for graph neural networks 2020. arXiv:  2006. 06830. Accessed Jul 2021  47. Kong K, Li G, Ding M, Wu Z, Zhu C, Ghanem B, Taylor G, Goldstein T. FLAG: adversarial data augmentation for graph  neural networks 2020. arXiv: 2010. 09891. Accessed Jul 2021  48. Gopalan A, Juan D-C, Magalhaes CI, Ferng C-S, Heydon A, Lu C-T, Pham P , Yu G, Fan Y, Wang Y. Neural structured  learning: Training neural networks with structured signals. In: Proceedings of the 14th ACM International Confer ence on Web Search and Data Mining. WSDM ’21, pp. 1150–1153. Association for Computing Machinery, New  York, NY, USA 2021. https:// doi. org/ 10. 1145/ 34379 63. 34416 66.  49. Li' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
218	page_content='34379 63. 34416 66.  49. Li J, Xiong C, Hoi S. Comatch: Semi-supervised learning with contrastive graph regularization. arXiv: 2011. 11183 .  Accessed Jul 2021  50. Guo H, Mao Y, Zhang R. Augmenting data with mixup for sentence classification: an empirical study. arXiv: 1905.  08941 . Accessed Jul 2021  51. Cheung T-H, Yeung, D.-Y.: Modals: Modality-agnostic automated data augmentation in the latent space. In:  International Conference on Learning Representations 2021. https:// openr  eview. net/ forum? id= XjYgR 6gbCEc .  Accessed Jul 2021  52. Khosla P , Teterwak P , Wang C, Sarna A, Tian Y, Isola P , Maschinot A, Liu C, Krishnan D. Supervised contrastive learning 2020. arXiv: 2004. 11362. Accessed Jul 2021  53. Li Y, Hu G, Wang Y, Hospedales T, Robertson NM, Yang Y. DADA: differentiable automatic data augmentation 2020.  arXiv: 2003. 03780. Accessed Jul 2021  54. Minderer M, Bachem O, Houlsby N, Tschannen M. Automatic shortcut removal for self-supervised representation  learning 2020. arXiv: 2002. 08822.' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
219	page_content='2020. arXiv: 2002. 08822. Accessed Jul 2021  55. Pham H, Wang X, Yang Y, Neubig G. Meta back-translation. In: International Conference on Learning Representations 2021. https:// openr  eview. net/ forum? id= 3jjmd p7Hha. Accessed Jul 2021  56. Longpre S, Wang Y, DuBois C. How effective is task-agnostic data augmentation for pretrained transformers? arXiv:  2010. 01764 . Accessed Jul 2021  57. Karras T, Laine S, Aila T. A style-based generator architecture for generative adversarial networks 2018. arXiv: 1812.  04948. Accessed Jul 2021  58. Gao L, Biderman S, Black S, Golding L, Hoppe T, Foster C, Phang J, He H, Thite A, Nabeshima N, Presser S, Leahy C.  The pile: an 800GB dataset of diverse text for language modeling 2020. arXiv: 2101. 00027. Accessed Jul 2021  59. Gururangan S, Marasović, A., Swayamdipta S, Lo K, Beltagy I, Downey D, Smith NA. Don’t stop pretraining: Adapt  language models to domains and tasks. In: Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp.' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
220	page_content='Linguistics, pp. 8342–8360. Association for Computational Linguistics, Online 2020. https:// doi. org/ 10.  18653/ v1/ 2020. aclmain. 740. Accessed Jul 2021  60. Wu X, Lv S, Zang L, Han J, Hu S. Conditional BERT contextual augmentation 2018. arXiv: 1812. 06705. Accessed Jul  2021  61. Scao TL, Rush AM. How many data points is a prompt worth? 2021. arXiv: 2103. 08493. Accessed Jul 2021 Page 32 of 34 Shorten\xa0et\xa0al. J Big Data           (2021) 8:101   62. Lester B, Al-Rfou R, Constant N. The power of scale for parameter-efficient prompt tuning 2021. arXiv: 2104. 08691.  Accessed Jul 2021  63. Houlsby N, Giurgiu A, Jastrzebski S, Morrone B, de Laroussilhe Q, Gesmundo A, Attariyan M, Gelly S. Parameterefficient transfer learning for NLP 2019. arXiv: 1902. 00751. Accessed Jul 2021  64. Zhang J, Zhao Y, Saleh M, Liu P . PEGASUS: Pre-training with extracted gap-sentences for abstractive summarization. In: III, H.D., Singh, A. (eds.) Proceedings of the 37th International Conference on Machine Learning. Proceedings of' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
221	page_content='Learning. Proceedings of Machine Learning Research, vol. 119, pp. 11328–11339. PMLR? 2020. http:// proce edings. mlr. press/ v119/  zhang 20ae. html . Accessed Jul 2021  65. Zhong R, Lee K, Zhang Z, Klein D. Meta-tuning language models to answer prompts better 2021. arXiv: 2104.  04670. Accessed Jul 2021  66. Schick T, Schütze H. Exploiting cloze-questions for few-shot text classification and natural language inference. In:  Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics:  Main Volume, pp. 255–269. Association for Computational Linguistics, Online 2021. https:// www. aclweb. org/  antho logy/ 2021. eaclmain. 20. Accessed Jul 2021  67. Schick T, Schütze H. It’s Not Just Size That Matters: small language models are also few-shot learners 2020. arXiv:  2009. 07118. Accessed Jul 2021  68. Tam D, Menon RR, Bansal M, Srivastava S, Raffel C. Improving and simplifying pattern exploiting training 2021.  arXiv: 2103. 11955. Accessed Jul 2021  69. Yoo KM,' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
222	page_content='Jul 2021  69. Yoo KM, Park D, Kang J, Lee S-W, Park W. GPT3Mix: leveraging large-scale language models for text augmentation  2021. arXiv: 2104. 08826. Accessed Jul 2021  70. Cer D, Yang Y, Kong, S.-y., Hua N, Limtiaco N, St. John R, Constant N, Guajardo-Cespedes M, Yuan S, Tar C, Strope B,  Kurzweil R. Universal sentence encoder for English. In: Proceedings of the 2018 Conference on Empirical Methods  in Natural Language Processing: System Demonstrations, pp. 169–174. Association for Computational Linguistics,  Brussels, Belgium 2018. https:// doi. org/ 10. 18653/ v1/ D182029. Accessed Jul 2021  71. Reimers N, Gurevych I. Sentence-BERT: Sentence embeddings using Siamese BERT-networks. In: Proceedings  of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint  Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 3982–3992. Association for Computational  Linguistics, Hong Kong, China 2019. https:// doi. org/ 10. 18653/ v1/ D191410. Accessed Jul 2021' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
223	page_content='D191410. Accessed Jul 2021  72. Lewis P , Perez E, Piktus A, Petroni F, Karpukhin V, Goyal N, Küttler H, Lewis M, Yih, W.-t., Rocktäschel T, Riedel S, Kiela  D. Retrieval-augmented generation for knowledge-intensive nlp tasks. In: Larochelle H, Ranzato M, Hadsell R,  Balcan MF, Lin, H. (eds.) Advances in Neural Information Processing Systems, vol. 33, pp. 9459–9474. Curran Associates, Inc.,? 2020. https:// proce edings. neuri ps. cc/ paper/ 2020/ file/ 6b493 23020 5f780 e1bc2 6945d f7481 e5Paper. pdf .  Accessed Jul 2021  73. Guu K, Lee K, Tung Z, Pasupat P , Chang, M.-W.: Realm: Retrieval-augmented language model pre-training. arXiv:  2002. 08909. Accessed Jul 2021  74. Shuster K, Poff S, Chen M, Kiela D, Weston J. Retrieval augmentation reduces hallucination in conversation 2021.  arXiv: 2104. 07567. Accessed Jul 2021  75. Kairouz P , McMahan HB, Avent B, Bellet A, Bennis M, Bhagoji AN, Bonawitz K, Charles Z, Cormode G, Cummings R,  D’Oliveira, R.G.L., Eichner H, Rouayheb SE, Evans D, Gardner J, Garrett Z,' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
224	page_content='D, Gardner J, Garrett Z, Gascón A, Ghazi B, Gibbons PB, Gruteser  M, Harchaoui Z, He C, He L, Huo Z, Hutchinson B, Hsu J, Jaggi M, Javidi T, Joshi G, Khodak M, Konečný, J., Korolova  A, Koushanfar F, Koyejo S, Lepoint T, Liu Y, Mittal P , Mohri M, Nock R, Özgür A, Pagh R, Raykova M, Qi H, Ramage D,  Raskar R, Song D, Song W, Stich SU, Sun Z, Suresh AT, Tramèr F, Vepakomma P , Wang J, Xiong L, Xu Z, Yang Q, Yu FX,  Yu H, Zhao S. Advances and open problems in federated learning 2019. arXiv: 1912. 04977. Accessed Jul 2021  76. Carlini N, Tramer F, Wallace E, Jagielski M, Herbert-Voss A, Lee K, Roberts A, Brown T, Song D, Erlingsson U, Oprea A,  Raffel C. Extracting training data from large language models 2020. arXiv: 2012. 07805. Accessed Jul 2021  77. Hinton G, Vinyals O, Dean J. Distilling the knowledge in a neural network. In: NIPS Deep Learning and Representation Learning Workshop 2015. arXiv: 1503. 02531. Accessed Jul 2021  78. Sanh V, Debut L, Chaumond J, Wolf T. DistilBERT, a distilled version of BERT:' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
225	page_content='a distilled version of BERT: smaller, faster, cheaper and lighter  2019. arXiv: 1910. 01108. Accessed Jul 2021  79. Chen X, He B, Hui K, Sun L, Sun Y. Simplified TinyBERT: knowledge distillation for document retrieval 2020. arXiv:  2009. 07531. Accessed Jul 2021  80. Xie Q, Luong M-T, Hovy E, Le QV. Self-training with noisy student improves imagenet classification. In: Proceedings  of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2020  81. Müller R, Kornblith S, Hinton G. When does label smoothing help? 2019. arXiv: 1906. 02629. Accessed Jul 2021  82. Salimans T, Goodfellow I, Zaremba W, Cheung V, Radford A, Chen X, Chen X. Improved techniques for training  gans. In: Lee D, Sugiyama M, Luxburg U, Guyon I, Garnett, R. (eds.) Advances in Neural Information Processing  Systems, vol. 29. Curran Associates, Inc.,? 2016. https:// proce edings. neuri ps. cc/ paper/ 2016/ file/ 8a336 3abe7 92db2  d8761 d6403 605ae b7Paper. pdf . Accessed Jul 2021  83. Pham H, Dai Z, Xie Q, Luong M-T, Le' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
226	page_content='Dai Z, Xie Q, Luong M-T, Le QV. Meta pseudo labels 2020. arXiv: 2003. 10580. Accessed Jul 2021  84. Raghu A, Raghu M, Kornblith S, Duvenaud D, Hinton G. Teaching with commentaries. In: International Conference  on Learning Representations 2021. https:// openr  eview. net/ forum? id= 4Rbdg Bh9gE. Accessed Jul 2021  85. Thakur N, Reimers N, Daxenberger J, Gurevych I. Augmented SBERT: data augmentation method for improving  bi-encoders for pairwise sentence scoring tasks 2020. arXiv: 2010. 08240. Accessed Jul 2021  86. Arjovsky M. Out of Distribution generalization in machine learning 2021. arXiv: 2103. 02667. Accessed Jul 2021  87. Chollet F. On the measure of intelligence 2019. arXiv: 1911. 01547. Accessed Jul 2021  88. Nakkiran P , Kaplun G, Bansal Y, Yang T, Barak B, Sutskever I. Deep double descent: Where bigger models and more  data hurt. In: International Conference on Learning Representations 2020. https:// openr  eview. net/ forum? id=  B1g5s A4twr . Accessed Jul 2021  89. Jia R, Liang P . Adversarial' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
227	page_content='Jia R, Liang P . Adversarial examples for evaluating reading comprehension systems. arXiv: 1707. 07328. Accessed Jul  2021 Page 33 of 34  Shorten\xa0et\xa0al. J Big Data           (2021) 8:101     90. Ribeiro MT, Wu T, Guestrin C, Singh S. Beyond accuracy: Behavioral testing of NLP models with CheckList. In:  Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 4902–4912. Asso ciation for Computational Linguistics, Online 2020. https:// doi. org/ 10. 18653/ v1/ 2020. aclmain. 442  91. Clark P , Tafjord O, Richardson K. Transformers as soft reasoners over language 2020. arXiv: 2002. 05867. Accessed Jul  2021  92. Koh PW, Sagawa S, Marklund H, Xie SM, Zhang M, Balsubramani A, Hu, W.-h., Yasunaga M, Phillips RL, Beery S,  Leskovec J, Kundaje A, Pierson E, Levine S, Finn C, Liang P . Wilds: a benchmark of in-the-wild distribution shifts.  arXiv: 2012. 07421. Accessed Jul 2021  93. Nakkiran P , Neyshabur B, Sedghi H. The deep bootstrap framework: Good online learners are good' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
228	page_content='Good online learners are good offline generalizers. In: International Conference on Learning Representations 2021. https:// openr  eview. net/ forum? id=  guetr IHLFGI.  Accessed Jul 2021  94. Ho J, Jain A, Abbeel P . Denoising diffusion probabilistic models 2020. arXiv: 2006. 11239. Accessed Jul 2021  95. Garg S, Balakrishnan S, Kolter JZ, Lipton ZC. RATT: Leveraging unlabeled data to guarantee generalization 2021.  arXiv: 2105. 00303. Accessed Jul 2021  96. Tan H, Bansal M. Vokenization: Improving language understanding with contextualized, visual-grounded supervision. In: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp.  2066–2080. Association for Computational Linguistics, Online 2020. https:// doi. org/ 10. 18653/ v1/ 2020. emnlp main. 162  97. Goodfellow IJ, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley D, Ozair S, Courville A, Bengio Y. Generative adversarial  nets. In: Proceedings of the 27th International Conference on Neural Information Processing' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
229	page_content='Neural Information Processing Systems Volume 2.  NIPS’14, pp. 2672–2680. MIT Press, Cambridge, MA, USA 2014  98. Clark K, Luong M-T, Le QV, Manning CD. Electra: Pre-training text encoders as discriminators rather than generators. In: International Conference on Learning Representations 2020. https:// openr  eview. net/ forum? id= r1xMH  1BtvB . Accessed Jul 2021  99. Zhang H, Zhang Z, Odena A, Lee H. Consistency regularization for generative adversarial networks. In: International Conference on Learning Representations 2020. https:// openr  eview. net/ forum? id= S1lxK  lSKPH. Accessed Jul  2021  100. Self-supervised learning: The Dark Matter of Intelligence. https:// ai. faceb ook. com/ blog/ selfsuper  visedlearn ing the darkmatter ofintel ligen ce . Accessed 14 May 2021.  101. Ji CX, Oberst M, Kanjilal S, Sontag D. Trajectory inspection: A method for iterative clinician-driven design of reinforcement learning studies. AMIA 2021 Virtual Informatics Summit 2021  102. Johnson A, Pollard T, Shen L, Lehman' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
230	page_content='A, Pollard T, Shen L, Lehman L-W, Feng M, Ghassemi M, Moody B, Szolovits P , Celi L, Mimic-iii MR. A freely  accessible critical care database. Sci Data. 2016. https:// doi. org/ 10. 1038/ sdata. 2016. 35.  103. Lachaux M-A, Roziere B, Chanussot L, Lample G. Unsupervised translation of programming languages 2020. arXiv:  2006. 03511. Accessed Jul 2021  104. Alberti C, Andor D, Pitler E, Devlin J, Collins M. Synthetic QA corpora generation with roundtrip consistency 2019.  arXiv: 1906. 05416. Accessed Jul 2021  105. Xie Q, Dai Z, Hovy E, Luong M-T, Le QV. Unsupervised data augmentation for consistency training 2019. arXiv: 1904. 12848.  Accessed Jul 2021  106. Chen T, Kornblith S, Norouzi M, Hinton G. A simple framework for contrastive learning of visual representations.  In: III, H.D., Singh, A. (eds.) Proceedings of the 37th International Conference on Machine Learning. Proceedings of  Machine Learning Research, vol. 119, pp. 1597–1607. PMLR? 2020. http:// proce edings. mlr. press/ v119/ chen2 0j. html .' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
231	page_content='v119/ chen2 0j. html .  Accessed Jul 2021  107. He K, Fan H, Wu Y, Xie S, Girshick R. Momentum contrast for unsupervised visual representation learning. In: Pro ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2020  108. Caron M, Misra I, Mairal J, Goyal P , Bojanowski P , Joulin A. Unsupervised learning of visual features by contrasting  cluster assignments 2020. arXiv: 2006. 09882. Accessed Jul 2021  109. Grill J-B, Strub F, Altché, F., Tallec C, Richemond PH, Buchatskaya E, Doersch C, Pires BA, Guo ZD, Azar MG, Piot B,  Kavukcuoglu K, Munos R, Valko M. Bootstrap your own latent: a new approach to self-supervised Learning 2020.  arXiv: 2006. 07733. Accessed Jul 2021  110. Krishna K, Roy A, Iyyer M. Hurdles to progress in long-form question answering 2021. arXiv: 2103. 06332. Accessed  Jul 2021  111. Gunel B, Du J, Conneau A, Stoyanov V. Supervised contrastive learning for pre-trained language model finetuning. In: International Conference on Learning Representations' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
232	page_content='on Learning Representations 2021. https:// openr  eview. net/ forum? id= cu7IU  iOhujH. Accessed Jul 2021  112. Rethmeier N, Augenstein I. A primer on contrastive pretraining in language processing: methods, lessons learned  and perspectives 2021. arXiv: 2102. 12982. Accessed Jul 2021  113. Thorne J, Vlachos A, Christodoulopoulos C, Mittal A. FEVER: a large-scale dataset for fact extraction and verification  2018. arXiv: 1803. 05355. Accessed Jul 2021  114. Sinha A, Ayush K, Song J, Uzkent B, Jin H, Ermon S. Negative data augmentation. In: International Conference on  Learning Representations 2021. https:// openr  eview. net/ forum? id= Ovp8d vB8IBH. Accessed Jul 2021  115. He X, Zhao K, Chu X. Automl: a survey of the state-of-the-art. Knowl-Based Syst. 2021. https:// doi. org/ 10. 1016/j.  knosys. 2020. 106622.  116. Li L, Jamieson K, DeSalvo G, Rostamizadeh A, Talwalkar A. Hyperband: a novel bandit-based approach to hyperparameter optimization. J Mach Learn Res. 2018;18:1–52.  117. Li L, Jamieson K,' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
233	page_content='117. Li L, Jamieson K, Rostamizadeh A, Gonina E, Hardt M, Recht B, Talwalkar A. A system for massively parallel hyperparameter tuning 2018. arXiv: 1810. 05934. Accessed Jul 2021  118. Joshi M, Chen D, Liu Y, Weld DS, Zettlemoyer L, Levy O. Spanbert: improving pre-training by representing and  predicting spans. TACL. 2019;8:64–77.  119. Morris JX, Lifland E, Yoo JY, Grigsby J, Jin D, Qi Y. TextAttack: a framework for adversarial attacks, data augmentation,  and adversarial training in NLP 2020. 2005.05909. Accessed Jul 2021 Page 34 of 34 Shorten\xa0et\xa0al. J Big Data           (2021) 8:101   120. Szegedy C, Zaremba W, Sutskever I, Bruna J, Erhan D, Goodfellow I, Fergus R. Intriguing properties of neural net works. In: International Conference on Learning Representations 2014. http:// arxiv. org/ abs/ 1312. 6199. Accessed  Jul 2021  121. Wang F, Zhang Y, Zheng Y, Ruan W. Gradient-guided dynamic efficient adversarial training. arXiv: 2103. 03076.  Accessed Jul 2021  122. Qu Y, Shen D, Shen Y, Sajeev S, Chen W, Han' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
234	page_content='Shen Y, Sajeev S, Chen W, Han J. Coda: Contrast-enhanced and diversity-promoting data augmentation for natural language understanding. In: International Conference on Learning Representations 2021. https://  openr  eview. net/ forum? id= Ozk9M  rX1hvA. Accessed Jul 2021  123. Xue L, Barua A, Constant N, Al-Rfou R, Narang S, Kale M, Roberts A, Raffel C. ByT5: Towards a token-free future with  pre-trained byte-to-byte models 2021. arXiv: 2105. 13626. Accessed Jul 2021  124. Clark JH, Garrette D, Turc I, Wieting J. CANINE: pre-training an efficient tokenization-free encoder for language  representation 2021. arXiv: 2103. 06874. Accessed Jul 2021  125. Prusa JD, Khoshgoftaar TM. Designing a better data representation for deep neural networks and text classification. https:// doi. org/ 10. 1109/ IRI. 2016. 61. Accessed Jul 2021  126. Prusa J, Khoshgoftaar T. Improving deep neural network design with new text data representations. JBig Data.  2017. https:// doi. org/ 10. 1186/ s405370170065-8.  127. Choi D, Passos' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
235	page_content='127. Choi D, Passos A, Shallue CJ, Dahl GE. Faster neural network training with data echoing 2019. arXiv: 1907. 05550.  Accessed Jul 2021  128. Fort S, Brock A, Pascanu R, De S, Smith SL. Drawing multiple augmentation samples per image during training  efficiently decreases test error 2021. arXiv: 2105. 13343. Accessed Jul 2021  129. Hoffer E, Ben-Nun T, Hubara I, Giladi N, Hoefler T, Soudry D. Augment your batch: Improving generalization  through instance repetition. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2020  130. Wei J, Huang C, Xu S, Vosoughi S. Text augmentation in a multi-task view. In: Proceedings of the 16th Conference  of the European Chapter of the Association for Computational Linguistics: Main Volume, pp. 2888–2894. Association for Computational Linguistics, Online 2021. https:// www. aclweb. org/ antho logy/ 2021. eaclmain. 252  131. Kuchnik M, Smith V. Efficient augmentation via data subsampling. In: International Conference on Learning' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
236	page_content='Conference on Learning Repre sentations 2019. https:// openr  eview. net/ forum? id= Byxpf h0cFm. Accessed Jul 2021  132. Wei J, Huang C, Vosoughi S, Cheng Y, Xu S. Few-shot text classification with triplet networks, data augmentation,  and curriculum learning 2021. arXiv: 2103. 07552. Accessed Jul 2021  133. Johnson J, Khoshgoftaar T. Survey on deep learning with class imbalance. J Big Data. 2019;6:27. https:// doi. org/ 10.  1186/ s405370190192-5.  134. Prusa J, Khoshgoftaar TM, Dittman DJ, Napolitano A. Using random undersampling to alleviate class imbalance on  tweet sentiment data. In: 2015 IEEE International Conference on Information Reuse and Integration, pp. 197–202  2015. https:// doi. org/ 10. 1109/ IRI. 2015. 39  135. Seiffert C, Khoshgoftaar TM, Van Hulse J, Napolitano A. Rusboost: a hybrid approach to alleviating class imbalance.  IEEE Trans Syst Man Cybern Part A. 2010;40(1):185–97. https:// doi. org/ 10. 1109/ TSMCA. 2009. 20295 59.  136. Chawla N, Bowyer K, Hall L, Kegelmeyer W. Smote:' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
237	page_content='Hall L, Kegelmeyer W. Smote: synthetic minority over-sampling technique. J Artif Intell Res.  2002;16:321–57. https:// doi. org/ 10. 1613/ jair. 953.  137. Karras T, Aittala M, Hellsten J, Laine S, Lehtinen J, Aila T. Training generative adversarial networks with limited data.  In: Larochelle H, Ranzato M, Hadsell R, Balcan MF, Lin, H. (eds.) Advances in Neural Information Processing Systems,  vol. 33, pp. 12104–12114. Curran Associates, Inc., ??? 2020. https:// proce edings. neuri ps. cc/ paper/ 2020/ file/ 8d30a  a96e7 24407 59f74 bd230 6c1fa 3dPaper. pdf . Accessed Jul 2021  138. Jun H, Child R, Chen M, Schulman J, Ramesh A, Radford A, Sutskever I. Distribution augmentation for generative  modeling. In: III, H.D., Singh, A. (eds.) Proceedings of the 37th International Conference on Machine Learning.  Proceedings of Machine Learning Research, vol. 119, pp. 5006–5019. PMLR? 2020. http:// proce edings. mlr. press/  v119/ jun20a. html . Accessed Jul 2021  139. Image GPT. https:// openai. com/ blog/ image' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
238	page_content='openai. com/ blog/ image gpt/. Accessed 14 May 2021.  140. HuggingFace Datasets. https:// huggi ngface. co/ docs/ datas ets/. Accessed 14 May 2021.  141. Raffel C, Shazeer N, Roberts A, Lee K, Narang S, Matena M, Zhou Y, Li W, Liu PJ. Exploring the limits of transfer learning with a unified text-to-text transformer 2019. arXiv: 1910. 10683. Accessed Jul 2021  142. Geva M, Katz U, Ben-Arie A, Berant J. What’s in your Head? Emergent behaviour in multi-task transformer models  2021. arXiv: 2104. 06129. Accessed Jul 2021 Publisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.' metadata={'title': 'Text Data Augmentation for Deep Learning', 'author': 'Connor Shorten', 'publish_date': '2021-07-16', 'subject': 'Journal of Big Data', 'doi': 'https://doi.org/10.1186/s40537-021-00492-0', 'keywords': 'Connor Shorten '}
239	page_content='RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation Run-Ze Fan1,2, Yixing Fan1,2, Jiangui Chen1,2, Jiafeng Guo1,2(B), Ruqing Zhang1,2, and Xueqi Cheng1,2 1ICT, CAS, CAS Key Lab of Network Data Science and Technology, Beijing, China {fanrunze21s,fanyixing,chenjiangui18z,guojiafeng,zhangruqing,cxq}@ict.ac.cn 2University of Chinese Academy of Sciences, Beijing, China Abstract. Automatic mainstream hashtag recommendation aims to accurately provide users with concise and popular topical hashtags beforepublication. Generally, mainstream hashtag recommendation faces challenges in the comprehensive diﬃculty of newly posted tweets in response to new topics, and the accurate identiﬁcation of mainstream hashtagsbeyond semantic correctness. However, previous retrieval-based methods based on a ﬁxed predeﬁned mainstream hashtag list excel in producing mainstream hashtags, but fail to understand the constant ﬂow ofup-to-date information. Conversely, generation-based methods demonstrate a superior' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
240	page_content='demonstrate a superior ability to comprehend newly posted tweets, but their capacity is constrained to identifying mainstream hashtags without addi-tional features. Inspired by the recent success of the retrieval-augmented technique, in this work, we attempt to adopt this framework to combine the advantages of both approaches. Meantime, with the help ofthe generator component, we could rethink how to further improve the quality of the retriever component at a low cost. Therefore, we propose RetrIeval-augmented Generative Mainstream HashTag Recommender (RIGHT ), which consists of three components: (i) a retriever seeks relevant hashtags from the entire tweet-hashtags set; (ii) a selector enhances mainstream identiﬁcation by introducing global signals;and (iii) a generator incorporates input tweets and selected hashtags to directly generate the desired hashtags. The experimental results show that our method achieves signiﬁcant improvements over state-of-the-artbaselines. Moreover, RIGHT can be easily' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
241	page_content='Moreover, RIGHT can be easily integrated into large language models, improving the performance of ChatGPT by more than 10%. Code will be released at:  . Keywords: Hashtag recommendation ·Retrieval-augmented generation ·Social media 1 Introduction Millions of user-generated microblogs ﬂood Twitter daily, surpassing users’ comprehension. To facilitate rapid and easy understanding, hashtags (e.g., #ChatGPT ) c/circlecopyrtThe Author(s), under exclusive license to Springer Nature Switzerland AG 2024 N. Goharian et al. (Eds.): ECIR 2024, LNCS 14608, pp. 39–55, 2024. _3 40 R.-Z. Fan et al. Fig. 1. Illustration of evaluating hashtag recommendation with diﬀerent methods. are extensively used to convey central ideas and topics, which also enhance content visibility to reach a broader audience [ 24]. Such hashtags are commonly referred to as mainstream hashtags, denoting their status as not only the most prevalent hashtags but also semantically accurate. For instance, in the context of Kobe Bryant’s untimely demise,' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
242	page_content='Bryant’s untimely demise, both #KobeDead and #KobeDeath can be utilized, with both possessing accurate semantic meanings. However, the former holds more widespread usage and has achieved the distinction of being a mainstream hashtag. To provide mainstream hashtags, two main challenges need to be addressed. First, comprehending a new tweet presents challenges primarily attributable to the absence of real-time information [ 42,50]. This is a direct consequence of the continuous emergence of numerous new tweets in response to new topics and events. Second, accurately identifying mainstream hashtags beyond semantic correctness remains a challenging task. The reason is that numerous hashtagscould be used to describe a topic, but only a few are mainstream. To address the above challenges, a considerable amount of work has been proposed, which could be divided into two research lines [ 10,13,15,42,43]. Retrievalbased methods retrieve hashtags from a ﬁxed predeﬁned mainstream hashtag list , which could alleviate the' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
243	page_content=', which could alleviate the second problem. However, their ability to fully grasp the meaning of a newly posted tweet in response to emerging topics and events is constrained. Moreover, it is a considerable cost to maintain the predeﬁned list [ 42]. In contrast, generation-based methods [ 30,42,50] demonstrate remarkable proﬁciency in comprehending new tweets and generating semantically accurate hashtags, owing to their substantial pretraining knowledge. Nevertheless, they may encounter diﬃculties when it comes to identifying mainstreamhashtags without enough mainstream information. As a result, the tweet might RIGHT 41 fail to be indexed by a mainstream hashtag on microblog services due to the tags’ unpopularity, weakening the recall rate of microblog searches. Inspired bythe recent success of retrieval-augmented generation technique [ 1,12,21,37,48], therefore, we try to adapt this method to mainstream hashtags recommendation, utilizing the advantages of both retrieval and generation approaches. Typically,' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
244	page_content='approaches. Typically, retrieval-augmented techniques incorporate the results of the retriever, whether explicitly or implicitly, into the generator to enhance the quality of generation. Utilizing this framework, the introduction of a generatorendowed with strong comprehensive capabilities might mitigate the dependency on the quality of the retriever [ 31]. Thus, we could rethink the trade-oﬀ between the quality and the cost of the retriever. Traditional retrieval-based methodsrely on a predeﬁned list of mainstream hashtags, which can ensure the quality of the retrieved information, but maintains such a list at a signiﬁcant cost. To reduce the maintenance burden, we transform the small predeﬁned list into a larger aggregation of existing tweet-hashtags pairs, which can be automatically collected and updated without manual cost. However, this approach carries therisk of introducing numerous low-quality hashtags due to the informal characteristics of social media content. Such hashtags have the potential to' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
245	page_content='have the potential to mislead the generator. As illustrated in Fig. 1, both #KobeDead and #ATL are results of the retriever. Nonetheless, it is noteworthy that #ATL is law-quality, even though tweet 1exhibits the highest degree of similarity with the input tweet. Consequently, it becomes imperative to further improve the quality of retrievedinformation without increasing the cost. Therefore, in this study, we propose a RetrIeval-augmented Generative Mainstream HashTag Recommender (RIGHT ), which combines the retriever and the generator by the retrieval-augmented technique with inserting a selector. Speciﬁcally, our method involves three components: 1) Retriever is utilized to acquire relevant hashtags. We retrieve the tweets most similar to the inputfrom the tweet-hashtags corpus and obtain the corresponding hashtags set. 2) Selector is used to improve the capability of identifying mainstream hashtags. We incorporate three features, the similarity between the input tweet and the retrieved tweet and its' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
246	page_content='the retrieved tweet and its hashtags, as well as the frequency of the hashtags, to enhance the mainstream information. 3) Generator is leveraged to provide strong semantic comprehension and the ability of hashtag generation. We concatenate the selected hashtags with the input tweet and feed it into the generator to obtain the desired hashtags. In this way, we can utilize not only the retrieverand the selector to seek the mainstream hashtags but also the generator to produce the desired hashtags ﬂexibly. We conduct experiments on two large-scale datasets (i.e., English Twitter (THG) and Chinese Weibo (WHG)). Experimental results show that our method achieves signiﬁcant improvements over state-of-the-art baselines. Moreover, as it can be easily incorporated in black-box language models, we also apply ourframework to ChatGPT by zero-shot instruction learning, bringing a 12.7% boost for THG and 18.3% for WHG in F1@1. Finally, to deeply understand this method, we present a detailed analysis. 42 R.-Z. Fan et al.' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
247	page_content='analysis. 42 R.-Z. Fan et al. Fig. 2. Our RIGHT framework consists of a retriever, a selector, and a generator. 2 Methodology We propose RetrIeval-augmented Generative Mainstream HashTag Recommender (RIGHT ), a simple yet eﬀective framework for mainstream hashtag recommendation, which includes three components: retriever, selector, and generator. Overall, we ﬁrst utilize the retriever to retrieve the tweets most similar to the input from the existing tweet-hashtags corpus and obtain the corresponding hashtags set. Then, we adopt a selector to select the hashtags that are most probable mainstream from the retrieved labels using three signals. Finally, We concatenate the selected hashtags with the input tweet and feed it into the generator to obtain the desired hashtags. An overview of our method is shownin Fig. 2. 2.1 Retriever The goal of the retriever is to retrieve the topNtweet-hashtags pairs on the same topic with the input tweet from the existing corpus, aiming to ﬁnd relevant hashtags on the same' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
248	page_content='relevant hashtags on the same topic. Inspired by Wang et al. [ 41], we view the labeled training data as our corpus and index these as input-label pairs, i.e., C={(˜t i,˜Hi)}. Then, given the input tweet t, the retrieval model Rmatches it with all tweets in the corpus and returns the topNmost similar tweet-hashtags pairs together with their scores: {(˜t1,˜H1,˜s1),..., (˜tN,˜HN,˜sN)}=R(t|C), where we denote ˜sias the similarity between tand the i-th retrieved tweet ˜ti. Each ˜Hiconsists of hashtags {˜hi 1,..., ˜hi |˜H i|}. We report the results with sparse retrieval (e.g., BM25 [ 38]) and dense retrieval (e.g., SimCSE [ 11]) in experiments. RIGHT 43 2.2 Selector The goal of the selector is to ﬁlter the low-quality and non-mainstream hashtags existing in the results of the retriever (see Fig. 1). We consider three mainstream features: the similarity between the input tweet and the retrieved tweet and itshashtags, as well as the frequency of the hashtags. Thus, we train a selector to compute the similarity' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
249	page_content='to compute the similarity between the tweet and the hashtags and propose a simple algorithm for hashtag ranking. Training. The training data consists of positive samples and hard negative samples. Each hashtag labeled in a tweet can be viewed as a positive sample t +. However, a signiﬁcant challenge lies in constructing hard negative samples ( t−) to facilitate the eﬃcient selection of mainstream hashtags on the same topic by the selector. Inspired by BERT [ 9], we propose to create a hard negative sample by disturbing the labeled hashtag without changing the semantic meaning. Speciﬁcally, we randomly select a word to: (i) replace with its synonym 70% ofthe time; (ii) delete 10% of the time; (iii) swap with the adjacent word 10% of the time; (iv) insert a synonym after it 10% of the time. Thus, we obtain a training dataset {(t i,t+ i,t−i)|i=1,...,N }. Finally, we utilize contrastive learning to train our selector by minimizing the following loss: LS=−logesim( hti,h+ ti)/τ /summationtextL j=1/parenleftBig' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
250	page_content='j=1/parenleftBig esim( hti,h+ tj)/τ+esim( hti,h− tj)/τ/parenrightBig where simpresents similarity, htindicates the representation of t,Lis mini-batch size, and τis a temperature hyperparameter. Inference. In the inference stage, we propose a simple algorithm for hashtag ranking. Given an input tweet tand the result of the retriever {(˜t1,˜H1,˜s1),..., (˜tN,˜HN,˜sN)}, we put retrieved hashtags into a set {˜h1,..., ˜hM}w h e r ew ed e n o t e Mas the number of diﬀerent hashtags, and record the number of occurrences {f1,...,f M}and the corresponding score of each retrieved hashtag {˜si,1..., ˜si,f i}. Then, we match the input tweet twith all hashtags using the selector Sto obtain the similarity score between the tweet and all hashtags {¨s1,..., ¨sM}: ¨sm=S(t,˜hm). (1) Finally, we average the tweet-to-tweet similarity for each hashtag and add the similarity between the tweet and the hashtag. Since hashtags that occur more frequently are more likely to be mainstream, we magnify the sum of the similarity score and' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
251	page_content='of the similarity score and ranking score with a downscaled frequency: si=( (1 fifi/summationdisplay j=1˜si,j)+¨si)×(1 + (( fi−1)/10)), and sort the hashtags by the ﬁnal score from largest to smallest to select the top-khashtags {˜h1,..., ˜hk}. 44 R.-Z. Fan et al. Table 1. Data statistics for the English Twitter hashtag generation (THG) dataset and the Chinese Weibo hashtag generation (WHG) dataset. # T-H pairs denotes the number of tweet-hashtags pairs. #AvgHashtags denotes the average number of hashtagsin each tweet-hashtags pair. AvgTweetLen denotes the avenge length (token level) of all input tweets. AvgHashtagLen denotes the average length (token level) of all hashtags. Dataset THG Dataset WHG Dataset Train Validation Test Train Validation Test # T-H pairs 201444 11325 11328 307401 2000 2000 # AvgHashtags 4.1 4.1 4.1 1.0 1.0 1.0 AvgTweetLen 39.7 39.6 39.6 87.1 86.8 87.8 AvgHashtagLen 3.1 3.0 3.0 6.6 6.5 6.5 2.3 Generator The goal of the generator is to generate the desired hashtags, given an input tweet' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
252	page_content='given an input tweet tand the selected hashtags {˜h1,..., ˜hk}. We concatenate the input tweet with the retrieved hashtags and separate each hashtag by a special token: I=<t ,SEP1,˜h1,SEP1,˜h2,..., SEP1,˜hk>, and feed it into the generator G, which will output a concatenated sequence O that includes the hashtags, with each hashtag separated by another token: O=<h 1,SEP2,h2,..., SEP2,h|H|>. By easily splitting by the special token, we would obtain the hashtag list H= {h1,h2,...,h |H|}. The generative model could be Transformer-based encoder-decoder architecture (e.g., T5 [ 35], BART [ 25]) or decoder-only architecture (e.g., a series of GPT [ 2,33,34]). Thus, the training stage focuses on the ﬁnetuning of generative models by minimizing the cross-entropy loss: LG=/summationdisplay (I,O )∈D−logp(O|I;θG), where Iis the input sequence consisting of the input tweet and the selected hashtags, Ois the output sequence consisting of the desired hashtags, and θGis the parameters of the generator. 3 Experiments 3.1' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
253	page_content='generator. 3 Experiments 3.1 Experimental Setup Datasets. Our experiments are conducted on two large-scale datasets, which were crawled from oﬃcial media and inﬂuencers of social media [ 30]. The details are shown in Table 1. RIGHT 45 –THG: The English Twitter hashtag generation (THG) dataset has been crawled from oﬃcial Twitter sources, encompassing organizations, media out-lets, and other authenticated users, with the primary objective of acquiring tweets of superior quality. –WHG: The Chinese Weibo hashtag generation (WHG) dataset has been acquired through the systematic extraction of microblogs from Weibo, encompassing notable sources including People’s Daily ,People.cn ,Economic Observe press ,Xinlang Sports , and various other accounts boasting over 5 million followers. These accounts span diverse domains, encompassing politics, economics, military aﬀairs, sports, and more. We use the training datasets as our retrieval corpus. Evaluation Metric. Following previous work [ 30,42], we utilize ROUGE' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
254	page_content='[ 30,42], we utilize ROUGE metrics and F1 scores at Kas our evaluation metric. The average ROUGE score measures the overlap between the generated sequence of hashtags (excluding special tokens) and the reference sequence, including ROUGE-1, ROUGE-2, and ROUGE-L. For F1 scores at K, diﬀerent Kvalues result in a similar trend, so only F1@1 and F1@5 are reported. We report results on the test dataset. Noticeably, for the WHG dataset, where input posts have only one hashtag, F1@1 and F1@5 are identical, so we only report F1@1 for this dataset. Implementation Details. Our implementation details of the retriever, selector, and generator are the following: –For Retriever , we utilize BM25 [ 38] and SimCSE [ 11] (i.e., RoBERTaLarge [ 29] for THG and Bert-Base-Chinese [ 9] for WHG) as our retrievers. Following Gao et al. [ 11], we train our model for 3 epochs with a learning rate of 1e −5. The hyperparameter of Nis set to 10, and the batch size is 6 per device. –For Selector , we use the training datasets from THG' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
255	page_content='training datasets from THG and WHG to construct our hard negative samples, which are subsequently employed for training our selectors in both English and Chinese independently. We utilize RoBERTaLarge for THG and Bert-Base-Chinese for WHG. The temperature τis0.05 and other hyperparameters are the same as the retriever. –For Generator , we ﬁne-tune a T5-base [ 35] for THG and a mT5-small [ 44] for WHG and use Adam [ 22] as an optimizer. We set the weight decay and batch size as 1e −5 and 16 and grid-search the learning rate, training epochs, and the number of concatenated hashtags kfrom {3e −4, 1e −4, 5e −5}, {5, 10}, and {1, 3, 5, 7, 9} respectively. The maximum length is 180 for T5-base and256 for mT5-small. The special token SEP1 and SEP2are<extra _id_0> and<extra _id_1>respectively. All models are trained on four NVIDIA Tesla K80. 46 R.-Z. Fan et al. Table 2. The prompt used for ChatGPT. The Chinese version is its translation. Baseline Instruction ChatGPT I want you to act as a hashtag annotator. I will' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
256	page_content='a hashtag annotator. I will provide you a tweet and your role is to annotate the relevant hashtag. You should use the related knowledge and ﬁnd the topic. I want you only replythe hashtags segmented by “#” and nothing else, do not write explanations. I want you segment the word in a hashtag by space. My ﬁrst tweet is { Input Tweet }. RIGHTChatGPTI want you to act as a hashtag annotator. I will provide you with a tweet, and your role is to annotatethe relevant hashtag. Using your related knowledge, you should identify the topic and reply with only the hashtags segmented by “#”, without anyexplanations. Make sure to capitalize the ﬁrst letter of the word. Make sure to split every word in a hashtag by a space. There are some potentialhashtags:[{ Retrieved TopkHashtags }]. You can decide whether use the part of them or not. My ﬁrst tweet is { Input Tweet }. Baselines. Our baselines consist of retrieval-based methods, generation-based methods, and retrieval-augmented generative methods: –Retrieval-based methods:' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
257	page_content='–Retrieval-based methods: Following Mao et al. [ 30], we construct the predeﬁned hashtags list from all hashtags in the training datasets and select top-4hashtags for THG and top-1 for WHG according to the average number of hashtags in each data item. We apply BM25 and SimCSE to the hashtag recommendation: (i) BM25  is a traditional strong sparse retrieval based on term matching. (ii) SimCSE  is a representative dense retriever, which applies a simple contrastive learning framework to present sentence embeddings on semantic textual similarity tasks. We ﬁne-tuned SimCSE by con-structing positive samples and hard negative samples from BM25. –Generation-based methods: We consider three predominant generative methods: (i) ChatGPT is a powerful large language model to execute various NLP tasks [ 23]. Speciﬁcally, we adopt gpt-3.5-turbo and instruction zero-shot learning to evaluate our task (Prompts are shown in Table 2). (ii) SEGTRM Soft  is the previous SOTA on our datasets, an endto-end generative method' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
258	page_content='endto-end generative method segments selection-based deep transformer. (iii) Seq2Seq  is the ﬁrst generation-based method for hashtag recommendation. Due to the unreality to assume the existence of conversations before publishing the tweet [ 50] and the lack of conversation contexts, we reimplement the Seq2Seq model on the pretrained language model (T5-base for THGand mT5-small for WHG) to formulate this task to a seq-to-seq paradigm. RIGHT 47 –Retrieval-augmented Generative Methods (Ours): We apply our retrieval-augmented framework to ChatGPT by incorporating the retrievalresults into the instruction to prompt the model to generate mainstream hashtags, denoted as RIGHT ChatGPT(Prompts are shown in Table 2). We only use the best retriever on the datasets (i.e., SimCSE for THG and BM25for WHG), due to the high cost of ChatGPT. Moreover, we use BM25 and SimCSE as our retriever of RIGHT, denoted them as RIGHT BM25 and RIGHT SimCSE . Table 3. Main results (%) on the THG and WHG datasets. Bold and underline' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
259	page_content='datasets. Bold and underline indicate the best and second method respectively. We donate ROUGE as RG. ∗indicates statistically signiﬁcant improvements over all baselines (p-value <0.05). Model THG WHG RG-1 RG-2 RG-L F1@1 F1@5 RG-1 RG-2 RG-L F1@1 Retrieval-based Methods BM25 16.23 4.17 15.11 5.92 9.84 61.98 58.76 61.81 48.20 SimCSE 28.43 10.34 26.38 12.40 15.15 59.71 55.81 59.54 47.65 Generation-based Methods ChatGPT 44.60 27.67 39.29 9.72 26.08 32.27 24.54 31.80 7.9 SEGTRM Soft 51.18 37.15 47.05 27.17 29.02 55.51 51.28 54.30 30.72 Seq2Seq 59.90 41.39 59.15 29.75 41.71 66.64 61.71 66.39 48.60 Retrieval-augmented Generative Methods (Ours) RIGHTChatGPT47.54 25.63 44.47 22.39 31.09 48.17 41.51 47.75 26.15 RIGHT BM25 61.60 43.77 60.85 30.27 42.98 70.62∗66.12∗70.35∗53.85∗ RIGHT SimCSE 62.11∗43.86∗61.39∗30.58∗43.23∗68.84 64.19 68.56 51.50 3.2 Main Results A ss h o w ni nT a b l e 3, we can observe that: 1. Among the retrieval-based methods, the performance of SimCSE outperforms BM25 in THG, while BM25 demonstrates' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
260	page_content='THG, while BM25 demonstrates superior performance in WHG. This diﬀerence may be attributed to that English hashtags tend to be concisesummaries, while Chinese hashtags often comprise small sentences extracted directly from the input text. Consequently, dense retrieval approaches utilizing semantic matching may be more suitable for English datasets, while Chinese datasets may beneﬁt more from sparse retrieval techniques based on term matching. 2. Among the generation-based methods, Seq2Seq performs well on both datasets, potentially attributable to the utilization of mainstream hashtagknowledge from the training dataset during ﬁne-tuning. However, ChatGPT lags behind other generation methods, suggesting a deﬁciency in mainstream hashtag knowledge despite its vast repository of general knowledge. 48 R.-Z. Fan et al. Table 4. Ablation study results on the THG datasets. Bold indicates the best method. Model ROUGE-1 ROUGE-2 ROUGE-L F1@1 F1@5 RIGHT 62.11 43.86 61.39 30.58 43.23 w/o Retriever 59.91 41.63 59.23' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
261	page_content='Retriever 59.91 41.63 59.23 29.66 41.70 w/o Selector 60.49 42.06 59.76 30.22 41.95 w/o Generator 36.24 16.02 32.86 24.61 26.73 3. Among the retrieval-augmented generative methods, retrieval augmentation brings the performance of baselines to a new level, demonstrating the eﬀectiveness of our method. For ChatGPT, retrieval augmentation boosts F1@1 performance by 12.67% for THG and 18.25% for WHG, indicating the sub-stantial value of mainstream hashtag knowledge. For RIGHT, both sparse and dense retrievers show the potential to enhance performance compared with Seq2Seq. Speciﬁcally, SimCSE is particularly eﬀective for THG, while BM25performs better for WHG. The reason could be attributed to the superiority in the performance of retrieval-based methods is directly proportional to the enhancement of the retrieval augmentation. Moreover, diﬀerent retrievers excel in diﬀerent scenarios, emphasizing the importance of the careful selection of retrievers based on speciﬁc use cases. The performance of' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
262	page_content='use cases. The performance of theretrieval-based approach serves as a preliminary guide for informed decisionmaking. Overall, our method shows robustness across various scenarios, whether applied with a ﬁne-tuned generation model or a large black box language model.Regardless of the retrieval approach used, our method consistently improves performance. 3.3 Analysis Ablation Study. We conduct an ablation study to explore the impact of each component in RIGHT on THG: 1) w/o Retriever : We remove the retriever and randomly concatenate khashtags from the training dataset with the input tweet. 2)w/o Selector : We remove the selector and directly use the topkhashtags from the retriever’s results by the similarity between the input tweet and the retrieved tweet. 3) w/o Generator : We remove the generator and output the top-4 hashtags produced by the selector. Table 4presents the results, indicating that: 1. The performance improvement is considerable through the integration of the retriever, conﬁrming that the' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
263	page_content='retriever, conﬁrming that the incorporation of mainstream hashtag knowledge indeed facilitates accurate hashtag selection. 2. Without the selector, the performance gains are limited, indicating that simply being on the same topic is insuﬃcient. It is crucial to identify and incorporate mainstream hashtags. RIGHT 49 Fig. 3. Our Rouge-1 results in the diﬀerent number of augmented hashtags (i.e., k= 1,3,5,7,9). 3. The generator is crucial in RIGHT, emphasizing the signiﬁcant impact of semantic comprehension on performance. In contrast to the retrieval-based approaches, it is more powerful to directly output the hashtags in the tweethashtags pair that are most similar to the input. Impact of the Number of Augmented Hashtags. To explore the impact of the number of concatenated hashtags with the input tweet, we conduct a series of experiments. Speciﬁcally, we concatenate various topk(k=1,3,5,7,9)w i t h the input tweet for the THG and the WHG datasets. Figure 3demonstrates the Rouge-1 results (other metrics show' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
264	page_content='results (other metrics show the same trends), showing that: 1. Retrieval augmentation aids in improving the performance when a suﬃcient number is considered, suggesting that augmenting more hashtags increases the probability of covering mainstream hashtags and makes the generator more robust in the presence of mismatches from certain hashtags. 2. Upon reaching a certain threshold of the number of augmented hashtags (i.e.,k=7), the performance converges, suggesting that the majority of mainstream hashtags might have already been augmented. Case Study. To validate the successful recall of mainstream hashtags and the potential for further improvement, we analyze the successful and unsuccessful cases and present a representative case study in Table 5. We conclude that: 1. Some retrieved tweets share the same topic as the input tweets but have subpar labeled hashtags (e.g., “fx logix” in Table 5). Fortunately, our generator demonstrates the capability to disregard these irrelevant hashtags. 2. Some retrieved' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
265	page_content='hashtags. 2. Some retrieved tweets are partially relevant to the input tweet. Although the retrieved hashtags align well with the topic of the retrieved tweet, it is not 50 R.-Z. Fan et al. Table 5. An example from the THG test set. Correct results are marked bold. Input: Geeks guide to microsoft teams optimization with windows virtual desktop citrix. Label: microsoft ;windows ;citrix ;wvd Retriever & Selector: citrix ;wvd; fs logix; v mware; azure; aws; microsoft Seq2Seq: microsoft ; windows virtual desktop; citrix ;v d i RIGHT: citrix ;wvd highly pertinent to the primary topic of the input tweet (e.g., “azure” in the retrieved hashtags). Nonetheless, our generator can ﬁlter out these irrelevanthashtags. 3. The generation model produces a semantically accurate but non-mainstream hashtag “windows virtual desktop” by directly copying the original wordfrom the input tweet due to its limited knowledge of mainstream hashtags. However, our retriever and selector eﬀectively identify the corresponding mainstream' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
266	page_content='the corresponding mainstream hashtag in its abbreviated form “wvd”. Our RIGHT successfullyreplaced the original hashtag with the mainstream hashtag, indicating the eﬀectiveness of retrieval augmentation. 4. Seq2Seq generates certain hashtags that are also retrieved by the retriever, while RIGHT fails to generate them (e.g., “microsoft”). These cases constitute less than 1% of the total. We speculate that this discrepancy may be due tothe selector placing the correct hashtags toward the end of the list, leading to reduced conﬁdence and subsequent non-adoption by the generator. 4 Related Works Our work mainly builds on two streams of previous work: hashtag recommendation and retrieval-augmented generation. 4.1 Mainstream Hashtag Recommendation Mainstream hashtag recommendation aims to provide users with short topical and popular tags representing the main ideas of their tweets before publication. Three primary methods have been proposed for this task [ 24]: 1)Keyphrase extraction method formulates this task as' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
267	page_content='formulates this task as keyphrases extraction from source posts [ 14,47,49], which fails to produce hashtags that do not appear in the microblog posts while large freedom is allowed for usersto write whatever hashtags they like. The performance of this method is much lower than other methods. 2) Retrieval-based method aims to retrieve from a predeﬁned hashtag list [ 15,19,43,46], which is limited to generating only the hashtags that are included in the list. In reality, a wide range of hashtags can RIGHT 51 be created every day, resulting impossibility to be covered by a ﬁxed list and the diﬃculty to maintain the list. 3) Generation-based method was proposed [ 30,32,42,50] to overcome the aforementioned challenges, which formulates the task as a sequence-to-sequence generation paradigm, allowing for the creation of a wider range of hashtags that better capture the main ideas of themicroblog post. However, previous studies pay limited attention to mainstream hashtags. Consequently, even though it produces' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
268	page_content='even though it produces semantically correct tags, the tweet might fail to be indexed by a mainstream hashtag on microblog servicesdue to tags’ unpopularity, thus weakening the recall rate of microblog searches. To the best of our knowledge, we are the ﬁrst to alleviate this issue by combining retrieval and generation methods. Meanwhile, we improve the qualityof the retriever at a low cost. 4.2 Retrieval-Augmented Generation The retrieval-augmented generation represents a novel paradigm that merges pre-trained generative models with information retrieval techniques [ 1,26]. Previous research in this ﬁeld primarily has focused on introducing external knowl-edge to address knowledge-intensive tasks [ 4,6–8,17,18,27,39,40,45] and utilizing similar data to enhance the model performance across various natural language processing (NLP) tasks, including image captioning [ 37], keyphrase generation [ 12,21], named entity recognition [ 5,48], and others. Recently, this technique has also been used in large language' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
269	page_content='been used in large language models to alleviate issues like factual hallucination [ 3,20,36], knowledge out-dating [ 16], and the lack of domainspeciﬁc expertise [ 28]. Notably, we adopt this framework to the mainstream hashtag recommendation task, by introducing a selector combining global signals to improve main-stream identiﬁcation. 5 Conclusion In this study, we have proposed a simple yet eﬀective retrieval-augmented generative recommender, designed to utilize the advantage of retrieval and generation methods for mainstream hashtag recommendation. To improve the quality of the retriever’s results at a low cost, we have integrated a selector module into the conventional retrieval-augmented framework. Speciﬁcally, the retriever’s role isto ﬁnd relevant hashtags on the same topic, the selector is employed to enhance the identiﬁcation of mainstream hashtags, and the generator is responsible for combining input tweets and selected hashtags to generate desired hashtags. Wehave conducted extension experiments' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
270	page_content='extension experiments using two extensive datasets to validate the eﬀectiveness of our approach. In future work, it is valuable to explore optimal strategies for combining the retrieval-based method with the generation-based method, as well as developing a co-training approach that jointly reﬁnes the three components. 52 R.-Z. Fan et al. Acknowledgements. This work was funded by the National Natural Science Foundation of China (NSFC) under Grants No. 62372431, and 62006218, the Youth Innovation Promotion Association CAS under Grants No. 2021100, the project under Grants No.2023YFA1011602, JCKY2022130C039 and 2021QY1701, and the Lenovo-CAS Joint Lab Youth Scientist Project. All content represents the opinion of the authors, which is not necessarily shared or endorsed by their respective employers and/or sponsors. References 1. Asai, A., Min, S., Zhong, Z., Chen, D.: Retrieval-based language models and applications. In: ACL, Toronto, Canada, July 2023, pp. 41–46 (2023).  10.18653/v1/2023.acl-tutorials.6 . 2.' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
271	page_content='. 2. Brown, T.B., et al.: Language models are few-shot learners. In: Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., Lin, H. (eds.) NeurIPS (2020). https:// proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64aAbstract.html 3. Cao, M., Dong, Y., Wu, J., Cheung, J.C.K.: Factual error correction for abstractive summarization models. In: EMNLP, November 2020 (2020).  18653/v1/2020.emnlp-main.506 . 4. Chen, D., Fisch, A., Weston, J., Bordes, A.: Reading Wikipedia to answer opendomain questions. In: ACL, July 2017 (2017).  5. Chen, J., Zhang, R., Guo, J., Fan, Y., Cheng, X.: GERE: generative evidence retrieval for fact veriﬁcation. In: SIGIR 2022, pp. 2184–2189. ACM (2022). https:// doi.org/10.1145/3477495.3531827 6. Chen, J., Zhang, R., Guo, J., Liu, Y., Fan, Y., Cheng, X.: CorpusBrain: pre-train a generative retrieval model for knowledge-intensive language tasks. In: CIKM 2022, pp. 191–200. ACM (2022).  7. Chen, J., et al.: Continual learning for generative retrieval over dynamic' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
272	page_content='retrieval over dynamic corpora. In: CIKM 2023, pp. 306–315. ACM (2023).  3614821 8. Chen, J., et al.: A uniﬁed generative retriever for knowledge-intensive language tasks via prompt learning. In: SIGIR 2023, pp. 1448–1457. ACM (2023). https:// doi.org/10.1145/3539618.3591631 9. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT: pre-training of deep bidirectional transformers for language understanding. In: NAACL, June 2019 (2019).  . 10. Ding, Z., Zhang, Q., Huang, X.: Automatic hashtag recommendation for microblogs using topic-speciﬁc translation model. In: COLING, December 2012 (2012).  11. Gao, T., Yao, X., Chen, D.: SimCSE: simple contrastive learning of sentence embeddings. In: EMNLP, November 2021 (2021).  2021.emnlp-main.552 . 12. Gao, Y., et al.: Retrieval-augmented multilingual keyphrase generation with retriever-generator iterative training. In: NAACL (2022).  18653/v1/2022.ﬁndings-naacl.92 . 13. Gong, Y., Zhang, Q., Huang, X.: Hashtag recommendation using Dirichlet process mixture models' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
273	page_content='process mixture models incorporating types of hashtags. In: EMNLP (2015).  org/10.18653/v1/D15-1046 . RIGHT 53 14. Gong, Y., Zhang, Q., Huang, X.: Hashtag recommendation using dirichlet process mixture models incorporating types of hashtags. In: Màrquez, L., Callison-Burch, C., Su, J., Pighin, D., Marton, Y. (eds.) EMNLP (2015).  v1/d15-1046 . 15. Gong, Y., Zhang, Q.: Hashtag recommendation using attention-based convolutional neural network. In: Kambhampati, S. (ed.) IJCAI (2016).  Abstract/16/395 16. He, H., Zhang, H., Roth, D.: Rethinking with retrieval: Faithful large language model inference. arXiv preprint (2022).  17. He, S., Fan, R.Z., Ding, L., Shen, L., Zhou, T., Tao, D.: MerA: merging pretrained adapters for few-shot learning. arXiv preprint arXiv:2308.15982 (2023) 18. He, S., Fan, R.Z., Ding, L., Shen, L., Zhou, T., Tao, D.: Merging experts into one: improving computational eﬃciency of mixture of experts. In: Bouamor, H., Pino, J., Bali, K. (eds.) Proceedings of the 2023 Conference on Empirical' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
274	page_content='2023 Conference on Empirical Methods in NaturalLanguage Processing, Singapore, December 2023, pp. 14685–14691. Association for Computational Linguistics (2023).  19. Huang, H., Zhang, Q., Gong, Y., Huang, X.: Hashtag recommendation using endto-end memory networks with hierarchical attention. In: COLING, December 2016 (2016).  20. Ji, Z., et al.: Survey of hallucination in natural language generation. ACM Comput. Surv. (2023).  21. Kim, J., Jeong, M., Choi, S., Hwang, S.: Structure-augmented keyphrase generation. In: EMNLP (2021).  .  22. Kingma, D.P., Ba, J.: Adam: a method for stochastic optimization. In: Bengio, Y., LeCun, Y. (eds.) ICLR (2015).  23. Kocoń, J., et al.: ChatGPT: jack of all trades, master of none. arXiv preprint (2023).  24. Kwak, H., Lee, C., Park, H., Moon, S.: What is Twitter, a social network or a news media? In: WWW (2010).  cgi?article=7104&context=sis_research 25. Lewis, M., et al.: BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
275	page_content='generation, translation, and comprehension. In: Jurafsky, D., Chai, J., Schluter, N., Tetreault, J.R. (eds.) ACL (2020).  acl-main.703 26. Lewis, P.S.H., et al.: Retrieval-augmented generation for knowledge-intensive NLP tasks. In: Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., Lin, H. (eds.) NeurIPS (2020).  6b493230205f780e1bc26945df7481e5-Abstract.html 27. Li, J., Sun, S., Yuan, W., Fan, R.Z., Zhao, H., Liu, P.: Generative judge for evaluating alignment. arXiv preprint arXiv:2310.05470 (2023) 28. Li, X., Zhu, X., Ma, Z., Liu, X., Shah, S.: Are ChatGPT and GPT-4 generalpurpose solvers for ﬁnancial text analytics? An examination on several typicaltasks. arXiv preprint (2023).  29. Liu, Y., et al.: RoBERTa: a robustly optimized bert pretraining approach. arXiv preprint (2019).  30. Mao, Q., et al.: Attend and select: a segment selective transformer for microblog hashtag generation. Knowl. Based Syst. 254, 109581 (2022).  10.1016/j.knosys.2022.109581 . S0950705122007973 54 R.-Z. Fan et al. 31. Mialon,' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
276	page_content='R.-Z. Fan et al. 31. Mialon, G., et al.: Augmented language models: a survey. arXiv preprint (2023).  32. Ni, S., Bi, K., Guo, J., Cheng, X.: A comparative study of training objectives for clariﬁcation facet generation. In: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Paciﬁc Region, pp. 1–10 (2023) 33. Radford, A., Narasimhan, K., Salimans, T., Sutskever, I., et al.: Improving language understanding by generative pre-training. preprint (2018).  openai.com/research-covers/language-unsupervised/language_understanding_ paper.pdf 34. Radford, A., et al.: Language models are unsupervised multitask learners. preprint (2019).  unsupervised_multitask_learners.pdf 35. Raﬀel, C., et al.: Exploring the limits of transfer learning with a uniﬁed text-totext transformer. J. Mach. Learn. Res. 21, 1–67 (2020).  v21/20-074.html 36. Raunak, V., Menezes, A., Junczys-Dowmunt, M.: The curious case of hallucinations in neural machine translation. In: ACL, June 2021' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
277	page_content='In: ACL, June 2021 (2021).  10.18653/v1/2021.naacl-main.92 . 37. Ramos, R., Elliott, D., Martins, B.: Retrieval-augmented image captioning. In: EACL (2023).  38. Robertson, S.E., Walker, S.: Some simple eﬀective approximations to the 2-Poisson model for probabilistic weighted retrieval. In: Croft, W.B., van Rijsbergen, C.J.(eds.) SIGIR 1994 (1994).  39. Wang, S., Gan, T., Liu, Y., Wu, J., Cheng, Y., Nie, L.: Micro-inﬂuencer recommendation by multi-perspective account representation learning. IEEE Trans. Multi-media 25, 2749–2760 (2022) 40. Wang, S., Gan, T., Liu, Y., Zhang, L., Wu, J., Nie, L.: Discover micro-inﬂuencers for brands via better understanding. IEEE Trans. Multimedia 24, 2595–2605 (2021) 41. Wang, S., et al.: Training data is more valuable than you think: a simple and eﬀective method by retrieving from training data. In: ACL, May 2022 (2022).  . 2022.acl-long.226 42. Wang, Y., Li, J., King, I., Lyu, M.R., Shi, S.: Microblog hashtag generation via encoding conversation contexts. In: NAACL, June' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
278	page_content='contexts. In: NAACL, June 2019 (2019).  10.18653/v1/N19-1164 . 43. Weston, J., Chopra, S., Adams, K.: #TagSpace: semantic embeddings from hashtags. In: EMNLP, October 2014 (2014).  .  44. Xue, L., et al.: mT5: a massively multilingual pre-trained text-to-text transformer. In: Toutanova, K., et al. (eds.) NAACL (2021).  naacl-main.41 45. Zhang, H., Zhang, R., Guo, J., de Rijke, M., Fan, Y., Cheng, X.: From relevance to utility: evidence retrieval with feedback for fact veriﬁcation. In: Bouamor, H., Pino, J., Bali, K. (eds.) Findings of the Association for Computational Linguistics, EMNLP 2023, Singapore December 2023, pp. 6373–6384. Association for Compu-tational Linguistics (2023).  46. Zhang, Q., Wang, J., Huang, H., Huang, X., Gong, Y.: Hashtag recommendation for multimodal microblog using co-attention network. In: Sierra, C. (ed.) IJCAI(2017).  RIGHT 55 47. Zhang, Q., Wang, Y., Gong, Y., Huang, X.: Keyphrase extraction using deep recurrent neural networks on Twitter. In: EMNLP, November 2016 (2016).' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
279	page_content='EMNLP, November 2016 (2016).  org/10.18653/v1/D16-1080 . 48. Zhang, X., et al.: Domain-speciﬁc NER via retrieving correlated samples. In: COLING (2022).  49. Zhang, Y., Li, J., Song, Y., Zhang, C.: Encoding conversation context for neural keyphrase extraction from microblog posts. In: NAACL, June 2018 (2018). https:// doi.org/10.18653/v1/N18-1151 . 50. Zheng, X., Mekala, D., Gupta, A., Shang, J.: News meets microblog: hashtag annotation via retriever-generator. arXiv preprint (2021).  08723' metadata={'title': 'RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation', 'author': 'Run-Ze Fan', 'publish_date': '2024-03-04', 'subject': 'Advances in Information Retrieval', 'doi': 'doi:10.1007/978-3-031-56027-9_3', 'keywords': 'Hashtag recommendation; Retrieval-augmented generation; Social media'}
280	page_content='Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain Chunxi Guo, Zhiliang Tian(B), Jintao Tang, Shasha Li, Zhihua Wen, Kaixuan Wang, and Ting Wang(B) College of Computer, National University of Defense Technology, Changsha, China {chunxi,tianzhiliang,tangjintao,shashali,zhwen,wangkaixuan18, tingwang }@nudt.edu.cn Abstract. Text-to-SQL aims at generating SQL queries for the given natural language questions and thus helping users to query databases.Prompt learning with large language models (LLMs) has emerged as a recent approach, which designs prompts to lead LLMs to understand the input question and generate the corresponding SQL. However, it faceschallenges with strict SQL syntax requirements. Existing work prompts the LLMs with a list of demonstration examples (i.e. question-SQL pairs) to generate SQL, but the ﬁxed prompts can hardly handle the scenariowhere the semantic gap between the retrieved demonstration and the input question is large. In this' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
281	page_content='question is large. In this paper, we propose a retrieval-augmented prompting method for an LLM-based Text-to-SQL framework, involvingsample-aware prompting and a dynamic revision chain. Our approach incorporates sample-aware demonstrations, which include the composition of SQL operators and ﬁne-grained information related to the givenquestion. To retrieve questions sharing similar intents with input questions, we propose two strategies for assisting retrieval. Firstly, we leverage LLMs to simplify the original questions, unifying the syntax andthereby clarifying the users’ intentions. To generate executable and accurate SQLs without human intervention, we design a dynamic revision chain that iteratively adapts ﬁne-grained feedback from the previouslygenerated SQL. Experimental results on three Text-to-SQL benchmarks demonstrate the superiority of our method over strong baseline models. Keywords: Large language model ·Text-to-SQL ·Prompt learning 1 Introduction Text-to-SQL task aims to convert natural' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
282	page_content='task aims to convert natural language question (NLQ) to structured query language (SQL), allowing non-expert users to obtain desired information from databases [ 1,2]. As databases are popular in various scenarios involving different domains (e.g., education and ﬁnancial systems, etc.), it is desirable to train c/circlecopyrtThe Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024 B. Luo et al. (Eds.): ICONIP 2023, LNCS 14452, pp. 341–356, 2024. _25 342 C. Guo et al. a model that generalizes well across multiple domains. To facilitate cross-domain generalization [ 3,4], researchers adapt encoder-decoder architecture [ 5,6], reducing the requirement for speciﬁc domain knowledge via end-to-end training. These approaches require diverse and extensive training data to train the model, which is prohibitively expensive [ 7]. Recent progress focuses on large language models (LLMs) (e.g., GPT-3 [ 8], Codex [ 9]a n dG P T 4[ 10]) with prompt learning [ 11], which refers to using speciﬁc' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
283	page_content='which refers to using speciﬁc prompts or instructions to generate desired responses. Rajkumar et al. [ 12] and Liu et al. [ 13] evaluate several prompt learning baselines for Text-to-SQL tasks. Their ﬁndings show that though it is natural for LLMs to generate text sequences, generating SQL is still a challenge due to the SQL’s strict syntaxrequirements. To address these issues, inspired by few-shot learning [ 11], existing work employs prompting the LLMs with a list of demonstration examples (i.e. question-SQL pairs) to generate SQL queries. However, they typically rely on manual labour to create static demonstration examples tailored to speciﬁc tasks. DIN-SQL [ 14] selects pre-deﬁned samples from each category, SELF-DEBUGGING [ 15] explains the code to LLMs but without explanation demonstration. These methods employ a static demonstration, meaning that the demonstration examples provided to LLMs are ﬁxed and do not adapt or changeacross diﬀerent examples. These static demonstration examples hardly adapt to' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
284	page_content='examples hardly adapt to the scenarios where the semantic gap between retrieved demonstrations and the input question is large, which is called retrieval bias [ 16], commonly appearing in the retrieval-augmented generation. Inspired by [ 17], we argue that providing dynamic demonstrations can be adaptive to speciﬁc samples and schema for SQL generation. Dynamic examplesenable the SQL generation to accommodate various scenarios. By adjusting to speciﬁc instances, demonstrations can be customized to incorporate the necessary query structure, logical operations, and question semantics. This adaptabil-ity makes it easier to generate SQL queries that are relevant and appropriate for various situations. In this paper, we propose retrieval-augmented prompts for an LLM-based Text-to-SQL model, which contains sample-aware prompting and a dynamic revision chain. Speciﬁcally, we propose to retrieve similar SQL queries to con-struct prompts with sample-aware demonstration examples. Notice that users often ask questions' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
285	page_content='users often ask questions in diﬀerent expressions, even if they have the same intention and SQL query. It makes the model hard to retrieve helpful examples. To solvethis issue, we propose to extract the question’s real intention via two strategies: Firstly, we simplify original questions through LLMs to clarify the user’s intentions and unify the syntax for retrieval. Secondly, we extract question skeletonsfor retrieving items with similar question intents. To produce executable and accurate SQL, we design a dynamic revision chain, generating SQL queries by iteratively adapting to ﬁne-grained feedback according to the previous version ofthe generated SQL. The feedback includes SQL execution results, SQL explanations, and related database contents. This dynamic chain manages to generate Retrieval-Augmented Text-to-SQL Framework 343 executable and accurate SQL through automatic interaction between the language model and the database without human intervention. Our contributions are as follows: (1) We develop a' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
286	page_content='as follows: (1) We develop a retrieval-augmented framework for Text-to-SQL tasks by prompting LLMs with sample-aware demonstrations. (2) We propose a dynamic revision chain, which adapts to the previouslygenerated SQL with ﬁne-grained feedback. (3) Our method outperforms strong baseline models on three Text-to-SQL benchmarks. 2 Related Work 2.1 Encoder-Decoder SQL Generation SQL generation tasks have achieved signiﬁcant advancements through the utilization of encoder-decoder architectures [ 2]. On the encoder side, Guo et al. [ 18] proposed IRNET, using attention-based Bi-LSTM for encoding and an intermediate representation-based decoder for SQL prediction. Later, [ 19,20] introduced graph-based encoders to construct schema graphs and improve input representations. Works such as RATSQL [ 1], SDSQL [ 5], LGESQL [ 21],S2SQL,R2SQL, SCORE [ 24], and STAR [ 25] further improved structural reasoning by modelling relations between schemasand questions. GRAPHIX-T5 [ 6] overcomes the limitations of previous methods' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
287	page_content='of previous methods by incorporating graph representation learning in the encoder. Concurrently, RASAT [ 26] also provided T5 with structural information by adding edge embedding into multi-head self-attention. On the decoder side, we divide the methods into four categories: sequencebased methods (BRIDGE [ 27], PICARD [ 3]) directly translate NLQ into SQL query token by token, template-based methods (X-SQL [ 28], HydraNet [ 29]) employ predeﬁned templates to regulate SQL generation and ensure structuralcoherence, stage-based methods (GAZP [ 30], RYANSQL [ 31]) ﬁrst establish a coarse-grained SQL framework and then ﬁlls in the missing details in the frame which calls slot-ﬁlling methodologies, and hierarchical-based methods (IRNet, RAT-SQL [ 1]) generate SQL according to grammar rules in a top-down manner, resulting in a tree-like structure. 2.2 LLM-Based SQL Generation LLM-based models recently emerge as a viable option for this task [ 12,13]. For eﬀectively utilizing, it is important to design appropriate' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
288	page_content='to design appropriate in-context demonstration  and chain-of-thought (CoT) [ 34] strategies that can elicit its ability [ 7]. In terms of searching for demonstrations, DIN [ 14] selects a fair number of demonstration examples from each category (e.g. simple classes, non-nested complex classes and nested complex classes), but they are ﬁxed. Moreover, Guo et al. [ 35] adaptively retrieve intention-similar SQL demonstration examples through de-semanticization of the questions. However, none of these methodscan solve the ambiguous and varied questioning of realistic scenarios. 344 C. Guo et al. Fig. 1. Framework overview: The left half shows retrieval repository construction in three steps. The top three sentences are three speciﬁc instances each. The Green dashedbox presents the training set. The right half is a dynamic revision chain with SQL queries generated by LLM iterations as nodes (green boxes). The output of steps 2 and 4 are collectively referred to as ﬁne-grained feedback. (Color ﬁgure online) As for' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
289	page_content='(Color ﬁgure online) As for the CoT prompting strategy, DIN-SQL [ 14] follows a least-to-most [ 36] prompting method, decomposing Text-to-SQL task into subtasks and solvesthem one by one. Pourreza and Chen et al. explore self-correction [ 14,15], where the LLM explain the question and SQL, providing valuable feedback for improvement. Tian et al. [ 37] propose interactive generation with editable step-by-step explanations, combining human intervention with LLM generation to reﬁne the ﬁnal SQL output. Additionally, Sun et al. [ 38] explore execution-based selfconsistent prompting methods. Nonetheless, creating task-speciﬁc demonstration examples [ 14,15,37,38] demands manual labour. Inspired by some retrieval-related research [ 16,39,40], we develop a retrieval-augmented framework for Text-to-SQL tasks. Our method works through automatic interaction between the LLMs and the databases without human intervention. Moreover, explaining to itself and simple feedbackalone [ 14,15] are weak for digging out errors for' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
290	page_content='for digging out errors for correction. Our approach takes into account all three aspects of ﬁne-grained feedback, which interact with each other to create eﬀective feedback. 3 Methodology Our framework consists of two modules as shown in Fig. 1: (1)Retrieval Repository: (see Sect. 3.1) We construct a retrieval repository with simpliﬁed questions added and then use question skeletons to retrieve sample-aware SQL demonstration examples. (2) Dynamic Revision Chain: (see Sect. 3.2) We further revise the generated SQL queries by adding ﬁne-grained feedback. Retrieval-Augmented Text-to-SQL Framework 345 3.1 Retrieval Repository We construct a retrieval repository consisting of multiple key-value retrieval items, where the keys represent the question skeletons and the values are k sample-aware SQL queries. These processes enable us to generate demonstration examples that showcase the desired behaviours of the LLM. Our method involves: (1) Simplifying original questions to unify various questioning styles(see Sect.' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
291	page_content='questioning styles(see Sect. 3.1.1). (2) Extracting question skeletons to construct a retrieval repository (see Sect. 3.1.2). (3) Retrieving SQL queries according to skeleton similarities (see Sect. 3.1.3). 3.1.1 Question Simpliﬁcation We simplify natural language questions by prompting the LLM with instructions. In this way, we can avoid the frustration of unusual questioning styles and enhance the syntax and wording variety in the repository. Speciﬁcally, we construct a prompt template prompt (.):“Replace the words as far as possible to simplify the question, making it syntactically clear, common and easy to understand: [QUESTION] ”, where “ [QUESTION] ” represents the original natural language question. We then obtain the simpliﬁed question by feeding prompt (Q) into the LLM. We maintain a consistent temperature setting in the language model to ensure that all simpliﬁed sentences exhibit the sameprobability distribution. 3.1.2 Question Skeleton Extraction We then extract question skeletons, including both' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
292	page_content='skeletons, including both original questions and simpliﬁed questions. We follow the method proposed by Guo et al. [ 35] to obtain question skeletons. This process removes speciﬁc schema-related tokens from the questions, focusing solely on the structure and intent. Finally, we take the (question skeleton, SQL) pairs from the training set and store them in the retrievalrepository. Note that the number of samples in the retrieval repository is twice as large as the training set, due to the addition of the simpliﬁed samples. LetD trainrepresent the training set, and Rdenotes the retrieval repository. The original natural language question is denoted as Qo, while Qrrepresents the simpliﬁed question. The question skeletons are denoted as SoandSrfor the original and simpliﬁed questions, respectively. We formalize the composition ofthe retrieval repository as follows: R={(S o,SQL),(Sr,SQL) |(Qo,SQL) ∈D train}. 3.1.3 Sample Retrieval The retrieval process searches for the most similar question skeletons and' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
293	page_content='question skeletons and returnstheir corresponding SQL queries from the retrieval repository. This search is based on the semantic similarity between the skeleton of the new question and the items’ keys in R. 346 C. Guo et al. Speciﬁcally, given a new question /tildewiderQo, we ﬁrst obtain its simpliﬁed sentence /tildewiderQr, and their corresponding question skeletons /tildewiderSoand/tildewideSr, following the same method used in previous two subsections (see Sects. 3.1.1and3.1.2). Then we calculate the cosine similarity scores sobetween the semantic vector of question skeleton /tildewiderSoand all question skeletons SinR. Similarly, we also compute the cosine similarity scores srfor simpliﬁed question skeleton /tildewideSrusing the formula: s=c o s/parenleftBig f(S)·f(/tildewideS)/parenrightBig , where f(.) represents an oﬀ-the-shelf semantic encoder1. Here, /tildewideSwill be instantiated as /tildewiderSoand/tildewideSr,a n d swill be instantiated as soand sr, correspondingly. From these scores, we select' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
294	page_content='From these scores, we select the topkretrieval samples with the highest rankings. Let k1andk2denote the number of samples retrieved from the original question skeleton /tildewiderSoand the simpliﬁed question skeleton /tildewideSrrespectively, such thatk=k1+k2. We then concatenate the ksamples to form a demonstration example as input to the LLM. Our retrieval repository oﬀers LLMs with sampleaware SQL examples, which display a more practical answer space. 3.2 Dynamic Revision Chain We employ LLMs to generate an initial SQL query, and then we iteratively revise the generated SQL queries based on ﬁne-grained feedback, forming a dynamic revision chain. The dynamic revision chain consists of the SQL queries generated by the LLM iteration as nodes and the prompts provided to the LLM as edges.With minimal human intervention, LLMs interact with databases to generate accurate and executable SQL queries in two stages of the dynamic revision chain: (1) assembling prompt based on the ﬁne-grained feedback (see Sect.' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
295	page_content='feedback (see Sect. 3.2.1), and (2) generating SQL via iterative prompting (see Sect. 3.2.2). 3.2.1 Fine-Grained Feedback We collect three ﬁne-grained pieces of information based on the SQL generated in the previous iteration. The intuition is that various information hampers LLMs’focus, so they struggle to extract necessary data from extensive and complex databases. Thus, we should progressively narrow down the scope and prioritize the most likely information. The ﬁne-grained feedback in our approach consistsof three aspects of information: (1)Execution Error Feedback : We feed the SQL query generated by LLM into the database engine (i.e. SQLite) for execution. We then obtain theerror messages reported during the execution and add them to the prompt. It checks whether the predicted SQL can be executed correctly, and reports the speciﬁcs of the error (e.g. “no such table: [TABLE] ”,“no such function: YEAR ”,“misuse of aggregate: COUNT() ”). By incorporating the execution error messages into the prompt, LLM' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
296	page_content='messages into the prompt, LLM can learn from its errors. This helps to generate queries that follow the SQL syntax rules. 1We utilize SBERT [ 41]i no u re x p e r i m e n t . Retrieval-Augmented Text-to-SQL Framework 347 (2)Natural Language Explanation : We prompt the LLM with instructions, converting the SQL predicted in the previous iteration back into its corre-sponding natural language expression. Speciﬁcally, we construct an instruction:“What does this SQL query mean? What are the diﬀerences between the predicted meaning and the question meanings above? ”. The LLM identiﬁes semantic gaps and ﬁlls them by explaining the meaning of its own generated SQL and comparing it to the meaning of the original question. (3)Related Database Contents: We provide the LLM with content details about the database tables and columns involved in the SQL queries predicted in the previous iteration, including the possible values involved in the question. It aims to allow LLMs to simulate execution and thus gener-ate more' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
297	page_content='and thus gener-ate more contextually relevant and accurate SQL queries. Overall, the ﬁne-grained feedback approach aims to enable LLMs to learn from their mistakes, understand the meaning of the SQL queries generated anduse contextual information in the database to generate more accurate and relevant SQL queries. By addressing challenges and focusing on important aspects, the methodology aims to help the LLm better extract the necessary data from complex databases and improve the performance of its query generation. 3.2.2 Iterative SQL Generation Based on prompts with ﬁne-grained feedback, the LLM iteratively generates SQL queries. The intuition for iterative generation is that one iteration of ﬁne-grained feedback might not check for all mistakes, whereas multiple iterations of feedback generation are more likely to get progressively closer to the gold answer. Speciﬁcally, we concatenate three ﬁne-grained feedback components with the previously generated SQL in each iteration, feeding them into the LLM. We' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
298	page_content='feeding them into the LLM. We thenobtain a new SQL and collect new ﬁne-grained feedback based on it, proceeding so to iterative generation. Let’s denote the previous SQL query generated by the LLM as SQL prevand the current SQL query as SQL curr. The ﬁne-grained feedback components are represented as Ferrorfor execution error feedback, FNL for natural language explanation, and FDBfor related database contents. At each iteration i, the LLM generates a new SQL query SQL(i) currby incorporating the ﬁne-grained feedback components: SQL(i) curr= LLM( SQL prev,F(i) error,F(i) NL,F(i) DB). After executing SQL(i) currusing the database engine, we obtain the result R(i) prevfrom the previous iteration and R(i) currfrom the current iteration. To avoid inﬁnite loops, we set a maximum number of iterations Nmax. The termination condition is deﬁned as: R(i) prev=R(i) currori=Nmax. This control mechanism ensures that the generated SQL queries converge to an optimal and executable solution within a reasonable timeframe. 348' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
299	page_content='a reasonable timeframe. 348 C. Guo et al. In this iterative feedback loop, we enable a dynamic interaction between the LLM and the database engine, maximizing the generation of executable SQLwithout extensive human intervention. 4 Experiments 4.1 Experimental Setup 4.1.1 Setting We evaluate our method on text-davinci-003, which oﬀers a balance between capability and availability. We apply FAISS [ 42] for storing the question skeletons and eﬃcient retrieval followed by Guo et al. [ 35]. For the initial simpliﬁcation of questions, we set temperature τ=1.0. When generating SQL samples, we set temperature τ= 0.5. For the number of retrieval samples, we assign k1=4 a nd k2= 4. The maximum number of iterations N is 8. 4.1.2 Datasets (1)Spider  is a large-scale benchmark of cross-domain Text-to-SQL across 138 diﬀerent domain databases. (2) Spider-Syn  is a challenging variant based on Spider that eliminates explicit alignment between questions and database schema by synonym substitutions. (3) Spider-DK  is also a' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
300	page_content='(3) Spider-DK  is also a variant dataset based on Spider with artiﬁcially added domain knowledge. 4.1.3 Evaluation We consider two key metrics: execution accuracy (EX) and test-suite accuracy (TS) [ 46]. EX measures the accuracy of the execution results by comparing them with the standard SQL queries, while TS measures whether the SQL passes allEX evaluations for multiple tests, generated by database augmentation. Note that EX is the most direct indication of the model performance in Text-to-SQL, although it contains false positives. Exact match evaluation is not performed,as multiple correct SQLs exist for one query. We use the oﬃcial TS evaluation procedure, while for EX, we slightly modify the evaluation procedure due to the need to decouple the ﬁne-tuning-based models for independent evaluation. 4.1.4 Baselines We compare to two groups of methods: Fine-Tuning T5-3B Baselines: PICARD  is a technique that constrains auto-regressive decoders in language models through incremental parsing;RASAT , which' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
301	page_content='parsing;RASAT , which incorporates relation-aware self-attention into transformer models while also utilizing constrained auto-regressive decoders; and RESDSQL , which introduces a ranking-enhanced encoding and skeleton-aware decoding framework to eﬀectively separate schema linking and skeleton parsing. Retrieval-Augmented Text-to-SQL Framework 349 Prompting LLMs Baselines: As for the large language models, we use two variants of the Codex family [ 9,12](Davinci andCushman ),PaLM-2 , theGPT-4 model [ 10,14] and the ChatGPT model [ 13]. In addition to a simple baseline assessment model, we choose several recent LLM-based works. DIN decompose the Text-to-SQL tasks into sub-tasks: schema linking, query classiﬁ-cation and decomposition, SQL generation, and self-correction; then performing few-shot prompting with GPT-4 [ 10].SELF-DEBUGGING  adds error messages to the prompt and conducts multiple rounds of few-shot promptingfor self-correction. Few-shot SQL-PaLM  adopts an execution-based selfconsistency prompting' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
302	page_content='selfconsistency prompting approach. 4.2 Main Results 4.2.1 Performance on Spider Dataset Table 1shows how ours performed on Spider compared to baseline methods. Across all three datasets, our methods achieve the highest of execution accuracy (EX) and test suite accuracy (TS). Table 1. Performance comparison on Spider with various methods. “-” indicates that the results are not available. Schema indicates that the prompt contains the SQL for creating the database tables (i.e. tables, columns, value and its type)4. Model Method EX TS T5-3B + PICARD [ 3] 79.3 69.4 RASAT + PICARD [ 26] 80.5 70.3 T5-3B RESDSQL-3B + NatSQL [ 5]84.1 73.5 Few-shot [ 12] 61.5 50.4Codex-cushman Few-shot + Schema [ 12] 63.7 53.0 Few-shot [ 12] 60.8 51.2 Few-shot + Schema [ 12] 67.0 55.1 Few-shot [ 14] 71.0 61.5 DIN-SQL [ 14] 75.6 69.9Codex-davinci SELF-DEBUGGING [ 15] 84.1 Few-shot SQL-PaLM [ 38] 82.7 77.3PaLM2Fine-tuned SQL-PaLM [ 38]82.8 78.2 Zero-shot [ 14] 72.9 64.9 Few-shot [ 14] 76.8 67.4 GPT-4 DIN-SQL [ 14] 82.8 74.2 ChatGPT' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
303	page_content='[ 14] 82.8 74.2 ChatGPT Zero-shot [ 13] 70.1 60.1 Zero-shot 73.1 71.6Text-davinciOurs 85.0 (0.9 ↑)83.2 (5.9 ↑) 350 C. Guo et al. Ours exhibits strong performance on test-suite accuracy, which exceeds the next-best method results in ﬁne-tuning and prompting by 9.7% and 5.9% respec-tively. In terms of EX, ours outperforms the next best method in both ﬁne-tuning and prompting by 0.9%. Comparison with Zero-Shot Prompting Models: Across all three metrics, ours surpasses Codex, ChatGPT and even GPT-4 models utilizing zeroshot prompting, despite they employ the prescribed format as outlined in theoﬃcial guidelines 5. This indicates that although LLMs are trained using a speciﬁc format, their acquired competencies become internalized and subsequently expanded for application within more ﬂexible formats. Comparison with Few-Shot Prompting Models: Ours also outperforms all models in a few-shot setting. The closest EX performance compared to ours is SELF-DEBUGGING, with an iterative prompting strategy as well, but we' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
304	page_content='strategy as well, but we still outperform it by 0.9%. Notice that the two methods with similar few-shot prompting in the Codex-davinci model, the latter performs 10% better thanthe former in both EX and TS. It indicates that the selection of demonstration examples (easy, non-nested complex, and nested complex classes) [ 14]p l a y sa signiﬁcant role. While ours uses an adaptive sample-aware method brings 8.2%more eﬀective than this static demonstration, which suggests that incorporating more eﬀective prompts is crucial for LLMs to understand new speciﬁc tasks. 4.2.2 Performance on Spider-SYN and DK Datasets Table 2shows that ours is signiﬁcantly more robust than baseline methods for Spider variants. As compared to Spider-SYN, ours improved 4.5% on EX and 12.6% on TS. Surprisingly, ours improved by 13.6% over the previous SOTA on Spider-DK. 4.3 Various Diﬃculty Levels Analysis As shown in Table 3, we evaluate our eﬀectiveness at various diﬃculty levels, which are determined by the number of SQL keywords used,' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
305	page_content='number of SQL keywords used, the presence ofnested sub-queries, and the utilization of column selections or aggregations. The results show that ours outperforms the other models at all levels except for the easy level, where it is worse than SQL-PaLM. The improvement in performancewith increasing diﬃculty levels indicates that our model’s strengths become more pronounced as the queries become more challenging. This suggests that our model excels in handling complex SQL queries. 4.4 Ablation Study Figure 2demonstrates with and without each of the two modules at four complexity levels. It shows that the exclusion of any of the modules leads to a 5 . Retrieval-Augmented Text-to-SQL Framework 351 Table 2. Evaluation of our method on Spider-SYN and Spider-DK datasets10.“ ” indicates that the results are not available11. SPIDER-SYN Method EX TS T5-3B + PICARD [ 3] 69.8 61.8 RASAT + PICARD [ 26] 70.7 62.4 Fine-tuning RESDSQL-3B + NatSQL [ 5]76.9 66.8 ChatGPT [ 13] 58.6 48.5 Text-davinci 60.7 60.3 Few-shot SQL-Palm' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
306	page_content='60.7 60.3 Few-shot SQL-Palm [ 38] 74.6 67.4 Fine-tuned SQL-Palm [ 38]70.9 66.4Prompting Ours 81.4(4.5 ↑) 80.0(12.6 ↑) SPIDER-DK Method EX TS T5-3B + PICARD [ 3] 62.5 RASAT + PICARD [ 26] 63.9 Fine-tuning RESDSQL-3B + NatSQL [ 5]66.0 ChatGPT [ 12] 62.6 Text-davinci 66.2 Few-shot SQL-Palm [ 38] 66.5 Fine-tuned SQL-Palm [ 38]67.5 -Prompting Ours 81.1 (13.6 ↑)Table 3. Test-suite accuracy at various complexity levels on Spider. The ﬁrst four rows are from [ 38], which is described as execution accuracy data in the original paper [ 14], but actually, it is test-suite accuracy data. Prompting Easy Medium Hard Extra All Few-shot (CodeX-davinci) [ 14] 84.7 67.3 47.1 26.5 61.5 Few-shot (GPT-4) [ 14] 86.7 73.1 59.2 31.9 67.4 DIN-SQL (CodeX-davinci) [ 14] 89.1 75.6 58.0 38.6 69.9 DIN-SQL (GPT-4) [ 14] 91.1 79.8 64.9 43.4 74.2 Few-shot SQL-PaLM (PaLM2) [ 38] 93.5 84.8 62.6 48.2 77.3 Fine-tuned SQL-PaLM (PaLM2) [ 38]93.5 85.2 68.4 47.0 78.2 Ours (Text-davinci) 91.9 88.6 75.3 63.9 83.2 352 C. Guo et al. decrease in' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
307	page_content='352 C. Guo et al. decrease in performance at all levels of diﬃculty, in terms of hard and extra levels. Decreases in model performance are similar for the w/o revise and w/osimplify settings. Note that both modules of our method are most eﬀective in improving the Spider-DK’s easy level by 13.6% each, which requires additional domain knowledge. This suggests that the simpliﬁcation strategy and dynamicrevision chain strategy contribute to a variety of generalisation issues. Fig. 2. Ablation study of our model components at various complexity levels across three datasets. w/o simplify refers to using a direct retrieval of the question skeletons rather than a strategy of simplifying questions. w/o revise refers to removing the dynamic revision chain module. We found that removing the simpliﬁcation module resulted in a signiﬁcant drop in model performance, particularly in the DK dataset where the overall drop was 12.5%. The impact at diﬀerent diﬃculty levels is in descending orderof extra, hard, easy, and medium.' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
308	page_content='hard, easy, and medium. This is possibly due to the fact that the model can incorporate more external knowledge as a supplementary description when simplifying, especially in the case of more SQL components. Note that w/osimplify is rather more eﬀective for solving easy-level problems than mediumlevel ones, probably because the execution accuracy of easy-level problems is already high and short sentences are more likely to cause ambiguity. Without the revision module, model performance suﬀers more as the diﬃculty level increases. On Spider-DK the model performance decreases by 11.0%,especially on easy-level and extra-level by 13.6% and 13.3% respectively. As higher diﬃculty levels require more knowledge, this suggests that the ﬁne-grained feedback in the revision module eﬀectively complements the domain knowledgerequired for SQL generation. Retrieval-Augmented Text-to-SQL Framework 353 4.5 Iterative Round Analysis From Fig. 3, we observe that the major improvement comes from the ﬁrst two iteration turns. We' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
309	page_content='ﬁrst two iteration turns. We note that in addition to the 4.6% improvement in the ﬁrstiteration of Spider, the other two datasets studied for generalisability, Spider-DK and Spider-SYN, also showed a slight improvement in accuracy in the second iteration over the ﬁrst. This indicates that iterative feedback of ﬁne-grained information from a dynamic revision chain helps to deal with more complex generalisation problems, comparable to multiple reasoning needs to progressivelyderive the target answer. Fig. 3. Analysis of dynamic SQL revision chain with diﬀerent numbers of iteration rounds across three datasets: Spider, Spider-SYN, and Spider-DK. 4.6 Case Study To demonstrate our model, we show a comparison of predicted SQL queries in Fig.4using ChatGPT [ 12], DIN-SQL [ 14], SQL-PaLM [ 38] and Ours. In the ﬁrst example, since the question obviously mentions “ French ”, the general models will be confused about the exact value of the column “ citizenship ” even if they pick it out. Noting that a SQL query must' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
310	page_content='Noting that a SQL query must match the exact word mentioned to ﬁnd the correct answer. Our approach provides the exact value of the database content involved in the ﬁrst ﬁne-grained iteration, which leads toa golden answer. The second example requires only the selection of one item, whereas DINSQL and SQL-PaLM both select two. ChatGPT incorrectly uses the aggregatefunction COUNT() , which in this case is required in conjunction with GROUP BY. Our approach self-corrects the error in the second ﬁne-grained iteration by interpreting the SQL interpretation in natural language. 354 C. Guo et al. Fig. 4. Two illustrative cases from Spider [ 43]. Blue-coloured text is the correct generation, while the red-coloured text indicates the wrong generation. On the right handside,/checkmeans correct SQL while ×means wrong. (Color ﬁgure online) 5 Conclusion We propose retrieval-augmented prompts for an LLM-based Text-to-SQL model. By utilizing sample-aware prompting and a dynamic revision chain, we addressthe challenge of' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
311	page_content='we addressthe challenge of retrieving helpful examples and adapting the generated SQL based on ﬁne-grained feedback. Experimental results on three Text-to-SQL benchmarks demonstrate the eﬀectiveness of our method. Acknowledgements. Research on this paper was supported by National Natural Science Foundation of China (Grant No. 62306330). References 1. Wang, B., Shin, R., Liu, X., Polozov, O., Richardson, M.: RAT-SQL: relation-aware schema encoding and linking for text-to-SQL parsers. ACL (2020) 2. Cai, R., Xu, B., Zhang, Z., Yang, X., Li, Z., Liang, Z.: An encoder-decoder framework translating natural language to database queries. In: IJCAI, July 2018 (2018) 3. Scholak, T., Schucher, N., Bahdanau, D.: PICARD: parsing incrementally for constrained auto-regressive decoding from language models. In: EMNLP (2021) 4. Cai, R., Yuan, J., Xu, B., Hao, Z.: SADGA: structure-aware dual graph aggregation network for text-to-SQL. In: NIPS, December 2021 (2021) 5. Li, H., Zhang, J., Li, C., Chen, H.: Decoupling the' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
312	page_content='C., Chen, H.: Decoupling the skeleton parsing and schema linking for text-to-SQL. arXiv arXiv:2302.05965 (2023) 6. Li, J., Hui, B., et al.: Graphix-T5: mixing pre-trained transformers with graphaware layers for text-to-SQL parsing. arXiv arXiv:2301.07507 (2023) 7. Zhao, W.X., Zhou, K., Li, J., et al.: A survey of large language models. arXiv preprint arXiv:2303.18223 (2023) 8. Brown, T., Mann, B., Ryder, N., et al.: Language models are few-shot learners. In: NIPS, vol. 33, pp. 1877–1901 (2020) 9. Chen, M., Tworek, J., Jun, H., Yuan, Q., de Oliveira Pinto, H.P., et al.: Evaluating large language models trained on code. arXiv arXiv:2107.03374 (2021) Retrieval-Augmented Text-to-SQL Framework 355 10. OpenAI: GPT-4 technical report (2023) 11. Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., Neubig, G.: Pre-train, prompt, and predict: a systematic survey of prompting methods in natural language processing. ACM Comput. Surv. 55(9), 1–35 (2023) 12. Rajkumar, N., Li, R., Bahdanau, D.: Evaluating the text-to-SQL' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
313	page_content='Evaluating the text-to-SQL capabilities of large language models. arXiv arXiv:2204.00498 (2022) 13. Liu, A., Hu, X., Wen, L., Yu, P.S.: A comprehensive evaluation of ChatGPT’s zero-shot text-to-SQL capability. arXiv arXiv:2303.13547 (2023) 14. Pourreza, M., Raﬁei, D.: DIN-SQL: decomposed in-context learning of text-to-SQL with self-correction. arXiv preprint arXiv:2304.11015 (2023) 15. Chen, X., Lin, M., Sch¨ arli, N., Zhou, D.: Teaching large language models to selfdebug. arXiv preprint arXiv:2304.05128 (2023) 16. Song, Y., et al.: Retrieval bias aware ensemble model for conditional sentence generation. In: ICASSP, pp. 6602–6606. IEEE (2022) 17. Min, S., et al.: Rethinking the role of demonstrations: what makes in-context learning work? arXiv preprint arXiv:2202.12837 (2022) 18. Guo, J., et al.: Towards complex text-to-SQL in cross-domain database with intermediate representation. arXiv preprint arXiv:1905.08205 (2019) 19. Bogin, B., Berant, J., Gardner, M.: Representing schema structure with graph neural' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
314	page_content='structure with graph neural networks for text-to-SQL parsing. In: ACL, September 2019 (2019) 20. Chen, Z., et al.: ShadowGNN: graph projection neural network for text-to-SQL parser. In: NAACL, June 2021 (2021) 21. Cao, R., Chen, L., et al.: LGESQL: line graph enhanced text-to-SQL model with mixed local and non-local relations. In: ACL, July 2021 (2021) 22. Hui, B., Geng, R., Wang, L., et al.: S2SQL: injecting syntax to question-schema interaction graph encoder for text-to-SQL parsers. In: ACL, pp. 1254–1262 (2022) 23. Hui, B., Geng, R., Ren, Q., et al.: Dynamic hybrid relation exploration network for cross-domain context-dependent semantic parsing. In: AAAI, May 2021 (2021) 24. Yu, T., Zhang, R., Polozov, A., Meek, C., Awadallah, A.H.: SCore: pre-training for context representation in conversational semantic parsing. In: ICLP (2021) 25. Cai, Z., Li, X., Hui, B., Yang, M., Li, B., et al.: STAR: SQL guided pre-training for context-dependent text-to-SQL parsing. In: EMNLP, October 2022 (2022) 26. Qi, J., Tang,' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
315	page_content='2022 (2022) 26. Qi, J., Tang, J., He, Z., et al.: RASAT: integrating relational structures into pretrained Seq2Seq model for text-to-SQL. In: EMNLP, pp. 3215–3229 (2022) 27. Lin, X.V., Socher, R., Xiong, C.: Bridging textual and tabular data for crossdomain text-to-SQL semantic parsing. In: EMNLP, pp. 4870–4888 (2020) 28. He, P., Mao, Y., Chakrabarti, K., Chen, W.: X-SQL: reinforce schema representation with context. arXiv arXiv:1908.08113 (2019) 29. Lyu, Q., Chakrabarti, K., Hathi, S., Kundu, S., Zhang, J., Chen, Z.: Hybrid ranking network for text-to-SQL. arXiv preprint arXiv:2008.04759 (2020) 30. Zhong, V., Lewis, M., Wang, S.I., Zettlemoyer, L.: Grounded adaptation for zeroshot executable semantic parsing. In: EMNLP, pp. 6869–6882 (2020) 31. Choi, D., Shin, M.C., Kim, E., Shin, D.R.: RYANSQL: recursively applying sketchbased slot ﬁllings for complex text-to-SQL in cross-domain databases. In: CL (2021) 32. Guo, J., et al.: Towards complex text-to-SQL in cross-domain database with intermediate' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
316	page_content='database with intermediate representation. In: ACL, pp. 4524–4535 (2019) 33. Brown, T., Mann, B., et al.: Language models are few-shot learners. In: NIPS, vol. 33, pp. 1877–1901 (2020) 34. Wei, J., et al.: Chain-of-thought prompting elicits reasoning in large language models. In: Advances in Neural Information Processing Systems, vol. 35, pp. 24824– 24837 (2022) 356 C. Guo et al. 35. Guo, C., et al.: A case-based reasoning framework for adaptive prompting in crossdomain text-to-SQL. arXiv preprint arXiv:2304.13301 (2023) 36. Zhou, D., et al.: Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625 (2022) 37. Tian, Y., Li, T.J.J., Kummerfeld, J.K., Zhang, T.: Interactive text-to-SQL generation via editable step-by-step explanations. arXiv preprint arXiv:2305.07372 (2023) 38. Sun, R., et al.: SQL-PaLM: improved large language model adaptation for text-toSQL. arXiv arXiv:2306.00739 (2023) 39. Tian, Z., Bi, W., Li, X., Zhang, N.L.: Learning to abstract for' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
317	page_content='Learning to abstract for memory-augmented conversational response generation. In: ACL, pp. 3816–3825 (2019) 40. Wen, Z., et al.: GRACE: gradient-guided controllable retrieval for augmenting attribute-based text generation. In: Findings of ACL 2023, pp. 8377–8398 (2023) 41. Reimers, N., Gurevych, I.: Sentence-BERT: sentence embeddings using Siamese BERT-networks. In: EMNLP-IJCNLP, pp. 3982–3992. ACL (2019). https:// aclanthology.org/D19-1410 42. Johnson, J., Douze, M., Jegou, H.: Billion-scale similarity search with GPUs. IEEE Trans. Big Data 7, 535–547 (2019) 43. Yu, T., Zhang, R., et al.: Spider: a large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-SQL task. In: EMNLP, June 2019(2019) 44. Gan, Y., Chen, X., Huang, Q., Purver, M., et al.: Towards robustness of text-toSQL models against synonym substitution. In: ACL, July 2021 (2021) 45. Gan, Y., Chen, X., Purver, M.: Exploring underexplored limitations of crossdomain text-to-SQL generalization. In: EMNLP, December' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
318	page_content='In: EMNLP, December 2021 (2021) 46. Zhong, R., Yu, T., Klein, D.: Semantic evaluation for text-to-SQL with distilled test suites. In: EMNLP, pp. 396–411 (2020) 47. Anil, R., et al.: PaLM 2 technical report. arXiv preprint arXiv:2305.10403 (2023)' metadata={'title': 'Retrieval-Augmented GPT-3.5-Based Text-to-SQL Framework with Sample-Aware Prompting and Dynamic Revision Chain', 'author': 'Chunxi Guo', 'publish_date': '2023-11-01', 'subject': 'Neural Information Processing', 'doi': 'doi:10.1007/978-981-99-8076-5_25', 'keywords': 'Large language model; Text-to-SQL; Prompt learning'}
319	page_content='LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base Shuangtao Yang(B), Mao Teng, Xiaozheng Dong, and Fu Bo Lenovo Knowdee (Beijing) Intelligent Technology, Haidian District, Beijing, China {yangst,Maoteng,dongxz}@knowdee.com Abstract. Knowledge base question answering (KBQA) aims to answer natural language questions using structured knowledge bases. Common approaches include semantic parsing-based approaches and retrieval-based approaches. How-ever, both approaches have some limitations. Retrieval-based methods struggle with complex reasoning requirements. Semantic parsing approaches have a complex reasoning process and cannot tolerate errors in earlier steps when generatingthe ﬁnal logical form. In this paper, we proposed a large language model (LLM)based SPARQL generation model, which accepts multiple candidate entities and relations as inputs, reducing the reliance on mention extraction and entity linkingperformance, and we found an entity combination strategy based on' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
320	page_content='combination strategy based on mentions, which can produce multiple SPARQL queries for a single question to boost the chances of ﬁnding the correct answer. Finally, our model achieves state-of-the-artperformance in the CCKS2023 CKBQA competition, F1 score is 75.63%. Keywords: KBQA ·Large Language Model ·SPARQL Generation 1 Introduction Knowledge based question answering (KBQA) [ 1] has recently gained research interest, as it provides an intuitive way to access factual knowledge. The KBQA system makes use of structured knowledge bases such as Freebase, Wikidata, and DBpedia, which havelogically organized entities and relations. A knowledge base typically contains a large number of triples, which can be represented as (head, relation, tail) , the head refers to main entity, the tail refers to another entity or a literal value, and the relation is a directedrelationship between head and tail [ 2]. KBQA systems can infer answers to questions by matching relevant entities and relations. The existing KBQA' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
321	page_content='relations. The existing KBQA approaches can be divided into two main categories: retrievalbased methods [ 3–9] and semantic parsing-based methods [ 10–23]. Retrieval-based methods directly represent and rank entities parsed from the input question. Among them, some methods ﬁrst extract a subgraph containing only question-relevant entities from the knowledge base before performing reasoning. By narrowing the focus to a subset of KB, these methods can reduce the space for reasoning and be more efﬁcient, whilestill struggling with complex questions. In contrast, semantic parsing-based (SP-based) methods parse a question into a logic form like SPARQL [ 10], Lambda-DCS [ 11], and © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023 H. Wang et al. (Eds.): CCKS 2023, CCIS 1923, pp. 304–316, 2023. _24 LLM-Based SPARQL Generation with Selected Schema 305 KoPL [ 12] that can be executed against the KB. However, these methods rely heavily on expensive annotations of intermediate logic' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
322	page_content='of intermediate logic forms and tend to be limited to narrow domains. With the advance of pre-trained language models (PLMs), many works have reformulated the semantic parsing task as a sequence-to-sequence (Seq2Seq) logicalexpression generation problem, which directly translate natural language queries into logical forms. More recently, Large language models(LLM) have made signiﬁcant advancements in natural language processing (NLP), such as GPT-3 [ 24], PaLM [ 25], LLaMA [ 26], which has proven to be an effective technique for improving performance on a wide range of language tasks [ 27]. Considering the large scale of the knowledge graph to process, containing 66,630,393 triplets, 11,327,935 entities, and 408,794 relations, we adopt a semantic parsing-based method with LLM as CKBQA solution. Like traditional semantics-based approaches, our method adopts a staged pipeline architecture.Traditional semantic parsing pipeline comprises mention extraction, entity linking, and SPARQL generation. However, for' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
323	page_content='generation. However, for extremely large knowledge graphs, SPARQL generation performance by traditional semantic parsing pipeline often decreases substantiallydue to error propagation across pipeline. Due to the outstanding capabilities of large language models (LLMs) [ 20], we proposed large language model (LLM)-based SPARQL generation model that accepts multiple candidate entities and relations as inputs, whichhelps to reduce the reliance on mention extraction and entity linking performance. We incorporate an entity relation selection model into the pipeline to prune noisy inputs for the generation model. Additionally, we implement an entity combination strategy based on mentions, which can produce multiple SPARQL queries for a single question to boost the chances of ﬁnding the correct answer. The main contributions of this paper are summarized below: •This work represents the ﬁrst attempt at leveraging large pre-trained language models (LLM) for SPARQL generation to address Chinese knowledge graph' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
324	page_content='Chinese knowledge graph ques-tion answering, achieving top-1 ranking performance in the CCKS2023 CKBQA competition. •We propose an effective SPARQL generation method based on large language models, utilizing mention extraction, entity linking, attribute selection models, and entity combination to provide high-quality inputs for the language models, signiﬁcantlyimproving SPARQL generation quality. The model process is shown in Fig. 1. •Ablation experiments were conducted to assess the importance of each module in SPARQL generation for our approach. 2 Related Work Retrieval-Based Methods. Zhang et al. proposed a subgraph retriever (SR) separate from the subsequent reasoner for KBQA. The SR was designed as an efﬁcient dual-encoder capable of updating the question representation when expanding the path, as well as determining when to stop the expansion [ 3]. He et al. proposed a teacher-student approach for multi-hop KBQA. The teacher network utilized bidirectional reasoning to produce reliable intermediate' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
325	page_content='produce reliable intermediate supervision signals that improved the reasoning of the student network and reduced spurious reasoning [ 4]. 306 S. Yang et al. Fig. 1. SPAEQL generation with selected entity and relations. Mentions (highlighted in white boxes) need to be linked to entites which are from knowledge base. There are two entities (high-lighted in green boxes), we need to obtain all the relations or attributes of each entity, and then use attribute/relation rank model to sort them. The selected entities (in green boxs) and relations (in red boxes) will as input to the SPARQL generation model. The given textual mentions canbe utilized to construct focused SPARQL queries, incorporating the most relevant entities and relations. Semantic Parsing-Based Methods. Purkayastha et al. [ 13] used a Seq2Seq model to generate SPARQL query sketch, and then apply entity and relation linkers to ﬁll in the sketch and produce a complete SPARQL query. Lambda-DCS (lambda dependencybased compositional semantics) [ 11] is' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
326	page_content='semantics) [ 11] is a tree-structured logical Forms, which propose to reduce the complexity in compositionally creating the logical form of a sentence. Cao et al. [ 12] ﬁrst parse the original question into the skeleton of KoPL program, a sequence of symbolic functions, and then train an argument parser to retrieve corresponding arguments of these functions. Seq2Seq Methods. Nie et al. proposed a uniﬁed intermediate representation (GraphQ IR) that bridges the semantic gap between natural language queries and formal graph query languages. GraphQ IR can produce intermediate representation sequences using composition rules consistent with English to capture natural language semantics while main-taining fundamental graph structures [ 14]. Cao et al. proposed a Line Graph Enhanced Text-to-SQL (LGESQL) to extract relational features from text without having to construct meta paths. The Line Graph representation allowed messages to propagate more efﬁciently by considering not just connections between nodes, but' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
327	page_content='between nodes, but also the topology of directed edges [ 15]. Das et al. ﬁrst identify different queries with semantically equivalent components, and then construct a new logical form by combining these matching components from the discovered queries [ 21]. Huang et al. utilize a large model-based LLM-Based SPARQL Generation with Selected Schema 307 algorithm to identify entities and relations within a question, and then generate a query structure with placeholders, which are then populated in a post-processing step [ 22]. Xiong et al. utilize advanced generative pre-trained language models to generate questions from logical form and then make predictions, the auto-prompter has the ability toparaphrase predicates in a consistent and ﬂuent manner [ 23]. LLM-Based Methods. LLM with billions of parameters have achieved state-of-the-art results on many NLP benchmarks by learning powerful contextual representations oflanguage from large amounts of text data. One key development in LLM is the use of self-attention' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
328	page_content='is the use of self-attention mechanism [ 28] and transformer architectures [ 29]. Another important development is the use of pre-training, where models are ﬁrst trained on massive datasetsand then ﬁne-tuned on downstream tasks. LLM transfers broad linguistic knowledge that signiﬁcantly improves performance across many language understanding tasks. One remarkable recent development is the launch of ChatGPT [ 30], a conversational AI system powered by LLMs. ChatGPT has gained widespread public attention for its ability to engage in surprisingly natural conversations, which highlight the substantialprogress LLMs have made in language understanding and generation that allows them to partake in coherent human-like dialogue. 3M e t h o d As shown in Fig. 2, The methodology we propose comprises four fundamental components: 1) extracting textual mentions from the input, 2) linking mentions to entities in theknowledge graph, 3) selecting relevant attributes and relations from these entities, and 4) combining these' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
329	page_content='and 4) combining these entities to generate SPARQL queries. The speciﬁc implementations of each module will be described fully in subsequent sections. The complete descrip-tions of the individual modules’ speciﬁc implementations will be provided in subsequent sections. 3.1 Mention Extraction Mention Extraction is the task of identifying the mention span of all entities in the question [ 31]. Each such span is referred to as an entity mention. The word or sequence of words that refers to an entity is also known as the surface form of the entity. An utterance may contain multiple entity, often also consisting of more than one word. Additionally, a broader classiﬁcation of entities, such as person, location, and organization, cansometimes be assigned. Our mention extraction model architecture is composed of a BERT encoder with a token-level classiﬁer on top followed by a Linear-Chain CRF. We ﬁrst use BERT toencode user question and outputs a sequence of encoded token representations, then a classiﬁcation model' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
330	page_content='then a classiﬁcation model projects each token’s encoded representation to the tag space. We also frame mention extraction as a generative task, and attempt to extract mentions usingChatGLM [ 35]. 308 S. Yang et al. Fig. 2. Method Flow: (a) Mention extraction is carried out on the question. (b) For each mention, top-5 candidate entities are selected from the knowledge graph by using Elasticsearch and rules, and then ranked by the entity linking model. (c) Relation selection is applied to choose the most relevant relations for entities from the previous entity linking results. (d) Candidate entities acrossdifferent mentions are combined and fed into the SPARQL generation model to produce multiple SPARQL queries. 3.2 Entity Linking The task of Entity Linking involves establishing connections between annotated mentions in a given utterance and their corresponding entities within a knowledge base [32–34]. This task was addressed by using popular knowledge bases such as DBpedia, Freebase or Wikipedia. Entity' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
331	page_content='Freebase or Wikipedia. Entity linking serves as a bridge between textual spans and structured entities within a knowledge base, thereby will be beneﬁcial to various downstream tasks like question answering and knowledge extraction. EL aims to link entity mentions in unstructured text to their corresponding entities in a designated knowledge base. Our entity linking model is trained to assign a score to each candidate entity as shown in (1). Speciﬁcally, given the question qand the candidate entity e_text,w eu s e a BERT-based encoder to generate a score indicating the conﬁdence of the link [ 29]. el_score=sigmoid (AVG (BERT ([q:e_text]))) (1) For every mention, we will select top-5 entities according to their linking conﬁdence scores for the next phase. LLM-Based SPARQL Generation with Selected Schema 309 3.3 Entity Attribute/Relation Select When given an entity and its relations, Entity Attribute/Relation Select model can select question related relations, thus the model also learns to score each entity' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
332	page_content='learns to score each entity relation. Speciﬁ-cally, given the question qand the candidate entity relations r_text,w ea l s ou s eaB E R T based encoder to generate a correlation score between the question and either entity attributes or relations. es_score=sigmoid (AVG (BERT ([q:r_text]))) (2) The entity and its relation are represented by triples consisting of the entity, relationship, and tail. For each entity, we will select top-5 relationships based on their correlationscore for the next phase. 3.4 Entity Combination and SPARQL Generation After the phase of entity linking and entity attribute/relation select, we have obtained top-5 entities for each mention, and each entity has top-5 relations, as key supporting evidence. In the SPARQL generation stage, we attempted different methods. Method 1 : The question and all key supporting evidence from different mentions are concatenated as input to the SPARQL generation model, resulting in a single expression. Method 2 : Entities from different elements are' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
333	page_content='from different elements are combined and concatenated within each combination to generate multiple SPARQL queries, which ca be executed against the KB. Unlike Method 1, the approach will produce multiple SPARQL expressions. Taking the question “What are the hotels afﬁliated with Sheraton in Jiangyin?” as an example, after mention extraction, entity linking, and entity attribute/relation selection, we obtaine the most relevant knowledge related to this question from the knowledge graph. In Method 1, we ﬁlled all relevant information into the prompt, obtaining thecomplete prompt as shown below. 请根据问题:\\”隶属于喜来登的酒店在江阴有哪几家?\\”,和候选实体信息: 名称:<喜来登>,属性集:酒店品牌名称,类型,隶属,公司性质,公司名称,附近酒店, 成立时间;名称:<江阴 >,属性集:城市,市花/市树,所属地区,隶属,所属城市,出 生地,gdp,城市网站,隶属于,位置,市长,所在城市,适用地区,分布 区域,所属地区,著名景点,位于,行政区域,属于,家乡;名称:<江阴黄嘉喜来登酒 店 >,属性集:实体名称,酒店品牌名称,酒店入住开始时间,是否有鲜花店,是否有酒 吧,是否有接机服务,是否有接机服务-营业时间,是否有接送服务-营业时间,是否有 温泉,是否有桑拿浴室,是否有允许带宠物,是否有茶室,是否有会议室,是否有桌球 室,是否有管家服务,是否有熨衣服务,是否有图书馆,是否 有wiﬁ服务,是否有游戏室,是否有礼宾服务;名称:<镇江富力喜来登酒店 >,属 性集:实体名称,酒店品牌名称,房型名称,是否有鲜花店,是否有桑拿浴室,酒店入住' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
334	page_content='开始时间,是否有允许带宠物,是否有温泉,是否有高尔夫球场,是否有保龄球馆,是 否有租车服务,是否有大堂吧,是否有多功能厅,是否有网球场,是否有婚宴服务,是 否有叫醒服务,是否有礼宾服务,是否有KTV ,是否有图书馆,是否有会议室;名 称:\\”喜来登\\”,属性集:中文名称,公司名称,对应查询图谱的Sparql的语句为: Please follow the question: \\”Which hotels are afﬁliated to Sheraton in Jiangyin?\\”, and candidate entity information:  Name: <Sheraton >, attribute set: hotel brand 310 S. Yang et al. name, type, afﬁliation, company nature, company Name, nearby hotels, establishment time; Name: <Jiangyin >, attribute set: city, city ﬂower/city tree, region, afﬁliation, city, place of birth, gdp, city website, afﬁliation, location, city Length, city, applicable area, distribution area, belonging area, famous scenic spot, location, administra-tive area, belonging to, hometown; name: <Jiangyin Huangjia Sheraton Hotel >, attribute set: entity name, hotel brand name, hotel Check-in start time, whether there is a ﬂower shop, whether there is a bar, whether there is a pick-up service, whetherthere is a pick-up service-opening hours, whether there is a pick-up' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
335	page_content='whether there is a pick-up service-opening hours, whether there is a hot spring, whether there is a sauna, whether pets are allowed, whether there is a tea room, whether there is a meeting room, whether there is a billiardroom, whether there is a butler service, whether there is an ironing service, whether there is a library, whether there is wiﬁ service, whether there is a game room, whether there is a concierge service; name: <Sheraton Zhenjiang Hotel >, attribute set: entity name, hotel brand name, room type name, whether there is a ﬂower shop, whether there is a sauna, hotel check-in start time, whether pets are allowed, whether there is a hot spring, whether there is a golf course, Is there a bowling alley, is there a car rentalservice, is there a lobby bar, is there a multi-function hall, is there a tennis court, is there a wedding banquet service, is there a wake-up call service, is there a concierge service, is there a KTV , is there a book Museum, whether there is a conference room;  Name:' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
336	"page_content='is a conference room;  Name: \\”Sheraton\\”, attribute set: Chinese name, company name, the Sparql statement corresponding to the graph is: In Method 2, we combined entity information from different mentions, then ﬁlled each combination into the prompt, so we could obtain multiple prompts to generate SPARQL statements. For the combination <Sheraton >,<Jiangyin >, the complete prompt is shown below. 请根据问题:\\”隶属于喜来登的酒店在江阴有哪几家?\\”,和候选实体信息: 名称:<喜来登>,属性集:酒店品牌名称,类型,隶属,公司性质,公司名称,附近酒店, 成立时间;名称:<江阴 >,属性集:城市,市花/市树,所属地区,隶属,所属城市,出 生地,gdp,城市网站,隶属于,位置,市长,所在城市,适用地区,分布区域,所属地区,著 名景点,位于,行政区域,属于,家乡,对应查询图谱的Sparql的语句为: Please follow the question: \\""Which hotels are afﬁliated to Sheraton in Jiangyin?\\”, and candidate entity information:  Name: <Sheraton >, attribute set: hotel brand name, type, afﬁliation, company nature, company Name, nearby hotels, establishmenttime; Name: <Jiangyin >, attribute set: city, city ﬂower/city tree, region, afﬁliation, city, place of birth, gdp, city website, afﬁliation, location, city Length, city,' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}"
337	page_content='location, city Length, city, applicable area, distribution area, area, famous scenic spot, location, administrative area,belonging, hometown, the Sparql statement corresponding to the graph is: After obtaining the complete prompt, we feed it to the LLM to generate SPARQL. We select ChatGLM-6B 1 as the SPARQL generation models. ChatGLM-6B is a pre-trained large language model with 6.2 billion parameters, based on the General Language Model (GLM) architecture. ChatGLM-6B was trained on around 1 trilliontokens of Chinese and English corpus, with additional supervised ﬁne-tuning, feedback 1 . LLM-Based SPARQL Generation with Selected Schema 311 bootstrap, and reinforcement learning using human feedback. This enables ChatGLM6B to generate answers that are aligned with human preference, with ﬂuency in both English and Chinese. We use low-rank adaptation (LoRA) to ﬁnetune ChatGLM-6B for SPARQL Generation [ 36]. The parameter settings used for LoRA ﬁne-tuning are shown in Table 1. Ta b l e 1 . Knowledge Graph' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
338	page_content='Ta b l e 1 . Knowledge Graph Information. Item Quantity lora_alpha 32 lora_dropout 0.1 lora_rank 8 lora_target query_key_value 4 Results The key statistics for the knowledge graph and training data used in this work are presented in Table 2. The knowledge graph contains 66,630,393 triplets, 11,327,935 entities, and 408,794 relations. The training data is comprised of 7,625 examples. Ta b l e 2 . Knowledge Graph and Data Information. Item Quantity Triplet 66,630,393 Entity 11,327,935 Relation 408,794 Train Case 7,625 4.1 Mention Extraction Result We compared several mention extraction methods on CKBQA dataset, including BERT +CRF, Roberta +CRF, and ChatGLM-6b(LoRA). As shown in Table 3, the ChatGLM6b(LoRA) model achieved the highest F1 score. 4.2 Entity Linking Result We compared Bert and Roberta on entity linking task. As shown in the Table 4, RoBerta achieved the higher F1 score of 94.48%, compared to 93.64% for Bert. This indicates RoBerta is more effective for this entity linking task, outperforming Bert' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
339	page_content='task, outperforming Bert by 0.84% interms of F1 score. 312 S. Yang et al. Ta b l e 3 . Mention Extraction Result Method F1 Performance (100%) Bert+CRF 84.5 Roberta +CRF 85.2 ChatGLM-6b(LoRA) 89.4 Ta b l e 4 . Entity Linking Result Method F1 Performance (100%) Bert 93.64 RoBerta 94.48 4.3 Entity Attribute/Relation Select F1 scores for Bert and RoBerta models on an entity attribute/relation selection task are presented in Table 5. RoBerta model achieved the higher F1 score of 95.17%, compared to 94.12% for Bert model, indicating RoBerta is more effective for extracting entity attributes and relations, outperforming Bert model by 1.05% based F1 evaluation metric. Ta b l e 5 . Entity Attribute/Relation Select Result Method Performance (100%) Bert 94.12 RoBerta 95.17 4.4 Entity Combination and SPARQL Generation At this stage, we compared the impact of different entity combination methods on SPARQL generation. Using the same ChatlGLM-6B model and LoRA ﬁne-tuning parameters, we trained and ﬁne-tuned two SPARQL' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
340	page_content='and ﬁne-tuned two SPARQL generation models with differententity combination approaches. Table 6shows the performance of the two entity combination methods on the training and validation set, whis is evaluated using ROUGE-1, ROUGE-2, ROUGE-L [ 37]. To evaluate the correctness of SPARQL, we introduced the Pass Rate metric. ChatGLM-6b-Method2 achieved higher scores across all metrics, with notably large improvements in ROUGE-2 (90.11%vs 85.96%) and Pass rate (68.9% vs 61.5%). This suggests that ChatGLM-6b-Method2 is more effective for SPARQL generation. The pass rate metric measures the ratio of generated SPARQL queries that are syntactically valid and return correct answers on test set. LLM-Based SPARQL Generation with Selected Schema 313 Ta b l e 6 . Entity Combination and SPARQL Generation Result. Method Acc Performance (100%) ROUGE-1 ROUGE -2 ROUGE -L Pass Rate ChatGLM-6b-Method1 91.72 85.96 89.09 61.5 ChatGLM-6b-Method2 94.89 90.11 91.72 68.9 4.5 End to End Performance We conducted ablation experiments to' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
341	page_content='ablation experiments to evaluate the importance of each module in our pipeline. The results of these experiments are shown in Table 7. Table 6shows the incremental impact of on KBQA system from adding different knowledge graph components. We evaluated ﬁve system variations (V1-V5) on the CKBQA training dataset. System V1 uses only a mention extraction (ME) model and SPARQL generation (SG) module, achieving an F1 score of 45.11%. The lack of entity linking, relation selection, and entity combining modules limits its performance. By analyzing the gener-ated SPARQL, we found that errors often occur due to inconsistent entity formats with the knowledge base, making it impossible to obtain answers through SPARQL. System V2 adds an entity linking (EL) module using RoBerta, improving performance to 66.45% F1. Linking mentions to knowledge graph entities provides useful contextual information. System V3 further incorporates an entity attribute/relation selection (ERS) module based on Roberta. This model eliminates' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
342	page_content='This model eliminates interference from irrelevant attributes and relationship of entities in the input, increasing F1 to 69.23%. System V4 adds an entity combination (EC) module. Through this module, we can assemble entity information from different mentions to generate multiple SPARQL queries. Concurrently, we can determine the relevance of each SPARQL query based onrelatedness between entities. The most relevant SPARQL that can retrieve results from the knowledge graph is selected as the ﬁnal generated query. By utilizing this method, we improved the performance of our system to 73.93% F1 score. Even after System V4, we still found a limited number of questions for which it was not possible to generate an accurate SPARQL query that could retrieve answers from the knowledge graph. Therefore, we supplemented with an additional KBQA method basedon triple retrieval. By integrating this approach, we further improved our system’s score to 75.63%. 314 S. Yang et al. Ta b l e 7 . Knowledge Graph Information. ME' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
343	page_content='Graph Information. ME means Mention Extract Model; EL means Entity Linking Model; ERS means Entity attribute/relation Select Model and EC means Entity Combination Module and SG means SPARQL Generation, and Retrieval means Retrieval Method For KBQA. System ME EL ERS EC SG Retrieval Acc (100%) V1√× × ×√× 45.11 V2√ √× ×√× 60.45 V3√ √ √×√× 69.23 V4√ √ √ √ √× 73.93 V5√ √ √ √ √ √75.63 5 Conclusion In this paper, we proposed large language model (LLM)-based SPARQL generation model, which accepts multiple candidate entities and relations as inputs, reducing the reliance on mention extraction and entity linking performance. And we found an entity combination strategy based on mentions, which can produce multiple SPARQL queries for a single question to boost the chances of ﬁnding the correct answer. Finally, we get1st place in CCKS2023 CKBQA competition with F1 score of 75.63%. In the future, we will delve into research on SPARQL query generation with large language models, especially focus on multiple hops and multi' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
344	page_content='on multiple hops and multi constraints query. References 1. Zhang, J., Chen, B., Zhang, L., et al.: Neural, symbolic and neural-symbolic reasoning on knowledge graphs. AI Open 2, 14–35 (2021).  2. Ye, X., Yavuz, S., Hashimoto, K., et al.: RnG-KBQA: Generation Augmented Iterative Ranking for Knowledge Base Question Answering. arXiv e-prints  arXiv .2109.08678 (2021) 3. Zhang, J., Zhang, X., Y u, J., et al.: Subgraph Retrieval Enhanced Model for Multi-hop Knowledge Base Question Answering (2022).  4. He, G., Lan, Y ., Jiang, J., et al.: Improving multi-hop knowledge base question answering by learning intermediate supervision signals. Proceedings of the 14th ACM International Conference on Web Search and Data Mining, pp. 553–561 (2021) 5. Chen, Y ., Wu, L., Zaki, M.J.: Bidirectional Attentive Memory Networks for Question Answering Over Knowledge Bases. arXiv preprint arXiv:1903.02188 (2019) 6. Saxena, A., Tripathi, A., Talukdar, P .: Improving multi-hop question answering over knowledge graphs using knowledge' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
345	page_content='graphs using knowledge base embeddings. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 4498–4507 (2020) 7. Xu, K., Lai, Y ., Feng, Y ., et al.: Enhancing key-value memory neural networks for knowledge based question answering. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, V olume 1 (Long and Short Papers), pp. 2937–2947 (2019) LLM-Based SPARQL Generation with Selected Schema 315 8. Sun, H., Dhingra, B., Zaheer, M., et al.: Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text. arXiv preprint arXiv:1809.00782 (2018) 9. Sun, H., Bedrax-Weiss, T., Cohen, W.W.: Pullnet: Open Domain Question Answering with Iterative Retrieval on Knowledge Bases and Text. arXiv preprint arXiv:1904.09537 (2019) 10. Pérez, J., Arenas, M., Gutierrez, C.: Semantics and complexity of SPARQL. ACM Trans. Database Syst. 34(3), 1–45 (2009) 11. Liang, P .: Lambda' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
346	page_content='(2009) 11. Liang, P .: Lambda dependency-based compositional semantics. Computer Science (2013).  .] 12. Cao, S., et al.: KQApro: a dataset with explicit compositional programs for complex question answering over knowledge base. In: Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (V olume 1: Long Papers). pp. 6101–6119 (2022) 13. Purkayastha, S., Dana, S., Garg, D., Khandelwal, D., Bhargav, G.S.: A deep neural approach to KGQA via SPARQL Silhouette generation. In: 2022 International Joint Conference on Neural Networks. IJCNN, IEEE, pp. 1–8 (2022) 14. Nie, L., et al: GraphQ IR: Unifying the Semantic Parsing of Graph Query Languages with One Intermediate Representation. ArXiv, arXiv:2205.12078 (2022) 15. Cao, R., Chen, L., Chen, Z., Zhao, Y ., Zhu, S., Y u, K.: LGESQL: Line graph enhanced textto-SQL model with mixed local and non-local relations. In: Proceedings of the 59th AnnualMeeting of the Association for Computational Linguistics and the 11th International Joint' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
347	page_content='the 11th International Joint Conference on Natural Language Processing. ACL/IJCNLP 2021, (V olume 1: Long Papers), Virtual Event, August 1–6, 2021, Association for Computational Linguistics, pp. 2541–2555(2021) 16. Das, R., Zaheer, M., Thai, D., et al.: Case-Based Reasoning for Natural Language Queries Over Knowledge Bases. arXiv preprint arXiv:2104.08762 (2021) 17. Kapanipathi, P ., Abdelaziz, I., Ravishankar, S., et al.: Leveraging Abstract Meaning Representation for Knowledge Base Question Answering. arXiv preprint arXiv:2012.01707 (2020) 18. Lan, Y ., Jiang, J.: Query Graph Generation for Answering Multi-Hop Complex Questions from Knowledge Bases. Association for Computational Linguistics (2020) 19. Sun, Y ., Zhang, L., Cheng, G., et al.: SPARQA: skeleton-based semantic parsing for complex questions over knowledge bases. Proceedings of the AAAI Conference on Artiﬁcial Intelligence 34(05), 8952–8959 (2020) 20. Qiu, Y ., Wang, Y ., Jin, X., et al.: Stepwise reasoning for multi-relation question answering' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
348	page_content='question answering over knowledge graph with weak supervision. Proceedings of the 13th International Conference on Web Search and Data Mining, pp. 474–482 (2020) 21. Das, R., Zaheer, M., Thai, D., et al.: Case-based reasoning for natural language queries over knowledge bases. Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 9594-9611 (2021) 22. Huang, X., Kim, J.J., Zou, B.: Unseen entity handling in complex question answering over knowledge base via language generation. Findings of the Association for Computational Linguistics: EMNLP 2021, pp. 547–557 (2021) 23. Xiong, G., Bao, J., Zhao, W., et al.: AutoQGS: auto-prompt for low-resource knowledge-based question generation from SPARQL. Proceedings of the 31st ACM International Conference on Information & Knowledge Management, pp. 2250–2259 (2022) 24. Floridi, L., Chiriatti, M.: GPT-3: Its Nature, Scope, Limits, and Consequences. [2023–08–17].  25. Chowdhery, A., Narang, S., Devlin, J., et al.: PaLM: Scaling Language' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
349	page_content='al.: PaLM: Scaling Language Modeling with Pathways (2022).  26. Touvron, H., Lavril, T., Izacard, G., et al.: Llama: Open and Efﬁcient Foundation Language Models. arXiv preprint arXiv:2302.13971 (2023) 316 S. Yang et al. 27. Min, B., Ross, H., Sulem, E., et al.: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey. arXiv preprint arXiv:2111.01243 (2021) 28. V aswani, A., Shazeer, N., Parmar, N., et al.: Attention is all you need. Advances in Neural Information Processing Syst. 30(2017) 29. Kenton, J.D.M.W.C., Toutanova, L.K.: Bert: Pre-training of deep bidirectional transformers for language understanding. Proceedings of NaacL-HLT, 1, p. 2 (2019) 30. Team O A I. ChatGPT: Optimizing Language Models for Dialogue (2022) 31. Zhao, W.X., Zhou, K., Li, J., et al.: A Survey of Large Language Models. arXiv preprint arXiv:2303.18223 (2023) 32. Lin, Y ., Ji, H., Huang, F., et al.: A joint neural model for information extraction with global features. Proceedings of the 58th' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
350	page_content='Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 7999–8009 (2020) 33. Wu, L., Petroni, F., Josifoski, M., et al.: Scalable Zero-Shot Entity Linking with Dense Entity Retrieval. arXiv preprint arXiv:1911.03814 (2019) 34. Li, B.Z., Min, S., Iyer, S., et al.: Efﬁcient One-Pass End-to-End Entity Linking for Questions. arXiv preprint arXiv:2010.02413 (2020) 35. Du, Z., Qian, Y ., Liu, X., et al.: Glm: General Language Model Pretraining with Autoregressive Blank Inﬁlling. arXiv preprint arXiv:2103.10360 (2021) 36. Hu, E.J., Shen, Y ., Wallis, P ., et al.: Lora: Low-Rank Adaptation of Large Language Models. arXiv preprint arXiv:2106.09685 (2021) 37. Lin, C.Y .: Rouge: a package for automatic evaluation of summaries. Text Summarization Branches Out, pp. 74–81 (2004)' metadata={'title': 'LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base', 'author': 'Shuangtao Yang', 'publish_date': '2023-10-26', 'subject': 'Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence', 'doi': 'doi:10.1007/978-981-99-7224-1_24', 'keywords': 'KBQA; Large Language Model; SPARQL Generation'}
351	page_content='A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks Eghbal Ghazizadeh(&)and Pengxiang Zhu Whitireia Polytechnic, 450 Queen Street, Auckland 1010, New Zealand Eghbal.ghazizadeh@whitireia.ac.nz Abstract. In this research paper, a comprehensive literature review was undertaken in order to analyze Natural Language Processing (NLP) applicationbased in different domains. Also, by conducting qualitative research, we will tryto analyze the development of the current state and the challenge of NLP technology as a key for Arti ﬁcial Intelligence (AI) technology, pointing out some of the limitations, risks and opportunities. In our research, we rely onprimary data from applicable legislation and secondary public domain data sources providing related information from case studies. By studying the structure and content of the published literature, the NLP-based applicationshave been clearly classi ﬁed into different ﬁelds which include natural language understanding, natural' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
352	page_content='understanding, natural language generation, voice or speech recognition, machine translation, spell correction and grammar check. The developmenttrend, open issues and limitations have also been analyzed. Keywords: Natural Language Processing /C1Voice recognition /C1Artiﬁcial intelligence /C1NLP applications 1 Introduction NLP technology converts daily oral or written language into binary code that can be recognized by the machine so that the machine can understand the real meaning ofhuman beings [ 1]. The NLP technology was primarily designed to study how to match the input content on the semantic level, and it also has certain common-senseknowledge and reasoning ability. This is a comprehensive subject across multiplesubjects such as mathematics, psychology, computer science, and linguistics. It isdivided into Natural Language Understanding (NLU) and Natural Language Generation (NLG). Young [ 2] indicated that NLP is one of the important branches of computational linguistics and a very active ﬁeld in AI' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
353	page_content='and a very active ﬁeld in AI research. The NLP technology has achieved tremendous results and is rapidly practiced in all industries even though it hasbeen a short time in its development. Industries supported by NLP, such as AI, are alsoconstantly breaking new ground and becoming the focus of the investment market. The objective demand for NLP in the computer ﬁeld is language translation. Warren Weaver was the ﬁrst person who used computers for language translation. Georgetown University and IBM conducted a machine translation experiment of ©Springer Nature Switzerland AG 2021 K. Arai et al. (Eds.): FTC 2020, AISC 1288, pp. 634 –647, 2021.  Russian to English on an IBM-701 computer in 1954 [ 3]. This is the world ’sﬁrst application of computers in the ﬁeld of non-numerical computing information processing. The main technique adopted by Noam Chomsky [ 4] was syntactic matching in pattern recognition but there was a lack of mature syntactic analysis. In 1972, Noam Chomsky developed the famous Augmented' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
354	page_content='the famous Augmented Transition Network (ATN) by basing the development from his natural language information retrieval system. In the 1980s,various new grammatical systems emerged, such as generalized phrase structuregrammar, lexical functional grammar, and functional uni ﬁcation grammar [ 3]. In the 1990s, Corpus Linguistic research became popular, and many countries and academicinstitutions successively launched extensive corpora or knowledge bases in differentlanguages [ 4]. These linguistic achievements have greatly improved the features of NLP systems, and well-known practical systems such as American METAL and LOGOS, Japanese PIVOT and HICAT, French Ariane and German SUSY have emerged [ 4]. Cambria & White [ 1] pointed out that the research and development of NLP in the past 60 years can be divided into NLU, NLG, machine translation, voicerecognition, and check for spelling and grammar. There are many dif ﬁculties in NLP, but the key factor of the dif ﬁculties is nothing more than the numerous' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
355	page_content='more than the numerous ambiguities or ambiguities that exist in natural language textsand conversations [ 2]. If the ambiguity of language units at all levels cannot be properly handled, the computer cannot accurately understand the meaning of natural language expressions. Moreover, the problem of acquiring contextual content is also a challenge for machine translation. When understanding a sentence, the exact meaningof the sentence is usually inferred according to the context in which the sentence islocated. Taking pronouns as an example, to understand what pronouns refer to, theprevious sentence must be inferred. Zhang [ 5] summarized the drawbacks of this technology, mainly re ﬂected in the limitations of the current system and the necessity of manual operation. From the literature research, it is found that the current development prospects of NLP are all positive and optimistic, and the research on risks and challenges is relatively lacking. We need to objectively evaluate and study the development of' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
356	page_content='and study the development of allcriteria of NLP. In this research, we will try to address NLP ’s challenges with considering the below research questions: RQ1: What are the main ﬁelds which uses NLP technology? RQ2: What have been the limitations of NLP technology in recent years?RQ3: What are the main risks of developing NLP technology in the future? Based on document analysis, this article will summarize a brief development history on NLP. Then, it will illustrate the applications of NLP. We also brie ﬂy discuss the limitations of NLP and the current and future studying of NLP. The research paperaims to provide underestimated methods for researchers, scholars, and companies whowant to keep pace with NLP technology and applications in the past, present, andfuture. Our work helps to fully understand the development and application of NLP and hopes to provide a research basis for researchers, scholars and companies who will research and develop NLP technology and its applications in the future. Based on the' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
357	page_content='in the future. Based on the content analysis method, we emphasized our interest in academia and determined threeA Systematic Literature Review of Natural Language Processing 635 main research directions: (i) classi ﬁcation of the application range based on NLP in many ﬁelds (ii) limitations to create value in these areas and (iii) by providing promising research paths, challenges and opportunities, conduct further research on theroad map to guide researchers. It is worth mentioning that since NLP technology is continuing to grow at a very fast rate, this study cannot be considered exhaustive. This article will initially introduce the development history and current research results of NLP technology; it will then brie ﬂy introduce the framework structure and the current application ﬁelds and applications. Then, through a systematic literature review method, a descriptive analysis is performed on the retrieved documents. Next, aconceptual model of this research will be analyzed. After that, it classi ﬁes and' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
358	page_content='After that, it classi ﬁes and summarizes the current applications based on NLP technology. Next, it lists the currentproblems and challenges of NLP technology and presumes the future trend of this technique. Finally, it gives the conclusion of this research. 2 NLP Overview NLP is the processing of information such as the shape, sound, and context of natural language with a computer [ 6]. Realizing the exchange of information between humans and machines is an important issue of common concern in AI, computer science and linguistics. Speci ﬁc forms of NLP cover machine translation, text summarization, text categorization, information extraction, speech synthesis, and voice recognition. Gurbuz pointed out that the NLP mechanism involves two processes, including NLU and NLG. NLU means that real content can be recognized by the computer, while, on theother hand, NLG is focusing on a natural language text. The methods of NLP can be summarized into the rule method, statistical method and rule statistical method.' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
359	page_content='and rule statistical method. From a methodological perspective, the rule method iscalled the rationalist method, and the statistical method is called the empirical method. The architecture of the whole text processing technology is shown in Fig. 1. First, each word is marked as a separate text, and then the data is pre-trained using learningmodels such as word2vec and GloVe. After that, the pre-trained results are input intovarious deep learning applications to use in different NLP applications [ 7]. Fig. 1. The technical architecture of NLP636 E. Ghazizadeh and P. Zhu Liu & Zhang [ 8] proposed that usually a linguist ﬁrst writes a rule base, such as a dictionary, and then a technical expert builds an algorithm applied to explain andexecute the rule library, as shown in Fig. 2. Speci ﬁcally, the syntactic analyzer analyses the input sentence into a syntactic structure according to the set natural language grammar and then maps the grammatical symbol structure to the semantic symbol structure according to the' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
360	page_content='structure according to the semantic rules. The statistical method is used to predict the parameters in the statistical model through the training data in the corpus, to establish a statistical language processingmodel [ 8]. The corpus is established by a linguist, and the computer scientist is responsible for establishing statistical models, using the corpus to train model parameters, and writing algorithms to ﬁnd the solution, as shown in Fig. 3. Rule statistics method is the fusion of rule law and statistical law, which fully absorbs the advantages of the two rules. The rule method is easy to express complexlanguage knowledge, and the expression of language knowledge is more intuitive andﬂexible. However, the coverage of language knowledge is low, and the lack of a uni ﬁed conﬂict resolution mechanism for language knowledge. The statistical model of the statistical method provides a uni ﬁed con ﬂict resolution mechanism. Also, the largescale number guarantees a broad coverage of language knowledge; at the' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
361	page_content='of language knowledge; at the same time, it is not good at expressing complex and deep language knowledge, therefore, it is notgood for languages with scarce data solutions [ 1]. Statistical methods have been continuously improved in the development process, gradually absorbing the advantages of the rule method to make up for their Fig. 2. Process of rule method Fig. 3. Process of statistical methodA Systematic Literature Review of Natural Language Processing 637 shortcomings. Statistical models tend to be more complex, and even some models are directly built based on rule representation, which can express very complex languageknowledge. Rule statistics method is the clever integration of the two forms. At present,this method has become the mainstream method of NLP [ 9]. In our research, we found that the analysis of NLP is extremely extensive, and various classi ﬁcation methods are emerging one after another; each of which has its rationality. From the technology aspect, there are two categories; basic' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
362	page_content='are two categories; basic technology andapplied technology which we have summerized in Table 1. 3 Research Methodology In this article, based on the research process mentioned by Briner [ 10], combined with some of the functions mentioned by Moher [ 11] in the PRISMA statement, under the principles of transparency, reproducibility and science, the literature of NLP applica-tions is provided. The literature study is carried out through the following steps: 1. Clarify the research purpose and prepare the corresponding research plan. 2. Record and analyze the research results according to the research plan.3. Summarize the research records and form a research report. 3.1 Locating Studies In this research paper, most of the well-known library such as AIS library, Google Scholar, Science Direct, ACM digital Library are used as the data sources, and keywords are searched based on the research questions. Irrelevant records such as duplicate records and meeting notices are ﬁltered out, and 22 related papers are' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
363	page_content='and 22 related papers are ﬁnally retrieved. Figure 4shows the search strategy ﬂow chart.Table 1. Technical classi ﬁcation of NLP. Basic technology Application technology Grammar and syntax analysis Semantic analysisDiscourse analysis Knowledge graph Language cognitive modelLanguage knowledge representation and deeplearningMachine translation Information retrievalemotion analysis Automatic question and answer Automatic digestInformation extractionInformation recommendation and ﬁltering Text classi ﬁcation and clustering Text recognition638 E. Ghazizadeh and P. Zhu 3.2 Study Selection and Evaluation By pre-de ﬁning the criteria of inclusion and exclusion for the literature review (see Table 2), the author independently evaluated the articles retrieved based on this criterion. Firstly, the assessment is according to the title of the peer review research papersand then by viewing the abstract. Articles that do not meet the standards are removedfrom the list of candidate articles. However, the reasons are' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
364	page_content='However, the reasons are recorded and included in the table. After that, the content of the articles was checked, and more articles that did Fig. 4. Flowchart of the search strategy Table 2. Inclusion and exclusion criteria Selection criteriaScienti ﬁc database Inclusion Peer-reviewed articles, conference papers Limited to the past ten years Exclusion Filtering by title Generic articles focus on NLP technology Filtering by abstractSoftware-oriented articles focus on NLP technology Filtering by full textTechnical articles focus on NLP technologyA Systematic Literature Review of Natural Language Processing 639 not meet the criteria were ignored. Also, the content which does not focus on the NLP technology was removed. 3.3 Analysis and Synthesis For all selected articles that meet the chosen criteria, authors have independently reviewed their contents. Moreover, in this research, the selected articles have beensummarized. 4 Descriptive Analysis This article deliberately selected 22 articles published between' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
365	page_content='22 articles published between 2009 and 2019 forresearch and analysis. The aim of this descriptive analysis is as follows: (i) lists thecurrent research trends and related applications of NLP technology; (ii) summarizes theresearch methods in the ﬁeld from the literature; (iii) provides suf ﬁcient evidence for the classi ﬁcation of NLP applications in the following sections. The distribution of the subject and type of literature over time will be a key criterion for descriptive analysis. Figure 5shows the annual statistical conclusion of the selected papers. It shows that the volume of research literature was the largest, reaching 4, in 2015. This is basedon the growth of deep learning technology and the improved maturity of this tech-nology, which results in a highly accurate output, thereby attracting people ’s interest in the use of this technology whilst also increasing the developer ’s enthusiasm. It should be noted that due to the limited number of articles selected in this article, it may not reﬂect' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
366	page_content='article, it may not reﬂect the real situation. 5 Taxonomy of NLP-Based Applications With the continuous deepening and development of NLP research, the ﬁelds of NLP applications are getting wider and wider. Especially with the rapid advancement ofdeep learning technology, the development of NLP applications has also become more Fig. 5. Year-wise analysis of the chosen public literature per year640 E. Ghazizadeh and P. Zhu rapid and more accurate. Figure 6shows the Mind map (the result of our descriptive analysis) of NLP technology and its applications. Gurbuz [ 12] found that there are two types of NLP applications; text application and voice application. Text applications include intelligent search engine and intelli-gent retrieval based on natural language understanding, intelligent machine translation,automatic summarization, text synthesis, text classi ﬁcation, ﬁle organization, intelligent automatic composition system, automatic judgment system, information ﬁltering, spam processing, literary research,' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
367	page_content='literary research, ancient text research, grammar proo ﬁng, text data mining, intelligent decision-making, and computer programming based on natural language.Voice applications include machine simultaneous interpretation, intelligent remote teaching and answering, voice control, intelligent customer service, machine chat, intelligent staff, intelligent transportation information service, intelligent interpretation,real-time interpretation of sports news, voice mining and multimedia mining, multi-media information extraction, text conversion, and intelligent help system for thedisabled. Due to limitations, this article only introduces some more frequent applica-tions. Table 3and Table 4show the main characteristics and commercial values of these common applications. Fig. 6. Mind map of NLP applications Table 3. Main characteristics of frequent NLP applications Application Performance Popularity Maturity Knowledge graph Slow Low Low Machine translation Middle High MiddleText categorization Slow Low LowSearch' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
368	page_content='Slow Low LowSearch engine Quick High HighRecommended system Quick Middle MiddleA Systematic Literature Review of Natural Language Processing 641 5.1 Knowledge Graph The knowledge graph can describe complex associations [ 9], and the most well-known is to be used in search engines to enrich search results and provide structured results for search results. According to the application model, the application of knowledge graphcan be divided into semantic search, knowledge question answering, and knowledge-based big data analysis and decision-making. Semantic search utilizes the establishment of a large team of knowledge bases to semantically annotate search keywords and document content to improve searchresults, such as Google and Baidu embedding knowledge graphs in search results.Knowledge question and answer is a question and answer based on the knowledge base, through semantic analysis of the question sentence, and then parse it into a structured query to obtain answers in the existing knowledge base. In the' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
369	page_content='knowledge base. In the analysis anddecision-making of big data, the knowledge graph plays an auxiliary role. 5.2 Machine Translation Machine translation is the most well-known application of NLP. Generally, machine translation is used as a part of an application, such as cross-language search anddrainage [ 13]. At present, the research institutions and enterprises (such as IBM, Google, and Microsoft) have successively established development teams of machinetranslation to specialize intelligent translation research. Since 2011, with the rapiddevelopment of speech recognition, machine translation technology, and Deep Neural Network (DNN) technology, research on the automatic translation of spoken language has become a new research hotspot in the ﬁeld of information processing. For example, Google of ﬁcially launched an upgraded version of its machine translation service on its Android system in January 2011. 5.3 Text Categorization Text classi ﬁcation refers to the process of classifying a large number of' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
370	page_content='classifying a large number of documents into one or more categories based on the content or attributes of the documents [ 7]. The key problem of this technology is how to construct a classi ﬁcation model and use this model to map unknown documents. It is possible to classify different journals, news reports, and even multiple documents according to their ﬁelds. An important application of text classi ﬁcation is spam email detection. With the signi ﬁcant development of network technology, a lot ofTable 4. Commercial values of frequent NLP applications Application Values Satisfaction Provider Knowledge graph High Good Google, Microsoft, Apple, IBM Machine translation High Good Google, BaiduText categorization Middle Bad Net ﬂix, Facebook, Twitter Search engine High Middle Google, Baidu, Yahoo Recommended system High Bad Net ﬂix, Facebook, LinkedIn, Twitter642 E. Ghazizadeh and P. Zhu information has been generated by users all over the world. It would be a timeconsuming and unrealistic work if relying on' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
371	page_content='work if relying on manual sorting. Currently, this technol-ogy has become extremely important. 5.4 Search Engine NLP techniques such as word sense disambiguation, syntactic analysis, and referential resolution are often used in search engines [ 14]. The responsibility of a search engine is not only to help users ﬁnd answers but also to help users ﬁnd the services they need to connect people and the physical world. The most basic model of a search engine is toautomatically aggregate enough content, parse, process and organize it, and return thecorresponding result to the user. Every link requires natural language processing. Userscan search for fuzzy requirements such as weather, calendar, ticket, and exchange ratethrough the search engine, and the results will be presented directly. Users can alsosearch for complex questions, and the search engine can answer them accurately. NLPtechnology also enables search engines to quickly and accurately return the user ’s search results. 5.5 Recommended System The' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
372	page_content='5.5 Recommended System The recommendation system relies on the cooperation of data, algorithms, humancomputer interaction and other links [ 15]. It uses data mining technology, information retrieval technology, and computational statistics. The target of using the recommen-dation system is to analyze the past information generated by users, which can help theuser to ﬁnd value for themselves. While displaying the information in front of interested users, it solves the problems of information overload and supports users withoutclear requirements through accurate suggestions. 6 Open Issues and Future Trends 6.1 Open Issues Although the related research on NLP is relatively abstract, the most basic research is still on the study of grammar, syntax, and semantics [ 16–23]. The core of concern is language and text. There are many dif ﬁculties in NLP technology, but the critical factor of the dif ﬁculties is nothing more than the various ambiguities or ambiguities that exist in natural language texts and' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
373	page_content='in natural language texts and conversations. Ambiguity refers to language misunderstandings generated during language processing, such as semantic analysis and dis-ambiguation requires a lot of knowledge [ 1]. For example, when performing human language translation, the translator needs to have certain linguistic knowledge andbackground knowledge. Natural language is full of ambiguity, human activities and expressions are very complex, and the vocabulary and grammatical rules in the language are limited, whichleads to the same language form may represent many different meanings [ 17]. Taking Chinese as an example, Chinese generally consists of words forming words, sentencesA Systematic Literature Review of Natural Language Processing 643 forming words, and sentences forming paragraphs, which contain multiple layers of conversion. Statements of the same form may have different meanings in differentcontexts. Conversely, the same meaning can also be expressed in different forms ofsentences. This is the charm of' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
374	page_content='This is the charm of language, but it also brings dif ﬁculties to NLP. In Chinese, the words segmentation problem is one of the disambiguation tasks. Words are the units with the smallest semantics, so the word segmentation problem inNLP is urgently needed to be solved. Since the Chinese do not have natural wordsegmentation in languages like English, the processing of Chinese has an additionallayer of obstacles. In the process of word segmentation, the computer will add aseparator after each word, and sometimes the semantics are ambiguous, and theinsertion of the separator becomes dif ﬁcult. To achieve correct word segmentation, it is necessary to combine the context and fully understand the semantics of the text, which is a challenge for the computer. Language problems at the phrase level still exist. If the ambiguity of language units at all levels cannot be properly handled, the computercannot accurately understand the meaning of natural language expressions. Moreover, the problem of acquiring contextual' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
375	page_content='of acquiring contextual content is also a challenge for machine translation [ 17]. When understanding a sentence, the exact meaning of the sentence is usually inferred according to the context which the sentence is located.Taking pronouns as an example, to understand what pronouns refer to, we mustconsider what we said in the previous sentence. 6.2 Future Trends With the rapid advancement of technology in recent years, people realize that the traditional rationalism method based on syntactic-semantic rules is too complicated, and the empiricism based on statistics can only obtain limited data [ 4]. The primary development trend of NLP is excessive language data processing in the process ofcorpus construction. Statistical mathematics methods are getting more and moreattention, and the language knowledge generated by machine learning methods isbecoming more and more expanded. Besides, NLP technology is also paying more andmore attention to the role of vocabulary, and lexicalism has emerged. The establish-ment' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
376	page_content='emerged. The establish-ment of a vocabulary knowledge base has become a hot issue in development. At present, the research of NLP has expanded from text to speech recognition, syntactic analysis, machine translation, machine learning, and information retrieval. While nat-ural language processing is being continuously applied, it is also promoting otheremerging disciplines, such as the development of bioinformatics. The spotlight offuture research is how to improve the computer ’s ability to process language. In the long run, NLP has broad application ﬁelds and prospects. As an emerging ﬁeld that combines the three subjects of computer science, AI, and linguistics, its longterm development has great signi ﬁcance and impact on all subjects. The future development trend of natural language may be from arti ﬁcial knowledge construction to automatic construction. People can use some explicit knowledge to construct amethod to mine the relationship between language components, thus avoiding thetedious and' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
377	page_content='thus avoiding thetedious and time-consuming process of arti ﬁcial intelligence.644 E. Ghazizadeh and P. Zhu The future development trend is the in-depth combination of NLP and many ﬁelds, thereby creating value for various related industries. The need for NLP in the ﬁelds of banking, electrical appliances, and medicine is increasing. The closer the integration ofNLP with various industries, the more professional service trends will be. 7 Conceptual Model Within AI, NLP is an autonomous development; therefore, it is used to analyze,understand, and generate natural language to facilitate communication between peopleand computer equipment, as well as between people. Its application ﬁelds include machine translation, text, voice, image conversion, chatbots, sentimental analysis, text categorization, and information extraction. Figure 7is our summary of research and brief conceptual model of a knowledge architecture diagram of NLP. 8 Conclusion There are some problems in the process of statistical analysis in' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
378	page_content='of statistical analysis in this article, which theseproblems will affect quantity of the statistical results. Firstly, there are inadequacies in the process of the collection of data. The subjective reason is that the keywords retrieved are not comprehensive enough. It is impossible to consider all relevantkeywords in NLP research. Moreover, there is a problem with missing data. Theprimary reason is that the journals included are not completed. There are also certainproblems, including missing or undetected data. Furthermore, the data cleansing pro-cess also has de ﬁciencies. For example, this article only treats papers with empty authors or institutions as informal papers, and not all authors and institutions such asconference notices and their outputs. Although the statistics of the data mainly rely on automation, the analysis of the statistical results of the data is completely manual and lacks in-depth analysis. Fig. 7. Conceptual model of knowledge architecture of NLPA Systematic Literature Review of' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
379	page_content='Literature Review of Natural Language Processing 645 The research results show that NLP is an emerging technology and is growing in discipline. The advancement of NLP technology is full of opportunities and challenges,difﬁculties and frustrations. The establishment of various models and the proposal of various methods have brought vitality to this technology. Although current systems such as machine translation and speech recognition exist, they are at a very immature stage. The increasingly widespread application of NLP proves that it is in an importantposition in the computer ﬁeld and even the entire scienti ﬁc and technological ﬁeld. It is believed that in the near future, NLP technology will shine even brighter. References 1. Cambria, E., White, B.: Jumping NLP curves: a review of natural language processing research. IEEE Comput. Intell. Mag. 9(2), 48 –57 (2014).  2307227 2. Young, T., Hazarika, D., Poria, S., Cambria, E.: Recent trends in deep learning based natural language processing. IEEE Comput.' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
380	page_content='processing. IEEE Comput. Intell. Mag. 13(3), 55 –75 (2018).  1109/mci.2018.2840738 3. Locke, J., Rowbottom, N., Troshani, I.: Sites of translation in digital reporting. Acc. Auditing Account. J. 31(7), 2006 –2030 (2018).  4. Wu, D., He, D.: Exploring the further integration of machine translation in English-Chinese cross language information access. Program 46(4), 429 –457 (2012).  00330331211276495 5. Zhang, X., Meng, M., Sun, X., Bai, Y.: FactQA: question answering over domain knowledge graph based on two-level query expansion. Data Technol. Appl. 54(1), 34 –63 (2019).  6. Liu, D., Li, Y., Thomas, M.A.: A roadmap for natural language processing research in information systems. In: 2017 Proceedings of the 50th Hawaii International Conference on System Sciences (2017).  7. Dasgupta, S., Ng, V.: Mine the easy, classify the hard. In: Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International JointConference on Natural Language Processing of the AFNLP, ACL-IJCNLP 2009,' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
381	page_content='the AFNLP, ACL-IJCNLP 2009, vol. 2 (2009).  8. Liu, Y., Zhang, M.: Neural network methods for natural language processing. Comput. Linguist. 44(1), 193 –195 (2018).  9. Mills, M.T., Bourbakis, N.G.: Graph-based methods for natural language processing and understanding —a survey and analysis. IEEE Trans. Syst. Man. Cybern.: Syst. 44(1), 59 –71 (2014).  10. Briner, R.B., Denyer, D.: Systematic review and evidence synthesis as a practice and scholarship tool. Oxford (2012).  11. Moher, D.: Preferred reporting items for systematic reviews and meta-analyses: the PRISMA statement. Ann. Intern. Med. 151(4), 264 (2009).  12. Gurbuz, O., Rabhi, F., Demirors, O.: Process ontology development using natural language processing: a multiple case study. Bus. Process Manag. J. 25(6), 1208 –1227 (2019). https:// doi.org/10.1108/bpmj-05-2018-0144 13. Karimi, S., Scholer, F., Turpin, A.: Machine transliteration survey. ACM Comput. Surv. 43 (3), 1 –46 (2011).  E. Ghazizadeh and P. Zhu 14. Taskin, Z., Al, U.: Natural language' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
382	page_content='Z., Al, U.: Natural language processing applications in library and information science. Online Inf. Rev. 43(4), 676 –690 (2019).  15. Wahl, H., Winiwarter, W., Quirchmayr, G.: Towards an intelligent integrated language learning environment. Int. J. Pervasive Comput. Commun. 7(3), 220 –239 (2011).  org/10.1108/17427371111173013 16. Vlachidis, A., Tudhope, D.: Negation detection and word sense disambiguation in digital archaeology reports for the purposes of semantic annotation. Program 49(2), 118 –134 (2015).  17. Chen, X., Qiu, X., Zhu, C., Huang, X.: Gated recursive neural network for Chinese word segmentation. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) (2015).  18. Chen, J., Ding, R., Jiang, S., Knudson, R.: A preliminary evaluation of metadata records machine translation. Electron. Libr. 30(2), 264 –277 (2012).  02640471211221377 19. Mukherjee, S., Bala, P.K.:' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
383	page_content='Mukherjee, S., Bala, P.K.: Detecting sarcasm in customer tweets: an NLP based approach. Indu. Manag. Data Syst. 117(6), 1109 –1126 (2017).  20. Rodrigo, A., Penas, A.: On evaluating the contribution of validation for question answering. IEEE Trans. Knowl. Data Eng. 27(4), 1157 –1161 (2015).  2373363 21. Demirtas, K., Cicekli, N.K., Cicekli, I.: Automatic categorization and summarization of documentaries. J. Inf. Sci. 36(6), 671 –689 (2010).  2070 22. Schubotz, M., Scharpf, P., Dudhat, K., Nagar, Y., Hamborg, F., Gipp, B.: Introducing MathQA: a math-aware question answering system. Inf. Discovery Deliv. 46(4), 214 –224 (2018).  23. Sun, S., Luo, C., Chen, J.: A review of natural language processing techniques for opinion mining systems. Inf. Fusion 36,1 0–25 (2017).  Systematic Literature Review of Natural Language Processing 647' metadata={'title': 'A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks', 'author': 'Eghbal Ghazizadeh', 'publish_date': '2020-10-23', 'subject': 'Proceedings of the Future Technologies Conference (FTC) 2020', 'doi': 'Volume 1', 'keywords': 'Natural Language Processing,Voice recognition,Artificial intelligence,NLP applications'}
384	page_content='Conversation-Driven Reﬁnement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop Dominik Buhl, Daniel Szafarski, Laslo Welz, and Carsten Lanquillon(B) Heilbronn University of Applied Sciences, 74076 Heilbronn, Germany carsten.lanquillon@hs-heilbronn.de Abstract. The value of knowledge-grounded cognitive agents is often limited by a lack of high-quality knowledge. Although advances in naturallanguage processing have substantially improved knowledge-extraction capabilities, the demand for diﬀerent types of knowledge fragments and the potential for error in extraction processes has created a next gener-ation of the knowledge acquisition bottleneck. Instead of waiting for a perfect knowledge base, we propose a design for an agent that is aware of these issues and that actively seeks feedback from users in conversationsto improve its knowledge and extraction processes. This approach allows for imperfection and incompleteness, and for the agent to improve over time. Any feedback' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
385	page_content='over time. Any feedback provided by the users in this conversational appli-cation loop is used to not only reﬁne the underlying knowledge graph, but also to improve the knowledge extraction processes. Eventually, the agent’s knowledge and the quality of its answers rises while talking to itsusers. Keywords: Conversational AI ·Human-in-the-Loop AI · Knowledge-Grounded Cognitive Assistants ·Knowledge Graph Reﬁnement 1 Introduction Chatbots or, more speciﬁcally, task-speciﬁc cognitive agents, also referred to as intelligent virtual assistants, with natural language interfaces are steadily gaining attention and traction in many application domains [ 1,2,56]. This is largely due to the emergent abilities [ 55] of current transformer-based [ 51] large language models [ 5,10,38,39,45,46,59]. Impressive as their generative linguistic abilities may be, in disciplines other than creative ones their value is limited due totheir tendency to hallucinate and, thus, due to lacking faithfulness and factuality . One way to' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
386	page_content='and factuality . One way to address this critical issue is to enhance language models with internal or external knowledge bases [ 19] yielding knowledge-grounded cognitive agents or systems [ 1,16,22,37]. Using internal domainand organization-speciﬁc c/circlecopyrtThe Author(s), under exclusive license to Springer Nature Switzerland AG 2023 H. Degen and S. Ntoa (Eds.): HCII 2023, LNAI 14051, pp. 41–54, 2023. _3 42 D. Buhl et al. knowledge bases can not only enhance faithfulness and factuality, but also helps to protect conﬁdential data and to support knowledge preservation and transferamong co-workers. Yet, the value of knowledge-grounded cognitive agents is often limited due to a lack of relevant and accessible high-quality domain-speciﬁc knowledge. Sincethe manual construction of knowledge bases is time-consuming and tedious, we focus on automating and reﬁning the process of constructing a knowledge graph (KG) as a common form of knowledge base [ 17]. Typically, knowledge fragments are extracted as' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
387	page_content='fragments are extracted as relations between two entities, so-called RDF-triples, from available documents [ 25,49] such as project artifacts and, also, from conversions among co-workers in project-speciﬁc communication channels and groups. Advances in natural language processing (NLP) based on deep learning–in particular the prompting paradigm based on large language models supporting few shot and low resource learning [ 32]–have substantially pushed the limits of information extraction capabilities [ 9,11,15,23,31,49] for an automated KG construction. Nevertheless, we are facing the next generation of the knowledgeacquisition bottleneck. One reason is the ever-increasing demand for diﬀerent types of knowledge fragments. Knowledge extraction approaches must learn to recognize new types of relations and entities over time. Another reason regardsknowledge quality. The automatically extracted knowledge fragments are errorprone and, hence, answers derived from them are at peril of being incorrect. Instead of' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
388	page_content='being incorrect. Instead of waiting for a perfect knowledge base to be established, we propose to embrace imperfection and incompleteness and to design a knowledge-grounded cognitive agent that is aware of these issues and tries to improve over time. The agent should act just as humans do, when facing new and challenging situations.To achieve this, we propose to reﬁne the KG while talking to the users: The cognitive system tries to learn from the humans in the loop (HitL) [ 54,57]. For any uncertain or unknown knowledge fragments, the agent will actively askusers for feedback, who are engaged in conversations and are assumed to know possible answers. In addition, the agent’s background system will keep track of uncertain or out-dated knowledge fragments based on age, conﬁdence levels of the extraction processes, and feedback from its users. Any feedback provided by the users in this conversational application loop is used to not only reﬁne theKG, but also to improve the knowledge extraction processes [' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
389	page_content='extraction processes [ 54,57]. Eventually, the agent’s knowledge and the quality of its answers rise while talking to its users. Consequently, when using cognitive agents, reﬁning the KG is a key issuethat signiﬁcantly aﬀects the performance of the entire system [ 56]. We follow a problem-oriented design science research approach [ 43] focusing on the ﬁrst four of its six phases. The following research work is structuredaccording to these phases. First, the problem is identiﬁed by deﬁning a problem statement and research question. Their relevance for research is validated based on a systematic literature review [ 4]. Three key sub-questions obtained using a deductive approach [ 35] will help to answer the main research question. In the design phase, an artifact is proposed and, subsequently, implemented as a proof of concept. To demonstrate its functionality, a prototype was implemented andevaluated for a university case study [ 14]. Conversation-Driven Knowledge Graph Reﬁnement 43 2 Problem Identiﬁcation' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
390	page_content='43 2 Problem Identiﬁcation and Objectives As introduced above, the use of cognitive agents is currently frustrating for many users due to their insuﬃcient knowledge. Moreover, to support further use cases,it is necessary to manually enhance existing data sets and ﬁne-tune underlying language models [ 56]. Since machines are unlikely to have omniscient knowledge soon, the integration of humans into the process is essential to ensure high-quality standards [ 40,57]. Although some approaches with human integration may successfully compensate for the missing knowledge, they usually do not enhance the underlying knowledge base [ 40]. In fact, the necessity to frequently integrate human assistance without learning from the feedback renders these approaches ineﬃcient and expensive. Evidently, this conﬂicts with the commonreasons to implement a chatbot solution. A useful cognitive agent should have the ability to acquire new knowledge based on feedback to continuously optimize itself [ 29]. The adaption of this' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
391	page_content='[ 29]. The adaption of this concept, often achieved by approaches referred to ashuman-in-the-loop (HitL) AI ormachine learning (see Sect. 3for more details), motivates our approach to optimize chatbot performance. Since most traditional NLP pipelines are not designed to integrate humans in the loop [ 54], there are many open issues to be addressed in this context [ 57]. This motivates the research question to be pursued in this paper: How can a system architecture for a cognitive agent be designed and implemented in whichuncertain or unknown knowledge fragments are veriﬁed or provided by its users? Numerous open questions arise when designing and implementing such a system [ 54,57]. Based on the literature, we have identiﬁed three fundamental sub-questions that we will address in the paper: 1.How can existing weaknesses within a KG be identiﬁed? Issues like incompleteness, incorrectness, and inconsistencies among entities and relations between entities in a KG may lead to potential problems [ 53]. Mostly,' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
392	page_content='problems [ 53]. Mostly, these weaknesses result from error-prone extraction processes or from manual user input. Therefore, it is important to develop mechanisms that ﬂag critical objects. They are candidates for which the system may actively seek feed-back. 2.How can the right users to ask be identiﬁed? For any candidate identiﬁed above, the system should determine user groups that are suitable to provide feedback that helps to solve the issue. Asking users arbitrarily withoutjustiﬁcation quickly leads to frustration and rejection of the system [ 7,54]. 3.How can the responses be validated and used for KG reﬁnement? The feedback provided by the users has to be validated, and relevant information has to be extracted and incorporated in the KG. In this context, coping with partiallynoisy or misleading feedback is a key challenge [ 26,54]. 3 Background The following section brieﬂy introduces some basic concepts regarding the topics human-in-the-loop (HitL) machine learning andconversational AI . 44 D. Buhl et' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
393	page_content='AI . 44 D. Buhl et al. 3.1 Human-in-the-Loop (HitL) Machine Learning Along the machine learning (ML) pipeline, many algorithms are used for a great variety of tasks. An algorithm that exploits human interaction to improve itsoutput is deﬁned as a HitL approach [ 18]. In particular, approaches may beneﬁt from human assistance if the tasks are complex and deploy large-scale training data with higher quality for better ML model performance [ 57]. Human interaction is used for diﬀerent steps, especially for data pre-processing [ 7], labeling [ 7] and model evaluation [ 41]. In HitL learning scenarios, typically there is a trade-oﬀ between cost and resources, human feedback quality and model performance. Issues like inferring the truth from multiple inputs, assigning the right tasks to the right persons, reducing the latency of the human feedback, and extending label generation withexisting ML techniques have to be addressed [ 7]. 3.2 Conversational Artiﬁcial Intelligence As a subdomain of artiﬁcial intelligence' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
394	page_content='of artiﬁcial intelligence (AI), conversational AI combines the use of chatbots and cognitive agents or systems with NLP techniques. The resulting AI-based systems interact with humans in written or spoken language. Currently,there are many reference architectures for chatbots [ 1]. A conversational AI systems typically comprises three main components: [ 27] Natural Language Understanding (NLU) handles the users’ input, detecting their intents and recognizing entities. An intent states what a user is trying to achieve with the conversation [ 44], whereas relevant context information is typically provided by entities such as by people, locations, or organizations [ 12]. Dialog Management (DM) takes care of the actions of the conversational agent and keeps track of the current state of the ongoing conversation. It can be task-oriented ornon-task-oriented . Natural Language Generation (NLG) is responsible for generating human understandable responses based on the results of the NLU and DM components. Approaches' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
395	page_content='and DM components. Approaches range from simple predeﬁned templates to advanced deep learning models. Current large language models like ChatGPT can generate high-quality conversations [ 38]. NLG performance is crucial regarding the usability of conversational agents [ 27]. Figure 1shows a common system architecture of a chatbot based on the three components introduced above. The NLU component has a connection to a userinterface that enables interactions between users and the bot. The intent and relevant entities are passed to the DM, which may access required additional information via data connectors to prepare content for the response. Based onthe DM output, the NLG generates human understandable responses which are passed to the messaging backend. 4 Design and Development of the Artifact The integration of HitL approaches into the chatbot system architecture shown in Fig. 1results in changes which are explained in the following section. Design Conversation-Driven Knowledge Graph Reﬁnement 45 Fig. 1.' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
396	page_content='Graph Reﬁnement 45 Fig. 1. Common chatbot system architecture based on [ 3]. decisions for the artifact are derived and explained based on the three subquestions from the problem identiﬁcation. A ss h o w ni nF i g . 2, the KG is supplemented by another database storing data items relevant for the HitL approach such as the weaknesses identiﬁed in the form of a question backlog, the user responses, and further information regarding the users and the system status. 4.1 KG Weakness Identiﬁcation As already discussed, the agent’s knowledge base may contain incorrect and incomplete data. For our approach, we adapt the layer approach from the multihop architecture, which divides data into three layers depending on the processing status: The bronze layer stores raw data with low data quality, preprocessed and cleaned data is stored in the silver layer, and the goldlayer stores highquality data that is used in downstream applications [ 42]. Often, data in the gold layer has been manually validated [ 42]. While a' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
397	page_content='validated [ 42]. While a common chatbot architecture should focus on high-quality knowledge stored in the gold layer, we focus on data with insuﬃcient quality stored in the silver layer. Instead of manual quality validation, however, we rely on automatedquality assessment based on data processing and usage statistics. High-quality objects are automatically transferred into the gold layer, while inferior objects with speciﬁc weaknesses remain in the silver layer. To identify weaknesses inthe KG, data quality dimensions such as accuracy, consistency, completeness, timeliness, and redundancy must be considered in the silver layer [ 58]. Since the system architecture already with the KG already ensures consistency and uniqueness (absence of redundancy) [ 42], our HitL approach focuses on accuracy, completeness ,a n dtimeliness . The improvement of a KG can be broken down into two main goals: [ 42] 46 D. Buhl et al. (a)Identifying incorrect information: Incorrect information can be caused by either incorrect' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
398	page_content='be caused by either incorrect entities or relations between two entities in the KG or expir-ing validity. Therefore, important processing and usage statistics (metadata) is stored for each entity or relation object in the KG in addition to common attributes [ 21]. Based on the metadata, an aggregated quality score is calculated that reﬂects an entity’s or relation’s probability of being valid and current. Based on a provided threshold, relevant objects can be easily selected and stored in the HitL database as a backlog for user queries. (b)Supplementing missing knowledge: Regarding missing knowledge , we focus on entities in the KG without any relations to other entities. Several approachesfor predicting missing KG objects have been explored [ 42]. A common approach is to use traversal algorithms to identify gaps in RDF-triples [ 47]. 4.2 Relevant User Identiﬁcation To receive high-quality feedback, it is important to ask the right users [ 7,54]. Splitting the users into diﬀerent roles or expert groups helps' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
399	page_content='roles or expert groups helps to reduce human errors and knowledge gaps in advance. [ 7]. Selecting users involves a trade-oﬀ between explicitly asking individual experts and including entire groups to ask for feedback [ 6]. The exact groups can be derived based on available entities and relevant attributes in the KG. In a corporate context, for example, the entitydepartment could be used to create appropriate user groups. User groups with certain roles and properties will subsequently be mapped onto the corresponding questions regarding the candidate objects. Moreover, information that users provide may be used to describe their expertise and help narrow down the most appropriate user group. Finally, considering user statistics and behavior canensure fast and regular feedback for HitL. 4.3 Answer Validation Any user feedback received for speciﬁc questions should be validated before used to reﬁne the KG. To support this, the users’ responses must be collected andstored in a database with unique identiﬁers for' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
400	page_content='with unique identiﬁers for later access. There are methods thatensure correctness based on uniqueness. For example, intentions ( aﬃrm ordeny are set according to the pattern yesorno) that categorize answers. This is useful when verifying information. Another way to verify the answers istruth discovery from crowd-sourcing [ 7] where typically the most frequently mentioned answer is considered correct [ 41]. In case of closed-form questions with predeﬁned answers, these methods work well. For open questions with free text input, validation is more complex since comparison between answers requiresresponse harmonization [ 33]. In this context, fuzzy search has become a common approach: [ 36] Divergent answers that are similar in structure can be matched with entities from the KG as keywords. After successful validation, the KG canbe reﬁned. For this purpose, there are two main properties to be considered: We can choose to reﬁne the KG online , i.e., immediately after input has been processed, or oﬄine at speciﬁc' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
401	page_content='or oﬄine at speciﬁc intervals or events [ 54]. Regarding the values to Conversation-Driven Knowledge Graph Reﬁnement 47 Fig. 2. HitL-based chatbot architecture (own illustration). (Color ﬁgure online) be updated, it is important to know whether a new entity or relation has to be inserted or the quality score of an entity or relation has to be updated. To update existing objects, they have to be discovered with regular or fuzzy searchﬁrst. 5 Demonstration Finally, the prototypical implementation and development of the architecture is presented based on the components used. 5.1 Implementation The prototypical implementation of the system architecture is based on the open-source framework Rasa version 3, which is widely used for the develop-ment of chatbots in practice. The main component of the Rasa core is the NLU component, which can be trained using various language models. For our prototype, we selected the large German Spacy NLP model. The Rasa actions aswell as separate scripts like the initial user' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
402	page_content='scripts like the initial user contact and various database and KG queries are implemented in Python. The KG is created with ArangoDB. Simple CRUD operations can be made with the query language AQL, which greatlysimpliﬁes data extraction and updates. For the storage of relevant HitL data, a light-weight relational database is set up with SQLite. The database contains three tables for the backlog, users, and answers. To drive adoption of HitL, the chatbot should be shared and used as early as possible via an existing, user-friendly, and widely used chat application. Therefore, instead of the standard command line usage, the Rasa system is directlyconnected to WebEx Teams as our default chat application via an API. 48 D. Buhl et al. 5.2 Case Study We evaluate our prototype based on a case study in our university context. Traditionally, universities are organized into faculties with various programs of study.Often, the faculties are quite diverse and interact only to a limited extent [ 52]. This may put the' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
403	page_content='[ 52]. This may put the innovative capacity of universities at risk [ 28,52]. Improving technological support is one approach that can help to resolve this issue [ 50]. The chatbot application presented above makes teaching and research topics and contact information easily accessible for interested parties like faculty members, administrative staﬀ, and students. In the following, speciﬁc implementation details and their implications regarding the three sub-questions introduced in Sect. 2will be discussed. The basic functionality is shown in Fig. 2. The description references parts of the ﬁgure using the numbers given in blue circles. The chatbot can initiate a conversation via WebEx Teams as our default messaging application. If the backlog is not empty and relevant users are active,the system asks them if they are willing to answer questions. Whether a question regarding a particular weakness from the backlog is relevant for a user is simply determined based on aﬃliation with faculties and our programs of' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
404	page_content='faculties and our programs of study,assuming the members of a faculty or a program of study are likely to answer questions regarding the respective unit (step 0) . If a user agrees, a question is selected from the backlog in the HitL database. A background process for scanning the KG for weaknesses is scheduled regularly. It ﬁlls the backlog with weakness of types (a) and (b) according to Sect. 4.1as follows. Each object in the KG has a quality score that is initiated based on the conﬁdence of the associated extraction process and the credibility of the source, and will be discounted based on age and frequency of access. In addition, thequality score will be further discounted in case spelling errors are detected. If the quality score of an object drops below a threshold of 0.5, it is stored in the backlog as weakness of type uncertain (step 1a) . Positive feedback from users may increase the quality score again. To identify missing knowledge or gaps, a traversal algorithm is applied over all edges of the KG' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
405	page_content='over all edges of the KG in the prototype [ 47]. As the KG is a directed graph, this process is triggered from both the regulardirection and also the inverse direction. Any objects lacking relevant information are stored in the backlog labeled as lack (step 1b) . The chatbot will continue the conversation and ask the active user a question about a suitable object drawn from the backlog with probabilities complimentary to their quality score. As the set of entity and relation types is ﬁxed, we create suitable question based on simple templates with relevant names or descriptions from the objects which are aﬀected ﬁlled into their slots. This approach works well, but obviously lacks variation in the chatbots utterances (step 2) . Any answers from the users need to be parsed and validated. Validation depends on the type of weakness. For possibly incorrect objects, the chatbot asks closed-form questions and has to recognize whether the user states the objectis correct or not. For lacking objects, the chatbot' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
406	page_content='lacking objects, the chatbot uses its NLU component to recognize entities or relations mentioned in the answer (step 3) . Conversation-Driven Knowledge Graph Reﬁnement 49 If the answer passes the plausibility check, the KG has to be reﬁned. For possibly incorrect objects, their quality score will be updated according to theanswer. If an object is conﬁrmed, its quality score is increased. With enough conﬁrmation, high-quality objects can be deleted from the backlog and transferred from the silver to the gold layer. If the user believes the object is incorrect, thequality score is further discounted, which will eventually cause the object to be invalidated or removed from the KG. In case the user provides missing information, we need to distinguish between inserting a missing relation between existingentities and inserting new entities, which may entail new questions. Currently, processing the user feedback is run in oﬄine mode because it is easier to control and inspect the processes. All user feedback is' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
407	page_content='All user feedback is stored in the HitL database toallow for manual inspection and adaptation of the systems in case processes do not work as expected (step 4) . To summarize, the case study demonstrates the positive eﬀect of applying our approach. The users of the system were able to eliminate weaknesses through their input, thus contributing to the reﬁnement of the KG. 6 Related Work Several research papers discuss the use of human-in-the-loop (HitL) frameworks with chatbots or dialog-based systems. Li et al. have built a simulator to conduct a conversation with a chatbot agent based on reinforcement learning [ 29]. By applying feedback from real humans, the quality of their question-answeringsystem is signiﬁcantly improved. In a similar approach, Liu et al. have deployed a hybrid approach that introduces a human feedback pipeline on top of an agentbased model to further improve the performance of the agent’s capabilities [ 30]. First, the model learns from its mistakes via an imitation learning from human' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
408	page_content='imitation learning from human teaching. Subsequently, human feedback is applied to reward or penalize completed conversations. Karmakharm et al. have conducted a study on humanfeedback for rumor analysis [ 24]. Users can commence feedback over a web-based application to further train the underlying machine learning model. Santos et al. have developed a human-supervised process model focusing on the chatbotlife-cycle [ 48]. Humans can interact on several touch-points, like knowledge bases, model training and conversation history. Furthermore, the model assigns speciﬁc roles to the chatbot development team. HitL is also used regarding cyber-physicalsystems. Fernandes et al. discuss a platform concept that combines human interaction with several data sources from mobile devices and sensors [ 13]. 7 Discussion, Limitations, and Future Work We have presented a new system architecture for the integration of the HitL concept into a chatbot application using a design science research approach. The essential' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
409	page_content='approach. The essential properties of the system have been derived based on existing approaches in scientiﬁc publications and enriched by own considerations addressing three 50 D. Buhl et al. sub-questions that have also been identiﬁed as research gaps and, thus, underline the relevance of our contribution [ 57]. To generate a backlog of candidates with potential weaknesses within a KG on which our chatbot is grounded, it is important to consider each type of error or weakness separately. Within the scope of our case study, both incorrect andcompletely missing entities and relations were considered as weaknesses. Using quality scores derived from processing and usage metadata and stored with each KG object turned out to be a simple, but very valuable choice that we highlyrecommend. Further, collecting and using user properties such as aﬃliation with study programs or research projects to ﬁlter the right users to ask for feedback based on matching with fuzzy search and simple mappings onto entity types' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
410	page_content='mappings onto entity types andcharacteristics worked well in our small case study. With an increasing number of entity and relation types, more sophisticated approaches will certainly be needed to further diﬀerentiate among user groups and roles. Based on analysis of the user feedback received, we suggest to also consider the type of weakness when seeking appropriate user groups, as it may allowto better anticipate diﬀerent user reactions. Furthermore, the identiﬁcation of gaps has only been done by simple traversing and not by complex algorithms. As a result, not all the gaps that could have been inferred based on implicitcorrelations have been identiﬁed. Despite successful validation of our design choice, it has to be noted that the evaluation is only a ﬁrst step as it is based on a small case study with onlya few entity and relation types and a set of well-known users that are willing to provide answers and restrain from harming the system with inappropriate answers. Consequently, it is not feasible to' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
411	page_content='it is not feasible to generalize the ﬁndings to generalchatbot applications, and further research and evaluation is necessary to be able to generalize beyond our university domain. Regarding the implementation, further research is also possible. For instance, regarding the identiﬁcation of weaknesses in a KG, it should be investigated which models can be utilized to identify anomalies as errors or gaps. Furthermore, there is still a lack of research on the evaluation of KG completeness [ 58]. Regarding the validation of feedback and KG reﬁnement, relevant processes should be further automated. Prompting large language models with speciﬁctasks is a promising solution that should be investigated. References 1. Adamopoulou, E., Moussiades, L.: An overview of chatbot technology. In: Maglogiannis, I., Iliadis, L., Pimenidis, E. (eds.) Artiﬁcial Intelligence Applications andInnovations, pp. 373–383. Springer, Cham (2020).  31 2. Almansor, E.H., Hussain, F.K.: Survey on intelligent chatbots: state-of-the-art and' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
412	page_content='state-of-the-art and future research directions. In: Barolli, L., Hussain, F.K., Ikeda, M. (eds.) CISIS 2019. AISC, vol. 993, pp. 534–543. Springer, Cham (2020).  1007/978-3-030-22354-0 47 Conversation-Driven Knowledge Graph Reﬁnement 51 3. Ayanouz, S., Abdelhakim, B.A., Benhmed, M.: A smart chatbot architecture based NLP and machine learning for health care assistance. In: Proceedings of the 3rd International Conference on Networking, Information Systems & Security,NISS2020. Association for Computing Machinery, New York, NY, USA (2020).  4. vom Brocke, J., Simons, A., Niehaves, B., Reimer, K., Plattfaut, R., Cleven, A.: Reconstructing the giant: on the importance of rigour in documenting the literature search process. In: ECIS 2009 Proceedings, vol. 161 (2009) 5. Brown, T.B., Mann, B., Ryder, N., et al.: Language models are few-shot learners. In: Proceedings of the 34th International Conference on Neural Information Processing Systems. Curran Associates Inc. (2020) 6. Budd, S., Robinson, E.C., Kainz, B.: A' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
413	page_content='Robinson, E.C., Kainz, B.: A survey on active learning and human-inthe-loop deep learning for medical image analysis. Med. Image Anal. 71(2021).  7. Chai, C., Li, G.: Human-in-the-Loop Techniques in Machine Learning (2020).  . Accessed 08 Feb 2023 8. Chen, H., Liu, X., Yin, D., Tang, J.: A survey on dialogue systems: recent advances and new frontiers. ACM SIGKDD Exp. Newsl. 19(2), 25–35 (2017).  org/10.1145/3166054.3166058 9. Chen, X., et al.: KnowPrompt: knowledge-aware prompt-tuning with synergistic optimization for relation extraction. In: Proceedings of the ACM Web Conference 2022. ACM, April 2022.  10. Chowdhery, A., Narang, S., Devlin, J., et al.: PaLM: scaling language modeling with pathways (2022).  11. Cui, L., Wu, Y., Liu, J., Yang, S., Zhang, Y.: Template-based named entity recognition using BART (2021).  12. Dong, X., Qian, L., Guan, Y., Huang, L., Yu, Q., Yang, J.: A multiclass classiﬁcation method based on deep learning for named entity recognition in electronic medical records. In: 2016 New' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
414	page_content='medical records. In: 2016 New York Scientiﬁc Data Summit (NYSDS), pp. 1–10(2016).  13. Fernandes, J., et al.: A human-in-the-loop cyber-physical approach for students performance assessment. In: Proceedings of the 4th International Workshop onSocial Sensing, pp. 36–42. ACM, New York, NY, USA (2019).  1145/3313294.3313387 14. Gibbert, M., Ruigrok, W.: The “what” and “how” of case study rigor: three strategies based on published work. Organ. Res. Meth. 13(4), 710–737 (2010). https:// doi.org/10.1177/1094428109351319 15. Giorgi, J., Wang, X., Sahar, N., Shin, W.Y., Bader, G.D., Wang, B.: End-to-end named entity recognition and relation extraction using pre-trained language models (2019).  16. Guu, K., Lee, K., Tung, Z., Pasupat, P., Chang, M.W.: REALM: retrievalaugmented language model pre-training (2020).  17. Hogan, A., et al.: Knowledge Graphs. ACM Comput. Surv. 54(4), 1–37 (2021).  18. Holzinger, A.: Interactive machine learning for health informatics: when do we need the human-in-the-loop? Brain Inf. 3(2),' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
415	page_content='Brain Inf. 3(2), 119–131 (2016).  s40708-016-0042-6 1 9 .H u ,L . ,L i u ,Z . ,Z h a o ,Z . ,H o u ,L . ,N i e ,L . ,L i ,J . :as u r v e yo fk n o w l e d g e enhanced pre-trained language models (2022). arXiv:  ARXIV.2212.13428 . 52 D. Buhl et al. 20. Ji, Z., et al.: Survey of hallucination in natural language generation. ACM Comput. Surv. (2022).  21. Jia, Y., Qi, Y., Shang, H., Jiang, R., Li, A.: A practical approach to constructing a knowledge graph for cybersecurity. Engineering 4, 53–60 (2018).  10.1016/j.eng.2018.01.004 22. Kalo, J.-C., Fichtel, L., Ehler, P., Balke, W.-T.: KnowlyBERT hybrid query answering over language models and knowledge graphs. In: Pan, J.Z., et al. (eds.) ISWC 2020. LNCS, vol. 12506, pp. 294–310. Springer, Cham (2020).  org/10.1007/978-3-030-62419-4 17 23. Kan, Z., Feng, L., Yin, Z., Qiao, L., Qiu, X., Li, D.: A uniﬁed generative framework based on prompt learning for various information extraction tasks (2022). https:// doi.org/10.48550/ARXIV.2209.11570 24. Karmakharm, T.,' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
416	page_content='24. Karmakharm, T., Aletras, N., Bontcheva, K.: Journalist-in-the-loop: continuous learning as a service for rumour analysis. In: Proceedings of the 2019 Conference onEmpirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations, pp. 115–120. Association for Computational Linguistics, Hong Kong,China (2019).  25. Kejriwal, M.: Domain-Speciﬁc Knowledge Graph Construction. SCS, Springer, Cham (2019).  26. Kreutzer, J., Riezler, S., Lawrence, C.: Oﬄine reinforcement learning from human feedback in real-world sequence-to-sequence tasks (2020).  2011.02511 27. Kulkarni, P., Mahabaleshwarkar, A., Kulkarni, M., Sirsikar, N., Gadgil, K.: Conversational ai: an overview of methodologies, applications & future scope. In: 5th International Conference On Computing, Communication, Control And Automa-tion (ICCUBEA), pp. 1–7 (2019) 28. Laˇ s´akov´a, A., ˇLubica Bajz´ ıkov´a, Dedze, I.: Barriers and drivers of innovation in' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
417	page_content='and drivers of innovation in higher education: case study-based evidence across ten European universities. Int.J. Educ. Dev. 55, 69–79 (2017).  29. Li, J., Miller, A.H., Chopra, S., Ranzato, M., Weston, J.: Dialogue learning with human-in-the-loop. In: 5th International Conference on Learning Representations,ICLR 2017 Conference Track Proceedings, pp. 1–23 (2017) 30. Liu, B., Tur, G., Hakkani-Tur, D., Shah, P., Heck, L.: Dialogue learning with human teaching and feedback in end-to-end trainable task-oriented dialogue sys-tems (2018).  31. Liu, J., Chen, Y., Xu, J.: Low-resource NER by data augmentation with prompting. In: Raedt, L.D. (ed.) Proceedings of the 31st International Joint Conferenceon Artiﬁcial Intelligence, IJCAI-22, pp. 4252–4258. IJCAI Organization (2022).  32. Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., Neubig, G.: Pre-train, prompt, and predict: a systematic survey of prompting methods in natural language processing (2021).  33. Ma, F., et al.: FaitCrowd: ﬁne grained truth discovery' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
418	page_content='ﬁne grained truth discovery for crowdsourced data aggregation. In: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD 2015, pp. 745–754. Association forComputing Machinery, New York, NY, USA, August 2015.  1145/2783258.2783314 Conversation-Driven Knowledge Graph Reﬁnement 53 34. Maynez, J., Narayan, S., Bohnet, B., McDonald, R.: On faithfulness and factuality in abstractive summarization. In: Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 1906–1919. Association forComputational Linguistics (2020).  35. Mayring, P.: Qualitative content analysis. Forum Qual. Soc. Res. 1(2000). https:// doi.org/10.17169/FQS-1.2.1089 36. Misargopoulos, A., et al..: Building a knowledge-intensive, intent-lean, question answering chatbot in the telecom industry challenges and solutions. In: Artiﬁcial Intelligence Applications and Innovations, AIAI 2022 IFIP WG 12.5 International Workshops, pp. 87–97 (2022).  8 37. Moiseev, F., Dong,' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
419	page_content='8 37. Moiseev, F., Dong, Z., Alfonseca, E., Jaggi, M.: SKILL: structured knowledge infusion for large language models. In: Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 1581–1588 (2022).  v1/2022naacl-main.113 38. OpenAI: ChatGPT: optimizing language models for dialogue (2022). https:// openai.com/blog/chatgpt/ . Accessed 26 Jan 2023 39. Ouyang, L., et al..: Training language models to follow instructions with human feedback (2022).  . abs/2203.02155 40. Paikens, P., Znotin ,ˇs, A., B¯ arzdin ,ˇs, G.: Human-in-the-loop conversation agent for customer service. In: M´ etais, E., Meziane, F., Horacek, H., Cimiano, P. (eds.) NLDB 2020. LNCS, vol. 12089, pp. 277–284. Springer, Cham (2020).  org/10.1007/978-3-030-51310-8 25 41. Parameswaran, A., Sarma, A.D., Garcia-Molina, H., Polyzotis, N., Widom, J.: Human-assisted graph search: it’s okay to ask questions. In: Proceedings of theVLDB Endowment, vol. 4, pp.' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
420	page_content='Endowment, vol. 4, pp. 267–278. VLDB Endowment, February 2011.  42. Paulheim, H.: Knowledge graph reﬁnement: a survey of approaches and evaluation methods. Semant. Web 8, 489–508 (2017).  43. Peﬀers, K., Tuunanen, T., Rothenberger, M.A., Chatterjee, S.: A design science research methodology for information systems research. J. Manag. Inf. Syst. 24(3), 45–77 (2007).  44. Qiu, L., Chen, Y., Jia, H., Zhang, Z.: Query intent recognition based on multi-class features. IEEE Access 6, 52195–52204 (2018).  2018.2869585 45. Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I.: Language models are unsupervised multitask learners (2019).  gpt-2 46. Raﬀel, C., et al.: Exploring the limits of transfer learning with a uniﬁed text-to-text transformer (2019).  47. Ranganathan, V., Barbosa, D.: HOPLoP: multi-hop link prediction over knowledge graph embeddings. World Wide Web 25(2), 1037–1065 (2021).  1007/s11280-021-00972-6 48. Santos, G.A., de Andrade, G.G., Silva, G.R.S., Duarte, F.C.M., Costa, J.P.J.D., de' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
421	page_content='F.C.M., Costa, J.P.J.D., de Sousa, R.T.: A conversation-driven approach for chatbot management. IEEEAccess 10, 8474–8486 (2022).  49. Singh, S.: Natural language processing for information extraction (2018). https:// doi.org/10.48550/ARXIV.1807.02383 54 D. Buhl et al. 50. Sohail, M.S., Daud, S.: Knowledge sharing in higher education institutions: perspectives from Malaysia. Vine 39, 125–142 (2009).  03055720910988841 51. Vaswani, A., et al.: Attention is all you need. In: Advances in Neural Information Processing Systems, vol. 30. Curran Associates Inc. (2017) 52. Veiga Avila, L., Beuron, T.A., Brandli, L.L., Damke, L.I., Pereira, R.S., Klein, L.L.: Barriers to innovation and sustainability in universities: an international comparison. Int. J. Sustain. High. Educ. 20, 805–821 (2019).  IJSHE-02-2019-0067 53. Verint Systems Inc.: Conversational AI Barometer: Chatbots and Next-Gen AI (2021).  . Accessed 07 February 2023 54. Wang, Z.J., Choi, D., Xu, S., Yang, D.: Putting humans in the natural language' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
422	page_content='in the natural language processing loop: a survey. In: Bridging Human-Computer Interaction and NaturalLanguage Processing, HCINLP 2021 Proceedings of the 1st Workshop, pp. 47–52 (2021) 55. Wei, J., et al.: Emergent Abilities of Large Language Models (2022).  org/abs/2206.07682 56. Meyer von Wolﬀ, R., Hobert, S., Schumann, M.: Sorry, i can’t understand you! – inﬂuencing factors and challenges of chatbots at digital workplaces. In: Ahlemann,F., Sch¨ utte, R., Stieglitz, S. (eds.) WI 2021. LNISO, vol. 47, pp. 150–165. Springer, Cham (2021).  11 57. Wu, X., Xiao, L., Sun, Y., Zhang, J., Ma, T., He, L.: A Survey of Human-inthe-loop for Machine Learning. Fut. Gener. Comput. Syst. 135, 364–381 (2022).  58. Xue, B., Zou, L.: Knowledge graph quality management: a comprehensive survey. IEEE Trans. Knowl. Data Eng. (2022).  3150080 59. Xue, L., et al.: mT5: a massively multilingual pre-trained text-to-text transformer (2020).' metadata={'title': 'Conversation-Driven Refinement of Knowledge Graphs: True Active Learning with Humans in the Chatbot Application Loop', 'author': 'Dominik Buhl', 'publish_date': '2023-06-30', 'subject': 'Artificial Intelligence in HCI', 'doi': 'doi:10.1007/978-3-031-35894-4_3', 'keywords': 'Conversational AI; Human-in-the-Loop AI; Knowledge-Grounded Cognitive Assistants; Knowledge Graph Refinement'}
423	page_content='Vol.:(0123456789)SN Computer Science           (2023) 4:595    SN Computer Science ORIGINAL RESEARCH Open‑Domain Long‑Form Question–Answering Using  Transformer‑Based Pipeline Aprameya\xa0Dash1\xa0· Mohit\xa0Awachar1\xa0· Anshul\xa0Patel1\xa0· Bhawana\xa0Rudra1  Received: 13 March 2023 / Accepted: 6 June 2023  © The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd 2023 Abstract For a long time, question–answering has been a crucial part of natural language processing (NLP). This task refers to fetching accurate and complete answers for a question using certain support documents or knowledge sources. In recent years,  much work has been done in this field, especially after the introduction of transformer models. However, analysis reveals  that the majority of research done in this domain mainly focuses on answering questions curated to have short answers, and  fewer works focus on long-form question–answering (LFQA). LFQA systems generate explanatory answers for questions  and pose more challenges than the' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
424	page_content='pose more challenges than the short-form version. This paper investigates the long-form question–answering task by  proposing a system in the form of a pipeline consisting of various transformer-based models, enabling the system to give  explanatory answers to open-domain long-form questions. The pipeline mainly consists of a retriever module and a generator module. The retriever module retrieves the relevant support documents containing evidence to answer a question from  a comprehensive knowledge source. On the other hand, the generator module generates the final answer using the relevant  documents retrieved by the retriever module. The Explain Like I’m Five (ELI5) dataset is used to train and evaluate the  system, and the final results are documented using proper metrics. The system is implemented in the Python programming  language using the PyTorch framework. According to the evaluation, the proposed LFQA pipeline outperforms the existing research works when evaluated on the Knowledge-Intensive' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
425	page_content='on the Knowledge-Intensive Language Tasks (KILT) benchmark and is thus effective in  question–answering tasks. Keywords ELI5\xa0· Long-form question–answering\xa0· Natural language processing\xa0· Passage retrieval\xa0· Transformers Introduction Question–answering systems are an integral part of the  natural language processing domain. Due to substantial  technological improvements and the progress in mak ing the Internet accessible in the nooks and corners of the  world, information regarding a large number of topics is  now readily available to common people. As a result, question–answering systems are necessary to automatically find  and generate answers for the various questions and queries  posed by the users. While extracting information using special query languages may be easier, answering a question  written in natural language by a user is a very challenging  task for a machine. For answering a question, the machine  needs to properly understand a question, fetch relevant documents for the given question, and' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
426	page_content='for the given question, and then formulate a response  that is not only correct according to the fetched documents  but also correct according to the grammar and vocabulary This article is part of the topical collection “Research Trends  in Computational Intelligence” guest edited by Anshul Verma,  Pradeepika Verma, Vivek Kumar Singh, and S. Karthikeyan.  * Bhawana Rudra   bhawanarudra@nitk.edu.in  Aprameya Dash   aprameyadash2001@gmail.com  Mohit Awachar   mohitawachar2001@gmail.com  Anshul Patel   darshan.patelndps@gmail.com 1 Department of\xa0Information Technology, National  Institute of\xa0Technology Karnataka, Surathkal, Mangalore,  Karnataka\xa0575025, India  SN Computer Science           (2023) 4:595     595  Page 2 of 14 SN Computer Science of the language. The retrieved answers should be factually,  syntactically, and semantically correct. Over the years, a lot of research [1 –4] has been done  for creating question–answering systems. Previously, the  question–answering systems used to be based on' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
427	page_content='systems used to be based on probabilistic or basic vector space models, which do not take the  semantic meaning of the questions into consideration. Later,  the advancements in word embedding systems allowed the  creation of systems that could somewhat improve the under standing of the question and answers. In recent years, the  introduction of transformer models opened the door for  highly advanced question–answering systems, which can  also take advantage of pre-trained transformer models like  BERT to get a very high understanding of natural language.  However, most of the work done in question–answering  systems deals with answering questions that have small  answers, mostly consisting of a few words. These systems  perform very well in short-form question–answering but do  not work well when generating answers for questions that  require explanatory, paragraph-length answers. Recently, the long-form question–answering (LFQA)  task has gained attraction in the NLP domain. The LFQA  task integrates the' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
428	page_content='The LFQA  task integrates the retrieval of relevant documents and question–answering. This means that such a system has to fetch  support documents relevant to a question from a vast knowledge base consisting of a huge number of support documents  related to different fields and topics. Next, the system has  to generate a semantically correct and explanatory answer  using the relevant documents. Even modern search assistants are only capable of searching relevant web pages for a  given question and answering short-form questions but fail  to generate rich, abstractive, and explanatory answers by  collecting relevant passages from multiple sources across  different domains. Thus, this task is quite challenging, and  the systems employed for such tasks should be capable of  having a rich understanding of natural language. This paper investigates the LFQA task by proposing a  system to answer open-domain long-form questions in the  form of a pipeline consisting of different modules that contribute to answering' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
429	page_content='that contribute to answering a question. There are two main modules in the proposed pipeline: the retriever module and the  generator module. The retriever module consists of a core  transformer-based model, which is used to retrieve the most  relevant documents from a huge external knowledge source,  and a re-ranking model that re-ranks the top-ranked retrieved  documents. The second module is the generator module,  again a transformer-based generative module that takes the  question and the relevant documents fetched by the retriever  module and generates an answer for the question. The entire  system is trained on the ELI5 dataset [5 ], a dataset intro duced by Facebook consisting of questions with explanatory  answers, and Wikipedia is used as the external knowledge  source. The proposed system is then evaluated on ELI5’s test dataset as well as the KILT benchmark platform , and the  results are noted and compared with the existing works. In  summary, the following are the main contributions of this' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
430	page_content='main contributions of this  research work:  1. Creation of a transformer-based retriever module capable of retrieving the relevant documents for an opendomain question from a vast external knowledge source  (Wikipedia). The retriever module contains a core  retriever model trained to retrieve relevant passages for  a question. Next, a re-ranking strategy is integrated into  the module to strengthen relevant document/passage  retrieval further. 2. Creation of a generator module capable of generating  explanatory answers for an open-domain question using  the documents retrieved by the retriever module. 3. Extensive experimentation is done by training different  transformer architectures as the core retriever model,  varying the re-ranking strategy’s parameters for relevant  document retrieval, and thus, identifying the best configuration for the retriever module. Similarly, different  sequence-to-sequence (seq2seq) models are trained for  answer generation, and the best configuration is identified. 4. The' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
431	page_content='is identified. 4. The best-proposed configurations of the LFQA system  are also evaluated on the KILT benchmark for the ELI5  dataset. Evaluation reveals that the proposed LFQA  systems are very effective and outperform the existing  research works in the same field. Further, the system  is also evaluated using the BERTScore [7 ] metric to  gain insights into the answer-generation quality from a  semantic perspective. There are a total of five main sections in this paper. \xa0“Introduction” briefly introduces the proposed work. “Related  work ” gives a detailed account of existing datasets and  research works in the question–answering domain. “Methodology” describes the methodology proposed in this research  work. \xa0“Experiments and results” explains the experiments  carried out to evaluate the proposed system and then reveals  the results of those experiments. Finally, \xa0“Conclusion and  future work” draws the research work’s conclusion and gives  suggestions regarding ways to improve the research. Related Work' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
432	page_content='the research. Related Work Many of the earlier works in the field of question–answering  were based on statistical and rule-based techniques. Initially,  probabilistic models like Naive Bayes and decision trees  were paired up with techniques like bag-of-words, n -grams,  etc., to create query-answering systems. Further, representation methods like the Term Frequency-Inverse Document  SN Computer Science           (2023) 4:595    Page 3 of 14   595  SN Computer Science Frequency (TF-IDF) [8 –10] were also integrated into the  querying systems. Later, methodologies such as the Best  Match (BM) models like BM-25 [1 ] also gathered attraction for use in querying systems. But, then, advancements  in computing and the introduction of neural networks influenced the NLP field a lot, and a lot of research has been done  to employ deep learning in question–answering systems.  Architectures like Recurrent Neural Networks (RNNs) and  their more advanced versions, Gated Recurrent Unit (GRU),  and Long Short-Term Memory' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
433	page_content='and Long Short-Term Memory (LSTM)  were also  used a lot due to their inherent capabilities to handle long  sequences . Later, the introduction of transformer  models, especially pre-trained ones, like Bidirectional  Encoder Representations from Transformers (BERT) [ 14,  15] influenced this field a lot, and these transformer models  became very useful in the most recent question–answering  systems due to their capability to understand a sentence. Datasets used for training question–answering systems are  generally of two types, extractive or abstractive. Extractive  datasets are those in which the answer is a phrase directly  taken from the provided context itself, whereas abstractive datasets deal with more general and natural answers.  The SQUAD  dataset and the NewsQA  dataset  are prominent examples of extractive datasets. SQUAD is  a reading comprehension dataset with more than 100,000  questions created using a set of Wikipedia articles. The  answer for each question is a phrase directly taken from' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
434	page_content='a phrase directly taken from the  Wikipedia document/passage associated with the question.  The NewsQA extractive dataset, on the other hand, contains  about 100,000 question–answer pairs created using a set of  over 10,000 articles. On the other hand, some prominent  examples of abstractive datasets include NarrativeQA ,  a book and movie summaries dataset, and CoQA , a dialogue dataset. The NarrativeQA dataset is a more complex  dataset in which a reader has to answer questions by reading  entire books or movie scripts and thoroughly understanding the context and narrative. The CoQA dataset contains  about 127K questions with answers and is built using a huge  number of conversational texts from different domains. All  these datasets consist of answers which range from a few  words to a few sentences and are thus suited for short-form  question–answering systems. The ELI5 dataset [5 ], introduced by Facebook, is one of the very few datasets suited for  long-form question–answering containing questions with' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
435	page_content='containing questions with an  average word count of 42.6 and answers having an average  of 130.6 words. Over the years, many research works have focused on  short-form question–answering (QA). Many pre-trained  standard transformer models, as well as seq2seq models,  which are generalized to perform well in large number of  NLP tasks, also achieve great results when evaluated on  short-form question–answering datasets such as SQUAD.  Chen et\xa0al.  proposed a two-stage model consisting of a document retriever and a machine comprehension model to  achieve competitive results in multiple short-form QA data sets. Tang et\xa0al.  explored the power of pre-training by  combining 77 datasets to create a huge dataset MVPCorpus  and pre-trained a text generation model to achieve excellent  performance in QA tasks. Bhojanapalli et\xa0al.  improved  the standard transformers by eliminating redundancy in  pairwise dot product-based attention and achieved com petitive results in many datasets, including SQUAD. Riabi  et\xa0al.' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
436	page_content='SQUAD. Riabi  et\xa0al.  proposed a method to improve cross-lingual QA.  Huang et\xa0al.  proposed new ways to improve transformer  models by suggesting a relative position embedding tech nique and received improved performance on QA datasets  like SQuAD1.1. However, these works often perform poorly  when employed in LFQA tasks. Nitish et\xa0al. [ 25] investigated the LFQA task by extracting  long procedural answers from long PDFs using transformerbased models like BERT, trained on a self-made dataset ProLongQA. The paper also implements the long-form question–answering system using different transformer-based  models such as BERT and its variants like RoBerta, DistilBert, Albert, etc. Results displayed that BERT and RoBerta  worked the best, achieving accuracies of 87.2% and 86.4%,  respectively. In Fan et\xa0al. [5 ], the ELI5 dataset is introduced.  This dataset is created by selecting questions and answers  from a subreddit Explain Like I’m Five (ELI5). The answers  in this dataset are explanatory, long, and' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
437	page_content='are explanatory, long, and generally written in  simple and plain language. The paper also examines various  methods like TF-IDF, BidAF, etc., for relevant document  retrieval and extractive models. Next, the paper investigates  the use of language models and Seq2Seq models for answer  generation and concludes that a multi-tasking Seq2Seq  model works the best. The paper also analyses different  metrics that can be used for evaluating LFQA models. Bui  et\xa0al. [ 4] proposed a self-made dataset, FitQA, containing  question–answer pairs related to nutrition. The paper then  uses various state-of-the-art models to train on this dataset  and provides a detailed comparison between the models. The  paper also discovers that the same models which work very  well on datasets like SQUAD perform poorly when trained  on a dataset containing questions with longer answers. The  model also tries techniques like curriculum learning to  improve the performance of the models. Butler et\xa0al.   focused on creating an accurate,' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
438	page_content='on creating an accurate, open-domain, deployable  question–answering system that uses different modules for  zero-shot classification, relevant document retrieval, and  answer generation to generate answers for open-domain  questions. The model is also built to be sufficiently efficient  for deployment purposes. For a completely automated and independent LFQA  system, retrieving passages containing evidence to answer  a question and serve as support documents is also quite  important. This passage retrieval is mainly done using a   SN Computer Science           (2023) 4:595     595  Page 4 of 14 SN Computer Science vast knowledge source such as Wikipedia. Guu et\xa0al.   introduced an intuitive retrieval technique for LFQA tasks  called REALM or Retrieval-Augmented Language Model  which involves training a retrieval model on unsupervised  text using a performance-based signal. The model is then  employed in the open domain question–answering task, and  analysis reveals that the model outperformed many previous' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
439	page_content='outperformed many previous  methods by a significant margin. Karpukhin et\xa0al.  introduced another retrieval technique, DPR or Dense Passage  retrieval, which aims at using a dual-encoder architecture  to increase the dot product of the representations of query  and relevant documents. The DPR model learns embeddings  using a dual-encoder framework from a small number of  question–answer pairs and can defeat the existing methods  by a good margin. Lee et\xa0al.  introduced Open Retrieval  Question–Answering system (ORQA), an open-domain  question–answering system in which no separate retrieval  system is used, and the retriever and the reader are jointly  trained using only question–answer pairs, after pre-training  the retriever with an Inverse Cloze Task. The proposed system is then evaluated on five different question–answering  datasets, and the system outperformed traditional IR systems  like BM-25 in most cases. Lewis et\xa0al.  explored Retrieval-Augmented Generation (RAG) models for language generation by' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
440	page_content='for language generation by combining non-parametric and parametric memory. The work  proposed and compared two different formulations of the  RAG model, fine-tuned the proposed models on a wide  variety of NLP tasks, and set state-of-the-art performance  in many question–answering tasks. Krishna et\xa0al. [2 ] proposed a question–answering system that uses contrastive  REALM (C-REALM) to retrieve relevant documents from  a knowledge source and a routing transformer-based model  to generate the final answer using the retrieved documents,  trained on the ELI5 dataset. The paper also identifies various shortcomings of the ELI5 dataset and lists challenges  that must be overcome to improve LFQA systems. The  paper also explains that the metrics mentioned in the ELI5  paper are not informative enough, and better metrics are  needed to create better LFQA systems. The paper also suggests ways that can be used to mitigate these problems. In  Nakano et\xa0al. [3 ], a GPT-3 model is trained on the ELI5  dataset to generate' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
441	page_content='the ELI5  dataset to generate explanatory answers, and the relevant  documents are retrieved using the MS Bing API. This way,  the paper fine-tunes a language model to use a web-browsing  environment. The paper further uses reinforcement learning,  imitation learning, and other similar methods to optimize  answer quality. The model is built in such a way that it generates answers supported with references to make human  evaluation easier. Su et\xa0al.  investigated the generation  of accurate answers to open-domain long-form questions by  proposing the Read Before Generate (RBG) model, which  models machine reading and generation of answers jointly. The proposed model is an end-to-end framework in which  answer-related information is used to strengthen the generator model and emphasize correct facts. Analysis of existing research works reveals that, even  though a lot of work has been done in the general question–answering domain, there are still very few works in  the domain of long-form question–answering.' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
442	page_content='long-form question–answering. Further, while  many datasets are present in the question–answering domain  like SQUAD, NewsQA, etc., all these datasets are suited  for short-form question–answering. ELI5 is one of the few  public datasets suitable for LFQA. Similarly, there are fewer  works in the field of LFQA due to the inherent complexity of  the task. Thus, there is ample opportunity for more research  in the LFQA domain. Methodology This section provides a detailed description of the proposed  question–answering pipeline responsible for providing an  explanatory answer for a question using retrieved documents  containing evidence for the question. Dataset Description The ELI5 dataset used in this paper is suited for long-form  question answering. The original dataset, introduced in [5 ],  contains about 272\xa0K question–answer pairs. Out of this,  about 237\xa0K question–answer pairs belong to the training  dataset, 10\xa0K to the validation dataset, and about 25\xa0K to the  testing dataset. The average question' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
443	page_content='dataset. The average question length is 42.6 words,  whereas the average answer is 130.6 words long. The dataset has been constructed by selecting a set of questions and  answers from a subreddit Explain Like I’m Five (ELI5). This  subreddit encourages users to post questions on any topic,  and answers are usually written in a very simple and natural  language, so that even users without pre-existing knowledge  of the topic can understand the answers. A vast majority of  the questions are ‘Why’and ‘How’ type questions. About  63% of the questions have more than one answer, and the  score of each answer (number of up-votes in Reddit) is also  present in the dataset. The most important fields present in a  sample of the dataset are the question itself, a list of answers,  and scores assigned to each answer. The external knowledge source used in this paper for  retrieving support documents for a question is KILT Wikipedia. This knowledge source is vast and holds information  related to various fields, making it' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
444	page_content='to various fields, making it suitable for open-domain  question–answering systems. KILT Wikipedia is a standardized Wikipedia snapshot created by the KILT Benchmark,  containing about 5.9 million Wikipedia articles. The knowledge source is divided into snippets of length 100, and each  snippet is considered a separate document for retrieval tasks.  SN Computer Science           (2023) 4:595    Page 5 of 14   595  SN Computer Science This creates a knowledge source containing about 30 million  passages or documents in total. LFQA Pipeline Overview The LFQA pipeline proposed in this paper consists of two  main modules, a retriever module and a generator module. The retriever module takes the question as input and  retrieves the support documents relevant to the question  from the knowledge source. The retriever module ranks the  documents present in the knowledge source. Based on this  ranking, the K most relevant documents for the question  are selected and passed on to the generator module. These  retrieved' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
445	page_content='module. These  retrieved documents will serve as the context for generating  the answer to the question. The generator module takes the  question and the context (consisting of documents received  from the retriever) and generates the answer. This way, the  retriever and the generator module together empower the  pipeline to answer open-domain questions. Figure\xa0 1 shows  the high-level architecture of the proposed LFQA pipeline. Retriever Module The retriever module is responsible for retrieving the support documents related to a particular question from a large  knowledge source. Data Pre‑processing The first step in document retrieval is the data pre-processing  step. In this step, the question–answer pairs are extracted  from the ELI5 training dataset and processed, so that the  input can be directly fed to the core retrieval model, a  transformer-based encoder model. In the ELI5 dataset, each  question may have multiple answers. Therefore, to keep the  training process highly robust, one of its answers' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
446	page_content='robust, one of its answers is selected  randomly for each question in every epoch. Then, a sufficiently sized, randomly chosen span of this selected answer  is considered as the relevant passage for the question. This  ensures that each question is paired up with a slightly differ ent relevant passage in every epoch, which can improve the  generality of the model. Next, each question–passage pair is lightly cleaned to remove links, extra whitespaces, etc.,  and then passed through the tokenizer corresponding to the  core retrieval model. Each question is converted to 64-length  vectors, whereas each passage is converted to 128-length  vectors. Tokenization results in the following vectors for  each question/passage: • Input Token IDs: A vector of the token IDs of the tokens  present in the input sequence. These token IDs are  assigned based on the embeddings of the tokenizer. • Attention Mask: A vector to differentiate between the  tokens corresponding to the actual sequence and the padding tokens. The value' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
447	page_content='the padding tokens. The value will be 1 for a token belonging to  the actual text and 0 for a padding token. After tokenization, the tokenized question–passage pairs are  sent to the core retriever model. As the relevant passage  for a question changes in every epoch, tokenization is also  performed after every epoch to the altered question–passage pair. Core Retriever Model and\xa0Training In its core, the retriever module contains a transformer-based  model. Each training step feeds a batch of tokenized questions and corresponding relevant passages into the model.  Each question and passage pair separately passes through the  core transformer-based encoder, which returns a 768-length  vector for each question/passage. Gradient check-pointing is  performed, so that large batch sizes can be used even in the  presence of limited GPU memory. The embedding for each  question is passed through a dense layer consisting of 128  neurons, which reduces the question vector to a 128-length  projection. Similarly, the' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
448	page_content='projection. Similarly, the embedding of each passage is  passed through a separate dense layer with 128 neurons to  convert the passage to a 128-length projection. Next, a custom loss function is employed to train the model in such a  way that the dot product of the projection of a question with  its corresponding passage is higher than the dot product of  the projection of that question and any other passage present  in the batch. In this way, the model learns to project the  question and any passage in such a way that the dot product  Fig. 1  High-level architecture of  LFQA pipeline   SN Computer Science           (2023) 4:595     595  Page 6 of 14 SN Computer Science of the question and the passage will be higher if the passage  is relevant to the question. Figure\xa0 2 shows the architecture  of the core retrieval model of the LFQA pipeline. Retrieving Top K/uni2032.var Passages Once the model is trained, it can be used for ranking pur poses. First, the model can be separated into two submodels: a' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
449	page_content='into two submodels: a question encoder that converts a question into  128-length projection and a passage encoder that converts a  passage into 128-length projection. Next, each passage from  the knowledge source is passed through the passage encoder,  and the 128-length encoding of each passage is stored. Once  this is done, the ranked list of passages (documents) for a given question can be found. For this, first, the question is  passed through the question encoder, and the 128-length projection of the question is computed. Next, the dot product  of the question projection vector and each of the pre-stored  passage projection vectors is computed. Passages for which  the dot product is larger will be given a higher ranking. As  the number of passages in the knowledge source is too large,  thus, the ranking based on the dot product is done using  the Faiss library , which is built and optimized for this  purpose. This way, a ranked list of passages (documents) is  retrieved. Top K/uni2032.var passages from' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
450	page_content='K/uni2032.var passages from this list are selected for each  question and passed on for re-ranking. Figure\xa0 3 shows the  process for retrieving and ranking passages for a question  from a Knowledge Source. Re‑ranking Top K/uni2032.var Passages The top K/uni2032.var passages retrieved using the retriever model are  re-ranked using the zero-shot re-ranking technique introduced by Sachan et\xa0al. . The method involves re-scor ing the top K/uni2032.var passages to determine the probability of a  question generation conditioned on each retrieved passage  using a Pre-trained Language Model (PLM). This method  is a zero-shot re-ranking strategy; thus, it does not require  any domain-specific training and can be used directly for  any type of passage re-ranking. Given a question q  and an  ordered list of retrieved passages Z={z1,z2, ...,zk�} , the  new relevance score for a passage zi is calculated by p(zi/uni007C.varq)  which can be estimated by computing the quantity p(q/uni007C.varzi) . A  pre-trained language' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
451	page_content='. A  pre-trained language model is used to calculate log p(q/uni007C.varzi) ,  which can be defined as the mean log-likelihood of each of  the tokens of the question, q , conditioned on the passage zi .  This is done for each retrieved passage of a question using a  PLM in a zero-shot manner by adding an appropriate natural language instruction after the passage and passing this  new passage to the PLM. After calculating log p(q/uni007C.varzi) for  each passage for a given question, the passages are re-sorted  according to the new relevance score, and the top K  passages  are passed on to the generation module. The top K passages   Fig. 2  Architecture of retrieval model Fig. 3  Process of retrieving passages for a question from a knowledge source SN Computer Science           (2023) 4:595    Page 7 of 14   595  SN Computer Science for each question of the training dataset are then retrieved  and stored, so that the generator module can directly use  these passages. Figure\xa0 4 shows the re-ranking process of' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
452	page_content='the re-ranking process of top  K’ passages retrieved from the retriever model. Answer‑Generator Module The generator module takes the top K  documents (or passages) retrieved by the retriever module for a given question  and generates the answer to that question using the retrieved  passages as context. The answering is done by a fine-tuned  sequence-to-sequence (seq2seq) model. Data Pre‑processing The top K  relevant passages for each question are retrieved  for each question using the best-performing retriever module. Next, the top K  passages for each question are concatenated using a special token acting as the separator to create  the context for that question. Next up, the question and its  context are concatenated using proper prefixes like question:   and context: to create the input sentence, whereas the bestrated answer of the question is chosen as the target sequence.  In the case of multiple answers to a question, answers whose  score is higher than a threshold are also chosen as the tar get' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
453	page_content='also chosen as the tar get sequences and paired up with the input sequence. This  results in a list of input and target sequence pairs. Next, each  pair of input and target sequence is tokenized to get the following vectors: • Input Token IDs: A vector of the token IDs of the tokens  present in the input sequence, according to the vocabu lary of the tokenizer. These vectors are padded at the end. • Attention Mask: A vector to differentiate between the  tokens corresponding to the actual sequence and the padding tokens. • Labels: A vector of the token IDs of the tokens present  in the target sequence, with padding at the end. Padding tokens are replaced by −100  , so that these tokens will be  ignored (masked). The length of the input IDs and the attention mask for an  input–target sequence pair is 1024, whereas the length of  the labels is kept between 320 and 400 depending on the  seq2seq model used. Core Generator Model and\xa0Training A pre-trained seq2seq model is used as the core generator  model. To' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
454	page_content='the core generator  model. To improve its performance in the long-form question–answering domain, the model is fine-tuned using the  question-answer pairs of the ELI5 dataset. To make the  seq2seq model fit for generation purposes, a sequence-tosequence language modeling head is placed on top of the  seq2seq model. The language modeling head helps in text  generation as well as in training the model for text generation tasks. The tokenized vectors for each question–answer  pair are then grouped into batches of appropriate sizes, and  these batches are used to fine-tune the core seq2seq model. To reduce the training time, data parallelism is used,  which replicates the model on multiple devices at once, and  then, a portion of an input batch is handled by each replica.  The gradients of each replica are then accumulated into the  main model. This way, each batch is processed in parallel,  leading to a shorter training time. The model is trained to  minimize the language modeling loss, through which it  learns' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
455	page_content='through which it  learns to generate an appropriate answer given a question  and its context as input in a proper format. Further, as the  pre-trained seq2seq models are quite large and the batch  size is small, thus, instead of updating the weights after each  batch, the gradients are accumulated over multiple batches,  and then, the weights are updated, leading to more stable  training. Also, experimentation of hyperparameters is done  depending on the seq2seq model used to enhance the training process. Fig. 4  Process of re-ranking passages  SN Computer Science           (2023) 4:595     595  Page 8 of 14 SN Computer Science Post‑training Utilization Once the training of the generator model is completed, the  pipeline becomes complete and is ready to use. The retriever  module fetches the relevant documents for a question, and  the generator module generates the answer for the question  using the retrieved documents (context). Figure\xa0 5 shows the  process of answer generation given a question and a list' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
456	page_content='given a question and a list of  relevant passages containing evidence for answering that  question. Next up, extensive evaluation of both the retriever  and the generator module is done on the test partition of the  ELI5 dataset as well as the KILT benchmark platform, and  the performance of the proposed models is compared with  the previous works. The evaluation process and results, as  well as the inferences drawn from the extensive evaluation,  are discussed in detail in the next section. Experiments and\xa0Results This section provides a detailed description of the vari ous experiments performed to evaluate the proposed question–answering system, the evaluation results of those exper iments, and the inferences drawn from the evaluation. As the  retriever and generator modules are two main components  of the proposed pipeline, thus, the evaluation results of the  two modules are detailed separately. Evaluation of\xa0Retriever Module Many experiments are conducted to evaluate the retriever  module and find the' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
457	page_content='module and find the best configuration. The following different variations of the core retrieval model are trained  and evaluated: • BERT  (bert-base-uncased): BERT stands for Bidirectional Encoder Representations from Transformers.  It is a standard transformer model pre-trained on a huge  text corpus with two objectives: Next sentence prediction (NSP) and Masked language modeling (MLM). The  bert-base-uncased variant of the BERT model from HuggingFace  is used as the encoder for the core retrieval  model. • MPNet  (multi-qa-mpnet-base-dot-v1): MPNet is a  powerful pre-training strategy devised to take advantage  of two popular models: BERT and XLNet, simultaneously avoiding their limitations. The multi-qa-mpnetbase-dot-v1 model, available on HuggingFace, is an  MPNet-based sentence transformer model trained on  multiple question–answering datasets, which can be used  to map paragraphs into fixed-length vectors by preserv ing their semantic meanings. • DistilBert  (multi-qa-distilbert-dot-v1): DistilBert' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
458	page_content='DistilBert  is the distilled version of BERT; it is smaller and faster  and uses knowledge distillation. The multi-qa-distilbertdot-v1  model, available on HuggingFace, is a DistilBertbased sentence transformer model trained on multiple  question–answering datasets, which can be used to gener ate fixed-length embeddings containing semantic meaning for a paragraph. For each configuration, the retriever model is trained for ten  epochs on the ELI5 training dataset using AdamW optimizer  in a GPU-accelerated environment. In the case of the BERTbased retriever model, different variations of this model are  trained using batch sizes of 512, 1024, 2048, and 4096. The  batch size which produced the best results is then used as the  batch size for the other two models. Further, for the re-rank ing model of the retrieval module, the pre-trained language  model, T0_3B [ 37], is used, which is a transformer-based  PLM trained with an objective similar to Masked language  modeling. Each fine-tuned retriever model is' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
459	page_content='fine-tuned retriever model is then evaluated using  the test partition of the ELI5 dataset. All the answers present  in the test dataset are collected to create a knowledge source  for evaluation. The testing dataset contains about 25K questions, and in total, there are about 75K passages (answers)  constituting the knowledge source. For each question, the  retriever module should be able to rank that question’s  answers as high as possible, whereas the answers to other  questions should be at lower positions in the ranking. For  evaluation, the following metrics are considered: • Recall@K: It gives the proportion of relevant documents  present in the top K retrieved documents for a given   Fig. 5  Process of answer generation SN Computer Science           (2023) 4:595    Page 9 of 14   595  SN Computer Science query. The Recall@K value for all queries is averaged to  get the final value. • R-Precision: If R is the number of relevant documents  for a given query, then this metric gives the proportion  of top' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
460	page_content='gives the proportion  of top R documents which are relevant. The R-precision  value for all queries is averaged to get the final value. • Questions with at least one relevant retrieved passage  @K (Q1RRP@K): It gives the proportion of questions  for which at least one relevant passage is present in the  top K retrieved passages. The results of the evaluation of BERT-based retriever  models are shown in Table\xa0 1. Among the different variations of the BERT-based model, the model trained on a batch  size of 2048 performs the best. A larger batch size provides  a better result as it increases the generalization of the model.  Therefore, the other models (mpnet and distilbert) are also  trained on a batch size of 2048. Evaluation of these models  using the same strategy, as shown in Table\xa0 2, reveals that the best-performing model is the one in which multi-qadistilbert-dot-v1 is used as the encoder. As this model per formed the best, thus, re-ranking is performed on the top 50  retrievals of the' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
461	page_content='the top 50  retrievals of the multi-qa-distilbert-dot-v1-based model, and  the new results are recorded. It can be noted that re-ranking  improves the performance of the best-performing model, as  is evident from Table\xa0 2. To make the task even more challenging, the knowledge  source explicitly created for testing using the answers pre sent in the testing dataset is extended by adding all answers  present in the training dataset, bringing the number of passages to about 880K. Table\xa0 3 displays the evaluation results  on the extended knowledge source. Again the model in  which multi-qa-distilbert-dot-v1 is used as the encoder per forms the best, and re-ranking the top 50 retrievals enhances  the performance of this model. The benefits of re-ranking  are quite noticeable in this case, as re-ranking increases the  values of the metrics by a considerable amount. Next, the best-performing model, the one which uses  multi-qa-distilbert-dot-v1 as encoder, is evaluated on the  Table 1  Comparison of BERTbased' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
462	page_content='1  Comparison of BERTbased retriever models trained  with different batch sizes across  different metrics (in %) The results generated by the best-performing model for each metric are highlighted in boldMetric Bert-base-uncased  (BS:512)Bert-base-uncased  (BS:1024)Bert-base-uncased  (BS:2048)Bert-baseuncased  (BS:4096) Recall@5 44.36 47.26 48.86 48.19 Recall@10 54.93 58.18 59.65 59.01 Recall@20 64.74 67.81 69.30 68.32 Recall@50 75.69 78.05 78.98 78.21 Q1RRP@5 66.15 69.25 70.69 70.09 Q1RRP@10 75.16 77.68 78.94 78.30 Q1RRP@20 82.07 84.15 85.18 84.45 Q1RRP@50 88.67 90.07 90.68 90.13 R-Precision 31.67 34.43 36.07 35.08 Table 2  Comparison of best  BERT-based retriever model  with all other transformer  models across different metrics  (in %) The results generated by the best-performing model for each metric are highlighted in boldMetric Bert-baseuncased (BS:  2048)Multi-qa-mpnet-basedot-v1 (BS: 2048)Multi-qa-distilbertdot-v1 (BS: 2048)Multi-qa-distilbert-dotv1+ re-ranking (BS:  2048) Recall@5 48.86 46.49 52.99' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
463	page_content='Recall@5 48.86 46.49 52.99 56.09 Recall@10 59.65 57.41 63.50 66.43 Recall@20 69.30 67.14 72.41 74.82 Recall@50 78.98 77.81 81.89 81.89 Q1RRP@5 70.69 68.41 74.67 77.27 Q1RRP@10 78.94 77.18 82.05 84.11 Q1RRP@20 85.18 83.90 87.37 88.89 Q1RRP@50 90.68 90.06 92.39 92.39 R-Precision 36.07 33.26 40.07 43.65  SN Computer Science           (2023) 4:595     595  Page 10 of 14 SN Computer Science already established KILT benchmark. The KILT benchmark  is a unified benchmark platform that allows evaluation for  multiple datasets covering a wide range of tasks. The benchmark provides a standardized Wikipedia Knowledge source  and a curated test dataset for ELI5 containing 600 samples,  whose answers are hidden from the public. For creating  a submission to the KILT platform, the best-performing  retrieval model, the one based on multi-qa-distilbert-dot-v1   is used to retrieve top K/uni2032.var passages for every question from  the Wikipedia knowledge source. Next, these passages are  re-ranked using the re-ranking' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
464	page_content='using the re-ranking model, and the top K passages  ( K=10 ) of the re-ranked list are submitted for each question. The value of K/uni2032.var is varied ( K/uni2032.var = 50, 100, 200) to evaluate  the performance at different values of K/uni2032.var . The KILT platform  evaluates retrieval systems using two metrics: R-precision  and Recall@5. The results are shown in Table\xa0 4. From Table\xa0 4, it can be concluded that re-ranking  improves the performance a lot after the initial passage  retrieval. The configuration in which K/uni2032.var = 50, i.e., the top  50 passages from the retrieval stage are re-ranked, gives the  best performance. Also, as seen from the table, the proposed  models give better or competitive results when compared to  most of the existing works.Based on the evaluation of the retrieval module, it is evident that using multi-qa-distilbert-dot-v1 as the encoder of  the retriever model gives the best results. This can be due  to the fact that this encoder is already pre-trained on a large' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
465	page_content='pre-trained on a large  number of question–answer datasets. Further, training the  model on large batch sizes (e.g., 2048) improves the per formance as larger batch size results in more generalization. Furthermore, even though re-ranking is comparatively  expensive, re-ranking the retrieved passages using a PLM  also improves the performance of the retrieval module. The  performance of the proposed retrieval module is comparable  to or better than many of the existing works and is, thus,  effective at performing passage retrieval for questions from  a large knowledge source. Evaluation of\xa0Answer‑Generator Module The experiments conducted to evaluate the answer-generator  module are described here. The seq2seq model with language modeling head is the core component of the generator  model. Thus, each of the following three pre-trained seq2seq  models is used as the core model for experimentation:Table 3  Comparison of some  of the best-performing retriever  models on the extended  knowledge source across' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
466	page_content='knowledge source across  different metrics (in %) The results generated by the best-performing model for each metric are highlighted in boldMetric Bert-base-uncased  (BS: 2048)Bert-base-uncased  (BS: 4096)Multi-qa-distilbertdot-v1 (BS: 2048)Multi-qa-distilbert-dotv1+re-ranking (BS:  2048) Recall@5 20.69 20.36 24.64 29.62 Recall@10 27.95 27.24 32.18 37.01 Recall@20 36.21 35.52 40.78 44.72 Recall@50 48.82 48.14 53.36 53.36 Q1RRP@5 36.52 36.05 42.05 49.07 Q1RRP@10 46.39 45.43 51.77 57.34 Q1RRP@20 56.22 55.59 61.32 65.42 Q1RRP@50 69.24 68.46 73.28 73.28 R-Precision 13.63 13.20 16.64 21.21 Table 4  Evaluation of retriever  module on KILT benchmark  and comparison with other  related works (bottom 4 models  are proposed models) The results generated by the best-performing model for each metric are highlighted in boldModel R-precision Recall@5 RAG 11.0 22.9 RBG 10.83 27.25 BART + DPR 10.7 26.9 RT + REALM 6.7 15.7 RT + c-REALM 10.7 24.6 Multi-qa-distilbert-dot-v1 retriever 8.33 18.47 Multi-qa-distilbert-dot-v1' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
467	page_content='Multi-qa-distilbert-dot-v1 retriever + re-ranking with K�=50 11.33 23.27 Multi-qa-distilbert-dot-v1 retriever + re-ranking with K�=100 11.33 22.69 Multi-qa-distilbert-dot-v1 retriever + re-ranking with K�=200 11.16 22.94 SN Computer Science           (2023) 4:595    Page 11 of 14   595  SN Computer Science • bart-large : BART (Bidirectional Auto-Regressive  Transformers) is a standard encoder–decoder transformer  architecture that can be used for seq2seq tasks such as  translation. It consists of a decoder like GPT and an  encoder like BERT, thus, taking advantage of both. • T5-large : T5 (Text-to-Text-Transfer-Transformer)  is a seq2seq that achieves excellent performance in  multiple NLP tasks by assessing every NLP task as a  text-to-text task; that is, both the input and the target  sequences are text sequences. The model is pre-trained  on C4 (Colossal Clean Crawled Corpus) using different  supervised and unsupervised objectives. • switch-base-8 : Switch transformer is a new family of transformers' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
468	page_content='a new family of transformers similar to the T5 model, with the  most crucial difference being that sparse MLP layers  are used to replace the feed-forward layers of the T5  model. This allows faster training and good generalization in multiple NLP tasks. Each of the above pre-trained models is trained using  the training dataset according to the proposed methodology in a GPU-accelerated environment. The bart-large   and T5-large models are trained for two epochs, and the  switch-base-8 model is trained for three epochs. The bartlarge and switch-base-8 models are trained with a learning rate of 2e−4 and AdamW optimizer. In contrast, the  T5-large model is trained using a learning rate of 4e−4  and Adafactor optimizer. The relevant passages for each  question are retrieved using the best-performing retriever  model, which uses the multi-qa-distilbert-dot-v1 as the  encoder, and the top K  ( K=10 ) passages for each question are retrieved for this purpose (after re-ranking). Once  the models are trained, the' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
469	page_content='the models are trained, the models are stored for inference  and evaluation. The answer generated for a sample question by the bartlarge-based generator module is shown below: Question: How did people clean their teeth before the invention of  the toothbrush? Answer: Before the invention of the toothbrush, people used to  chew on twigs and leaves to clean their teeth. The bristles of a  toothbrush are the same as the bristles on a twig, so it is not that  hard to clean your teeth with twigs or leaves. It is also worth noting that toothbrushes have been around for a very long time, and  people have been using them for thousands of years. Before the  modern day, people did not brush their teeth as much as they do  now, so they did not have to worry about brushing their teeth like  we do now. They did not need a brush, and they just used twigs. Next, the answer-generation capability of the three  models is evaluated on the KILT benchmark platform. The  test set available on the KILT benchmark contains 600' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
470	page_content='KILT benchmark contains 600  questions. The top K(K=10) passages for these questions  are extracted using the retriever module, which uses multiqa-distilbert-dot-v1 as the encoder. Next, each of the three trained seq2seq models is used to generate answers for  the questions using the corresponding relevant passages  as context. The answers are then submitted to the KILT  benchmark in the prescribed format. The benchmark evaluates the system answers through the following metrics: • ROUGE-L: This metric measures the longest matching  sequence of words between the system answer and the  reference answer. • F1: This metric calculates the harmonic mean of the  recall and precision for a given reference and system  answer pair, thus giving a single measure by combining  recall and precision. • KILT-RL & KILT-F1: These two metrics are calculated  by combining retrieval results with ROUGE-L and F1  score, respectively. For each data point in the test set,  if the R-precision is 1, then the benchmark awards  ROUGE-L' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
471	page_content='the benchmark awards  ROUGE-L and F1 points to KILT-RL and KILT-F1,  respectively. This way, points are awarded to the system  answer only when the relevant passages for the ques tion are located at the top of the retrieved passages. Table\xa0 5 shows the performance of the three trained answergenerator models and compares these results with that of  existing works on the KILT benchmark. The bottom three  entries of Table\xa0 5 refer to the proposed models, whereas the  rest belong to other related works. It can be inferred from the  comparison that all three proposed models perform better  than all the previous works in all metrics except ROUGE-L,  in which they are slightly behind one of the works. Further,  among the proposed models, it can be inferred that the question–answer-generation pipeline, which uses a trained bartlarge as the core seq2seq model, performs the best. Thus, the  Table 5  Evaluation of answer-generator module on KILT benchmark  and comparison with other related works (bottom 3 models are' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
472	page_content='works (bottom 3 models are proposed models, DBR: multi-qa-distilbert-dot-v1-based retriever; RR:  re-ranking) The results generated by the best-performing model for each metric  are highlighted in boldModel ROUGE-L F1 KILT-RL KILT-F1 T5-base 19.08 16.10 0.00 0.00 BART 20.55 19.23 0.00 0.00 RAG 14.05 14.51 1.69 1.79 RBG 24.53 27.13 2.62 3.00 BART + DPR 17.41 17.88 1.90 2.01 RT + c-REALM 23.19 22.88 2.36 2.34 DBR + RR + bart-large 24.29 27.70 2.70 3.12 DBR + RR + T5-large 24.39 27.38 2.68 3.12 DBR + RR + switchbase-823.87 27.46 2.64 3.05  SN Computer Science           (2023) 4:595     595  Page 12 of 14 SN Computer Science proposed models are able to outperform the existing works  in almost all metrics and are, thus, capable of performing the  question–answering in a better way. Although the KILT benchmark only uses metrics like  ROUGE-L and F1, which work on the syntactic overlap  (exact matching) between the reference answer and the sys tem answer, these metrics are incapable of performing a  comparison by' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
473	page_content='performing a  comparison by taking the semantic similarity into account.  For this reason, the proposed models are also evaluated  using BERTScore, a metric that performs comparison by  understanding what is generated (system answer) and what  is supposed to be generated (reference answer). This metric works by taking advantage of the pre-trained contextual  embeddings of a transformer model, such as BERT or RoBERTa, and then using cosine similarity to match words in  the system and reference answers. As a result, this metric  gives a more comprehensive evaluation of the generated  answers by taking semantic meaning into account and is  proven to be more similar to human judgment. Table\xa0 6 shows  the BERTScore values for the three proposed models when  evaluated on the ELI5 test dataset. BERTScore comprises three metrics: precision, recall,  and F1, and each of these metrics is a value between 0 and  1. Table\xa0 6 shows that the three proposed models have similar  performance, and all the values are much' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
474	page_content='and all the values are much closer to 1, which  implies that the proposed models performed well and gener ated answers which are very close to the reference answers. Computational Efficiency To measure the computational efficiency of the proposed  system, the average duration taken by each module to  process a given question is calculated. According to the  experimentation, the core retriever model takes about  0.002\xa0s/question using a single Tesla V100 GPU. The  re-ranking model takes about 0.53\xa0s/question with a 4-GPU  setup, 0.94\xa0s/question with a 2-GPU setup, and about 2\xa0s/ question with a single GPU setup. The final answer generator  module takes about 3\xa0s/question to generate an answer using  a single GPU setup, once the relevant passages are available.  These durations can vary according to the type and number of GPUs used and can decrease further with more powerful  GPU setups. Inferences and\xa0Important Takeaways From the extensive evaluation of both the retriever module  and the generator module, it' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
475	page_content='and the generator module, it can be inferred that the proposed question–answering pipeline outperforms the existing  research works in answer generation in almost all metrics on  the KILT benchmark. The pipeline configuration that uses  multi-qa-distilbert-dot-v1 as the encoder in the retriever  model, a PLM, T0_3B, for passage re-ranking and a trained  bart-large as answer-generator model performs the best in  most metrics, with the other proposed configurations following closely behind. The accurate retrieval capabilities  of the retrieval module can be accredited to the contrastive  learning-based training objective of the multi-qa-distilbertdot-v1-based retriever module, using large batch size, that  enabled the model to project relevant passages closer to the  projection of their corresponding question. The re-ranking  model further improved the retrieval results by re-ordering  the top retrieved passages for a question based on the probability that the question can be generated from each of the' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
476	page_content='generated from each of the  passages, calculated using a powerful PLM in an unsuper vised manner. Finally, the accurate answer-generation capabilities of the answer-generator model can be accredited to  the trained seq2seq model, for instance, bart-large, trained  to take the question and relevant passages as input and generate an output answer by minimizing the language modeling  loss. Evaluation using the BERTScore metric, which takes  semantic meaning into account, also reveals that the answer  generation of proposed models is quite close to the reference  answer. However, the pipeline is quite resource intensive as  it consists of multiple language models, which are computationally expensive and thus require a proper GPU environment for good performance and latency, as is evident from  the computational efficiency measurement results. Further,  in some cases, when the evidence for answering the question is not present in the retrieved support documents, it is  observed that the answer generator model' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
477	page_content='the answer generator model will attempt to get  information from the data it is pre-trained and generate some  text which may not contain the actual answer. Apart from  this, the proposed question–answering pipeline can be used  to answer questions from different domains automatically  and correctly, and further research can be done to improve  the pipeline. Conclusion and\xa0Future Work Systems for answering questions are a crucial and essential  component of the natural language processing (NLP)  field. The long-form question–answering (LFQA) task Table 6  BERTScore values (precision, recall, and F1) achieved by  each of the proposed models when evaluated on the ELI5 test dataset  (DBR: multi-qa-distilbert-dot-v1 based retriever; RR: Re-ranking) Model Precision Recall F1 DBR + RR + bart-large 0.839 0.837 0.838 DBR + RR + T5-large 0.843 0.837 0.840 DBR + RR + switch-base-8 0.844 0.836 0.840 SN Computer Science           (2023) 4:595    Page 13 of 14   595  SN Computer Science has grown in popularity recently' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
478	page_content='grown in popularity recently in the NLP field. The  LFQA task incorporates both question–answering and  document retrieval. In this paper, a pipeline for the LFQA  task, consisting of a retriever module and a generator  module, is constructed using various transformer-based  models. The retriever module is responsible for fetching  support documents relevant to a question. In contrast, the  generator module is the one that generates the answer to  the question using the retrieved documents. Evaluation of  the retriever module reveals that using encoders pre-trained  on question–answering datasets, using large batch sizes,  and using re-ranking strategies are effective in boosting  the performance of retrieval models. The best-performing  module, which uses a fine-tuned multi-qa-distilbert-dot-v1   as encoder and a PLM, T0_3B for re-ranking achieves  11.33 in R-Precision and 23.27 in Recall@5 on the KILT  benchmarking platform, which is comparable to or better  than many of the existing works and is thus' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
479	page_content='existing works and is thus effective at  performing passage retrieval for open-domain questions.  Next, the evaluation of the answer generation module  shows that a properly fine-tuned sequence-to-sequence  model can generate correct and meaningful answers for  a question using the retrieved documents as context. The  best-performing model, which is a fine-tuned bart-large   model, achieves 24.29 in ROUGE-L, 27.70 in F1, 2.70 in  KILT-RL, and 3.12 in KILT-F1, outperforming the existing  research works. Evaluation using the BERTScore metric also  confirms that the generated answers are semantically close to  ground truth. Further improvement can be made by finding  ways to maintain the performance using computationally  lighter models and improving the core retriever model and  generator module, such that the generated answers are more  grounded in the retrieved passages. Data Availability The Dataset and Knowledge Source used and  analyzed in the current study, i.e., ELI5 [5 ] and KILT Wikipedia' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
480	page_content='[5 ] and KILT Wikipedia   respectively, are publicly available and can be used with proper  citations. Declarations   Conflict of Interest The authors declare that they have no competing  interests. References  1. Chen W, Chang M-W, Schlinger E, Wang W, Cohen WW. Open  question answering over tables and text. 2020. arXiv preprint  arXiv: 2010. 10439.  2. Krishna K, Roy A, Iyyer M, Hurdles to progress in long-form  question answering. 2021. arXiv preprint arXiv: 2103. 06332.  3. Nakano R, Hilton J, Balaji S, Wu J, Ouyang L, Kim C, Hesse C,  Jain S, Kosaraju V, Saunders W et\xa0al. Webgpt: browser-assisted question-answering with human feedback. 2021. arXiv preprint  arXiv: 2112. 09332.  4. Bui M-Q, Tran V, Nguyen H-T, Le Nguyen M, How state-ofthe-art models can deal with long-form question answering. In:  Proceedings of the 34th Pacific Asia conference on language,  information and computation, 2020; pp. 375–382.  5. Fan A, Jernite Y, Perez E, Grangier D, Weston J, Auli M, Eli5:  long form question answering.' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
481	page_content='long form question answering. 2019. arXiv preprint arXiv: 1907.   09190.  6. Petroni F, Piktus A, Fan A, Lewis P, Yazdani M, De Cao N,  Thorne J, Jernite Y, Karpukhin V, Maillard J et\xa0al. Kilt: a benchmark for knowledge intensive language tasks. 2020. arXiv preprint  arXiv: 2009. 02252.  7. Zhang T, Kishore V, Wu F, Weinberger KQ, Artzi Y. Bertscore:  evaluating text generation with bert. 2019. arXiv preprint arXiv:   1904. 09675.  8. Bahri S, Sumpeno S, Nugroho SMS. An information retrieval  approach to finding similar questions in question–answering of  Indonesian government e-procurement services using tf* idf and  lsi model. In: 2018 10th international conference on information technology and electrical engineering (ICITEE). New York:  IEEE; 2018. p. 626–631 .  9. Huang X, Zhang Y, Wei B, Yao L, A question–answering system  over traditional Chinese medicine. In: 2015 IEEE international  conference on bioinformatics and biomedicine (BIBM). New  York: IEEE; 2015. p. 1737–1739.  10. Mohapatra SK, Upadhyay' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
482	page_content='10. Mohapatra SK, Upadhyay A. Using TF-IDF on Kisan call centre dataset for obtaining query answers. In: 2018 international  conference on communication, computing and internet of things  (IC3IoT). New York: IEEE; 2018. p. 479–482.  11. Hochreiter S, Schmidhuber J. Long short-term memory. Neural  Comput. 1997;9(8):1735–80.  12. Karimi E, Majidi B, Manzuri MT. Relevant question answering in  community based networks using deep lSTM neural networks. In:  2019 7th Iranian joint congress on fuzzy and intelligent systems  (CFIS). New York: IEEE; 2019. p. 1–5.  13. Chen L, Zeng G, Zhang Q, Chen X, Wu D, Question answer ing over knowledgebase with attention-based lstm networks and  knowledge embeddings. In: 2017 IEEE 16th International Confer ence on Cognitive Informatics & Cognitive Computing (ICCI*  CC). New York: IEEE; 2017. p. 243–246.  14. Luo D, Su J, Yu S, A bert-based approach with relation-aware  attention for knowledge base question answering. In: 2020 Inter national Joint Conference on Neural Networks' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
483	page_content='Conference on Neural Networks (IJCNN). New  York: IEEE; 2020. p. 1–8.  15. Devlin J, Chang M-W, Lee K, Toutanova K. Bert: pre-training of  deep bidirectional transformers for language understanding. 2018.  arXiv preprint arXiv: 1810. 04805.  16. Rajpurkar P, Zhang J, Lopyrev K, Liang P. Squad: 100,000+ questions for machine comprehension of text. 2016. arXiv preprint  arXiv: 1606. 05250.  17. Trischler A, Wang T, Yuan X, Harris J, Sordoni A, Bachman P,  Suleman K, Newsqa: a machine comprehension dataset. 2016.  arXiv preprint arXiv: 1611. 09830.  18. Kočiskỳ T, Schwarz J, Blunsom P, Dyer C, Hermann KM, Melis  G, Grefenstette E. The narrative QA reading comprehension chal lenge. Trans Assoc Comput Linguist. 2018;6:317–28.  19. Reddy S, Chen D, Manning CD. COQA: a conversational  question answering challenge. Trans Assoc Comput Linguist.  2019;7:249–66.  20. Chen D, Fisch A, Weston J, Bordes A. Reading Wikipedia to  answer open-domain questions. 2017. arXiv preprint arXiv: 1704.   00051.  21. Tang T, Li J,' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
484	page_content='00051.  21. Tang T, Li J, Zhao WX, Wen J-R. MVP: multi-task supervised  pre-training for natural language generation. 2022. arXiv preprint  arXiv: 2206. 12131.  SN Computer Science           (2023) 4:595     595  Page 14 of 14 SN Computer Science  22. Bhojanapalli S, Chakrabarti A, Veit A, Lukasik M, Jain H, Liu F,  Chang Y-W, Kumar S. Leveraging redundancy in attention with  reuse transformers. 2021. arXiv preprint arXiv: 2110. 06821.  23. Riabi A, Scialom T, Keraron R, Sagot B, Seddah D, Staiano J.  Synthetic data augmentation for zero-shot cross-lingual question  answering. 2020. arXiv preprint arXiv: 2010. 12643.  24. Huang Z, Liang D, Xu P, Xiang B. Improve transformer models  with better relative position embeddings. 2020. arXiv preprint  arXiv: 2009. 13658.  25. Nitish S, Darsini R, Shashank G, Tejas V, Arya A. Bidirectional  encoder representation from transformers (bert) variants for procedural long-form answer extraction. In: 2022 12th international  conference on cloud computing, data science &' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
485	page_content='computing, data science & engineering (confluence). New York: IEEE; 2022. p. 71–76.  26. Butler R, Duggirala VD, Banaei-Kashani F. ILFQA: a platform for  efficient and accurate long-form question answering. In: Proceedings of the fifteenth ACM international conference on web search  and data mining; 2022. p. 1565–1568.  27. Guu K, Lee K, Tung Z, Pasupat P, Chang M, Realm: retrievalaugmented language model pre-training. 2020. arXiv preprint  arXiv: 2002. 08909.  28. Karpukhin V, Oğuz B, Min S, Lewis P, Wu L, Edunov S, Chen  D, Yih W-T. Dense passage retrieval for open-domain question  answering. 2020. arXiv preprint arXiv: 2004. 04906.  29. Lee K, Chang M-W, Toutanova K. Latent retrieval for weakly  supervised open domain question answering. 2019. arXiv preprint  arXiv: 1906. 00300.  30. Lewis P, Perez E, Piktus A, Petroni F, Karpukhin V, Goyal N, Küttler H, Lewis M, Yih W-T, Rocktäschel T. Retrieval-augmented  generation for knowledge-intensive NLP tasks. Adv Neural Inf  Process Syst. 2020;33:9459–74.  31.' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
486	page_content='Syst. 2020;33:9459–74.  31. Su D, Li X, Zhang J, Shang L, Jiang X, Liu Q, Fung P. Read  before generate! Faithful long form question answering with  machine reading. 2022. arXiv preprint arXiv: 2203. 00343.  32. Johnson J, Douze M, Jégou H. Billion-scale similarity search with  GPUS. IEEE Trans Big Data. 2019;7(3):535–47.  33. Sachan DS, Lewis M, Joshi M, Aghajanyan A, Yih W-T, Pineau J,  Zettlemoyer L. Improving passage retrieval with zero-shot question generation. 2022. arXiv preprint arXiv: 2204. 07496. 34. Wolf T, Debut L, Sanh V, Chaumond J, Delangue C, Moi A,  Cistac P, Rault T, Louf R, Funtowicz M. Transformers: state-ofthe-art natural language processing. In: Proceedings of the 2020  conference on empirical methods in natural language processing:  system demonstrations; 2020. p. 38–45.  35. Song K, Tan X, Qin T, Lu J, Liu T-Y. Mpnet: masked and per muted pre-training for language understanding. Adv Neural Inf  Process Syst. 2020;33:16857–67.  36. Sanh V, Debut L, Chaumond J, Wolf T, Distilbert, a' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
487	"page_content=""J, Wolf T, Distilbert, a distilled ver sion of bert: smaller, faster, cheaper and lighter. 2019. arXiv preprint arXiv: 1910. 01108.  37. Sanh V, Webson A, Raffel C, Bach SH, Sutawika L, Alyafeai Z,  Chaffin A, Stiegler A, Scao TL, Raja A et\xa0al. Multitask prompted  training enables zero-shot task generalization. 2021. arXiv preprint arXiv: 2110. 08207.  38. Lewis M, Liu Y, Goyal N, Ghazvininejad M, Mohamed A, Levy  O, Stoyanov V, Zettlemoyer L, Bart: denoising sequence-tosequence pre-training for natural language generation, translation,  and comprehension. 2019. arXiv preprint arXiv: 1910. 13461.  39. Raffel C, Shazeer N, Roberts A, Lee K, Narang S, Matena M,  Zhou Y, Li W, Liu PJ. Exploring the limits of transfer learning with a unified text-to-text transformer. J Mach Learn Res.  2020;21(140):1–67.  40. Fedus W, Zoph B, Shazeer N. Switch transformers: scaling to  trillion parameter models with simple and efficient sparsity. 2021. Publisher's Note Springer Nature remains neutral with regard to"" metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}"
488	page_content='neutral with regard to  jurisdictional claims in published maps and institutional affiliations. Springer Nature or its licensor (e.g. a society or other partner) holds  exclusive rights to this article under a publishing agreement with the  author(s) or other rightsholder(s); author self-archiving of the accepted  manuscript version of this article is solely governed by the terms of  such publishing agreement and applicable law.' metadata={'title': 'Open-Domain Long-Form Question–Answering Using Transformer-Based Pipeline', 'author': 'Aprameya Dash', 'publish_date': '2023-07-15', 'subject': 'SN Computer Science', 'doi': 'https://doi.org/10.1007/s42979-023-02039-x', 'keywords': 'SN Computer Science, https://doi.org/10.1007/s42979-023-02039-x'}
489	page_content='Design and Development of Retrieval-Based Chatbot UsingSentence Similarity Haritha Akkineni, P . V . S. Lakshmi, and Lasya Sarada Abstract Chatbots or the well-known automated conversational agents have become a raging trend among all the sectors of businesses as a result of the rapidtransition happening towards automation in processes. They are already being used extensively and will spread their wings to newer horizons shortly. The basic model of Chatbots is to interact with the user to answer their questions using various modes like text messages, voice replies, or any other predeﬁned suitable interface. This paper discusses the development of a Chatbot for the college, Prasad V Potluri SiddharthaInstitute of technology, to answer various questions related to the college like the facilities, procedures, policies, etc. This is a web-based software application implemented using Flask framework. This model is designed to capture text inputs fromthe user through a console and outputs the response in text' metadata={'title': 'Design and Development of Retrieval-Based Chatbot Using Sentence Similarity', 'author': 'Haritha Akkineni', 'publish_date': '2021-09-04', 'subject': 'IoT and Analytics for Sensor Networks', 'doi': 'doi:10.1007/978-981-16-2919-8_43', 'keywords': 'Chatbot,Machine learning,Retrieval approach,Flask framework'}
490	page_content='outputs the response in text format using machine learning concepts. A retrieval approach is implemented to process the input and to respond with an appropriate answer using logic adapters. The performance of thismodel is analyzed using a questionnaire that uses various parameters like performance, humanity, effect, and accessibility. This paper presents the overall approach used to design the Chatbot and compares the web application as-is study with theto-be website when the Chatbot is incorporated. The web application along with the Chatbot showed a 20% improvement in performance and 5% increase in accessibility by analyzing the performance metrics. Keywords Chatbot ·Machine learning ·Retrieval approach ·Flask framework 1 Introduction The usage of Chatbots has skyrocketed in the recent times. They have a strong footing in the customer support industry which involves text-based dealings or support. A chatbot is basically a term for a conversational agent which in actual is a computer system software that' metadata={'title': 'Design and Development of Retrieval-Based Chatbot Using Sentence Similarity', 'author': 'Haritha Akkineni', 'publish_date': '2021-09-04', 'subject': 'IoT and Analytics for Sensor Networks', 'doi': 'doi:10.1007/978-981-16-2919-8_43', 'keywords': 'Chatbot,Machine learning,Retrieval approach,Flask framework'}
491	page_content='computer system software that can take natural language input and returns a chatty responseinstantaneously [ 1]. As observed, chatbots have been in great demand over the past H. Akkineni ( B)·P . V . S. Lakshmi ·L. Sarada Prasad V Potluri Siddhartha Institute of Technology, Vijayawada, India © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022 P . Nayak et al. (eds.), IoT and Analytics for Sensor Networks , Lecture Notes in Networks and Systems 244,  478 H. Akkineni et al. few years. The number of internet users is increasing year-by-year. Proportionately, we can also observe a signiﬁcant rise in the e-commerce sector which in turn demands increased customer support services for these online digital platforms. A delay of even5 minutes in providing the customer support could reduce the chances of reaching out and selling to a customer [ 2]. A Chatbot of any particular organization is designed to perform certain tasks pertaining to their requirements. In reality, if the chatbots' metadata={'title': 'Design and Development of Retrieval-Based Chatbot Using Sentence Similarity', 'author': 'Haritha Akkineni', 'publish_date': '2021-09-04', 'subject': 'IoT and Analytics for Sensor Networks', 'doi': 'doi:10.1007/978-981-16-2919-8_43', 'keywords': 'Chatbot,Machine learning,Retrieval approach,Flask framework'}
492	page_content='In reality, if the chatbots donot exist, the chances of getting the information across to each and every person of a particular organization (college in this case) are very meek. A Chatbot completes almost 25–30% of the tasks that are done by the organization to the end-user. The College Enquiry Chatbot uses Machine Learning (ML) algorithms. The chatbot provides simple and trouble-free query clariﬁcation platform to students by addressing their queries in text format. The chatbot system makes it easy forthe student to clarify his/her queries in lesser time. It is used to perform tasks like answering the questions related to the organization, supply the relevant links for the questions encountered by the user (if necessary), etc. Basically, the initial chatbot named “ELIZA” was designed by Joseph Weizenbaum. With the innovation of the existing Chatbots, there came the evolution of the Chatbot technology. Chatbots can be implemented based on two approaches; Rule-Based Approach and Self-Learning Approach. In' metadata={'title': 'Design and Development of Retrieval-Based Chatbot Using Sentence Similarity', 'author': 'Haritha Akkineni', 'publish_date': '2021-09-04', 'subject': 'IoT and Analytics for Sensor Networks', 'doi': 'doi:10.1007/978-981-16-2919-8_43', 'keywords': 'Chatbot,Machine learning,Retrieval approach,Flask framework'}
493	page_content='Self-Learning Approach. In rule-based approach, there are some speciﬁc rules to be followed when training the bot. Here, the chatbot cannotanswer complex questions triggered by the user. In self-learning approach, the chatbot follows the machine learning approach. This approach can further be divided into two models; Retrieval-Based Model (Chatbot retrieves the best response from thecollection of responses) and Generative Model (Chatbot answers the question asked by the user from the set of answers). Chatbots that implement generative models are termed as intelligent chatbots. The main sequence of ﬂow for a functional chatbot involves three stages: (i) to get natural language user input, (ii) generate most appropriate automated response, and (iii) returning prudent natural language output. This College Enquiry Chatbotis developed using the Python Flask framework, where the front-end is written in HTML, CSS, and internal JavaScript. To implement the working of College Enquiry Chatbot, Chatterbot Library is' metadata={'title': 'Design and Development of Retrieval-Based Chatbot Using Sentence Similarity', 'author': 'Haritha Akkineni', 'publish_date': '2021-09-04', 'subject': 'IoT and Analytics for Sensor Networks', 'doi': 'doi:10.1007/978-981-16-2919-8_43', 'keywords': 'Chatbot,Machine learning,Retrieval approach,Flask framework'}
494	page_content='Chatterbot Library is used. Chatterbot is language independent and makesit easy to design a product that takes part in conversation. The inspiration to build this chatbot came when going through our college’s website. This Chatbot follows the generative approach, which answers the user from a predeﬁned set of answers.This Chatbot functions similar to the initial chatbot “ELIZA.” Section 2discusses the motivation behind developing this chatbot. Section 3talks about the related work done in this area. Section 4is about the proposed approach and Sect. 5shows the implementation part and results. Section 6is the conclusion part. Design and Development of Retrieval-Based Chatbot … 479 2 Motivation For every student, to get the information related to the fee structure, due fees, events that are being organized, etc., is a lengthy and difﬁcult process most of the times.Some of the events that are being organized by one department are not known to the other departments due to lack of effective communication channels.' metadata={'title': 'Design and Development of Retrieval-Based Chatbot Using Sentence Similarity', 'author': 'Haritha Akkineni', 'publish_date': '2021-09-04', 'subject': 'IoT and Analytics for Sensor Networks', 'doi': 'doi:10.1007/978-981-16-2919-8_43', 'keywords': 'Chatbot,Machine learning,Retrieval approach,Flask framework'}
495	page_content='communication channels. Sometimes, the changes in the fee structure are often not known to many students. We areliving in a world where people are striving towards increased automation rather than manual intervention for repetitive tasks to arrive at faster and simpler solutions for the complex problems. This is the main reason behind building the College enquiryChatbot where the user can ask the queries and a bot responds within no time. It reduces the users’ time and can be easily available to any user with a mobile phone as well. With this Chatbot, the student no longer needs to take trips to notice boards or contact his/her friends or faculty to get timely information. This Chatbot in turn reduces the work of the organization. The user can get answers for any questionsrelated to the college like address, admission process, and subsequent procedures which may be very difﬁcult to ﬁnd out for many students due to the pandemic situations. 3 Related Work Harsh Pawar et al. developed College Enquiry Chatbot' metadata={'title': 'Design and Development of Retrieval-Based Chatbot Using Sentence Similarity', 'author': 'Haritha Akkineni', 'publish_date': '2021-09-04', 'subject': 'IoT and Analytics for Sensor Networks', 'doi': 'doi:10.1007/978-981-16-2919-8_43', 'keywords': 'Chatbot,Machine learning,Retrieval approach,Flask framework'}
496	page_content='College Enquiry Chatbot using Knowledge Database.This System is built using LUIS.ai, Microsoft Bot builder, and MongoDB for database. The user can interact with this system through web interface, in which the web application is connected to the bot through bot connector. This system willbe a chatbot that responds to the questions by the user. In this system, they used LUIS.ai for training language model, which is used to identify the intention of the user and fetches the adequate response using pattern matching algorithm [ 3]. Nidhi Mishra et al. developed Dr. Vdoc, a medical Chatbot in 2018 which acts as a virtual doctor. The interaction can take place between a patient and a virtualchatbot, and this is made possible using natural language processing and pattern matching algorithms. It is more useful to provide awareness on the disease in case of unavailability of the doctors. The results showed that Dr. Vdoc is capable of returningthe responses with 80% accuracy [ 4]. Pooja Prashanth et al. designed a' metadata={'title': 'Design and Development of Retrieval-Based Chatbot Using Sentence Similarity', 'author': 'Haritha Akkineni', 'publish_date': '2021-09-04', 'subject': 'IoT and Analytics for Sensor Networks', 'doi': 'doi:10.1007/978-981-16-2919-8_43', 'keywords': 'Chatbot,Machine learning,Retrieval approach,Flask framework'}
497	page_content='Prashanth et al. designed a college enquiry chatting system using knowledgeable database. In education system, few works can be very lengthy, timeconsuming, and require extra manpower. But in today’s world, we see that almost everything is turning to digital format. This chatbot updates the students with college’s cultural activities. It is based on client server architecture. All the infor-mation is kept in the database on the central server. By installing application in the smart phone, a user can access the information from the database. This system is 480 H. Akkineni et al. developed with the combined technologies of Artiﬁcial Intelligence, Knowledgeable Database, and Virtual Assistance, such that the chatbot can make conversations between humans and machine [ 5]. Sagar Pawar et al. developed a web-based college enquiry chatbot with results. The system uses bigram and some sentence similarity algorithms to provide answers to student or any other user queries. If the response is invalid or irrelevant to' metadata={'title': 'Design and Development of Retrieval-Based Chatbot Using Sentence Similarity', 'author': 'Haritha Akkineni', 'publish_date': '2021-09-04', 'subject': 'IoT and Analytics for Sensor Networks', 'doi': 'doi:10.1007/978-981-16-2919-8_43', 'keywords': 'Chatbot,Machine learning,Retrieval approach,Flask framework'}
498	page_content='is invalid or irrelevant to theuser query, then user can mark the response as invalid. This is sent to the admin. The admin will be able to delete or modify the data [ 6]. Jayesh Gangrade et al. designed a Review on College Enquiry Chatbot in 2019. An intelligent voice recognition chatbot is designed and developed which replies to the user queries in a graphical user interface, which gives them a feel of talking to a person. In this system, the user must login into the web application to ask queries.This system also contains a notice board where the important notices are placed in the form of documents or portable document formats (pdf). Here, important keywords are fetched from the query, and those keywords are searched in the knowledge databaseusing keyword matching algorithms. If the answer is not found, then the system displays the following—“Answer to this query is not available at the moment, please revert after some time” [ 7]. 4 Proposed Approach The proposed system is designed to solve the user' metadata={'title': 'Design and Development of Retrieval-Based Chatbot Using Sentence Similarity', 'author': 'Haritha Akkineni', 'publish_date': '2021-09-04', 'subject': 'IoT and Analytics for Sensor Networks', 'doi': 'doi:10.1007/978-981-16-2919-8_43', 'keywords': 'Chatbot,Machine learning,Retrieval approach,Flask framework'}
499	page_content='is designed to solve the user queries in no time without the user approaching the college or contacting any other person. A retrieval-based model uses an archive of predeﬁned responses and performs some analysis to picka desired response based on the given input and text [ 8]. This analysis can be a simple expression match, or Machine Learning classiﬁers that work on the principle directed towards ﬂows of graphs. The systems that are designed using this modelchoose an appropriate response from a ﬁxed set instead of returning a new text. The chatbot is trained based on existing information in the database to provide best possible responses from the predeﬁned responses. In case of retrieval-based chatbot, the selection of appropriate responses can be determined based on techniques like machine learning, deep learning, and keywords matching. This model cannot generate new output and can only provide predeﬁned responses. Retrieval-basedchatbot design is shown in Fig. 1. User Query : The students can approach the' metadata={'title': 'Design and Development of Retrieval-Based Chatbot Using Sentence Similarity', 'author': 'Haritha Akkineni', 'publish_date': '2021-09-04', 'subject': 'IoT and Analytics for Sensor Networks', 'doi': 'doi:10.1007/978-981-16-2919-8_43', 'keywords': 'Chatbot,Machine learning,Retrieval approach,Flask framework'}
500	page_content='The students can approach the Chatbot to resolve their queries related to the College. This Chatbot receives the queries that are of any type (Greetings, College related queries, General questions, etc.) by the user in the form of text. The user inputs his queries in the textbox. T okenizing the words : Tokenization is a process of breaking a sentence or the sequence into pieces called tokens, perhaps eliminating the special characters likepunctuation marks. For example, if the input is “Hello, How are you?,” then the tokens obtained after tokenization are “Hello,” “How,” “are,” and “you.” After tokenizing, Design and Development of Retrieval-Based Chatbot … 481 Fig. 1 Retrieval-based chatbot design the tokens are processed by normalizer and matcher. Tables 1and 2depict how the normalizer and matcher process the tokens. A normalizer processes the tokens by matching them with the patterns stored in the dataset. It matches the keywords of the input sentence with the patterns of the datasetand stores the' metadata={'title': 'Design and Development of Retrieval-Based Chatbot Using Sentence Similarity', 'author': 'Haritha Akkineni', 'publish_date': '2021-09-04', 'subject': 'IoT and Analytics for Sensor Networks', 'doi': 'doi:10.1007/978-981-16-2919-8_43', 'keywords': 'Chatbot,Machine learning,Retrieval approach,Flask framework'}
501	page_content='of the datasetand stores the matched keywords. A Matcher is used to ﬁnd out the appropriate output Ta b l e 1 Processing of the normalizer S. No Input Output of the normalizer 1 Iw a n t Iw a n t 2 to talk to talk 3 in Hindi in Hindi Ta b l e 2 Processing of matcher S. No Input sentence Pattern in database Similarity threshold Output sentence 1 I code in python I prefer to code in python0.5 The output will be “Iprefer to code inpython” I like coding inpython 0.33 482 H. Akkineni et al. for the user query from the existing dataset. The Matcher checks by converting text into ASCII and checks the sensitivity of the characters (lower/upper case). Retrieving the matched response : Upon ﬁnding a sentence similar to the query from the predeﬁned dataset, the chatbot retrieves an appropriate response from the same [ 10]. Calculating the similarity: The similarity threshold is calculated for the input query, out of many sentences of the dataset that match with the input. The higher threshold valued sentence is sent to' metadata={'title': 'Design and Development of Retrieval-Based Chatbot Using Sentence Similarity', 'author': 'Haritha Akkineni', 'publish_date': '2021-09-04', 'subject': 'IoT and Analytics for Sensor Networks', 'doi': 'doi:10.1007/978-981-16-2919-8_43', 'keywords': 'Chatbot,Machine learning,Retrieval approach,Flask framework'}
502	page_content='valued sentence is sent to the user. For example, Input—“I code in python” and the dataset has two related sentences, Sentence 1—“I love to code in python” and Sentence 2—“I code in python language.” The similarity is checked by calculating the threshold of the input query with each of the two sentences in the dataset. The similarity threshold of the “Sentence 2” is higher than that of the “Sentence 1.” So, the appropriate answer for the “Sentence 2” is returned to the user. The intersection between two sentences, one which is the user query and the other is the pattern in database, gives the sentence similarity score. It is represented by S1 ∩S2 and S2 ∩S1, where S1 and S2 are two sentences. The formula to calculate sentence similarity score is shown in Eq. ( 1). Count (S1∩S2)∪Count (S2∩S1)/Count (S1)∪Count (S2) (1) Sample user input statement S1=“I code in python.” and the pattern in the database as: S2 =“I prefer to code in python.” Using the similarity algorithm, we get:S1={I code, code in, in python}' metadata={'title': 'Design and Development of Retrieval-Based Chatbot Using Sentence Similarity', 'author': 'Haritha Akkineni', 'publish_date': '2021-09-04', 'subject': 'IoT and Analytics for Sensor Networks', 'doi': 'doi:10.1007/978-981-16-2919-8_43', 'keywords': 'Chatbot,Machine learning,Retrieval approach,Flask framework'}
503	page_content='code, code in, in python} Count (S1) =3 S2={I prefer, prefer to, to code, code in, in python} Count (S2) =5 Now, S1 ∩S2=2 and S2 ∩S1=2. Calculated score for Sentence Similarity Let a=Count (S1 ∩S2) v Count (S1 ∩S2)=2∪2=4. Let b=Count (S1) ∪Count (S2) =3∪5=8. Similarity score is a/b =0.5. This procedure is adopted to calculate the sentence similarity score for each pattern stored in the database. The output for the users input query is displayed in the designed College enquiry Chatbot web app. The proposed system design is shown in Fig. 2which depicts the procedure of how the system is developed. Design and Development of Retrieval-Based Chatbot … 483 Fig. 2 College enquiry chatbot system design 5 Results and Discussion This system follows three main steps as shown in Fig. 3, i.e., Get Input, Process Input, and Return Response. Get Input : In the ﬁrst step, the user asks the Chatbot a question from any source (sources can be screen, speech recognition, or API). In this project, the user uses a console to' metadata={'title': 'Design and Development of Retrieval-Based Chatbot Using Sentence Similarity', 'author': 'Haritha Akkineni', 'publish_date': '2021-09-04', 'subject': 'IoT and Analytics for Sensor Networks', 'doi': 'doi:10.1007/978-981-16-2919-8_43', 'keywords': 'Chatbot,Machine learning,Retrieval approach,Flask framework'}
504	page_content='the user uses a console to converse with the Chatbot [ 11]. The initial message is displayed as “Hi, Welcome to PVPSIT Chatbot. I am at your service. Y ou can ask me questions!!” Process Input : The input given by the user is processed by the logic adapters. The logic adapters are those which are used to decide the logic for the Chatterbot to selecta response for the input asked by the user. Any number of logic adapters can be used in the project. There are two logic adapters used in this paper; “Mathematical Evaluation and “Best Match.” The bot gives back the response of the logic adapter that has higher conﬁdence value. If any two logic adapters have the same threshold/conﬁdence, then the ﬁrst logic adapters’ response is returned to the user. One can set the parametersfor the logic adapters like setting the default response, threshold, paths, etc. The “Best Match” logic adapter responds the user with the conﬁdence level of 0.70, and when the bot does not ﬁnd the best match for the input, it gives the' metadata={'title': 'Design and Development of Retrieval-Based Chatbot Using Sentence Similarity', 'author': 'Haritha Akkineni', 'publish_date': '2021-09-04', 'subject': 'IoT and Analytics for Sensor Networks', 'doi': 'doi:10.1007/978-981-16-2919-8_43', 'keywords': 'Chatbot,Machine learning,Retrieval approach,Flask framework'}
505	page_content='for the input, it gives the default response 484 H. Akkineni et al. Fig. 3 Flow chart diagram of college enquiry chatbot saying “I am sorry, but I do not understand. I am still learning.” Figure 4gives the responses after processing the input data by the Chatbot. Return Response : The bot returns the response through the console. The bot in this project is trained with the data related to the college and English language. This Chatbot can also respond to the input of various kinds like mathematical calculations,sports, emotions, and simple conversations. Figure 5depicts the logic of how training is performed. A questionnaire was constituted of various questions related to performance levels, humanity, effect, and accessibility, and was distributed among the students of the department. A sample of 240 responses was taken and analyzed, and the results conclude that the performance of the website improved by 20% when the chatbot isincluded. Considering humanity and affection, when compared to the existing one,' metadata={'title': 'Design and Development of Retrieval-Based Chatbot Using Sentence Similarity', 'author': 'Haritha Akkineni', 'publish_date': '2021-09-04', 'subject': 'IoT and Analytics for Sensor Networks', 'doi': 'doi:10.1007/978-981-16-2919-8_43', 'keywords': 'Chatbot,Machine learning,Retrieval approach,Flask framework'}
506	page_content='compared to the existing one, it reached an average level and a 5% improvement over the previous version. The statistics are shown in Table 3. Performance, Humanity, Effect, and Accessibility were the parameters that were considered to analyze the performance of the bot. A questionnaire was used for the comparative analysis [ 12]. This helps in designing more effective bots. To assess Design and Development of Retrieval-Based Chatbot … 485 Fig. 4 Responses after processing the input data by the chatbot Fig. 5 Training the chatbot Ta b l e 3 ChatBot quality assessment Category Quality attribute Metric Old system New system Performance Robustness to unexpected input % of success 60% 80% Humanity Able to maintain discussion Low to high Low Low Affect Provides greetings Low to high Low Average Accessibility Can detect meaning and intent % of success 70% 75% 486 H. Akkineni et al. the performance questions related to robustness, an unexpected input was questioned on. After analysis, it was evident that' metadata={'title': 'Design and Development of Retrieval-Based Chatbot Using Sentence Similarity', 'author': 'Haritha Akkineni', 'publish_date': '2021-09-04', 'subject': 'IoT and Analytics for Sensor Networks', 'doi': 'doi:10.1007/978-981-16-2919-8_43', 'keywords': 'Chatbot,Machine learning,Retrieval approach,Flask framework'}
507	page_content='analysis, it was evident that respondents stated that there is a clear improvement of 20% over the previous version. Coming to the category of humanity,questions based on maintaining discussion was assessed, and there was a signiﬁcant improvement from average to high [ 13]. Coming to the effect, questions on providing greetings were assessed. There is no speciﬁc change noted in both the versions [ 14]. Coming to the accessibility, there was improvement by 5% which is not quite noteworthy. This paper presents the overall approach used to design the chatbot, and compares the web application as-is study with the to-be website when the chatbot isincorporated. 6 Conclusion In this paper, a machine learning approach for College Enquiry Chatbot has been proposed. The responses of the Chatbot are obtained with the help of a “RetrievalBased” approach. This Chatbot can perform almost 30% of the entire task of the college. This makes the work easy and provides results within seconds. This proposed chatbot is designed' metadata={'title': 'Design and Development of Retrieval-Based Chatbot Using Sentence Similarity', 'author': 'Haritha Akkineni', 'publish_date': '2021-09-04', 'subject': 'IoT and Analytics for Sensor Networks', 'doi': 'doi:10.1007/978-981-16-2919-8_43', 'keywords': 'Chatbot,Machine learning,Retrieval approach,Flask framework'}
508	page_content='proposed chatbot is designed in python using “Flask Framework.” The chatbot mainly followsthree steps: Getting input queries from the user, processing the input, and returning the responses to the user. The methodology of the Chatbot is that it takes the input from the user, tokenizes the input, retrieves the matched response, calculates thesimilarity score, and then returns the appropriate response to the user. The results of to-be website when Chatbot is incorporated and the as-is website are compared based on the performance, humanity, effect, and accessibility. Of all those tests, thewebsite that incorporates the chatbot shows better performance, humanity, effect, and accessibility. Thus, implementing chatbot will reduce the work of the organization. Some of the limitations of the chatbot are domain knowledge, not possessing thepersonality. References 1. Schachner, T., Keller, R., & von Wangenheim, F. (2020). Artiﬁcial intelligence-based conversational agents for chronic conditions: Systematic literature' metadata={'title': 'Design and Development of Retrieval-Based Chatbot Using Sentence Similarity', 'author': 'Haritha Akkineni', 'publish_date': '2021-09-04', 'subject': 'IoT and Analytics for Sensor Networks', 'doi': 'doi:10.1007/978-981-16-2919-8_43', 'keywords': 'Chatbot,Machine learning,Retrieval approach,Flask framework'}
509	page_content='Systematic literature review. Journal of Medical Internet Research, 22 (9), e20701.  2. Xu, A., Liu, Z., Guo, Y ., Sinha, V ., & Akkiraju, R. (2017). A new chatbot for customer service on social media. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems—CHI ’17 (pp. 3506–3510). 3. Pawar, H., Prabhu, P ., Yadav, A., Mendonca, V ., & Lemos, J. (2018). College enquiry chatbot using knowledge in database. International Journal for Research in Applied Science & Engineering Technology (IJRASET) . ISSN: 2321-9653. 4. Mishra, S. K., Bharti, D., & Mishra, N. (2017), Dr. Vdoc: A medical chatbot that acts as a virtual doctor. Research & Reviews: Journal of Medical Science and Technology, 6 (3). Design and Development of Retrieval-Based Chatbot … 487 5. Prashant, B. P ., Anil, M. S., Dilip, K. M. (2018). Online chatting system for college enquiry using knowledgeable database. International Journal of Engineering Research in Electronics and Communication Engineering, 5 . 6. Pawar, S., Rane,' metadata={'title': 'Design and Development of Retrieval-Based Chatbot Using Sentence Similarity', 'author': 'Haritha Akkineni', 'publish_date': '2021-09-04', 'subject': 'IoT and Analytics for Sensor Networks', 'doi': 'doi:10.1007/978-981-16-2919-8_43', 'keywords': 'Chatbot,Machine learning,Retrieval approach,Flask framework'}
510	page_content='5 . 6. Pawar, S., Rane, O., Wankhade, O., Mehta, P . (2018). A web based college enquiry chatbot with results. International Journal of Innovative Research in Science, Engineering and Technology, 7(4). 7. Gangrade, J., Surme, S. S., Somu, S., Raskonda, S., Gupta, P . (2019). A review on college enquiry chatbot. International Journal of Engineering Science and Computing, 9 (3). 8. V amsi, G. K., Rasool, A., & Hajela, G. (2020). Chatbot: A deep neural network based human to machine conversation model. In 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT) (pp. 1–7). Kharagpur, India.  ICCCNT49239.2020.9225395 9. Wu, Li, Z., Wu, W., & Zhou, M. (2018). Response selection with topic clues for retrieval-based chatbots. Neurocomputing, 316 , 251–261. 10. Setiaji, B., & Wibowo, F. W. (2016). Chatbot using a knowledge in database: Humanto-machine conversation modeling. In 7th International Conference on Intelligent Systems, Modelling and Simulation (ISMS) (pp. 72–77).' metadata={'title': 'Design and Development of Retrieval-Based Chatbot Using Sentence Similarity', 'author': 'Haritha Akkineni', 'publish_date': '2021-09-04', 'subject': 'IoT and Analytics for Sensor Networks', 'doi': 'doi:10.1007/978-981-16-2919-8_43', 'keywords': 'Chatbot,Machine learning,Retrieval approach,Flask framework'}
511	page_content='(ISMS) (pp. 72–77). Bangkok.  6.53 11. Khan, R., & Das, A. (2018). Introduction to chatbots. In Build better chatbots (pp. 1–11). Berkeley, CA: Apress. 12. Maroengsit, W., Piyakulpinyo, T., Phonyiam, K., Pongnumkul, S., Chaovalit, P ., & Theeramunkong, T. (2019). A survey on evaluation methods for chatbots. In: Proceedings of the 2019 7th International Conference on Information and Education Technology (ICIET 2019)(pp. 111–119). New Y ork, NY , USA: Association for Computing Machinery.  10.1145/3323771.3323824 13. Miner, A. S., Milstein, A., Schueller, S., Hegde, R., Mangurian, C., & Linos, E. (2016). Smartphone-based conversational agents and responses to questions about mental health,interpersonal violence, and physical health. JAMA Internal Medicine, 176 (5), 619–625. 14. Seeger, A. M., & Heinzl, A. (2017). Human versus machine: Contingency factors of anthropomorphism as a trust-inducing design strategy for conversational agents. In Lecture notes in information systems and organization (V ol. 25, pp.' metadata={'title': 'Design and Development of Retrieval-Based Chatbot Using Sentence Similarity', 'author': 'Haritha Akkineni', 'publish_date': '2021-09-04', 'subject': 'IoT and Analytics for Sensor Networks', 'doi': 'doi:10.1007/978-981-16-2919-8_43', 'keywords': 'Chatbot,Machine learning,Retrieval approach,Flask framework'}
512	page_content='organization (V ol. 25, pp. 129–139). Cham: Springer.' metadata={'title': 'Design and Development of Retrieval-Based Chatbot Using Sentence Similarity', 'author': 'Haritha Akkineni', 'publish_date': '2021-09-04', 'subject': 'IoT and Analytics for Sensor Networks', 'doi': 'doi:10.1007/978-981-16-2919-8_43', 'keywords': 'Chatbot,Machine learning,Retrieval approach,Flask framework'}
513	page_content='SciPhyRAG Retrieval Augmentation to Improve LLMs on Physics Q&A Avinash Anand(B),A r n a vG o e l , Medha Hira , Snehal Buldeo , Jatin Kumar , Astha Verma , Rushali Gupta , and Rajiv Ratn Shah Indraprastha Institute of Information Technology, Delhi, India {avinasha,arnav21519,medha21265,snehal22074,jatin20206, asthav,rajivratn }@iiitd.ac.in Abstract. Large Language Models (LLMs) have showcased their value across diverse domains, yet their eﬃcacy in computationally intensivetasks remains limited in accuracy. This paper introduces a comprehensive methodology to construct a resilient dataset focused on High School Physics, leveraging retrieval augmentation. Subsequent ﬁnetun-ing of a Large Language Model through instructional calibration is proposed to elevate outcome precision and depth. The central aspiration is reinforcing LLM eﬃciency in educational contexts, facilitating moreprecise, well-contextualized, and informative results. By bridging the gap between LLM capabilities and the demands of complex' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
514	page_content='and the demands of complex educational tasks, this approach seeks to empower educators and students alike,oﬀering enhanced support and enriched learning experiences. Compared to Vicuna-7b, the ﬁnetuned retrieval augmented model SciPhy-RAG exhibits a 16.67% increase in BERTScore and 35.2% increase on ROUGE-2 scores. This approach has the potential to be used to reshape Physics Q&A by LLMs and has a lasting impact on their use for Physics education. Furthermore, the data sets released can be a reference pointfor future research and educational domain tasks such as Automatic Evaluation and Question Generation . Keywords: Document Retrieval ·Neural Text Generation ·Large Language Models ·Natural Language Processing ·Question-Answering 1 Introduction The rising popularity of transformer-based [ 4] Large Language Models can be attributed to their exceptional performance in tasks such as text generation, question answering, and document summarization [ 1]. Recent advancements in language model architectures, such' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
515	page_content='model architectures, such as the GPT-3.5 [ 2], PaLM [ 30], and LLAMA  have showcased their remarkable ability to comprehend and generate humanlike text. However, when it comes to domain-speciﬁc computational tasks, such assolving physics problems, language models often struggle to achieve the desired level of accuracy. c/circlecopyrtThe Author(s), under exclusive license to Springer Nature Switzerland AG 2023 V. Goyal et al. (Eds.): BDA 2023, LNCS 14418, pp. 50–63, 2023. _4 SciPhyRAG 51 Datasets have played an instrumental role in pushing forward performance on domain-speciﬁc tasks. In this research paper, we address the challenge ofimproving the accuracy of large language models (LLMs) for computational tasks by ﬁnetuning the model on a high school physics dataset we designed. We also introduce a high-quality corpus containing high school physics concepts from theNCERT textbook, considered a higher-education physics standard. The corpus is annotated manually to ensure its reliability and investigate the' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
516	page_content='and investigate the eﬀectiveness of retrieval-augmentation techniques in further enhancing the model’s performance. Physics problem-solving requires an in-depth understanding of all underlying concepts and the ability to apply them sequentially and logically. Traditional approaches to computational tasks rely on rule-based algorithms or symbolicmanipulation [ 32,33]. However, recent advancements in deep learning and language modelling have presented an opportunity to leverage the power of LLMs for these tasks. We believe that the eﬃcacy of LLMs in domain-speciﬁc computational tasks would be a pivotal step in their usage for education and learning. Language Models (LMs) rely on their inherent parameters to generate responses based on their knowledge accumulated via training of a huge corpus. With thousands of parameters holding the vast information, instances arise where domain-speciﬁc expertise, particularly prominent in complex ﬁelds suchas physics question answering, demands enhanced support [ 15]. The' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
517	page_content='enhanced support [ 15]. The notable complexities of physics queries suggest a potential advantage in incorporating relevant passages within the prompt. Given the complex and knowledge-intensivenature of physics problems, such an approach becomes imperative. In light of this, retrieval mechanisms oﬀer a viable avenue to explore. This paper explores retrieval augmentation techniques to enhance the ﬁnetuned LLM’s performance using good-quality support passages. Retrieval enhancement involves incorporating a retrieval-based model to provide additional context and guidance to improve the model’s reasoning capabilities. The contributions of this research paper are twofold. First, we present a high school physics dataset corpus using NCERT textbook content, with goodquality annotations for mathematical equations speciﬁcally curated to enhance the precision of LLMs in computational tasks and serve as a benchmark for evaluating their performance. Second, we prepare a novel retrieval pipeline witha self-annotated' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
518	page_content='pipeline witha self-annotated document corpus to enhance model performance. By addressing the limitations of LLMs in computational problem-solving and leveraging the potential of ﬁnetuning and retrieval augmentation, we aimto push the boundaries of language models’ accuracy for high school physics tasks. The insights gained from this research have the potential to revolutionize educational technologies, enabling intelligent tutoring systems and personalizedlearning experiences that support students on their journey to master complex scientiﬁc concepts. The written work is structured as follows: Sect. 2addresses the related works on math and scientiﬁc problem solvers, and Sect. 3explains the process behind data collection, annotation and augmentation. Section 4explains how we performed our experiments, and Sect. 5describes our evaluation metrics used and 52 A. Anand et al. the results obtained. The paper’s future scope and conclusion are summarised in Sect. 6respectively. 2 Related Work 2.1 Mathematics and' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
519	page_content='Work 2.1 Mathematics and Science Solvers We encountered several Mathematics and Science domain Q&A datasets in our exploration of datasets. However, we encountered a signiﬁcant absence of highquality and challenging physics question-answering datasets. AQuA-RAT  is a dataset comprising more than 100K algebraic word problems with natural language rationales. Each data point in the dataset pro-vides four values, i.e. the question, the options, the rationale behind the solution and the correct option. The MathQA  was created using a novel representation language to annotate AQuA-RAT and correct the noisy-incorrect data. The limitation of this approach is its exclusive focus on multiple-choice questions. However, we found the rationale parameter intriguing as it empowers the ﬁnetuned model tooﬀer logical explanations, aiding users in deeper comprehension of the problem and its solution. GSM8K  claims to contain questions that can be solvable by a bright middle school student. Therefore, it cannot be used to' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
520	page_content='it cannot be used to ﬁnetune a model for complex reasoning and computational tasks. MATH  is a dataset of 12.5K challenging mathematics problems in competition. Recently, there has also beenan emphasis on evaluating the capabilities of models in answering open-domain science questions. ScienceQA , a dataset collected from elementary and high school science curricula, contains 21K multimodal multiple-choice science questions. ASDiv (Academia Sinica Diverse MWP Dataset)  is a notable dataset where each math word problem(MWP) is associated with a problem type and gradelevel. The SCIMAT (Science and Mathematics Dataset)  is a valuable resource as it provides chapter-wise questions for class 11 and 12 Mathematics and Science subjects, together with numerical answers. However, a notable limitation of the dataset is the absence of explicit explanations for the solutionsor the underlying formulas related to the topics. This absence of contextual information hinders the dataset’s eﬀectiveness in fully supporting' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
521	page_content='in fully supporting comprehensive learning and understanding. 2.2 Document Retrieval in Science Q&A In Large Language Models, the learned knowledge about the outside world is implicitly stored in the parameters of the underlying neural network. Findingout what knowledge is stored in the network and where becomes challenging as a result [ 15]. The network’s size also aﬀects how much data can be stored; to capture more global information, one must train larger and larger networks, which SciPhyRAG 53 might be prohibitively slow or expensive. To bridge this gap, adding context to a given query in the input of a Large Language Model is helpful.  mentions how generative models for question answering can beneﬁt from passage retrieval. It retrieves support text passages from an external source of knowledge, such as Wikipedia. Then, a generative encoder-decoder modelproduces the answer, conditioned on the question and the retrieved passages. This approach has obtained state-of-the-art results on the Natural Questions' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
522	page_content='on the Natural Questions a n d TriviaQA  open benchmarks. This idea can be extended to domain-speciﬁc question answering. Given the complex nature of Physics and Math Questions, we assume that presenting the model with a set of relevant passages containing domain knowledge and required formulas can help the gen-erative model answer the questions more accurately. Most of the research in retrieval-augmented generation has been directed towards open-domain question answering. This involves extracting relevant information from external sources like Wikipedia to answer questions across various topics [ 15]. The wide range of information in Wikipedia greatly aids open domain question answering. Previously, domain-speciﬁc knowledge has been used to improve the performance of information retrieval systems. [ 34] created a data set by collecting question and answer pairs from the internet in the insurance domain. Our assumption in this work is that a corpus containing information in the physics domain would increase' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
523	page_content='physics domain would increase a model’s performance on physics question-answering tasks. 3 Datasets To further advance the application of language models in physics, we propose the creation of a comprehensive and challenging dataset. This study thus releases two open-source datasets : 1.PhyQA consists of 9.5K high school physics questions and answers with step-wise explanations. The dataset is diverse and consists of topics studied by high school physics students in the range of 15–19 years of age are includedin the dataset. The list of topics includes: Alternating Current; Atoms and Nuclei; Communication Systems; Electric Charges, Fields and Current; Electromagnetic Induction; Electromagnetic Waves; Capacitors; Dynamics andRotational Mechanics; Units, Dimensions and Kinematics; Ray and Wave Optics; Thermodynamics and Heat; Gaseous State; Waves, Sound and Oscillations. Each topic is divided into several subtopics. Both of these datasetsare meticulously formatted to make it easy to train and test on' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
524	page_content='it easy to train and test on open-source language models such as: LLAMA ,Alpaca a n d Vicuna . 2. The RetriPhy Corpus is a curated collection of Physics chapter content from NCERT books for 11 thand 12thgrades. It is annotated manually with LaTeX representations of equations and examples. The dataset includes 14chapters from each grade, 11 thand 12th, respectively. When prompted with a question, the combined corpus of all chapters creates context passages using the retrieval pipeline. 54 A. Anand et al. The proposed data sets serve multiple important purposes. Firstly, they enable the training of language models on complex reasoning and computationaltasks speciﬁc to physics, which requires a deeper understanding of scientiﬁc principles and relationships between variables. Second, they could serve as a valuable benchmark to assess the performance of existing language models inphysics problem-solving, allowing for a meaningful comparison of diﬀerent models and driving further advancements in natural language' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
525	page_content='in natural language understanding within the physics domain. Third, our retrieval corpus can be used to prepare andbenchmark retrieval systems and to retrieve high-quality passages for physics Q&A (Fig. 1). 3.1 PhyQA The dataset comprises 9.5K Physics questions, with each chapter having nearly equal representation. Each data point in the dataset is associated with two keys,i.e. “instruction” and “output”, to organize the information. They are described as follows: –Instruction : Key containing the question which needs to be answered by the model –Output : Key containing the corresponding numerical answer and a detailed explanation of how that answer was obtained. An example of a question from the chapter Newton’s Laws of Motion is given below: Instruction: An aircraft of mass 176 kg executes a horizontal loop at a speed of 249 m/s with its wings banked at 80 degrees. What is the radius of the loop? Output: Answer: 35162.514 m <sep >Explanation: To calculate the radius, we use the formula (v2) (g∗tan(param ∗π' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
526	page_content='formula (v2) (g∗tan(param ∗π 180)) where v is the speed (249 m/s), g is the acceleration due to gravity (10 m/s2),a n d param is the angle of banking 80◦. Substituting the values, R=249·249 10·tan(80∗π 180)= 35162 .514 m SciPhyRAG 55 Fig. 1. Insight into the number of questions at chapter-wise granularity in PhyQA 3.2 RetriPhy Corpus The RetriPhy Corpus comprises content extracted from NCERT books of Physics subjects for 11thand 12thgrades. These NCERT (National Council of Educational Research and Training) books are known for their concise, accurate, and easily understandable presentation of concepts. The corpus contains theorems, equations, solving numerical problems, and explanations spanning various topics such as electric charges, gravitation, optics, atoms and nuclei, etc. Containing material from all 14 chapters of the 11thand 12thgrade NCERT Physics books, the corpus comprises 28 documents , each corresponding to a chapter. Each chapter contains around 30–32 paragraphs , with approximately 400 tokens' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
527	page_content='with approximately 400 tokens per paragraph. The corpus extracts a total of 927 paragraphs .W e have also included an overlapping of 20 tokens in these paragraphs to ensure consistency (Fig. 2). 56 A. Anand et al. Fig. 2. Left : A snippet from the Physics textbook of a section about “Motion of Centre of Mass”; Right : A snippet of the annotation ﬁle corresponding to the textbook snippet 3.3 Data Collection and Augmentation PhyQA: Data collection started by improving upon SCIMAT’s science problems [ 5]. Additional data was collected by scraping standard Indian High School open-source physics textbooks of classes 11 and 12. Solvers have improved performance in answering math questions when the ﬁnetuning data set undergoes data enhancement transformations [ 19]. We extend this to physics problem-solving by taking base problems from each sub-topic and applying these transformations to include a wider variety of questions. These transformations are two in nature: – Substitution: Changing the values of constants' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
528	page_content='the values of constants in a question. – Paraphrasing: Paraphrasing the problem qusing a model to generate Ncandidate questions that diﬀer from the one in which they were written. RetriPhy: We have used NCERT textbook content to create the RetriPhy (Retrieval-based Physics) corpus. Our motivation for using NCERT textbook content is the concise and easy-to-understand explanation of concepts in these books. Also, PhyQA consists of problems related to the topics of grade 11thand 12thphysics; hence, the focus is on the content from the 11thand 12thgrade NCERT Physics textbooks. These chapter-wise documents on physics are accessible on the oﬃcial NCERT website. Our methodology involved using these documents to retrieve textual content from the chapters. To ensure an accurate representation of mathematical symbols and equations, we employed LaTeX annotations, thereby elim-inating the potential for ambiguity in text interpretation. 3.4 Data Annotation PhyQA: Our team consisted of ﬁve dataset annotators, each of' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
529	page_content='dataset annotators, each of whom had graduated high school and studied physics until class 12. Upon self-evaluation SciPhyRAG 57 on a scale of 5, the annotators rated themselves as 3, 3, 4, 4 and 5. We veriﬁed this self-evaluation by giving them a small test on basic questions to checkfundamental understanding. They used this in-depth understanding of physics concepts to annotate the solutions and provide relevant formulae and concepts. The annotated questionswere then shuﬄed amongst the remaining annotators to evaluate the dataset’s quality. Upon this, the annotators who rated themselves as 3 could solve only 55% problems given to them, while the one rated 5 could solve 80% of theproblems. This shows that the dataset has high-quality questions and can be challenging for humans, too. RetriPhy: The annotation process for the Retriphy corpus is aimed at the accurate representation of mathematical symbols and equations present in the content of NCERT textbooks. For every mathematical notation or equation in the' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
530	page_content='notation or equation in the text, we have used LaTeX for its annotation. To identify the start and endof the LaTeX content in the text, we have added a $ symbol as the start and end delimiters (Fig. 2). In the annotation process of RetriPhy, our team comprised three annotators, each contributing to approximately one-third of the annotations. A shared segment of annotations was distributed to all annotators to validate the annotations, allowing for cross-evaluation. This experimentrevealed an impressive accuracy rate of 87% among the annotations. Furthermore, the accuracy of annotations for all chapters is veriﬁed by both the annotators and an expert in the domain. 3.5 Inter-Annotator Agreement for Data Validation In the data validation process, a team of ﬁve data annotators, all proﬁcient college students in the domain of high school Physics, was employed. The dataset was equally divided among the annotators to ensure a balanced workload. Within this team, one annotator possessed expert-level knowledge,' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
531	page_content='expert-level knowledge, while the remainingfour were classiﬁed as having intermediate expertise. Rigorous attention to detail was exercised throughout the data annotation process to uphold the accuracy of the annotations. A meticulous approach wastaken, whereby each segment annotated by one annotator underwent a veriﬁcation stage involving assessment by two other annotators. This multiple-layer validation strategy was adopted to enhance the reliability of the annotated data. TheFleiss’ Kappa score of this annotation process was 0.65. By combining the expertise of the annotators, the cross-validation process, and the Fleiss’ Kappa coeﬃcient application, a robust framework for data validation was established, ensuring the accuracy and integrity of the annotated high school Physics dataset. 4 Experiments We describe the SciPhy retrieval experiment that uses both data sets we released. Language models’ performance in question-answering tasks improves 58 A. Anand et al. with ﬁnetuning on data sets with questions' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
532	page_content='on data sets with questions rephrased as instruction-following data points [ 3]. Following this, we ﬁnetune an open-source large language model with PhyQA . We then incorporate retrieval by using our high-quality retrieval document dataset as a database for retrieving documents. We prepare a retrieval pipelinewith our document vectorbase and use that to provide context on the test questions to evaluate the accuracy of the model answers on evaluation metrics. We elaborate on this approach in forthcoming subsections. 4.1 Fine-Tuning Using LoRA Model and Hyperparameters: Vicuna [ 10] is a large language model prepared by ﬁnetuning a Llama base model on 70k user-shared conversations. We used a Vicuna model with 7 billion parameters as our baseline. Natural language processing consists of pre-training language models on general text and ﬁnetuningmodel parameters on domain-speciﬁc data. However, as the model size increases, it is computationally expensive to ﬁnetune models, which involves retraining all parameters' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
533	page_content='retraining all parameters fully. We thus adopt the LowRankAdaptation (LoRA) [ 9], which proposes freezing model weights and injecting lower rank matrices into transformer layers that can be trained. This reduces training time and the hardware needed to keep model accuracy intact. We hypothesize that ﬁnetuningVicuna-LoRA on our annotated PhyQA physics dataset will greatly improve the model’s capabilities to answer physics questions. Experiment: For this task, the PhyQA dataset is split into 8000 training samplesand 1500 test samples . The training set is used to ﬁnetune the model. The Vicuna-LoRA model is run with diﬀerent model weight representations, i.e. an 8-bit representation and a 16-bit representation. The LoRA rank ris set to 8with a LoRA-dropout of 0.05for preparing the 8-bit ﬁnetuned model and is set to 16for preparing the 16-bit ﬁnetuned model. The ﬁnetuning is run for 3 epochs with a batch size of 128and the learning rate equal to 3e-4i.e. the Karpathy constant on an NVIDIA RTX A6000 GPU. 4.2' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
534	page_content='an NVIDIA RTX A6000 GPU. 4.2 Rationale Behind Retrieval: Our second experiment hypothesizes that providing relevant context to our language model about the question as input will greatly improve the explanation and precision of the answers. This is based on physics being driven by conceptsand their interpretation rather than simply applying formulae. Given a query q, the retrieval-based system is prompted to ﬁnd Nrelevant passages. Each passage is retrieved and appended with a <s e p> token. Query qis prepended to the Nretrieved passages to form the ﬁnal user query q f, which can be described as: qf=q+<s e p> +n/summationdisplay i=1(Ni+<s e p> ) qfis then prompted to the ﬁnetuned Vicuna LoRA 7-billion model described in Sect. 4.1to get the answer. SciPhyRAG 59 4.3 Retrieval System Design: Combined with Vicuna-7b, LoRA ﬁnetuned on PhyQA , the retrieval system is called SciPhy-RAG . The RetriPhy Corpus creates passages of 400 tokens each. After creating the passages, the next step is to perform indexing, which' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
535	page_content='is to perform indexing, which addresses the challenge of memory storage. We retrieve relevant passages byusing similarity matches between the indexed passages and the user query. However, as the corpus grows with more passages, this task becomes progressively more time-consuming. To eﬃciently store and index the passages, we adopt amethod of representing them as dense vectors [ 22]. VectorStores, like Pinecone, are used for indexing and storing vector embeddings of text data for fast retrieval. It uses Approximate Nearest Neighbour(ANN) search in higher dimensions [ 27], which allows for handling large numbers of queries. ANN proposes, when given a set Pofnpoints (in this case, a set of nqueries), a metric ball B D(q|r) in metric space ( X, D). It creates a data structure Ssuch that for any query q∈X,Sreturns a point pthat satisﬁes: D(p, q)≤r ∀p∈BD(q, cr)∩P It minimises this for some c≥1 and returns the point pat the minima. In our approach, each passage is converted into a 384-dimensional dense' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
536	page_content='into a 384-dimensional dense vectorembedding using the all-MiniLM-L6-v2 model . These passages are then stored in the VectorStore described above. Experimentation: When prompted with a user query q, the system applies ANN search to identify top K relevant passages where the user speciﬁes K. The passages are returned by the system and appended to q. This ﬁnal prompt with the passages q fis prepared. We use the technique described in Sect. 4.1 to ﬁnetune Vicuna-7b using LoRA on PhyQA. The prompt qfis inputted into the model speciﬁed above to obtain our ﬁnal output. 5 Results 5.1 Evaluation Metrics We perform a two-tier evaluation of the ﬁne-tuned models. We ﬁrst choose the evaluation metrics such as BERT-Score [ 21], METEOR [ 24]a n dR O U G E L , ROUGE-1 and ROUGE-2 [ 25]. These help us assess the quality and correctness of the explanations generated by the models. We then sample 100 questions from each chapter and prompt the model to give a “One-Word Answer”. Thisgives the numeric answer, and we treat it as' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
537	page_content='answer, and we treat it as a classiﬁcation task measuring the accuracies with the ground-truth answers of the test set. We call this metric as Final Answer Accuracy (FAA) . We repeat this with ten randomly chosen samples and report the lowest accuracies achieved out of the 10. 60 A. Anand et al. 5.2 Experimental Results and Analysis Upon ﬁnetuning the baseline Vicuna-7B model and attaching the retrieval system, we get two models from the experimental setups described above. Table 1 shows their results on the evaluation metrics described above. Our ﬁnetuned SciPhy-RAG 16-bit model (i.e. our retrieval pipeline + Vicuna-LoRA 16-bit) shows a 16.67% increase on BERT-F1 scores over the base Vicuna-7b model. This shows that ﬁnetuning with PhyQA and using RetriPhy as our retrieval corpus increases the quality of explanations by a signiﬁcant amount over the base model. Table 1. Table showing the BERT, ROUGE and METEOR scores of the two ﬁnetuned Vicuna-LoRA models Metric Vicuna-7B SciPhy-RAG (8-bit) SciPhy-RAG' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
538	page_content='SciPhy-RAG (8-bit) SciPhy-RAG (16-bit) BERT (F1) 0.768 0.887 0.899 BERT (Precision) 0.744 0.876 0.865 BERT (Recall) 0.784 0.886 0.895 METEOR 0.285 0.347 0.352 ROUGE-L 0.321 0.371 0.389 ROUGE-1 0.315 0.358 0.363 ROUGE-2 0.147 0.181 0.195 On METEOR, our 8-bit SciPhy-RAG shows a 22.8% increase. On the ROUGE evaluation metrics (ROUGE-L, ROUGE-1 and ROUGE-2), 16-bit SciPhy-RAG shows a much higher improvement ( 19.4% ,22.2% and35.3% respectively) over the base Vicuna-7b model. We hypothesize that METEORscores are calculated based on unigram matching between the reference and candidate sentences [ 23], and the retrieval models drive the model output generation slightly away from the ground truth explan ation. The same hypothesis holds for lesser improvements in ROUGE scores. However, the increase in BERT scores validates that the explanations are semantically similar and high quality. Table 2shows the ﬁnal answer accuracy (FAA) for the base-Vicuna-7b model (i.e. before) and the SciPhy-RAG (16-bit) model after' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
539	page_content='(16-bit) model after ﬁnetuning and applying retrieval. Note that the lowest scores have been reported for both models, and this shows a massive increase across chapters, showing improvement despite skewness in the training data. Due to resource constraints, the lower accuracies can be attributed to running these experiments on smaller models. However, ourhypothesis can be extended to larger models with sizes of parameters ¿ 50 B and newer architectures. SciPhyRAG 61 Table 2. Final Answer Accuracy before and after Fine-Tuning with PhyQA Chapter Before After Alternating Current 21.3 26.2 Atoms and Nuclei 20.8 27.1 Communication Systems 15.3 21.2 Electric Charges 22.9 26.5 Fields and Current 23.5 28.6 Electromagnetic Induction 22.2 29.1 Electromagnetic Waves 23.8 26.3 Capacitors 25.1 28.3 Dynamics & Rotational Mechanics 24.7 29.2 Units, Dimensions & Kinematics 22.4 27.3 Ray and Wave Optics 23.6 26.5 Thermodynamics and Heat 21.5 27.2 Gaseous State 19.6 24.3 Waves, Sound and Oscillations 20.6 28.4 6 Conclusion' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
540	page_content='20.6 28.4 6 Conclusion and Future Work As we enter the future, we envision several promising avenues for further exploration. One such direction involves the incorporation of the Chain of Thought a n d Tree of Thought  prompting techniques. Augmenting our datasets to incorporate these prompting techniques could lead to richer explanations and higher accuracies. A custom annotated retrieval dataset could also be prepared for preparing the vector database to improve the quality of retrieved texts. Another extension area is curating benchmarks for other STEM ﬁelds, such as Chemistry and Biology, which will give rise to Multimodal models and further advancements in using LLMs and Artiﬁcial Intelligence to hasten up research and improve the quality of learning and education in these ﬁelds. The symbiosis of PhyQA andRetriPhy with advanced LLM ﬁnetuning techniques and retrieval augmentation marks a signiﬁcant step towards empowering AI-driven physics education. We envision a physics-based Q&A system catering to a' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
541	page_content='Q&A system catering to a student. As we embark on continuous improvement and explo-ration, we anticipate that our research will pave the way for more intelligent, interactive, and personalized learning experiences in physics and beyond. Additionally, these datasets will help drive research in AI-driven education tasks suchas Automatic Evaluation and provide a foundation for making similar datasets. Acknowledgments. We want to acknowledge the contribution of our data annotators, Aryan Goel, Ansh Varshney, Siddhartha Garg and Saurav Mehra. Rajiv RatnShah is partly supported by the Infosys Center for AI, the Center for Design and New Media, and the Center of Excellence in Healthcare at IIIT Delhi. 62 A. Anand et al. References 1. Goel, A., Hira, M., Anand, A., Bangar, S., Shah, D.R.R.: Advancements in scientiﬁc controllable text generation methods (2023) 2. Brown, T., et al.: Language models are few-shot learners (2020)3. Chung, H., et al.: Scaling instruction-ﬁnetuned language models (2022)4. Vaswani, A., et' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
542	page_content='(2022)4. Vaswani, A., et al.: Attention is all you need (2017)5. Chatakonda, S.K., Kollepara, N., Kumar, P.: SCIMAT: dataset of problems in science and mathematics. In: Srirama, S.N., Lin, J.C.-W., Bhatnagar, R., Agarwal, S., Reddy, P.K. (eds.) BDA 2021. LNCS, vol. 13147, pp. 211–226. Springer, Cham (2021).  16 6. Cobbe, K., et al.: Training veriﬁers to solve math word problems. ArXiv Preprint ArXiv:2110.14168 (2021) 7. Hendrycks, D., et al.: Measuring mathematical problem solving with the MATH dataset (2021) 8. Touvron, H., et al.: Open and eﬃcient foundation language models. In: LLaMA (2023) 9. Hu, E., et al.: Low-rank adaptation of large language models. In: LoRA (2021) 10. Chiang, W.L., et al.: Vicuna: an open-source chatbot Impressing GPT-4 with 90 (2023) 11. Ling, W., Yogatama, D., Dyer, C., Blunsom, P.: Learning to solve and explain algebraic word problems. In: Program induction by rationale generation (2017) 12. Miao, S., Liang, C., Su, K.: A diverse corpus for evaluating and developing English math' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
543	page_content='and developing English math word problem solvers (2021) 13. Izacard, G., Grave, E.: Leveraging passage retrieval with generative models for open domain question answering (2021) 14. Lu, P., et al.: Multimodal reasoning via thought chains for science question answering, learn to explain (2022) 15. Guu, K., Lee, K., Tung, Z., Pasupat, P., Chang, M.: Retrieval-augmented language model pre-training. In: REALM (2020) 16. Kwiatkowski, T., et al.: Natural questions: a benchmark for question answering research. In: Transactions Of The Association For Computational Linguistics, vol.7, pp. 453–466 (2019) 17. Joshi, M., Choi, E., Weld, D., Zettlemoyer, L.: Triviaqa: a large scale distantly supervised challenge dataset for reading comprehension. ArXiv Preprint ArXiv:1705.03551 . (2017) 18. Miao, S., Liang, C., Su, K.: A diverse corpus for evaluating and developing English math word problem solvers. ArXiv. abs/2106.15772 (2020) 19. Kumar, V., Maheshwary, R., Pudi, V.: Data augmentation for math word problem solvers. In:' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
544	page_content='word problem solvers. In: Practice Makes a Solver Perfect (2022) 20. Taori, R., et al.: Hashimoto stanford alpaca: an instruction-following LLaMA model (2023).  alpaca 21. Zhang, T., Kishore, V., Wu, F., Weinberger, K., Artzi, Y. Evaluating text generation with BERT. In: BERTScore (2020) 22. Karpukhin, V., et al.: Dense passage retrieval for open-domain question answering (2020) 23. Saadany, H.: Constantin or˘ asan and BLEU, METEOR, BERTScore: evaluation of metrics performance in assessing critical translation errors in sentiment-oriented text. In: Proceedings Of The Translation And Interpreting Technology Online Conference TRITON 2021 (2021).  006 SciPhyRAG 63 24. Banerjee, S., Lavie, A.: METEOR: an automatic metric for MT evaluation with improved correlation with human judgments. In: Proceedings of The ACL Workshop On Intrinsic And Extrinsic Evaluation Measures For Machine TranslationAnd/or Summarization, pp. 65–72 (2005) 25. Lin, C.: Rouge: a package for automatic evaluation of summaries. In: Text' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
545	page_content='of summaries. In: Text Summarization Branches Out, pp. 74–81 (2004) 26. Wang, W., et al.: Deep self-attention distillation for task-agnostic compression of pre-trained transformers. In: MiniLM (2020) 27. Andoni, A., Indyk, P., Razenshteyn, I.: Approximate nearest neighbor search in high dimensions (2018) 28. Wei, J., et al.: Chain-of-thought prompting elicits reasoning in large language models (2023) 29. Yao, S., et al.: Deliberate problem solving with large language models. In: Tree of Thoughts (2023) 30. Chowdhery, A., et al.: Scaling language modeling with pathways. In: PaLM (2022) 31. Deng, J., Dong, W., Socher, R., Li, L., Li, K., Fei-Fei, L.: ImageNet: a large-scale hierarchical image database. In: 2009 IEEE Conference On Computer Vision AndPattern Recognition, pp. 248–255 (2009) 32. Kojima, T., Gu, S., Reid, M., Matsuo, Y., Iwasawa, Y.: Large language models are zero-shot reasoners. Adv. Neural. Inf. Process. Syst. 35, 22199–22213 (2022) 33. He-Yueya, J., Poesia, G., Wang, R., Goodman, N.: Solving' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
546	page_content='R., Goodman, N.: Solving math word problems by combining language models with symbolic solvers (2023) 34. @miscfeng2015applying, title=Applying Deep Learning to Answer Selection: A Study and An Open Task, author=Minwei Feng and Bing Xiang and Michael R. Glass and Lidan Wang and Bowen Zhou, year=2015, eprint=1508.01585, archivePreﬁx=arXiv, primaryClass=cs.CL' metadata={'title': 'SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A', 'author': 'Avinash Anand', 'publish_date': '2023-11-24', 'subject': 'Big Data and Artificial Intelligence', 'doi': 'doi:10.1007/978-3-031-49601-1_4', 'keywords': 'Document Retrieval; Neural Text Generation; Large Language Models; Natural Language Processing; Question-Answering'}
547	page_content='Retrieval-Augmented Knowledge-Intensive Dialogue Zelin Wang, Ping Gong(B), Yibo Zhang, Jihao Gu, and Xuanyuan Yang School of Artiﬁcial Intelligence, Beijing University of Posts and Telecommunications, Beijing, China {wang zelin,pgong,zhangyibo,gujihao }@bupt.edu.cn Abstract. Large pre-trained language models have been shown to be powerful in open-domain dialogue. However, even the largest dialogue models suﬀer from knowledge hallucination, generating statements thatare plausible but factually incorrect. Recent works, such as RAG and FiD, have introduced retrieval methods to alleviate this issue by bringing in external knowledge sources. Based on this research direction, wepropose a plug-and-play method to enhance the generator’s performance by introducing demonstration-based learning, which allows the generator to better understand the task. Furthermore, we propose a novelrepresentation-interaction ranking model, RM-BERT, inspired by residual connections, which can more eﬀectively represent the semantic' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
548	page_content='represent the semantic information of context and document to improve retrieval accuracy. Experi-mental results indicate that the generator improvement method is applicable to multiple datasets and multiple models simultaneously. Additionally, we demonstrate that RM-BERT achieves performance close toBERT while signiﬁcantly reducing computational overhead. Keywords: Dialogue system ·Retrieval-augmented generation · Document retrieval 1 Introduction Large pre-trained language models, such as GPT3 [ 2], PaLM [ 4] and ChatGPT, have been shown to produce impressive performance on a range of tasks, espe-cially in generating coherent, ﬂuent and human like texts [ 7]. Knowledge is implicitly stored in the weights of these models, which often contain billions of parameters, enabling them to have certain knowledge on open-domain top-ics . Unfortunately, even the largest dialogue models suﬀer from the hallucination of knowledge, which can be interpreted as a form of lossy compression when employing training to encode' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
549	page_content='employing training to encode that knowledge within the weights of a neu-ral network [ 13]. The phenomenon of knowledge hallucination is prevalent in knowledge-intensive dialogue, which can signiﬁcantly erode the user’s trust in the model-generated results. This study was supported by the National Natural Science Foundation of China under Grant 51978300. c/circlecopyrtThe Author(s), under exclusive license to Springer Nature Switzerland AG 2023 F. Liu et al. (Eds.): NLPCC 2023, LNAI 14302, pp. 16–28, 2023. _2 Retrieval-Augmented Knowledge-Intensive Dialogue 17 Recent works, such as RAG [ 16]a n dF i D[ 9], have augmented model generation by integrating external knowledge sources, known as retrieval-augmentedtext generation. This approach eﬀectively mitigates the problem of knowledge hallucination. Retrieval-augmented text generation is a new text generation paradigm that fuses emerging deep learning technology and retrieval technol-ogy . Compared with generation-based counterpart, this new paradigm not only' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
550	page_content='this new paradigm not only improves the correctness of the model to generate factual answers, but also helps avoid safe but boring responses by leveraging external knowledge thatis not present in the dialogue history. Besides, without signiﬁcantly aﬀecting model performance, the knowledge is not necessary to be implicitly stored in model parameters, but is explicitly acquired in a plug-and-play manner, leadingto great scalability [ 17]. For example, Retro [ 1] obtains comparable performance to GPT-3 and Jurassic-1 [ 18], despite using 25 ×fewer parameters. The key to improving the quality of generation is how to extract useful information from retrieved external documents and integrate them into answers. Speciﬁcally, on the dialogue response generation task, exemplar/templateretrieval as an intermediate step has been shown beneﬁcial to informative response generation [ 3,29,30]. Therefore, our work proposes a demonstrationbased learning method, as shown in Fig. 1. We concatenate context and document with' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
551	page_content='context and document with demonstration examples retrieved from the training set and feeds them into the generator. Subsequently, only the document and context segments generated by the encoder are utilized as input for the decoder to compute multi-head attention. The goal is to provide the generator with a better understanding of the task from the demonstrations so that it can make better use of the retrieved documents. As a plug-and-play module, our approach can be appliedto various existing encoder-decoder models. To our knowledge, our work is the ﬁrst to use demonstration-based learning to improve generator structures in knowledge-intensive dialogue. Fig. 1. Demonstration-based learning framework for generator In knowledge-intensive dialogue, the accuracy of the retrieval model plays a crucial role in generating subsequent responses. [ 20] demonstrated for the ﬁrst time from both theoretical and experimental perspectives that when the docu-ment is longer, it is diﬃcult for a single ﬁxed-dimensional' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
552	page_content='for a single ﬁxed-dimensional vector to eﬀectively represent the semantic information of the document. To obtain better results, it is necessary to expand the dimension of the representation vector or increase 18 Z. Wang et al. the number of representation vectors. In this paper, we propose RM-BERT , a representation-interaction ranking model based on residual multi-vector over BERT , as shown in Fig. 2. By increasing the number of representation vectors, RM-BERT can better represent the semantic information of both documents and contexts, thereby improving retrieval performance. While conceptually simple,RM-BERT outperforms strong baselines on several benchmarks and achieves similar performance to BERT, while computing much faster than BERT. Fig. 2. Architecture of the RM-BERT 2 Related Work Dense Retriever. According to the diﬀerent ways of encoding the context and document as well as of scoring their similarity, dense retrievers can be roughlydivided into three types [ 31]. Representation-based models,' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
553	page_content='Representation-based models, such as Realm [ 8]a n d DPR [ 11], are known for their speed, as the representations of documents can be computed and indexed oﬄine in advance. However, the accuracy of these models is often compromised, as they only capture shallow interactions. Interactionbased models, such as BERT [ 5], can oﬀer high accuracy by allowing for deep interactions between context and document. However, the heavy computation required by these models is not practical for real-world applications. To strike a balance between eﬀectiveness and eﬃciency, a representation-interaction modelis preferred. Many of these models use a late interaction architecture, such as ColBERT [ 12]. This architecture can not only compute the document representation in advance but also allow deep interactions between context and document,thus oﬀering a good trade-oﬀ between speed and accuracy. Retrieval-Augmented Knowledge-Intensive Dialogue 19 Generator. Recent research has focused on how to train a generator to better use' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
554	page_content='a generator to better use retrieved external knowledge to improve the quality of the generated out-put. In previous studies, most models such as RAG and FiD just concatenate document and context and then input them into the model. They hope that the model will directly learn how to use the retrieved documents during the gradientdescent. In contrast to these approaches, our proposal uses demonstration-based learning. In the supervised learning setting, the text most similar in distribution to the data in inference is the training data [ 28]. Therefore, we retrieve data from the training set as demonstration examples. By providing appropriate training data as demonstration examples, the model can gain a better understanding of the task and produce improved answers. 3 Methodology Consider a conditional generation task where the input is a context cand the answer yis a sequence of tokens. To achieve better generation results in knowledge-intensive dialogue, external documents D={d1,d2,...,d n}are usually' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
555	page_content='D={d1,d2,...,d n}are usually introduced. Retrieval-augmented text generation is the approach of addingexternal documents Dfor the model to condition on during its generation of y. First, the retriever retrieves the top-k documents D k={d1,d2,...,d k}most relevant to context c. Retriever can either directly retrieve the entire documents, or perform a preliminary retrieval ﬁrst, and then sort the results. The generator then takes the context cand documents Dkas input to predict the answer y. Our generator is an encoder-decoder architecture designed according to the sequence-to-sequence modeling paradigm [ 26]. Speciﬁcally, the generator is based on the Transformer [ 27] architecture (e.g., BART [ 15] and T5 [ 23]) and parametrized by θ. We use the generator to model p(y|c,D k;θ), where candDk are encoded by the bidirectional encoder, and the decoder predicts yautoregressively (conditioned on the encoded candDkand its left context). The likelihood ofp(y|c,D k;θ) is deﬁned as: p(y|c,D k;θ)=N/productdisplay' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
556	page_content='p(y|c,D k;θ)=N/productdisplay t=1p/parenleftbig yt/vextendsingle/vextendsingley1:t−1,c,D k;θ/parenrightbig (1) where N is the number of answer tokens. Next, we introduce our generator improvement method and ranking model RM-BERT. 3.1 Generator An illustration of our demonstration-based learning framework for generator is shown in Fig. 1. In the traditional retrieval-augmented generation, only document and context are input into the encoder. As an improvement we add additional demonstration examples as input to the encoder. In contrast to existing approaches that require additional human eﬀort to generate such auxiliary 20 Z. Wang et al. supervisions, our demonstrations can be automatically constructed by retrieving appropriate data from the training set. More precisely, we use BM25 [ 24] to retrieve training instances from the training set. Following the encoding and semantic interaction of the above three by the encoder, only the document and context portions produced by the encoder are utilized as input' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
557	page_content='encoder are utilized as input for the decoderto compute multi-head attention. For a given training set T={(c 1,y1),...,(cm,ym)}, we index it into a list of key-value pairs, where ciis the context and yiis the ground-truth label. Given a context ci, we search for the top-q most similar contexts in the index as demonstrations Gq. Note that during training, as the context ciis already indexed, we ﬁlter it from the retrieval results to avoid data leakage. Then weconcatenate demonstrations with context c iand retrieved external documents Dk={d1,d2,...,d k}to feed into the encoder. In the multi-turn dialogue scene, we only use the answer as demonstration, so Gq={yi1,...,y iq}and the input form is [ dj;ci;yi1;...;yiq]. For the single-turn dialogue scene similar to question answering, we concatenate the context and answer as demonstration, so Gq= {(ci1,yi1),...,(ciq,yiq)}and its input form is [ dj;ci;ci1;yi1;...;ciq;yiq].djis one of the documents of Dk, so the actual input is a batch of size k. After adding the' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
558	page_content='of size k. After adding the demonstration examples, Eq. 1is rewritten as: p(yi|ci,D k,G q;θ)=N/productdisplay t=1p/parenleftbig yt i/vextendsingle/vextendsingley1:t−1 i,ci,D k,G q;θ/parenrightbig (2) where N is the number of answer tokens. The ﬁnal loss is deﬁned as the negative log-likelihood: LNL L=−logp(yi|ci,D k,G q;θ) (3) During inference, we will not ﬁlter any retrieved information, as all the retrieve data only come from training set. 3.2 RM-BERT As Fig. 2illustrates, the lower portion of RM-BERT is a representation-based model similar to DPR. However, unlike DPR, the two encoders we employ share parameters. Then we extend the representation-based model by adding a Transformer encoder layer. The motivation for this is that [ 21] has shown that the lower biLM layers specialize in local syntactic relationships, allowing the higher layers to model longer range relationships such as coreference, and to specialize for the language modeling task at the top most layers. To ensure retrieval eﬃ-ciency, we only' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
559	page_content='retrieval eﬃ-ciency, we only use one layer of Transformer encoder. Finally, we add a MLP classiﬁer behind the Transformer encoder layer for classiﬁcation. During training, we ﬁrst use two encoders to capture the local syntactic relationships of context and document respectively. Then we concatenate the outputs of these two encoders and feed them into the subsequent Transformer encoder layer to model longer range relationships. To represent semantic information more fully, we concatenate T C[CLS ]andTD[CLS ]output by the context encoder and document encoder with T/prime C[CLS ]andT/prime D[CLS ]output by the Retrieval-Augmented Knowledge-Intensive Dialogue 21 Transformer encoder layer. Finally, they are fed into the MLP classiﬁer for classiﬁcation. TC[CLS ]andTD[CLS ]focus on each individual sentence and play a role in expanding semantic information. T/prime C[CLS ]andT/prime D[CLS ]focus on the semantic information after interaction and play a role in fully understanding the relationship between context and' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
560	page_content='between context and document. Given a collection of contexts C={c1,c2,...,c m}and a collection of documents D={d1,d2,...,d n}, the relevance score of citodj, denoted as s(ci,d j), is estimated via a MLP classiﬁer: s(ci,d j)=MLP/parenleftBig Concat/parenleftBig T/prime C[CLS ],T/prime D[CLS ],T C[CLS ],T D[CLS ]/parenrightBig/parenrightBig (4) The probability of a document djbeing relevant to the context ciis calculated as: p(dj|ci,D)=exp(s(ci,d j)) /summationtext|D| k=1exp(s(ci,d k))(5) The ranking model parameters are updated by minimizing the cross-entropy loss: L=−/summationdisplay (ci,d j)(zi,jlog(pi,j)+( 1 −zi,j)log(1−pi,j)) (6) where zi,jis the ground-truth label of cianddjandpi,jis equivalent to p(dj|ci,D). During inference time, we ﬁrst apply the document encoder to all the documents and save the encoding results oﬄine. At runtime, only the context needsto be fed into the context encoder for encoding. The context encoding result is then fed into the Transformer encoder layer together with the' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
561	page_content='layer together with the precomputed document encoding result. 4 Experiments In this section, we will introduce more details about experiments and the corre-sponding analysis. 4.1 Datasets We conduct experiments on three datasets: Wizard of Wikipedia [ 6], Natural Questions [ 14] and TriviaQA [ 10]. Wizard of Wikipedia is a large dataset of Table 1. Dataset statistics Task Dataset Train Dev multi-turn dialogue WoW 63734 3054 single-turn dialogue NQ 87372 2837 single-turn dialogue TriviaQA 61844 5359 22 Z. Wang et al. multi-turn dialogue grounded with knowledge retrieved from Wikipedia. The input is a short dialog history ending with the information seekers turn. NaturalQuestions and TriviaQA are question answering datasets, which are equivalent to single-turn dialogue scenario in knowledge-intensive dialogues. Unlike the original versions, the relevant Wikipedia page must be found by a retrieval step.Overall statistics can be found in Table 1. To retrieve the necessary information, we employ the standard KILT' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
562	page_content='we employ the standard KILT Wikipedia dump 1. Without loss of generality, we only merge the groundtruth label documents of the three datasets as our knowledge source for retrieval. 4.2 Evaluation Metrics We employ standard KILT automatic metrics. KILT contains multiple evaluation metrics, which can be roughly divided into three types: (1) downstream results, (2) performance in retrieving relevant evidence to corroborate a prediction and (3) a combination of the two [ 22]. For retrieval task, in order to measure the correctness of the provenance, we adopt R-Precision and Recall@5. R-precision, calculated as r/R, where R is the number of Wikipedia pages inside each provenance set and r is the number of relevant pages among the top-R retrieved pages. Recall@k, calculated as w/n, where n is the number of distinct provenance sets for a given input and w is thenumber of complete provenance sets among the top-k retrieved pages [ 22]. For generation task, Wizard of Wikipedia uses Rouge-L, F1, KILT-RL and KILT-F1 to' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
563	page_content='F1, KILT-RL and KILT-F1 to measure the correctness of the generated output. Natural Questionsand TriviaQA use EM, F1, KILT-EM, KILT-F1. The KILT scores only award EM, ROUGE-L and F1 points to KILT-EM, KILT-RL and KILT-F1 respectively, if the R-precision is 1 [ 22]. This metric is employed to emphasize the importance of systems being able to substantiate their output with appropriate evidence, rather than just providing an answer. 4.3 Implementation Details The BM25 library we use is based on Anserini 2. Our models training is based on Transformers library3. All models use the AdamW optimizer [ 19] and ﬁne-tune on each dataset independently after loading the pre-trained weights. Retrieval. BM25 and DPR directly retrieve from the entire knowledge source, while ColBERT, BERT and our RM-BERT act as rerankers to rerank the top 100 results retrieved by BM25. For DPR and ColBERT, we use the same setting asthe original papers. For BERT, we employ the BERT base model. Both encoders for RM-BERT are also BERT base' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
564	page_content='RM-BERT are also BERT base models, and they share parameters. The transformer encoder layer of RM-BERT is initialized using the top layer weights 1 . 2 . 3 . Retrieval-Augmented Knowledge-Intensive Dialogue 23 of pre-trained BERT. For the MLP classiﬁer, we use two linear layers with a ReLU activation function for nonlinear transformation. Generation. To show the eﬃcacy of demonstration-based learning as a plugand-play method, we present performance in two models: RAG and FiD. Specifically, we use the RAG-Token model, and for FiD we use FiD-base. Referring to the original paper’s settings, RAG uses 5 retrieved documents, and FiD uses 20retrieved documents. For the Wizard of Wikipedia dataset, we use one demonstration, while for the Natural Questions and TriviaQA datasets, we use three demonstrations. We also consider demonstrations of other quantities and com-pare them empirically in Sect. 4.5. In addition, we also select BART and T5 as baselines, two models that do not retrieve knowledge sources, and their' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
565	page_content='knowledge sources, and their experimental results are sourced from [ 22]. 4.4 Results Table 2. Results for Retrieval Model WoW NQ TriviaQA R-Prec Recall@5 R-Prec Recall@5 R-Prec Recall@5 Bm25 37.07 61.23 49.10 65.04 51.37 69.44 DPR 40.86 65.62 61.02 69.69 60.94 68.28 ColBERT 44.47 70.37 65.84 76.56 68.43 79.42 RM-BERT 46.30 71.25 67.04 77.12 68.67 79.01 BERT 47.51 72.43 68.77 78.21 71.21 81.41 Retrieval. Table 2illustrates the retrieval evaluation results of our proposed model in comparison with the baselines. The results indicate that our model achieves performance close to BERT across all datasets, while requiring consid-erably less computational resources. Furthermore, in comparison with ColBERT, which is also a representation-interaction model, our approach exhibits superior performance on nearly all datasets. Despite BM25 and DPR’s advantagein terms of speed, they signiﬁcantly lag behind our model concerning retrieval eﬀectiveness. Overall, our model achieves an optimal trade-oﬀ between eﬃcacy and' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
566	page_content='trade-oﬀ between eﬃcacy and eﬃciency. Generation. In Tables 3,4and5, we present the performance evaluation results of our proposed approach and the baselines. Firstly, we observe that the inclusion of the demonstration-based learning approach leads to substantial improvements in nearly all evaluation metrics across all datasets for both RAG and 24 Z. Wang et al. Table 3. The results on Wizard of Wikipedia dataset Model Rouge-L F1 KILT-RL KILT-F1 BART 12.05 13.35 0 0 T5 12.80 13.28 0 0 RAG 16.03 18.10 10.61 12.00 FiD 14.81 16.73 9.79 11.07 RAG-demo 16.64(+0.61) 18.87(+0.77) 10.71(+0.10) 12.20(+0.20) FiD-demo 15.70(+0.89) 17.56(+0.83) 9.85(+0.06) 11.13(+0.06) Table 4. The results on Natural Questions dataset Model EM F1 KILT-EM KILT-F1 BART 26.15 32.06 0 0 T5 25.20 31.88 0 0 RAG 46.14 53.94 40.25 45.46 FiD 48.78 57.00 38.53 44.47 RAG-demo 47.83(+1.69) 55.41(+1.47) 41.63(+1.38) 46.83(+1.37) FiD-demo 51.50(+2.72) 59.68(+2.68) 41.17(+2.64) 46.98(+2.51) Table 5. The results on TriviaQA dataset Model EM F1 KILT-EM' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
567	page_content='dataset Model EM F1 KILT-EM KILT-F1 BART 32.54 39.58 0 0 T5 25.79 33.72 0 0 RAG 49.60 61.92 40.57 48.80 FiD 51.26 65.87 39.39 49.50 RAG-demo 53.41(+3.81) 64.69(+2.77) 42.30(+1.73) 49.60(+0.80) FiD-demo 54.75(+3.49) 64.23(-1.64) 42.02(+2.63) 48.52( −0.98) FiD models, as shown in the corresponding improvements indicated in parentheses. This ﬁnding not only conﬁrms the eﬃcacy of our proposed approach but also demonstrates its applicability to a wide range of models. Additionally, the results indicate the usefulness of our method for both single-turn and multi-turnknowledge-intensive dialogues. Next, we compare the performance of models with and without the usage of knowledge sources. We observe a signiﬁcant improvement in model performance after incorporating knowledge sources, as evidenced by the comparison results. This highlights the critical role of knowledge retrieval in knowledge-intensive dialogues. Retrieval-Augmented Knowledge-Intensive Dialogue 25 4.5 Ablations To explore the eﬀect of RM-BERT, we' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
568	page_content='the eﬀect of RM-BERT, we conduct relative ablation studies, as illustrated in Table 6. The RM-BERT-single model feeds only a single vector T/prime C[CLS ]into the MLP for classiﬁcation. Our ﬁndings suggest that reducing the number of representation vectors resulted in decreased model performance across all datasets, with the most signiﬁcant impact observed on the R-Prec metric for the Wizard of Wikipedia dataset. These results underscore the inadequacy of using only one vector to represent the semantic information of sentences and demonstrate the eﬃcacy of our proposed method in addressing this limitation. We also conduct ablation studies to investigate the impact of the number of demonstrations on the model’s performance. The results of these studies are presented in Table 7. Our ﬁndings indicate that, in the case of multi-turn dialogue, the model’s performance is optimal when only one demonstration is used. As the number of demonstrations increases, the model’s performance experiences a slight decrease.' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
569	page_content='a slight decrease. Conversely, for single-turn dialogue, the model’s performance isbest when three demonstration examples are used, with any additional demonstration examples leading to a degradation in performance. Table 6. Ablation experiment for the variation of RM-BERT Model WoW NQ TriviaQA R-Prec Recall@5 R-Prec Recall@5 R-Prec Recall@5 RM-BERT-single 40.47 71.09 66.13 76.81 65.07 78.32 RM-BERT 46.30 71.25 67.04 77.12 68.67 79.01 Table 7. The eﬀect of diﬀerent number of demonstrations on the performance of FiDdemo model Demo num WoW NQ Rouge-L F1 KILT-RL KILT-F1 EM F1 KILT-EM KILT-F1 1 15.70 17.56 9.85 11.13 49.24 57.64 39.27 45.31 2 15.48 17.15 9.71 10.84 50.90 59.08 40.54 46.41 3 15.12 16.69 9.30 10.36 51.50 59.68 41.17 46.98 4 15.14 16.61 9.27 10.31 51.22 59.50 41.03 46.82 5 15.00 16.41 9.10 10.09 51.22 59.37 40.89 46.56 4.6 Case Study We conduct a case study on the WoW and NQ dev sets to intuitively compare our model with the baseline, as presented in Table 8. On the WoW task, FiD 26 Z. Wang et al.' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
570	page_content='task, FiD 26 Z. Wang et al. generates incorrect answer due to insuﬃcient understanding of the context, while on the NQ task, it directly generates factually incorrect answer. In contrast, FiD-demo generates more speciﬁc and factually accurate responses. Table 8. Case study on the WoW and NQ dev sets Task Input Model Output WoW User: My favorite color is red do you like it? Bot: I like red, but pink is myfavorite it is named after a ﬂowering plant in the genus Dianthus. User: What is the wavelength of red?FiD I tw a sﬁ r s tu s e da sac o l o rn a m ei nthe late 17th century. FiD-demo I’m not sure, but I know it is the color at the end of the visible spectrum of light, next to orangeand opposite violet. NQ Who has made the most premierleague appearances? FiD Gary Speed FiD-demo Gareth Barry 5 Conclusions In this paper, we present a new method to improve the generator in knowledgeintensive dialogue and propose a ranking model RM-BERT. We propose to improve the generator through demonstration-based learning,' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
571	page_content='demonstration-based learning, allowing the gen-erator to better utilize the retrieved knowledge sources by enhancing model’s understanding of the task. Experiments prove that, as a plug-and-play method, it is applicable not only to multiple datasets, but also to a variety of models. Furthermore, we use multiple vectors to better represent the semantic information of context and document in a way similar to residual connections. Despite having amuch lower computational cost than BERT, RM-BERT achieves a performance very close to BERT, which is a signiﬁcant achievement in practical application scenarios. In future work, we intend to explore combining our demonstration-based learning method with other methods, potentially providing orthogonal improvement. We also intend to further explore how to represent sentences more eﬀectively and eﬃciently. References 1. Borgeaud, S., et al.: Improving language models by retrieving from trillions of tokens. In: International Conference on Machine Learning, pp. 2206–2240.' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
572	page_content='Learning, pp. 2206–2240. PMLR (2022) 2. Brown, T., et al.: Language models are few-shot learners. Adv. Neural. Inf. Process. Syst. 33, 1877–1901 (2020) 3. Cai, D., et al.: Skeleton-to-response: dialogue generation guided by retrieval memory. arXiv preprint arXiv:1809.05296 (2018) 4. Chowdhery, A., et al.: Palm: scaling language modeling with pathways. arXiv preprint arXiv:2204.02311 (2022) Retrieval-Augmented Knowledge-Intensive Dialogue 27 5. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT: pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018) 6. Dinan, E., Roller, S., Shuster, K., Fan, A., Auli, M., Weston, J.: Wizard of wikipedia: knowledge-powered conversational agents. arXiv preprintarXiv:1811.01241 (2018) 7. Glass, M., Rossiello, G., Chowdhury, M.F.M., Naik, A.R., Cai, P., Gliozzo, A.: Re2g: retrieve, rerank, generate. arXiv preprint arXiv:2207.06300 (2022) 8. Guu, K., Lee, K., Tung, Z., Pasupat, P., Chang, M.: Retrieval augmented' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
573	page_content='M.: Retrieval augmented language model pre-training. In: International Conference on Machine Learning, pp. 3929–3938. PMLR (2020) 9. Izacard, G., Grave, E.: Leveraging passage retrieval with generative models for open domain question answering. arXiv preprint arXiv:2007.01282 (2020) 10. Joshi, M., Choi, E., Weld, D.S., Zettlemoyer, L.: TriviaQA: a large scale distantly supervised challenge dataset for reading comprehension. arXiv preprint arXiv:1705.03551 (2017) 11. Karpukhin, V., et al.: Dense passage retrieval for open-domain question answering. arXiv preprint arXiv:2004.04906 (2020) 12. Khattab, O., Zaharia, M.: ColBERT: eﬃcient and eﬀective passage search via contextualized late interaction over BERT. In: Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval,pp. 39–48 (2020) 13. Komeili, M., Shuster, K., Weston, J.: Internet-augmented dialogue generation. arXiv preprint arXiv:2107.07566 (2021) 14. Kwiatkowski, T., et al.: Natural questions: a' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
574	page_content='et al.: Natural questions: a benchmark for question answering research. Trans. Assoc. Comput. Linguist. 7, 453–466 (2019) 15. Lewis, M., et al.: BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. arXiv preprintarXiv:1910.13461 (2019) 16. Lewis, P., et al.: Retrieval-augmented generation for knowledge-intensive NLP tasks. Adv. Neural. Inf. Process. Syst. 33, 9459–9474 (2020) 17. Li, H., Su, Y., Cai, D., Wang, Y., Liu, L.: A survey on retrieval-augmented text generation. arXiv preprint arXiv:2202.01110 (2022) 18. Lieber, O., Sharir, O., Lenz, B., Shoham, Y.: Jurassic-1: technical details and evaluation. White Paper. AI21 Labs 1 (2021) 19. Loshchilov, I., Hutter, F.: Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101 (2017) 20. Luan, Y., Eisenstein, J., Toutanova, K., Collins, M.: Sparse, dense, and attentional representations for text retrieval. Trans. Assoc. Comput. Linguist. 9, 329– 345 (2021) 21. Peters, M.E., Neumann, M.,' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
575	page_content='Peters, M.E., Neumann, M., Zettlemoyer, L., Yih, W.T.: Dissecting contextual word embeddings: architecture and representation. arXiv preprint arXiv:1808.08949 (2018) 22. Petroni, F., et al.: KILT: a benchmark for knowledge intensive language tasks. arXiv preprint arXiv:2009.02252 (2020) 23. Raﬀel, C., et al.: Exploring the limits of transfer learning with a uniﬁed text-to-text transformer. J. Mach. Learn. Res. 21(1), 5485–5551 (2020) 24. Robertson, S., Zaragoza, H., et al.: The probabilistic relevance framework: Bm25 and beyond. Found. Trends R/circlecopyrtInf. Retr. 3(4), 333–389 (2009) 25. Shuster, K., Poﬀ, S., Chen, M., Kiela, D., Weston, J.: Retrieval augmentation reduces hallucination in conversation. arXiv preprint arXiv:2104.07567 (2021) 28 Z. Wang et al. 26. Sutskever, I., Vinyals, O., Le, Q.V.: Sequence to sequence learning with neural networks. In: Advances in Neural Information Processing Systems, vol. 27 (2014) 27. Vaswani, A., et al.: Attention is all you need. In: Advances in Neural Information' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
576	page_content='in Neural Information Processing Systems, vol. 30 (2017) 28. Wang, S., et al.: Training data is more valuable than you think: a simple and eﬀective method by retrieving from training data. arXiv preprint arXiv:2203.08773 (2022) 29. Weston, J., Dinan, E., Miller, A.H.: Retrieve and reﬁne: improved sequence generation models for dialogue. arXiv preprint arXiv:1808.04776 (2018) 30. Wu, Y., Wei, F., Huang, S., Wang, Y., Li, Z., Zhou, M.: Response generation by context-aware prototype editing. In: Proceedings of the AAAI Conference onArtiﬁcial Intelligence, vol. 33, pp. 7281–7288 (2019) 31. Zhu, F., Lei, W., Wang, C., Zheng, J., Poria, S., Chua, T.S.: Retrieving and reading: a comprehensive survey on open-domain question answering. arXiv preprintarXiv:2101.00774 (2021)' metadata={'title': 'Retrieval-Augmented Knowledge-Intensive Dialogue', 'author': 'Zelin Wang', 'publish_date': '2023-09-25', 'subject': 'Natural Language Processing and Chinese Computing', 'doi': 'doi:10.1007/978-3-031-44693-1_2', 'keywords': 'Dialogue system; Retrieval-augmented generation; Document retrieval'}
577	page_content='A Survey on Intelligent Question and Answer Systems Xuechao Guo, Bin Zhao, and Bo Ning(B) School of Information Science and Technology, Dalian Maritime University, Dalian, China {xuechao,zhaobin,ningbo }@dlmu.edu.cn Abstract. With the rapid development of technology in society, people are surrounded by all kinds of data in the information age. So the means to access external information accurately and quickly have become particularly important. Currently, intelligent question and answer systemsare a promising area of research in the ﬁeld of artiﬁcial intelligence and natural language processing. As an interactive system, it signiﬁcantly diﬀers from traditional search engines. When people perform advancedinformation retrieval, it can accurately understand the natural language questions asked by the user and give the user a corresponding answer using natural language, which meets people’s needs for quickly, easilyand accurately accessing information. Intelligent question and answer systems are already widely' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
578	page_content='systems are already widely used in people’s daily life, such as common intelligent voice interaction, online customer service, knowledge acquisi-tion, emotional chat, etc. Deep learning, a branch of machine learning, is now widely used for various tasks in natural language processing. This paper focuses on the applications of deep learning to intelligent questionand answer systems. Keywords: Intelligent question and answer systems ·Information retrieval ·Natural language processing ·Deep learning 1 Introduction Traditional search engine systems have many drawbacks, such as a lack of accuracy in the representation of requirements when searching. The search needs ofusers are often very complex and speciﬁc, which cannot be expressed by a simple logical combination of a few keywords. Traditional search engines are not concise enough and return too many results making it extremely diﬃcult for users tolocate the information they need quickly and accurately. Lacking the support of semantic processing technology,' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
579	page_content='processing technology, traditional keyword-based information retrieval remains on the surface of language without containing semantics, making theretrieval eﬀect mediocre. Intelligent question and answer systems based on natural language processing technology are one of the directions in which traditional c/circlecopyrtICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2022 Published by Springer Nature Switzerland AG 2022. All Rights Reserved Y. Chenggang et al. (Eds.): MobiMedia 2022, LNICST 451, pp. 81–88, 2022.  _7 82 X. Guo et al. search engines are being improved. The query information is used to parse out the user’s query intent, then the location of the answer is pinpointed from thedocument based on the intent, and ﬁnally the answer is extracted and returned to the user. Rather than just returning a documented distribution of answers to questions to the user, which is a great improvement both in terms of accuracyand meeting the user’s search needs. Deep' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
580	page_content='the user’s search needs. Deep learning [ 10], a branch of machine learning, is a class of algorithms that attempt to perform high-level abstractions of data using multi-processing layer computational models that contain com-plex structures or consist of multiple non-linear transformations. It gradually transforms the initial low-level feature representation into a high-level feature representation through multi-layer processing, and allows complex learning taskssuch as classiﬁcation to be performed with simple models. Deep learning techniques have been used in a wide range of ﬁelds such as image recognition, speech recognition and natural language processing. A number of scholars have already applied deep learning to intelligent question and answer systems. Classiﬁed according to the type of domain, intelligent question and answer systems can be divided into limited domain-oriented question and answer systems and open domain oriented question and answer systems. Depending on the implementation method,' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
581	page_content='on the implementation method, domain-limited QA systems are divided into PipelineQA systems and end-to-end QA systems. Open domain QA systems are divided into search-based QA systems, generative-based QA systems and hybrid-based QA systems. The following article will focus on each of these types of QA sys-tems. 2 Qualiﬁed Domain Oriented QA Systems Domain-oriented QA systems, also known as task-based QA systems, are oriented towards vertical domains and aim to help users complete predetermined tasks or actions using as few dialogue rounds as possible. For example, book-ing tickets, restaurants, hotels, etc. The current mainstream research approach is to study task-based QA systems in three modules: Natural Language Understanding (NLU), Dialogue Management (DM) and Natural Language Generation(NLG) [ 2]. There are two broad approaches to the study of task-based QA systems, one is the Pipeline task-based QA systems and the other is the end-to-end task-based QA systems. 2.1 Pipelined Task-Based QA Systems' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
582	page_content='Task-Based QA Systems Pipelined task-based QA systems including Natural Language Understanding (NLU) modules, where Kim [ 8]a n dL e e[ 11], et al. use the user’s dialogue to perform intention analysis and translate it into pre-deﬁned semantic slots. Next comes the Dialogue State Tracking (DST) module, Williams et al. [ 26] assess the status of each round of dialogue based on information about the current dialogue and the history of the dialogue. There follows the Policy Learning (POL) module, it will make the next reaction based on the current state of A Survey on Intelligent Question and Answer Systems 83 the conversation, i.e. it determines the action of the system. And ﬁnally, there is the Natural Language Generation (NLG) module. Wen et al. [ 25] convert the responses made by the policy learning module into the corresponding natural language responses provided to the user. The Dialogue State Tracking module and the Dialogue Policy Learning module make up the Dialogue Manager(DM), which is the core' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
583	page_content='which is the core controller of the task-based QA systems. In some situations, several of these modules can be used in combination, depending on the needs of the task. Budzianowski et al. [ 1] combine NLU and DST modules and map the user’s historical conversation information to the corresponding conversation states. Chen et al. [ 3] combine POL and NLG modules and map the user’s historical discourse and conversation state to the system response. Theﬁrst joint modelling of intention recognition and slot ﬁlling tasks using a GRUbased approach by Zhang et al. [ 31] After the GRU encodes the sentence the representation of the sentence is obtained by the maxpooling layer for intent recognition. Finally the joint learning of the two tasks is performed through a shared GRU layer to obtain an implicit relationship between them. Liu et al. ﬁrst used a sequence-to-sequence fusion attention mechanism approach to jointly model intention recognition and slot-ﬁlling tasks. Goo et al. [ 6]ﬁ r s tu s e d the slot-gate' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
584	page_content='r s tu s e d the slot-gate mechanism to explicitly focus on learning the relationship betweenslot-ﬁlling and intention recognition tasks and to obtain better semantic information through global optimization. Li et al. [ 12] use the Gate mechanism to use information to guide the slot-ﬁlling task, explicitly exploiting information aboutintentions. They explored the role of self-attention mechanisms on this task for the ﬁrst time, which achieved good performance. 2.2 End-to-End Task-Based QA Systems Although pipelined task-based QA systems can achieve good performance on individual tasks with a combination of modules, this modular system has signiﬁ-cant drawbacks in deep learning training. When using a multi-step, multi-model to solve a complex task, inconsistency in the training objectives of each module makes it diﬃcult to achieve optimal performance of the trained model. Theend-to-end model uses only one model, one objective function and uses back propagation to optimise the parameters, the inherent pitfalls' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
585	page_content='the inherent pitfalls of multiple models are avoided. Recurrent neural networks are mostly used as encoder and decoder modules in end-to-end task-based dialogue systems. Madotto et al. [ 17]u s e d an end-to-end memory network (MemNN) to address the problem of unstableperformance in long sequences of recurrent neural networks as well as high temporal computational overhead. It uses several embedding matrices as external memory and reads the memory repeatedly using query vectors, it is thereforemore suitable for storing information from external knowledge bases in taskbased conversations. Eric et al. [ 5] propose a complete end-to-end model where they model conversation context and conversation generation based on an exist-ing sequence-to-sequence architecture. They added an attention-based key-value pair mechanism to the retrieval of knowledge base entries, addressing the issue of how the model could be more smoothly interfaced with the knowledge base. Wu 84 X. Guo et al. et al. [ 27] fused memory networks' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
586	page_content='[ 27] fused memory networks and copy mechanisms to more smoothly embed the knowledge base during sequence generation, allowing for better integrationof the knowledge base into task-based dialogue systems. Luo et al. [ 16]p r o p o s e d the Proﬁle Model and Preference Model based on the end-to-end memory network model. The former learns personalisation by embedding user proﬁles anduses global memory to store the conversation context of similar users. The latter is done by establishing a link between the portrait and the knowledge base, thus the best result among the candidate answers can be selected. 3 Open Domain Oriented QA Systems The Open Domain QA systems diﬀers signiﬁcantly from the Limited DomainQA system in that it does not target domain-speciﬁc questions and complete any task. Instead, they are data-driven [ 20] and use natural language to mimic human discourse for everyday interactions. Three broad categories of open domain QAsystems have been studied, including generative-based QA systems,' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
587	page_content='generative-based QA systems, retrievalbased QA systems and hybrid-based QA systems. The widespread use of deep learning techniques is now leading to breakthroughs in open domain QA systems. 3.1 Retrieval-Based QA Systems Retrieval-based QA systems usually begin with the construction of a large corpus that can be retrieved by the system. The system identiﬁes the responses from the conversation corpus that most closely resemble the input utterance. For each input statement, the retrieval model selects the statement with the greatestsemantic match from the candidate statements as its response. In recent years, some models have taken into account not only current conversations but also rich historical conversations in the selection of responses. The core modules ofa retrieval-based QA systems include a candidate answer retrieval module, a question-answer similarity calculation module and a ranking module. The overall step can be considered as a classiﬁcation prediction of candidate responses. Inanother way, the' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
588	page_content='responses. Inanother way, the question and the candidate responses are fed into a neural network model, and all candidate responses are classiﬁed or ranked. The calculation of question-answer similarity is a key aspect of retrievalbased QA systems. Traditional text similarity calculation methods are based on surface text similarity calculation. The main method is to directly target theunprocessed text and use the degree of match and distance of the characters or strings in it as a criterion of similarity. This method is simple to implement and easy to understand. Kondrak et al. [ 9] used an n-gram model to calculate the similarity between characters, the main idea being to calculate the ratio of the number of identical N tuples to the total number of N tuples for two texts. Surface text similarity calculations do not take into account the semantic rela-tionship of the text very well. In response to this problem, semantic similarity calculation methods have been proposed, of which neural network-based methods' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
589	page_content='neural network-based methods are currently the mainstream research direction. Mikolov et al. [ 18]p r o p o s e d A Survey on Intelligent Question and Answer Systems 85 the word vector embedding (Word2Vec) approach, which includes the CBOW model that uses context to predict central words and the Skip-gram model thatuses central words to predict context. It uses contextual information to transform words into high-dimensional vectors. Shen et al. [ 22] based on convolutional neural networks to obtain a semantic representation vector of the user’s queryand the word vector of candidate answers with its ﬁxed length by convolution and pooling operations, and then use the cosine similarity function to measure how well the queries and responses match. The task of simulating image recog-nition by Pang et al. [ 14] The matrix is ﬁrst constructed based on the similarity between word vectors, then the fused information is gradually captured using convolutional and pooling layers, and ﬁnally the matching scores are' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
590	page_content='the matching scores are calculatedfor answer ranking. Kim et al. [ 7] propose a DRCN model based on the generic framework of DenseRNN, which contains a multilayer recurrent neural network and an attention mechanism. The input to each layer of the neural network is a fusion of the outputs of all previous layers, and the output vector is used as input directly by the pooling layer before semantic fusion, thus alleviating theproblem of gradient disappearance caused by the increase in the number of layers of the model. With the creation of the Transformer [ 24] model, more and more pre-trained models are emerging and performing well on various tasks in natu-ral language processing. For example, the Bidirectional Encoder Representation from Transformers (BERT) [ 4] model addresses the case where the word2vec model is unable to determine multiple meanings of a word. The Bert model istrained using a large-scale unlabeled corpus, and the text obtained contains rich semantic information. 3.2 Generative-Based QA' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
591	page_content='3.2 Generative-Based QA Systems The main goal of a generative QA system is to generate responses based on the contextual information of the current conversation. This is usually done byusing a deep learning based encoder-decoder architecture. Deep learning-based techniques do not usually rely on speciﬁc answer banks or templates, but rather on linguistic competence acquired from a large corpus. Speciﬁcally, a recurrentneural network is used to encode the input utterance as a vector representation, while another recurrent neural network is used at the decoding end and an attention mechanism is used to generate the replies one by one. People do not simply ask one question and answer another in general chat. Answers often refer to the content of contextual chat messages, so contextualinformation should be introduced into the encoder, which helps the encoder to generate better session response content. Sordoni et al. [ 23] proposed the use of multilayer feedforward neural networks instead of recurrent neural' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
592	page_content='instead of recurrent neural networksin the encoder part. In this way, both the contextual information and the current conversation to be encoded by a multi-layer feed-forward neural network to generate an intermediate semantic representation of the encoder-decoder archi-tecture, while avoiding the problem of recurrent neural networks being sensitive to excessively long inputs. Li et al. [ 13] used the idea of adversarial learning to train both a response generator and a response discriminator. Generators 86 X. Guo et al. are sequence-to-sequence based generative dialogue models. The discriminator is a classiﬁcation model that completes a binary classiﬁcation task which classi-ﬁes the generated responses into two categories, human responses and machine responses, and is used to assess the quality of the responses. The core idea of the model is to motivate generators that can generate discourse in place of humanreplies. Xu et al. [ 29] used generative adversarial networks to the task of dialogue generation.' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
593	page_content='task of dialogue generation. They propose to replace the sampled decoding results in the decoder with an approximate embedding layer. It is an end-to-end model overall, allowingdiscriminators and generators to be trained with simultaneous parameter tuning by back-propagation. Shao et al. [ 21] connect the decoder head to tail and then use the generated part as part of an attention mechanism with further additionsto the existing informativeness for generating long replies with high information content. Wu et al. [ 28] improved the word mapping at decoding and proposed a sequence-to-sequence model based on a dynamically decoded lexicon. The model makes it possible to have a diﬀerent lexicon for each decoding step depending on the actual current conversation, in order to remove the interference of irrelevantwords, narrow the mapping and speed up decoding. 3.3 Hybrid-Based QA Systems QA systems based on retrieval-based approaches often respond to discourses that are limited by constructed corpus, and sometimes' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
594	page_content='corpus, and sometimes the retrieved content does not ﬁt well with the contextual content. QA systems based on generative approaches may generate discourse that is more generic, or even output answersthat are not relevant to the user’s input question. The hybrid-based QA systems integrates both retrieval and generative approaches, providing a clever blend of the two. Qiu et al. [ 19] generated responses using a sequence-to-sequence model and then scored the responses obtained by the retrieval method using the rerank model. If the score is below the initially set threshold, the response generated by the seq2seq model is used directly as the answer to the user, otherwise the response obtained by retrieval is used as the answer to the user. Liu et al.  built a neural network dialogue model that mixes retrieval-based ranking models and generative models, and combines the advantages of retrieval-based and generative QA systems, providing new insights into how to integrate retrieval and generative models to build' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
595	page_content='generative models to build QA systems. 4 Conclusion Current intelligent question and answer systems have signiﬁcant shortcomingsin terms of semantics, consistency and interactivity. In terms of semantics, deep learning-based generative models are more likely to generate meaningless universal replies, such as ’I don’t know’. The amount of information, appropriatenessand logic of the generated content is still inadequate, and there is a long way to go before semantic understanding in the true sense of the word. In terms of consistency, it is easy to create semantic identity and personality conﬂicts in the A Survey on Intelligent Question and Answer Systems 87 interaction. In terms of interactivity, current intelligent QA systems have significant shortcomings in terms of emotional interaction and strategic response. Itis not able to adaptively adjust its own strategies to the user’s topic status, such as topic strategies, active-passive strategies and emotional expression strategies, and it also makes it' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
596	page_content='and it also makes it impossible to achieve smooth and natural human-computerinteraction. With the advancement of technology and media publicity, people are more inclined to think of an intelligent QA system as their life companion rather than a machine that can only be used to perform a task. To meet this expecta-tion of users, the future intelligent QA systems will need to have some emotional intelligence. They can carry out emotional response and interaction, and reﬂect personality, language style and personality in dialogue and interaction. References 1. Budzianowski, P., Wen, T.H., Tseng, B.H., Casanueva, I., Gai, M.: MultiwOZ a large-scale multi-domain wizard-of-OZ dataset for task-oriented dialogue modelling (2018) 2. Chen, H., Liu, X., Yin, D., Tang, J.: A survey on dialogue systems: recent advances and new frontiers. ACM SIGKDD Explor. Newslett. 19(2), 25–35 (2017) 3. Chen, W., Chen, J., Qin, P., Yan, X., Wang, W.Y.: Semantically conditioned dialog response generation via hierarchical disentangled' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
597	page_content='via hierarchical disentangled self-attention (2019) 4. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT: pre-training of deep bidirectional transformers for language understanding (2018) 5. Eric, M., Manning, C.D.: Key-value retrieval networks for task-oriented dialogue (2017) 6. Goo, C.W., Gao, G., Hsu, Y.K., Huo, C.L., Chen, Y.N.: Slot-gated modeling for joint slot ﬁlling and intent prediction. In: Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics:Human Language Technologies, Volume 2 (Short Papers) (2018) 7. Kim, S., Kang, I., Kwak, N.: Semantic sentence matching with densely-connected recurrent and co-attentive information (2018) 8. Kim, Y.B., Lee, S., Stratos, K.: OneNet: joint domain, intent, slot prediction for spoken language understanding. Amazon Alexa Brain, Seattle, WA; Microsoft Research, Redmond, WA; Toyota Technological Institute, Chicago, IL 9. Kondrak, G.: N-Gram similarity and distance. In: Consens, M., Navarro, G. (eds.)' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
598	page_content='M., Navarro, G. (eds.) SPIRE 2005. LNCS, vol. 3772, pp. 115–126. Springer, Heidelberg (2005). https:// doi.org/10.1007/11575832 13 10. LeCun, Y., Bengio, Y., Hinton, G.: Deep learning. Nature 521(7553), 436–444 (2015) 11. Lee, S., et al.: ConvLab: multi-domain end-to-end dialog system platform (2019)12. Li, C., Li, L., Qi, J.: A self-attentive model with gate mechanism for spoken language understanding. In: Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 3824–3833 (2018) 13. Li, J., Monroe, W., Shi, T., Jean, S., Ritter, A., Jurafsky, D.: Adversarial learning for neural dialogue generation (2017) 14. Liang, P., Lan, Y., Guo, J., Xu, J., Cheng, X.: Text matching as image recognition (2016) 15. Liu, B., Lane, I.: Attention-based recurrent neural network models for joint intent detection and slot ﬁlling (2016) 88 X. Guo et al. 16. Luo, L., Huang, W., Qi, Z., Nie, Z., Xu, S.: Learning personalized end-to-end goal-oriented dialog (2018) 17. Madotto, A., Wu, C.S., Fung,' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
599	page_content='Madotto, A., Wu, C.S., Fung, P.: Mem2Seq: eﬀectively incorporating knowledge bases into end-to-end task-oriented dialog systems (2018) 18. Mikolov, T., Chen, K., Corrado, G., Dean, J.: Eﬃcient estimation of word representations in vector space. Comput. Sci. (2013) 19. Qiu, M., et al.: AliMe chat: a sequence to sequence and Rerank based chatbot engine. In: Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pp. 498–503. Association for Computational Linguistics, Vancouver, July 2017.  20. Ritter, A., Cherry, C., Dolan, B.: Data-driven response generation in social media. In: Empirical Methods in Natural Language Processing (EMNLP), January 2011.  21. Shao, L., Gouws, S., Britz, D., Goldie, A., Strope, B., Kurzweil, R.: Generating high-quality and informative conversation responses with sequence-to-sequencemodels (2017) 22. Shen, Y., He, X., Gao, J., Deng, L., Mesnil, G.: Learning semantic representations using convolutional neural network for web' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
600	page_content='neural network for web search. In: Proceedings WWW, pp.373–374 (2014) 23. Sordoni, A., et al.: A neural network approach to context-sensitive generation of conversational responses. In: Proceedings of the 2015 Conference of the NorthAmerican Chapter of the Association for Computational Linguistics: Human Language Technologies, May-Jun 2015 24. Vaswani, A., et al.: Attention is all you need. arXiv (2017)25. Wen, T.H., Gasic, M., Mrksic, N., Su, P.H., Vandyke, D., Young, S.: Semantically conditioned LSTM-based natural language generation for spoken dialogue systems. Comput. Sci. (2015) 26. Williams, J., Raux, A., Ramachandran, D., Black, A.: The dialog state tracking challenge. In: Proceedings of the SIGDIAL 2013 Conference (2013) 27. Wu, C.S., Socher, R., Xiong, C.: Global-to-local memory pointer networks for taskoriented dialogue (2019) 28. Wu, Y., Wu, W., Yang, D., Xu, C., Li, Z., Zhou, M.: Neural response generation with dynamic vocabularies (2017) 29. Xu, Z., et al.: Neural response generation via GAN' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
601	page_content='response generation via GAN with an approximate embedding layer. In: Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 617–626 (2017) 30. Yang, L., et al.: A hybrid retrieval-generation neural conversation model. In: Proceedings of the 28th ACM International Conference on Information and Knowledge Management (2019) 31. Zhang, X., Wang, H.: A joint model of intent determination and slot ﬁlling for spoken language understanding (2016)' metadata={'title': 'A Survey on Intelligent Question and Answer Systems', 'author': 'Xuechao Guo', 'publish_date': '2023-01-19', 'subject': 'Mobile Multimedia Communications', 'doi': 'doi:10.1007/978-3-031-23902-1_7', 'keywords': 'Intelligent question and answer systems; Information retrieval; Natural language processing; Deep learning'}
602	page_content='AI-Based Interactive Agent for Health Care Using NLP and Deep Learning U. Hemavathi and Ann C. V . Medona Abstract Artiﬁcial intelligence (AI)-based interactive agent plays a vital role in health care. In this paper, we have implemented AI-based Interactive agent usingnatural language processing (NLP) and deep learning (DL) which deals with resolving simple queries and provide health care services. This work helps to build a system for providing better health care service for user and increase user interaction. This work builds a chatbot using DL and NLP pipeline. We conclude that chatbots build with NLP and neural network are more efﬁcient than human resource andpredeﬁned chatbots that are not efﬁcient. It is necessary to discuss potential research directions that can improve capabilities. Keywords Deep learning ·Artiﬁcial intelligence ·Natural language processing · Health care 1 Introduction AI chatbot is intelligent software that can provide efﬁcient communication and perform actions similar to human' metadata={'title': 'AI-Based Interactive Agent for Health Care Using NLP and Deep Learning', 'author': 'U. Hemavathi', 'publish_date': '2022-06-07', 'subject': 'Information and Communication Technology for Competitive Strategies (ICTCS 2021)', 'doi': 'doi:10.1007/978-981-19-0095-2_2', 'keywords': 'Deep learning,Artificial intelligence,Natural language processing,Health care'}
603	page_content='actions similar to human beings [ 1]. It yields various services such as marketing on social networks and effective customer interaction. In recent periods, chatbots give answers to the client’s questionnaires for any particular domain whereit is used. It can accept speech and text inputs for its operation. Chatbots are mainly used for information acquisition. These AI embedded agents use natural language processing techniques to answer the user questions. Predeﬁned knowledge base helpsdevelop a response to the query [ 2,3]. There is a need for such mechanisms to U. Hemavathi ( B) Department of Computer Science and Egineering, V el Tech Rangarajan Dr. Sagunthala R&DInstitute of Science and Technology, Chennai, Tamil Nadu, Indiae-mail: uhemav@gmail.com A. C. V . Medona Department of Artiﬁcial Intelligence and Data Science, Saveetha Engineering College, Chennai,Tamil Nadu, Indiae-mail: medona@saveetha.ac.in © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023 A. Joshi et al.' metadata={'title': 'AI-Based Interactive Agent for Health Care Using NLP and Deep Learning', 'author': 'U. Hemavathi', 'publish_date': '2022-06-07', 'subject': 'Information and Communication Technology for Competitive Strategies (ICTCS 2021)', 'doi': 'doi:10.1007/978-981-19-0095-2_2', 'keywords': 'Deep learning,Artificial intelligence,Natural language processing,Health care'}
604	page_content='Pte Ltd. 2023 A. Joshi et al. (eds.), Information and Communication T echnology for Competitive Strategies (ICTCS 2021) , Lecture Notes in Networks and Systems 400,  12 U. Hemavathi and A. C. V . Medona determine the response to query from available data. Hence, to solve the problem, feed forward neural network-based mechanism is proposed which can analyze the response and reply the user [ 4,5]. 1.1 Scope of the W ork AI chatbots are time efﬁcient and cost effective which provides efﬁcient services for 24*7. This work proposes to implement AI-based interactive agent for health care using NLP and deep learning which deal with resolving simple queries and provide health care service. Deep learning techniques use artiﬁcial intelligence (AI) that canmake the computer to learn from the data instead of being explicitly programmed. Training data are processed, and features are extracted by ML algorithm which is stored in database for further investigation. Preprocessing is done by natural languageprocessing' metadata={'title': 'AI-Based Interactive Agent for Health Care Using NLP and Deep Learning', 'author': 'U. Hemavathi', 'publish_date': '2022-06-07', 'subject': 'Information and Communication Technology for Competitive Strategies (ICTCS 2021)', 'doi': 'doi:10.1007/978-981-19-0095-2_2', 'keywords': 'Deep learning,Artificial intelligence,Natural language processing,Health care'}
605	page_content='by natural languageprocessing pipeline. Literature survey expresses the use of chatbots in medical ﬁeld as well as various researchers and their experimental analysis of chatbots for various services. 1.2 Literature Survey This paper explains the systematic literature survey of medical chatbot applications proposed and used by various successful researchers. Taobias Gente et al. proposed a systematic literature review of Medical Chatbot Research from a behavior changeperspective in 2020. This paper reviews the published research results relating to details of designing techniques of chatbot. It explains about the design of conversation systems methodology. Emanuela Haller et al. designed a chatbot that can simulates anhistorical ﬁgure. This paper reviews the published research results related developing of architecture chatbots. It explains about the design and implementation NLP and machine learning. 1.3 Methodology The proposed work consists of the following modules, \x81Prepossessing and feature extraction' metadata={'title': 'AI-Based Interactive Agent for Health Care Using NLP and Deep Learning', 'author': 'U. Hemavathi', 'publish_date': '2022-06-07', 'subject': 'Information and Communication Technology for Competitive Strategies (ICTCS 2021)', 'doi': 'doi:10.1007/978-981-19-0095-2_2', 'keywords': 'Deep learning,Artificial intelligence,Natural language processing,Health care'}
606	page_content='and feature extraction \x81Training phase \x81Test phase. AI-Based Interactive Agent for Health Care … 13 Fig. 1 Feed forward neural network architecture Prepossessing and feature extraction It is implemented using the natural language processing pipeline. Tokenization is used for splitting a string into meaningful units, for example, “how are you?” is spitted as [“how,” “are,” “you,” “?”]. Stemming helps to generate the root form of the words. The crude heuristic is used to chops of the ends off words (for example,“organization” is chopped as “organi”). NLP and information retrieval techniques use the concepts of bag of words to convert string to vector. In this model, a text is characterized as the bag of its words by disregarding grammar. This method is commonly used for document classiﬁcation where the incidence of each word is used as a feature for training a classiﬁer. Training Model using Deep Learning Algorithms Figure 1depicts the feed forward neural network architecture used for training. The' metadata={'title': 'AI-Based Interactive Agent for Health Care Using NLP and Deep Learning', 'author': 'U. Hemavathi', 'publish_date': '2022-06-07', 'subject': 'Information and Communication Technology for Competitive Strategies (ICTCS 2021)', 'doi': 'doi:10.1007/978-981-19-0095-2_2', 'keywords': 'Deep learning,Artificial intelligence,Natural language processing,Health care'}
607	page_content='used for training. The step-by-step procedure is given as follows, \x81Creation of database which contains information about diseases and its ir symptoms \x81User or client sends a message in the form of text or voice. \x81NLP uses implicit and explicit expression analysis to identify the similar word patterns in the input data [ 4] \x81NLP converts input to machine understandable format. \x81To respond to the user’s input, the chatbot creates an answering sentence out of the knowledge stored in the database. This method does not need manual processing, hence time required for processing the data is very less and provides accurate response [ 1,5]. The retrieval-based method 14 U. Hemavathi and A. C. V . Medona Fig. 2 Proposed architecture diagram compares queries with message-response pairs and can retrieve sentences with high naturalize and ﬂuency but is usually used in a closed domain. T est phase Artiﬁcial neural networks (ANNs) and deep learning techniques yield better solutions for many real-world problems such as' metadata={'title': 'AI-Based Interactive Agent for Health Care Using NLP and Deep Learning', 'author': 'U. Hemavathi', 'publish_date': '2022-06-07', 'subject': 'Information and Communication Technology for Competitive Strategies (ICTCS 2021)', 'doi': 'doi:10.1007/978-981-19-0095-2_2', 'keywords': 'Deep learning,Artificial intelligence,Natural language processing,Health care'}
608	page_content='real-world problems such as image recognition, medial data analysis, and speech recognition [ 6]. NLP plays a vital role in AI ﬁeld that helps to examine how computer systems can interpret and control [ 1,7] text or speech. Most NLP techniques rely on deep learning and machine learning techniques. The proposed system helps to rectify all shortcomings of the existing system and helps users to exploit services maximum and also to provide more advantages than manual methods [ 8,9]. In this paper, we propose a general artiﬁcial intelligent chatbot agent, and model is built.Deep learning model which analysis the query data from NLP pipeline and provides response to user [ 10,11] (Fig. 2). 1.4 Module Description 1.4.1 Preparation of Dataset Deep learning models are used to train the dataset which is collected from the client. Every new data details collected at the time of application form act as a test dataset. 1.4.2 Preprocess Data Tokenizing is the ﬁrst and most basic step in preprocessing. It converts the' metadata={'title': 'AI-Based Interactive Agent for Health Care Using NLP and Deep Learning', 'author': 'U. Hemavathi', 'publish_date': '2022-06-07', 'subject': 'Information and Communication Technology for Competitive Strategies (ICTCS 2021)', 'doi': 'doi:10.1007/978-981-19-0095-2_2', 'keywords': 'Deep learning,Artificial intelligence,Natural language processing,Health care'}
609	page_content='It converts the entire text into small parts like words. Lemmatizing process is applied to convert word into AI-Based Interactive Agent for Health Care … 15 lemma form. At the end of preprocessing, pickle ﬁle is created to store the Python objects. 1.4.3 Creation of Training and T est Data Training dataset is created from the client input. After preprocessing, it is stored in database for experimental investigation purpose. Output pattern uses bag of words concepts to give response to the client. 1.4.4 Build the Model \x81Deep neural network layer which consists of three layers is built using keras sequential API. The model is trained for 200 epochs, and the model is saved as“data.pth” \x81Loading the trained model and then use a graphical user interface that will predict the response from the bot. \x81The model implements appropriate functions which will identify the class and then retrieve us a random response from the list of responses. 2 Implementation and T esting 2.1 Input and Output We can test the input by' metadata={'title': 'AI-Based Interactive Agent for Health Care Using NLP and Deep Learning', 'author': 'U. Hemavathi', 'publish_date': '2022-06-07', 'subject': 'Information and Communication Technology for Competitive Strategies (ICTCS 2021)', 'doi': 'doi:10.1007/978-981-19-0095-2_2', 'keywords': 'Deep learning,Artificial intelligence,Natural language processing,Health care'}
610	page_content='We can test the input by providing details by the user. After that, deep learning model provides the below output Figs. 3,4, and 5. 2.2 Sample Input and Output See Fig. 6. 2.3 Advantages of the Chatbot \x81Easy to analyze. \x81Less time consuming and easy to control. \x81External evaluation can be reduced. 16 U. Hemavathi and A. C. V . Medona Fig. 3 Output image1 Fig. 4 Output image2 \x81System can be accessed from anywhere using Internet. \x81Fast and more efﬁcient than existing system. 3 Results and Discussion This work is trained successfully using Python with custom dataset. Data are processed by tokenization, stemming, and bag of words (string to vector) using natural language toolkit (NLTK). Then, training data are created. The PyTorch model and training by feed forward neural network with 3 linear layers and 2 hidden layers AI-Based Interactive Agent for Health Care … 17 Fig. 5 Output image3 Fig. 6 Test image  18 U. Hemavathi and A. C. V . Medona with Softmax are used for train the data. The system proposed helps to' metadata={'title': 'AI-Based Interactive Agent for Health Care Using NLP and Deep Learning', 'author': 'U. Hemavathi', 'publish_date': '2022-06-07', 'subject': 'Information and Communication Technology for Competitive Strategies (ICTCS 2021)', 'doi': 'doi:10.1007/978-981-19-0095-2_2', 'keywords': 'Deep learning,Artificial intelligence,Natural language processing,Health care'}
611	page_content='The system proposed helps to provide health care services for all the people with high efﬁciency. 4 Conclusion and Future Enhancements The proposed system helps to provide health care services for all the people with high efﬁciency. The artiﬁcial intelligent agent component of the is receiving increasingattention from researchers. Since these health care services are provide help to user and aid in information. The information provided by chatbot becomes important. This will eradicate the manual method of human interaction to the user in this increasingpopulation which is very tough and hard to provide the service and also the efﬁciency of services will be very low in manual method. This work is trained successfully using Python with high accuracy. Our work is an initial attempt to develop and providehealth care service virtual agent. In future, we can improve it by having dataset and model in the cloud. Hence, the speed of accessing the system could be improved. We use various deep learning models and' metadata={'title': 'AI-Based Interactive Agent for Health Care Using NLP and Deep Learning', 'author': 'U. Hemavathi', 'publish_date': '2022-06-07', 'subject': 'Information and Communication Technology for Competitive Strategies (ICTCS 2021)', 'doi': 'doi:10.1007/978-981-19-0095-2_2', 'keywords': 'Deep learning,Artificial intelligence,Natural language processing,Health care'}
612	page_content='deep learning models and improve their accuracy and visualize the various parameters that help in improving the accuracy. References 1. Adamopoulou E, Moussiades L (2020) Chatbots: history, technology, and applications. Mach Learn Appl 2 (2020) 2. Ayanouz S, Abdelhakim BA, Benhmed M (2020) A Smart Chatbot Architecture based NLP and Machine learning for health care assistance. In: The 5th international conference on smartcity applications, 2020 3. Siddique S, Chow JC (2021) Machine learning in healthcare communication. Encyclopedia 1:220–239.  4. Gentner T, Neitzel T, Schulze J (2020) A systematic literature review of medical chatbot research from a behaviour change perspective. In: IEEE 44th annual (COMPASAC), 2020 5. Haller E, Rebedea T (2013) Designing a chat-botthat simulates an historical ﬁgure. In: IEEE conference publications, July 2013 6. Dzobo K, Adotey S, Thomford NE, Dzobo W (2020) Integrating artiﬁcial and human intelligence: a partnership for responsible innovation in biomedical engineering and' metadata={'title': 'AI-Based Interactive Agent for Health Care Using NLP and Deep Learning', 'author': 'U. Hemavathi', 'publish_date': '2022-06-07', 'subject': 'Information and Communication Technology for Competitive Strategies (ICTCS 2021)', 'doi': 'doi:10.1007/978-981-19-0095-2_2', 'keywords': 'Deep learning,Artificial intelligence,Natural language processing,Health care'}
613	page_content='in biomedical engineering and medicine. OmicsJ Integr Biol 24:247–263 7. Roos S, Supervisor: Ruth Loc:han (2018) Chatbots in education a passing trend or a valuable pedagogical tool? 8. Yang YC, Al-Garadi MA, Bremer W, Zhu JM, Grande D, Sarker A (2021) Developing an automatic system for classifying chatter about health services on twitter: case study for Medicaid.J Med Internet Res 23(5):e26616 9. Ahmed Z, Mohamed K, Zeeshan S, Dong X (2020) Artiﬁcial intelligence with multi-functional machine learning platform development for better healthcare and precision medicine. Database2020 10. Higashinaka R et al (2014) Towards an open domain conversational system fully based on natural language processing. In: COLING’14, pp 928–939 11. Mustaqeem, Kwon S (2020) A CNN-assisted enhanced audio signal processing for speech emotion recognition. Sensors 20:183' metadata={'title': 'AI-Based Interactive Agent for Health Care Using NLP and Deep Learning', 'author': 'U. Hemavathi', 'publish_date': '2022-06-07', 'subject': 'Information and Communication Technology for Competitive Strategies (ICTCS 2021)', 'doi': 'doi:10.1007/978-981-19-0095-2_2', 'keywords': 'Deep learning,Artificial intelligence,Natural language processing,Health care'}
614	page_content='A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods Dilan Bakır and Mehmet S. Aktas(B) Yildiz Technical University, Istanbul, Turkey dilan.bakir@std.yildiz.edu.tr, aktas@yildiz.edu.tr Abstract. Answering questions, ﬁnding the most appropriate answer to the question given by the user as input are among the important tasks of natural language processing. Many studies have been done on question answering and datasets, methods have been published. The aim ofthis article is to reveal the studies done in question answering and to identify the missing research topics. In this literature review, it is tried to determine the datasets, methods and frameworks used for questionanswering between 2000 and 2022. From the articles published between these years, 91 papers are selected based on inclusion and exclusion criteria. This systematic literature review consists of research analyzes suchas research questions, search strategy, inclusion and exclusion criteria, data extraction. We see' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
615	page_content='data extraction. We see that the selected ﬁnal study focuses on four topics. These are Natural Language Processing, Information Retrieval, Knowledge Base, Hybrid Based. Keywords: Question answering ·Information retrieval ·Knowledge based question answering ·NLP based question answering ·Systematic literature review 1 Introduction In the growing technology world, the importance of data is increasing. Question and answer systems have been developed for the growth of the data, the extraction of the desired information from the data and the processing of this information. Question answering (QA) is the system that takes a certain query input from the user and brings the closest answer to this query over the desired data. QA consists of various systems such as search engine, chatbot. These systems vary according to needs. At ﬁrst, search engines would only return documents containing information related to queries created by users in natural language,but over time, it is desired to return a direct answer to the' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
616	page_content='return a direct answer to the user’s question along with the documents and the needs are increasing. Question answering systems consist of research areas such as Information Retrieval (IR), Answer Extraction c/circlecopyrtThe Author(s), under exclusive license to Springer Nature Switzerland AG 2022 O. Gervasi et al. (Eds.): ICCSA 2022 Workshops, LNCS 13377, pp. 47–62, 2022. _4 48 D. Bakır and M. S. Aktas (AE), and Natural Language Processing (NLP). Diﬀerent studies, methods and datasets have been published in the ﬁeld of QA. To this end, a comprehensivepicture of the current state of QA is requested. In this study, our purpose is to analyze the studies conducted between 2000 and 2022 in the ﬁeld of QA. These analyzes are prepared on the methods used,the most used techniques, and datasets. The sections of this article are determined as follows. In Sect. 2, research methods are described. The criteria and results determined for the research questions are given in Sect. 3. In the last section, the summary of' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
617	page_content='last section, the summary of this study is given. 2 Methodology 2.1 Review Method A systematic approach is chosen when conducting a literature search on question answering systems. Systematic literature reviews are well established method ofreview in question answering. In a systematic literature review, it can be deﬁned as examining all the necessary research in a subject area and drawing conclusions [ 1]. This systematic literature review was prepared according to the criteria suggested by Kitchenham and Charters (2007). Some of the works and ﬁgures in this section have also been adapted by (Radjenovi´ c, Heriˇ cko, Torkar, ˇZivkoviˇ c, 2013) [ 2], (Unterkalmsteiner et al. 2012) [ 3] and Wahono [ 4]. Fig. 1. Systematic literature review steps As shown in Fig. 1, Srl work consists of certain stages. These stages are planning, executing and reporting. In the planning stage, the needs are determined. A Systematic Literature Review of Question Answering 49 In the introduction part, realization targets are' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
618	page_content='part, realization targets are mentioned. Then, existing slr studies on question answering are collected and reviewed. The purpose of thisreview is designed to reduce researcher bias when conducting the slr study (Step 2). Research questions, search strategy, inclusion and exclusion criteria, study process, data extraction are described in Sects. 2.2,2.3,2.4and2.5. 2.2 Research Questions The research questions studied in this review are indicated in Table 1. Table 1. Identiﬁed research questions ID Research question RQ1 Which journal is the most signiﬁcant Question Answering journal? RQ2 Who are the most active and inﬂuential researchers in the Question Answering ﬁeld? RQ3 What kind of research topics are selected by researchers in the Question Answering ﬁeld? RQ4 What kind of datasets are the most used for Question Answering? RQ5 What kind of methods are used for Question Answering? RQ6 Which method performs best when used for Question Answering? RQ7 What kind of method improvements are proposed for' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
619	page_content='improvements are proposed for QuestionAnswering? The methods and datasets used in the question answering area shown in Table 1from RQ1 to RQ7 were analyzed. Important methods, datasets are analyzed between RQ4 and RQ7. It gives a summary of the work done in the ﬁeld of question answering from RQ1 to RQ3. 2.3 Search Strategy The search process (Step 4) consists of several stages. Determination of digital libraries, determination of search keywords, development of search queries andﬁnal studies that match the search query from digital libraries are extracted. In order to select the most relevant articles, ﬁrst of all, appropriate database sets are determined. The most popular literature database sets are researched andselected in order to keep our ﬁeld of study wide. Digital databases used: ACM Digital Library, IEEE eXplore, ScienceDirect, Springer, Scopus The search query is determined according to certain criteria. These criteria are; 50 D. Bakır and M. S. Aktas 1. Search terms were determined from the' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
620	page_content='were determined from the research questions 2. Searching the generated query in related titles, abstracts and keywords3. Identifying diﬀerent spellings, synonyms and opposite meaning of query 4. A comprehensive search string was created using the speciﬁed search terms Boolean AND and OR. The generated search string is as follows. (“question answering” AND “natural language processing”) AND (“informationretrieval”) AND (“Document Retrieval” OR “Passage Retrieval” OR “Answer Extraction”) Digital databases were scanned based on keywords, titles and abstracts. The search limited publications between 2000 and 2022. Within the scope of the research, only journal articles and conference papers published in English were included in the search. 2.4 Study Selection Inclusion and exclusion criteria speciﬁed in Table 2are shown in order to determine the ﬁnal studies. Table 2. Inclusion and exclusion criteria Inclusion criteria Studies in academic and industry using large and small scale data sets Studies discussing and' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
621	page_content='sets Studies discussing and comparing modelingperformance in the area of question answering For studies that have both the conference and journal versions, only the journal version will be included For duplicate publications of the same study, only themost complete and newest one will be included Exclusion criteria Studies without a strong validation or including experimental results of question answering Studies discussing question answering datasets, methods, frameworks in a context other than question answering Studies not written in English Figure 2shows each step of the review process and the number determined. The study selection process was carried out in 2 steps. Title, abstract and fulltext studies have been removed. Literature studies and studies that did not include experimental results were also excluded. Other studies were included according to the degree of similarity with question answering from the remainingstudies. A Systematic Literature Review of Question Answering 51 Fig. 2. Search and' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
622	page_content='51 Fig. 2. Search and selection of ﬁnal studies In the ﬁrst stage, the ﬁnal list was selected. The ﬁnal list includes 91 ﬁnal studies. Considering the inclusion and exclusion criteria of 91 ﬁnal studies,research questions and study similarities were examined. 2.5 Data Extraction In the ﬁnal study, our goal is to identify studies that contribute to the research questions. A data extraction form was created for each of the 91 ﬁnal studies. This form was designed to collect information on studies and to answer researchquestions. In Table 3, ﬁve features were used to analyze the research questions. Table 3. Data extraction features matched to research questions Feature Research questions Researchers and Publications RQ1, RQ2 Question Answering Trends and Topics RQ3 Question Answering Datasets RQ4 Question Answering Metrics RQ4 Question Answering Methods RQ5, RQ6, RQ7 52 D. Bakır and M. S. Aktas 2.6 Threats to Validity of Research Some conference papers and journal articles were omitted because it is diﬃcult to' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
623	page_content='because it is diﬃcult to manually review all article titles during the literature review. 3 Analysis Results 3.1 Important Journal Publications In this literature study, there are 91 ﬁnal studies in the ﬁeld of question answering. Depending on the ﬁnal studies, we showed the numerical change of thestudies in the ﬁeld of question answering over the years. Our aim here is to see how the interest has changed over the years. Observation by years is shown in Fig. 3. It is observed that the interest in the ﬁeld of question answering has increased more since 2005 and it shows that the studies carried out are more contemporary. Fig. 3. Distribution of selected studies over the years The most important journals included in this literature study are shown in Fig.4. Fig. 4. Journal publications The Scimago Journal Rank (SJR) values of the most important journals with ﬁnal studies are given in Table 4. A Systematic Literature Review of Question Answering 53 Table 4. SJR of journals Journal Publications SJR BMC' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
624	page_content='Journal Publications SJR BMC Bioinformatics 1,567 Expert Systems with Applications 1,368 SIGIR Forum (ACM Special Interest Group on Information Retrieval)1,337 Information Processing Management 1,061 Journal of Biomedical Informatics 1,057 Artiﬁcial Intelligence in Medicine 0,98 Applied Intelligence 0,791 IEEE Access 0,587 Nongye Jixie Xuebao/Transactions of the Chinese Society for Agricultural Machinery0,461 Journal of Intelligent Information Systems 0,424 Frontiers of Information Technology, ElectronicEngineering 0,406 Natural Language Engineering 0,29 Lecture Notes in Computer Science 0,249 NIST Special Publication 0,202 IFMBE Proceedings 0,152 World Academy of Science 0,137 3.2 Most Active Researchers The researchers who are most active in the ﬁeld of question answering are shown in Fig. 5according to the number of studies. Boris Katz, Yuan-ping Nie, Mourad Sarrouti, SaidOuatik El Alaoui, Prodromos Malakasiotis, Ion Androutsopou-los, Paolo Rosso, Stefanie Tellex, Aaron Fernandes, Gregory Marton, Dragomir' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
625	page_content='Gregory Marton, Dragomir Radev, Weiguo Fan, Davide Buscaldi, Emilio Sanchis, Dietrich Klakow, Matthew W. Bilottiare are the most active researchers. Fig. 5. Inﬂuential researchers and number of studies 54 D. Bakır and M. S. Aktas 3.3 Research Topics in the Question Answering Field To answer this question, we considered Yao’s classiﬁcation paper. When the ﬁnal studies were examined, it was seen that the studies were carried out onfour topics [ 5]. 1. Natural Language Processing based (NLP): Machine learning, NLP techniques are used to extract the answers. 2. Information Retrieval based (IR): It deals with the retrieval or sorting of answers, documents and passages in search engine usage. 3. Knowledge Base based (KB): Finding answers is done through structured data. Standard database queries are used in replacement of word-based searches [ 6]. 4. Hybrid Based: A hybrid approach is the combination of IR, NLP and KB. Figure 6shows the total distribution of research topics on question answering from 2000 until' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
626	page_content='answering from 2000 until 2022. From the 91 studies, 6.72% of the papers implementeda knowledge base, 31.94% implemented a natural language processing, 59.24% implemented an information retrieval and 2.1% implemented a Hybrid. When the ﬁnal studies are examined, it is seen that there are more studies in the ﬁeldof NLP. As the reasons why researchers focus on this issue, studies on obtaining information through the search engine are increasing. A lot of text nlp and machine learning techniques have been tried to be applied in order to extractthe most correct answer from the unstructured data. Fig. 6. Ratio of subjects 3.4 Datasets Used for Question Answering Dataset is a data collection on which machine learning is applied [ 6]. The training set is the data on which the model is trained by giving it to the learning system. The test set or evaluation set is a dataset used to evaluate the model developedon a training set. The distribution of datasets by years is presented. 35.95% of the studies are private' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
627	page_content='of the studies are private datasets. Since these datasets are not public, the results of the studies A Systematic Literature Review of Question Answering 55 cannot be compared with the results of the proposed models. The distribution of ﬁnal studies by years is shown in Fig. 7. Looking at the distribution, there is an increasing awareness of the use of public data. Fig. 7. Number of datasets 3.5 Methods Used in Question Answering As can be seen in Fig. 8, fourteen methods used and recommended in the ﬁeld of question answering since 2000 have been determined. These determined methods are shown in Fig. 8. Fig. 8. Methods used in question answering 3.6 Best Method Used for Question Answering Many studies have been carried out in the ﬁeld of question answering. When the literature is examined, there is a pipeline process consisting of Natural Language Processing (NLP), Information Retrieval (IR), and Answer Extraction (IE). Aquestion given in natural language ﬁrst goes through the analysis phase. In other words,' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
628	page_content='phase. In other words, search queries are created to facilitate document retrieval, which is the next step. When the literature is examined, it is seen that the ﬁrst studies usedmostly classical methods such as tf-idf, bm25 [ 8–10] in the retrieval phase. Here, retrieval is provided by searching for words similar to the query received by the user as input. 56 D. Bakır and M. S. Aktas When we look at other studies, one of the most used methods is the name entity recognition(ner) and post tagging methods. It has been observed thatsuccess in the retrieval phase increases thanks to semantic role labeling with these methods [ 11–13]. It is seen that support vector machine (SVM) is used as the other classical method classiﬁer. Here, the category to which the querybelongs is the classiﬁer that performs document retrieval over that category. Semantic capture was improved with SVM [ 9,14]. The disadvantage of classical methods is that the query is misspelled or fails to ﬁnd semantically similar words. When we examine' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
629	page_content='words. When we examine the literature, we observe that deep learning studies have increased in recent years. When we examine the studies using deep learning, we see that more successful results are obtainedthan the classical methods (Chen, Y.,) (Pappas, D.) (X. Zhang,) (Lin, H.) (Nie P.) [15–18]. The advantage of deeplearning is that words are captured in semantic and misspelled words. In this way, most of the studies in the ﬁeld of question answering in recent years are on deep learning. 4 Conclusion and Future Works In this systematic literature study, our goal is to analyze and summarize thetrends, datasets and methods used in the studies in the ﬁeld of question answering between 2000–2022. According to the inclusion and exclusion criteria, 91 ﬁnal studies were determined. When the studies in the literature are examined, problems such as noisy data, performance and success rates have been dealt with and these problems are still among the subjects that are open to research. In the analysis of selected ﬁnal' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
630	page_content='the analysis of selected ﬁnal studies, it was determined that the current question answering researchfocused on four topics: KB, IR, NLP, Hybrid Base. When the studies in the ﬁeld of question answering are examined, 6.72% of the topics are KB topics, 31.94% are IR topics, 59.24% are NLP topics and 2.10% are Hybrid base. Inaddition, 65.05% of the studies were used as public datasets and 34.95% as private datasets. Fourteen diﬀerent methods were used for question answering. Among the fourteen methods, seven most applied methods were determined inthe ﬁeld of question answering. These are relation ﬁnding(similarity distance), parsing, ner, Tokenize, deep learning, post tagging, graph. Using some of these techniques, the researchers proposed some techniques to improve accuracy in theQA ﬁeld. References 1. Kitchenham, B., Charters, S.: Guidelines for performing systematic literature reviews in software engineering. EBSE Technical Report Version 2.3, EBSE (2007) 2. Radjenovi´ c, D., Heriˇ cko, M., Torkar, R.,' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
631	page_content='Heriˇ cko, M., Torkar, R., ˇZivkoviˇ c, A.: Software fault prediction metrics: a systematic literature review. Inf. Softw. Technol. 55(8), 1397–1418 (2013).  A Systematic Literature Review of Question Answering 57 3. Unterkalmsteiner, M., Gorschek, T., Islam, A., Cheng, C.K., Permadi, R.B., Feldt, R.: Evaluation and measurement of software process improvement-a systematic literature review. IEEE Trans. Softw. Eng. 38(2), 398–424 (2012).  org/10.1109/TSE.2011.26 4. Wahono, R.S.: A systematic literature review of software defect prediction: research trends, datasets, methods and frameworks. J. Softw. Eng. 1(1), 1–16 (2015) 5. Yao, X.: Feature-Driven Question Answering with Natural Language Alignment. John Hopkins University (2014) 6. Sammut, C., Webb, G.I.: Encyclopedia of Machine Learning. Springer, New York (2011).  7. Yang, M.-C., Lee, D.-G., Park, S.-Y., Rim, H.-C.: Knowledge-based question answering using the semantic embedding space. Expert Syst. Appl. 42(23), 9086– 9104 (2015).  8. Brokos, G.-I.,' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
632	page_content='(2015).  8. Brokos, G.-I., Malakasiotis, P., Androutsopoulos, I.: Using centroids of word embeddings and word mover’s distance for biomedical document retrieval in question answering. In: BioNLP 2016 Proceedings of the 15th Workshop on Biomedical Natural Language, pp. 114–118 (2016).  9. Cao, Y., Liu, F., Simpson, P., Ely, J., Yu, H.: AskHERMES, an online question answering system for complex clinical questions. J. Biomed. Inform. 44(2), 277–288 (2011) 10. Tellex, S., Katz, B., Fernandes, A., Marton, G.: Quantitative evaluation of passage retrieval algorithms for question answering. In: SIGIR 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Developmentin Information Retrieval, pp. 41–47 (2003) 11. Bilotti, M.W., Elsas, J., Carbonell, J., Nyberg, E.: Rank learning for factoid question answering with linguistic and semantic constraints. In: International Confer-ence on Information and Knowledge Management, Proceedings, pp. 459–468 (2010) 12. Pardi˜ no, M., G´ omez, J.M.,' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
633	page_content='Pardi˜ no, M., G´ omez, J.M., Llorens, H., Moreda, P., Palomar, M.: Adapting IBQAS to work with text transcriptions in QAst task. In: IBQAst: CEUR Workshop Pro-ceedings (2008) 13. Roth, B., Conforti, C., Poerner, N., Karn, S.K., Sch¨ utze, H.: Neural architectures for open-type relation argument extraction. Nat. Lang. Eng. 25(2), 219–238 (2019) 14. Niu, Y., Hirst, G.: Identifying cores of semantic classes in unstructured text with a semi-supervised learning approach. In: International Conference Recent Advances in Natural Language Processing, RANLP (2007) 15. Chen, Y., Zhang, X., Chen, A., Zhao, X., Dong, Y.: QA system for food safety events based on information extraction. Nongye Jixie Xuebao/Trans. Chin. Soc. Agric. Mach. 51, 442–448 (2020) 16. Pappas, D., Androutsopoulos, I.: A neural model for joint document and snippet ranking in question answering for large document collections. In: ACL-IJCNLP 2021–59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
634	page_content='the 11th International Joint Conference on Natural Language Processing, Proceedings of the Conference, pp. 3896–3907 (2021) 17. Lin, H.-Y., Lo, T.-H., Chen, B.: Enhanced Bert-based ranking models for spoken document retrieval. In: IEEE Automatic Speech Recognition and Understanding Workshop, ASRU 2019 Proceedings, vol. 9003890, pp. 601–606 (2019) 18. Zhang, Y., Nie, P., Ramamurthy, A., Song, L.: Answering any-hop open-domain questions with iterative document reranking. In: SIGIR 2021 Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Infor-mation Retrieval, vol. 3462853, pp. 481–490 (2021) 58 D. Bakır and M. S. Aktas 19. Kratzwald, B., Feuerriegel, S.: Adaptive document retrieval for deep question answering. In: Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP, pp. 576–581 (2018) 20. Cong, Y., Wu, Y., Liang, X., Pei, J., Qin, Z.: PH-model: enhancing multi-passage machine reading comprehension with passage reranking and' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
635	page_content='with passage reranking and hierarchical information. Appl. Intell. 51(8), 5440–5452 (2021).  21. Nguyen, T.M., Tran, V.-L., Can, D.-C., Vu, L.T., Chng, E.S.: QASA advanced document retriever for open-domain question answering by learning to rank questionaware self-attentive document representations. In: ACM International Conference Proceeding Series, pp. 221–225 (2019) 22. Guo, Q.-L., Zhang, M.: Semantic information integration and question answering based on pervasive agent ontology. Expert Syst. Appl. 36(6), 10068–10077 (2009) 23. Grau, B.: Finding an answer to a question. In: Proceedings of the International Workshop on Research Issues in Digital Libraries, IWRIDL-2006. In: Association with ACM SIGIR, vol. 1364751 (2007) 24. Radev, D., Fan, W., Qi, H., Wu, H., Grewal, A.: Probabilistic question answering on the web. In: Proceedings of the 11th International Conference on World Wide Web, WWW 2002, pp. 408–419 (2002) 25. Lin, J., et al.: The role of context in question answering systems. In: CHI EA 2003:' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
636	page_content='systems. In: CHI EA 2003: CHI 2003 Extended Abstracts on Human Factors in Computing Systems (2003) 26. P´erez-Couti˜ no, M., Solorio, T., Montes-y-G´ omez, M., L´ opez-L´ opez, A., Villase˜ norPineda, L.: Question answering for Spanish based on lexical and context annota-tion. In: Lemaˆ ıtre, C., Reyes, C.A., Gonz´ alez, J.A. (eds.) IBERAMIA 2004. LNCS (LNAI), vol. 3315, pp. 325–333. Springer, Heidelberg (2004).  1007/978-3-540-30498-2 33 27. Zhang, X., Zhan, K., Hu, E., Fu, C., Luo, L., Jiang, H.: Answer complex questions: path ranker is all you need. Artif. Intell. Rev. 55(1), 207–253 (2021) 28. Fan, Y., , J., Ma, X., Zhang, R., Lan, Y., Cheng, X.: A linguistic study on relevance modeling in information retrieval. In: The Web Conference 2021 Proceedings of the World Wide Web Conference, WWW 2021, pp. 1053–1064 (2021) 29. Kaiser, M. : Incorporating user feedback in conversational question answering over heterogeneous web sources. In: SIGIR 2020 Proceedings of the 43rd International ACM SIGIR Conference on' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
637	page_content='ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 28–42 (2020) 30. Lamurias, A., Sousa, D., Couto, F.M.: Generating biomedical question answering corpora from QA forums. IEEE Access 8(9184044), 161042–161051 (2020). https:// doi.org/10.1109/ACCESS.2020.3020868 31. Sarrouti, M., Ouatik El Alaoui, S.: SemBioNLQA a semantic biomedical question answering system for retrieving exact and ideal answers to natural language questions. Artif. Intell. Med. 102(101767) (2020) 32. Shah, A.A., Ravana, S.D., Hamid, S., Ismail, M.A.: Accuracy evaluation of methods and techniques in Web-based question answering systems. Knowl. Inf. Syst. 58(3), 611–650 (2019).  33. Roth, B., Conforti, C., Poerner, N., Karn, S.K., Sch¨ utze, H.: Neural architectures for open-type relation argument extraction. Nat. Lang. Eng. 25(2), 219–238 (2019) 34. Samarinas, C., Tsoumakas, G.: WamBY: an information retrieval approach to webbased question answering. In: ACM International Conference Proceeding Series (2018) A' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
638	page_content='Proceeding Series (2018) A Systematic Literature Review of Question Answering 59 35. Novotn, V., Sojka, P.: Weighting of passages in question answering. In: Recent Advances in Slavonic Natural Language Processing, December 2018, pp. 31–40 (2018) 36. Sarrouti, M., Ouatik El Alaoui, S.: A passage retrieval method based on probabilistic information retrieval and UMLS concepts in biomedical question answering. J. Biomed. Inform. 68, 96–103 (2017).  37. Jin, Z.-X., Zhang, B.-W., Fang, F., Zhang, L.-L., Yin, X.-C.: A multi-strategy query processing approach for biomedical question answering. In: BioNLP 2017 SIGBioMed Workshop on Biomedical Natural Language Processing, Proceedings of the 16th BioNLP Workshop, pp. 373–380 (2017) 38. Aroussi, S.A., Habib, N.E., Beqqali, O.E.: Improving question answering systems by using the explicit semantic analysis method. In: SITA 2016–11th International Conference on Intelligent Systems: Theories and Applications 7772300 (2016) 39. Omari, A., Carmel, D., Rokhlenko, O., Szpektor,' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
639	page_content='D., Rokhlenko, O., Szpektor, I.: Novelty based ranking of human answers for community questions. In: SIGIR 2016 Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 215–224 (2016) 40. Hoque, M.M., Quaresma, P.: An eﬀective approach for relevant paragraph retrieval in Question Answering systems. In: 2015 18th International Conference on Computer and Information Technology, ICCIT 2015 7488040, pp. 44–49 (2016) 41. Brokos, G.-I., Malakasiotis, P., Androutsopoulos, I.: Using centroids of word embeddings and word mover’s distance for biomedical document retrieval in question answering. In: BioNLP 2016-Proceedings of the 15th Workshop on BiomedicalNatural Language Processing, pp. 114–118 (2016) 42. Tsatsaronis, G., et al.: An overview of the BioASQ large-scale biomedical semantic indexing and question answering competition. BMC Bioinform. 16(1), 138 (2015) 43. Neves, M.: HPI question answering system in the BioASQ 2015 challenge. In: CEUR Workshop' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
640	page_content='challenge. In: CEUR Workshop Proceedings, vol. 1391 (2015) 44. Liu, Z.J., Wang, X.L., Chen, Q.C., Zhang, Y.Y., Xiang, Y.: A Chinese question answering system based on web search. In: Proceedings-International Conference on Machine Learning and Cybernetics, vol. 2,7009714, pp. 816–820 (2014) 45. Ageev, M., Lagun, D., Agichtein, E.: The answer is at your ﬁngertips: improving passage retrieval for web question answering with search behavior data. In: EMNLP 2013–2013 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference, pp. 1011–1021 (2013) 46. Sun, W., Fu, C., Xiao, Q.: A text inference based answer extraction for Chinese question answering. In: Proceedings-2012 9th International Conference on Fuzzy Systems and Knowledge Discovery, FSKD 2012, vol. 6234145, pp. 2870–2874 (2012) 47. Lu, W., Cheng, J., Yang, Q.: Question answering system based on web. In: Proceedings-2012 5th International Conference on Intelligent Computation Technology and Automation, ICICTA 2012, vol.' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
641	page_content='Automation, ICICTA 2012, vol. 6150169, pp. 573–576 (2012) 48. Saias, J., Quaresma, P.: Question answering approach to the multiple choice QA4MRE challenge. In: CEUR Workshop Proceedings, vol. 1178 (2012) 49. Foucault, N., Adda, G., Rosset, S.: Language modeling for document selection in question answering. In: International Conference Recent Advances in Natural Language Processing, RANLP, pp. 716–720 (2011) 50. Monz, C.: Machine learning for query formulation in question answering. Nat. Lang. Eng. 17(4), 425–454 (2011) 60 D. Bakır and M. S. Aktas 51. Zhang, W., Duan, L., Chen, J.: Reasoning and realization based on ontology model and Jena. In: Proceedings 2010 IEEE 5th International Conference on Bio-Inspired Computing: Theories and Applications, BIC-TA 2010, vol. 5645115, pp. 1057–1060(2010) 52. Li, F., Kang, H., Zhang, Y., Su, W.: Question intention analysis and entropybased paragraph extraction for medical question answering. In: ICCASM 2010–2010 International Conference on Computer Application and System' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
642	page_content='Application and System Modeling, Proceedings, vol. 3,5620229, pp. V3354–V3357 (2010) 53. Li, X., Chen, E.: Graph-based answer passage ranking for question answering. In: Proceedings-2010 International Conference on Computational Intelligence and Security, vol. 5696360, pp. 634–638 (2010) 54. Lu, W.-H., Tung, C.-M., Lin, C.-W.: Question intention analysis and entropy-based paragraph extraction for medical question answering. In: IFMBE Proceedings 31 IFMBE, pp. 1582–1586 (2010) 55. Nguyen, D.T., Pham, T.N., Phan, Q.T.: A semantic model for building the Vietnamese language query processing framework in e-library searching application. In: ICMLC 2010 The 2nd International Conference on Machine Learning andComputing, vol. 5460746, pp. 179–183 (2010) 56. Nguyen, D.T., Nguyen, H.V., Phan, Q.T.: Using the Vietnamese language query processing framework to build a courseware searching system. In: 2010 2nd Inter-national Conference on Computer Engineering and Applications, ICCEA 2010, vol. 2,5445613, pp. 117–121 (2010)' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
643	page_content='2,5445613, pp. 117–121 (2010) 57. Buscaldi, D., Rosso, P., G´ omez-Soriano, J.M., Sanchis, E.: Answering questions with an n-gram based passage retrieval engine. J. Intell. Inf. Syst. 34(2), 113–134 (2010) 58. Momtazi, S., Klakow, D.: A word clustering approach for language model-based sentence retrieval in question answering systems. In: International Conference on Information and Knowledge Management, Proceedings, pp. 1911–1914 (2009) 59. Dang, N.T., Thi, D., Tuyen, T.: Document retrieval based on question answering system. In: 2009 2nd International Conference on Information and Computing Science, ICIC 2009, vol. 1,5169570, pp. 183–186 (2009) 60. Guo, Q.-L., Zhang, M.: Semantic information integration and question answering based on pervasive agent ontology. Expert Syst. Appl. 36(6), 10068–10077 (2009) 61. Dang, N.T., Tuyen, D.T.T.: Natural language question-answering model applied to document retrieval system: world academy of science. Eng. Technol. 39, 36–39 (2009) 62. Dang, N.T., Tuyen, D.T.T.:' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
644	page_content='Dang, N.T., Tuyen, D.T.T.: E-document retrieval by question answering system: world academy of science. Eng. Technol. 38, 395–398 (2009) 63. Abouenour, L., Bouzoubaa, K., Rosso, P.: Structure-based evaluation of an Arabic semantic query expansion using the JIRS passage retrieval system. In: Proceedings of the EACL 2009 Workshop on Computational Approaches to Semitic Languages, SEMITIC@EACL 2009, pp. 62–68 (2009) 64. Ortiz-Arroyo, D.: Flexible question answering system for mobile devices: 3rd International Conference on Digital Information Management, ICDIM 2008, vol. 4746794, pp. 266–271 (2008) 65. Lita, L.V., Carbonell, J.: Cluster-based query expansion for statistical question answering. In: JCNLP 2008–3rd International Joint Conference on Natural Language Processing, Proceedings of the Conference (2008) 66. K¨ ursten, J., Kundisch, H., Eibl, M.: QA extension for Xtrieval: contribution to the QAst track. In: CEUR Workshop Proceedings, vol. 1174 (2008) A Systematic Literature Review of Question Answering 61' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
645	page_content='of Question Answering 61 67. Comas, P.R., Turmo, J.: Robust question answering for speech transcripts: UPC experience in QAst. In: CEUR Workshop Proceedings, vol. 1174 (2008) 68. Hu, B.-S., Wang, D.-L., Yu, G., Ma, T.: Answer extraction algorithm based on syntax structure feature parsing and classiﬁcation. Jisuanji Xuebao/Chin. J. Comput. 31(4), 662–676 (2008) 69. Yang, Z., Lin, H., Cui, B., Li, Y., Zhang, X.: DUTIR at TREC 2007 genomics track. NIST Special Publication (2007) 70. Schlaefer, N., Ko, J., Betteridge, J., Pathak, M., Nyberg, E.: Semantic extensions of the ephyra QA system for TREC 2007. NIST Special Publication (2007) 71. Hickl, A., Roberts, K., Rink, B., Shi, Y., Williams, J.: Question answering with LCC’s CHAUCER-2 at TREC 2007. NIST Special Publication (2007) 72. Pasca, M.: Lightweight web-based fact repositories for textual question answering. In: International Conference on Information and Knowledge Management, Proceedings, pp. 87–96 (2007) 73. Peters, C.: Multilingual information access:' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
646	page_content='information access: the contribution of evaluation. In: Proceedings of the International Workshop on Research Issues in Digital Libraries, IWRIDL-2006, vol. 1364761. Association with ACM SIGIR (2007) 74. Yang, Y., Liu, S., Kuroiwa, S., Ren, F.: Question answering system of confusian analects based on pragmatics information and categories. In: IEEE NLP-KE 2007 Proceedings of International Conference on Natural Language Processing andKnowledge Engineering, vol. 4368056, pp. 361–366 (2007) 75. Tiedemann, J.: Comparing document segmentation strategies for passage retrieval in question answering. In: International Conference Recent Advances in NaturalLanguage Processing, RANL (2007) 76. Yarmohammadi, M.A., Shamsfard, M., Yarmohammadi, M.A., Rouhizadeh, M.: Using WordNet in extracting the ﬁnal answer from retrieved documents in a ques-tion answering system. In: GWC 2008: 4th Global WordNet Conference, Proceedings, pp. 520–530 (2007) 77. Niu, Y., Hirst, G.: Comparing document segmentation strategies for passage' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
647	page_content='strategies for passage retrieval in question answering. In: International Conference Recent Advances in Natural Language Processing, RANLP 2007-January, pp. 418–424 (2007) 78. Hussain, M., Merkel, A., Klakow, D.: Dedicated backing-oﬀ distributions for language model based passage retrieval. Lernen, Wissensentdeckung und Adaptivitat, LWA 2006, 138–143 (2006) 79. Jinguji, D., Lewis, W., Efthimiadis, E.N., Yu, P., Zhou, Z.: The university of Washington’s UWCLMAQA system. NIST Special Publication (2006) 80. Balantrapu, S., Khan, M., Nagubandi, A.: TREC 2006 Q&A factoid TI experience. NIST Special Publication (2006) 81. Ofoghi, B., Yearwood, J., Ghosh, R.: TREC 2006 Q&A factoid: TI experience. In: Conferences in Research and Practice in Information Technology Series, vol. 48, pp. 95–101 (2006) 82. Ferr´ es, D., Rodr´ ıguez, H.: Experiments using JIRS and Lucene with the ADL feature type Thesaurus. In: CEUR Workshop Proceedings, vol. 1172 (2006) 83. Garc´ ıa-Cumbreras, M.A., Ure˜ na-L`opez, L.A., Santiago, F.M.,' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
648	page_content='L.A., Santiago, F.M., Perea-Ortega, J.M.: BRUJA system. The University of Ja´ en at the Spanish task of CLEFQA 2006. In: CEUR Workshop Proceedings, vol. 1172 (2006) 84. Blake, C.: A comparison of document, sentence, and term event spaces. In: COLING/ACL 2006–21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, Proceed-ings of the Conference, vol. 1, pp. 601–608 (2006) 62 D. Bakır and M. S. Aktas 85. Yu, Z.T., Zheng, Z.Y., Tang, S.P., Guo, J.Y.I.: Query expansion for answer document retrieval in Chinese question answering system. In: 2005 International Conference on Machine Learning and Cybernetics, ICMLC 2005, pp. 72–77 (2005) 86. Jousse, F., Tellier, I., Tommasi, M., Marty, P.: Learning to extract answers in question answering. In: CORIA 2005–2EME Conference en Recherche Informations et Applications (2005) 87. Ferr´ es, D., Kanaan, S., Dominguez-Sal, D, Surdeanu, M., Turmo, J.: Experiments using a voting scheme among three' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
649	page_content='a voting scheme among three heterogeneous QA systems. NIST Special Publication (2005) 88. Yang, G.C., Oh, H.U.: ANEX an answer extraction system based on conceptual graphs. In: Proceedings of the 2005 International Conference on Information andKnowledge Engineering, IKE 2005, pp. 17–24 (2005) 89. Tiedemann, J.: Integrating linguistic knowledge in passage retrieval for question answering. In: HLT/EMNLP 2005-Human Language Technology Conference andConference on Empirical Methods in Natural Language Processing, Proceedings of the Conference, pp. 939–946 (2005) 90. Isozaki, H.: An analysis of a high-performance Japanese question answering system. ACM Trans. Asian Lang. Inf. Process. 4(3), 263–279 (2005) 91. Tiedemann, J. : Integrating linguistic knowledge in passage retrieval for question answering. In: International Conference Recent Advances in Natural LanguageProcessing, RANLP 2005-January, pp. 540–546 (2005) 92. Amaral, C., Figueira, H., Martins, A., Mendes, P., Pinto, C.: Priberam’s question answering' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
650	page_content='Priberam’s question answering system for Portuguese. In: CEUR Workshop Proceedings, vol. 1171(2005). (Subseries of Lecture Notes in Computer Science), vol. 3315, pp. 325–333 (2004) 93. Banerjee P, Han H.: Incorporation of corpus-speciﬁc semantic information into question answering context. In: ONISW 2008 Proceedings of the 2nd International Workshop on Ontologies and Information Systems for the Semantic (2008) 94. Khushhal, S., Majid, A., Abbas, S.A., Nadeem, M.S.A., Shah, S.A.: Question retrieval using combined queries in community question answering. J. Intell. Inf. Syst. 55(2), 307–327 (2020).  95. Nie, Y., Han, Y., Huang, J., Jiao, B., Li, A.: Attention-based encoder-decoder model for answer selection in question answering. Front. Inf. Technol. Electron. Eng. 18, 535–544 (2017) 96. Cao, Y., Wen, Y., Chin, Y., Yong, Y.: A structural support vector method for extracting contexts and answers of questions from online forums. Inf. Process. Manag. 47(6), 886–898 (2011) 97. Monroy, A., Calvo, H., Gelbukh, A.:' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
651	page_content='A., Calvo, H., Gelbukh, A.: Using graphs for shallow question answering on legal documents. In: Gelbukh, A., Morales, E.F. (eds.) MICAI 2008. LNCS (LNAI), vol. 5317, pp. 165–173. Springer, Heidelberg (2008).  1007/978-3-540-88636-5 15 98. Ofoghi, B., Yearwood, J., Ghosh, R.: A semantic approach to boost passage retrieval eﬀectiveness for question answering. In: ACSC 2006: Proceedings of the29th Australasian Computer Science Conference, vol. 48, pp. 95–101 (2006)' metadata={'title': 'A Systematic Literature Review of Question Answering: Research Trends, Datasets, Methods', 'author': 'Dilan Bakır', 'publish_date': '2022-07-02', 'subject': 'Computational Science and Its Applications – ICCSA 2022 Workshops', 'doi': 'doi:10.1007/978-3-031-10536-4_4', 'keywords': 'Question answering,Information retrieval,Knowledge based question answering,NLP based question answering,Systematic literature review'}
652	page_content='DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping M. Arulmozhi V arman1and Gerard Deepak2(B) 1Department of Electronics and Electrical Engineering, SASTRA Deemed University, Thanjavur, Tamil Nadu, India 2Department of Computer Science and Engineering, National Institute of Technology, Tiruchirappalli, India gerard.deepak.christuni@gmail.com Abstract. There is an enormous amount of data stored on the World Wide Web throughout the years of internet practice. There is a necessity for sophisticated techniques of acquiring and categorizing information resources available on the internet. In the domains of information retrieval and natural language processing,document retrieval has been an important task. Despite the fact that document retrieval algorithms have evolved signiﬁcantly over the years, there is always space for improvement. Tokenization, lemmatization, SWE, and NER are among the preparation methods applied to the dataset. The' metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}
653	page_content='applied to the dataset. The preprocessed dataset is then transferred to XML format, where the RDF mapping is performed using the Jel-lyﬁsh method. The knowledge graph is built using blogs, social network APIs, crowdsource community ontology, wiki data and Freebase, and LODC. The formulated knowledge graph is converted to RDF format from OWL format. TheJellyﬁsh method is used on the updated knowledge graph in OWL format and the RCVI dataset in OWL format to conduct RDF mapping in terms of (subject predicate object predicate). To rank the document in increasing order of semanticsimilarity, KL divergence is applied to the RDF mapping obtained in the previous phase. Based on the increasing order of semantic similarity the most relevant document is recommended. The proposed framework accomplished an accuracyof 92.78%. Keywords: Jellyﬁsh ·KL divergence ·Optimization ·RDF mapping ·Text mining 1 Introduction The comparison of a speciﬁed user’s query against a collection of free-text data is termed document' metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}
654	page_content='data is termed document retrieval. The document retrieval application consists of a database of documents categorized according to the user queries and a user interface to access all these documents. The document retrieval has two main tasks: comparing the user queryand categorizing the documents rank-wise from most relevant documents to less similar © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023 A. Abraham et al. (Eds.): IBICA 2022, LNNS 649, pp. 414–424, 2023. _39 DRHTG: A Knowledge-Centric Approach for Document Retrieval 415 documents. The relevant document is suggested to the user based on the order of semantic similarity [ 1]. This paper proposes a novel approach incorporating a heterogeneous entity tree generation scheme with RDF mapping to retrieve documents from the database [ 2]. RDF mapping is created using Jellyﬁsh algorithm and the documents are re ranked inincreasing order of semantic similarity by KL divergence [ 3,4]. The re ranked documents is provided to the' metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}
655	page_content='documents is provided to the user. Motivation: Since the beginning of recorded language, humans have been using various methods to quickly index and retrieve information. The evolution of technology has allowed us to store and search vast amounts of information. This paper explores some of the more advanced methods of document retrieval. Semantic-based document retrievalis a method that uses semantic information to aid in document retrieval. Contribution: Document retrieval has been a signiﬁcant task in the domain of information retrieval and natural language processing. Although document retrieval algorithmshave undergone a signiﬁcant transformation over the decades, there is still room for developing a better algorithm. The RCVI dataset undergoes various preprocessing procedures such as tokenization, lemmatization, SWE, NER. The preprocessed dataset is then converted into XML format, on which the Jellyﬁsh algorithm is employed to perform RDF mapping. Blogs, social network API, crowd source community' metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}
656	page_content='API, crowd source community ontology,wiki data and Freebase, and LODC are used to formulate the knowledge graph. The knowledge graph formulated is converted into OWL format and further converted into RDF format. Jellyﬁsh algorithm is employed on the modiﬁed knowledge graph in OWLformat and the OWL format of the RCVI dataset to perform RDF mapping in terms of (subject predicate object predicate). KL divergence is used on the RDF mapping obtain in the previous step to rank the document in the increasing order of semantic similarity.Based on the document rank, the most relevant document is chosen and recommend to the user. Organization: The paper is divided into ﬁve other sections. Section one comprises of introduction. Section two depicts the related works. The proposed architecture is discussed in section three. The implementation and performance evaluation is given in section four. Section ﬁve consists of results. Finally, the paper is concluded in section six. 2 Related Work Ramya et al. [ 1] proposed DRDLC' metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}
657	page_content='et al. [ 1] proposed DRDLC framework is proposed to provide/retrieve more relevant digital data over the web, which is dispersed globally and unorganized. Thisframework works based on the similar of the keywords from search results. It extracts high relevant documents to the user’s query. Deka et al. [ 2] determined that KNN is one of the classiﬁcation methods of information retrieval, which considers all samples and results in high computational complexity. Hence, to overcome the difﬁculty, the K-means clustering algorithm will group all the samples. The cluster centers are considered newsamples in which KNN and Decision Tree are applied further to ﬁnd out the documents’ 416 M. Arulmozhi V arman and G. Deepak category and Sub-category of the documents, respectively. Hershey et al. [ 3] proposed a method for improving the KL divergence between two generalized methods of movements (GMMs) is proposed. We then introduce two new methods for the improvement of the correctness of the results. Chou et al. [ 4]' metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}
658	page_content='the results. Chou et al. [ 4] depicted the behavior of jellyﬁsh in the water that inspires the development of a unique metaheuristic algorithm named as artiﬁcial Jellyﬁsh search(JS) optimizer. In solving mathematical benchmark functions, the JS optimizer outperformed other methods. Li et al. [ 5] proposed semantic distance based Concept similarity is proposed to calculate concepts similarity effectively The distance is considered thoroughly and the semantic contact ratio and the depth differences between concepts. Shannon et al. [ 6] introduced a theory to incorporate a number of additional elements, including the inﬂuence of noise in the channel and the savings achievable owing to the statistical structure of the original message and the nature of the information’s eventual destination. Cilibrasi et al. [ 7] method is based on the idea of similarity complexity between terms and phrases based on the information distance and Kolmogorov complexity. First, to ﬁx thoughts, we use www and any search engines and' metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}
659	page_content='and any search engines and databases. Then, it is applied to construct a method to automatically extract similarity(Eg. Google page counts). This paper introduces an automatic method to extract similarities from the text. It can also perform an English-Spanish translation. Finally, using WordNet categories which is crafted by the experts is resulted from a massive random-ized trial in binary classiﬁcation using support vector machines. Kuzi et al. [ 8] proposed Hybrid strategies combine the semantic retrieval model with the linguistic approach and models in semantic retrieval. This study shows how effective our method is and provides insight into the various aspects of the semantic approach. Karami et al. [ 9] study uses a systematic strategy to mine many Twitter-based studies to describe the relevant liter-ature. This study gathered relevant articles from three databases and used text mining and trend analysis to discover semantic trends and investigate the annual evolution of research themes over a decade.' metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}
660	page_content='themes over a decade. Ensan et al. [ 9] proposed a semantic-aware language model that addresses the challenge of document relatedness in text mining. The model consists of a graph representation of concepts retrieved from text and nodes representing semantic relatedness. Antons et al. [ 10] proposed a set of prioritized development goals that will help improve the quality of text mining. Lui et al. [ 11] analyzed the XML tree structure and separated the XML components into three sub models based on the structure. They also abstract the aggregates into abstract structure models. In [ 12–17] several Ontology based approaches in support of the proposed approach has been discussed. 3 Proposed Work Figure 1depicts the architecture of the proposed approach for text mining from documents using an RDF-driven approach. The approach consists of three phases. The ﬁrst phase involves the preprocessing of the dataset. The RCVI dataset used for experimenta-tion is subject to preprocessing, which involves tokenization,' metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}
661	page_content='which involves tokenization, lemmatization, stop word removal, name entity recognition. The inﬂectional form of the terms within the documents and contents is converted into a custom structured XML ﬁle creation. The XML is created mainly for converting to RDF or the resource description framework as direct formulation of RDF is impossible, so an intermediate XML structuring is required. XML DRHTG: A Knowledge-Centric Approach for Document Retrieval 417 to RDF conversion is achieved using the ontocolab. At the end of phase one, the dataset is preprocessed. A structured RDF ﬁle from an intermediate XML structured ﬁle is created for all the documents available in the dataset. The second phase is the generation of the knowledge graph. The knowledge graph is generated by using the categories and the clue tag categories and the domains in the dataset, and several terms from existing user-contributed blocks; the Twitter API is used to extract the set of terms matching in the categories in the RCVI dataset.' metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}
662	page_content='in the RCVI dataset. Thecategorized RCVI dataset and the terms set generated from blogs and used in Twitter API are subjected to cloud source community ontology (OWL) ﬁles available on the current structure of the World Wide Web to yield much more concentrated knowledgegeneration. All the terms generated from the blogs and cloud source community ontology (OWL) are subjected to querying of the wiki data and the free base through agents to yield much more dense knowledge. Further, all the terms which are extracted from thecategories of the RCVI dataset, as well as the domains in the RCVI dataset and terms generated from the blogs, Twitter API, cloud source community ontology (OWL), wiki data, and free base, are all subjected to querying in LODC cloud to generate fragmentsof sub graphs and all the sub graphs, as well as the tag terms and the trees generated from each of the processes, are collectively formulated into knowledge graph through establishing the relation between the nodes either by semantic' metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}
663	page_content='the nodes either by semantic similarity analysis or topicmapping. Phase three involves converting the knowledge graph before it is mapped with the existing RDF ﬁle, which is generated from the dataset that is not in the appropriate format for RDF conversion. Once the knowledge graph is also subjected to conversion to RDF, the RDF-RDF mapping takes place. Mapping takes between the subject-subject mappingbetween the existing RDF generated from phases 1 and 2, then object-object mapping and the predicate analysis. Maybe the subject-subject mapping, object-object mapping, subject-object mapping, and object-subject mapping are considered by computing theKL divergence and Shannon’s entropy. Mainly predicate analysis is just a subsidiary process. It can be ignored, neglected, and not considered as subject-subject mapping, object-object mapping, subject-object mapping, and object-subject mapping are muchmore efﬁcient. Once the documents are mapped and re-ranked by increasing order of the semantic similarity.' metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}
664	page_content='of the semantic similarity. Subject-subject mapping, object-object mapping, subject-object mapping, andobject-subject mapping are done by computing the KL divergence, Shannon’s entropy, and semantic similarity computation. The KL divergence value must be less than 0.25, and for entropy, it should be greater than 0.5, and the semantic similarity threshold mustbe greater than 0.75. The intersection between Lin similarity and normalized Google distance (NGD) and concept similarity will be the semantic similarity. The reason for generating a lot of content from the blog, Twitter API, cloud source ontology, wiki data, free base, and LODC is to increase the number of entities exponentially so that the knowledge graph and extensive knowledge graph can be formulated. RDF map-ping is considered rather than an OWL-based ontology mapping is mainly because the speciﬁcity between the entities terms in RDF-based mapping is much higher when compared to the traditional stand-alone OWL-based ontology mapping. As a result,' metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}
665	page_content='mapping. As a result, there is 418 M. Arulmozhi V arman and G. Deepak Fig. 1. Architecture ﬂowchart of the proposed DRHTG model. a much better scope when compared to the traditional ontology matching or semantic similarity-based analysis. 4 Implementation and Performance Evaluation 4.1 Dataset Preparation The RCV1 and RCV2 datasets comprise a register containing ﬁve sub-register in ﬁve languages: English, French, German, Italian, and Spanish. Each sub-register in these ﬁve languages contains ﬁve ﬁles, each having directories of the ﬁles translated or written inthe respective language. In the English sub-register, there are ﬁve ﬁles translated from each to English respectively and similarly for four other languages. All directories have the same number of documents in the same order, and the number of lines will also bethe same. DRHTG: A Knowledge-Centric Approach for Document Retrieval 419 Algorithm 1. Algorithm for the proposed DRHTG Framework Input : RCVI dataset. Output: Most relevant documents to the' metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}
666	"page_content=""relevant documents to the user's query. Start Step 1 : The dataset is preprocessed: token ization, lemmatization, stop words  removal, word entity recognition. Step 2: The preprocessed dataset is converted into an XML format. Step 3: The dataset in XML is converted to RDF format. Step 4: RDF graph is converted into the co rresponding RDF mapping represented  in the form of subject object query predicate. Step 5: A knowledge graph is formulated from various blogs and social networks  API, crowd source community ontolo gy in OWL format, wiki data and  free base and LODC. Step 6 : The formulated knowledge graph is in  the OWL format and it is converted  into RDF format. Step 7 : The formulated knowledge grap h inn RDF format undergoes RDF  mapping. Step 8: Upon RDF mapping the jelly fish algorithm is employed along with KL  divergence to rank the documents in  the increasing order of semantic  similarity. Create a starting occupants Y = { ,,…., } Evaluate the volume of food at respective position by f( )"" metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}"
667	page_content='respective position by f( ) Observe the great answer of the starting occupants ′ For x = 1 to do For j = 1 to do Formulate the time control value D(t) If D(t) ≥  Jellyfish go along with ocean current Else Jellyfish goes into a swarm If rand  > [1-D(t)] Jellyfish displays passive shifting Else  Jellyfish displays active shifting End if End if Examine border state at a different position  Evaluate the volume of food at respective position f( ) Improve the best answer End for End for Step 9: Based on the rank the most relevant document is fetched to the user. End The Normalized Google Distance (NGD) between two search terms u and v is shown in Eq. ( 1). Where Nis the overall amount of Google-searched internet sites multiplied by the average number of singleton target keywords found on those pages; f(u) and f(v) are 420 M. Arulmozhi V arman and G. Deepak the amount of similar searches for terms uand v, respectively; and F (u, v) is the number of internet pages that include both a and b. The conditional entropy' metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}
668	page_content='b. The conditional entropy of two variables can also be deﬁned as X and Y taking values xiand yjrespectively is depicted in Eq. ( 2). Where p( xi,yj) is the probability that X =xiand Y =yj. This value should be interpreted as the amount of randomness in the random variable X given the random variable Y . The Kullback-Leibler Divergence score, often known as the KL divergence score, measures how one probability distribution differs from another which is shown in Eq. ( 3). The KL divergence is the negative sum of each event’s probability in P multiplied by the log of the event’s probability in Q over the probability of the event in P . Lin Similarity is engaged to estimate the degree of the semantic relationship between units of concepts, language,and instances. The Lin Similarity is calculated as the ratio of the similarity between the terms upon the difference between them, i.e., the commonality and difference ratio. It can be formulated, as shown in Eq. ( 4). The similarity of concepts and terms in terms of' metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}
669	page_content='and terms in terms of text and query is a reﬂection of the degree to which semantic matching exists between them. Similarity between concept Ci and Cj denoted by Sim(Ci,Cj) in the Eq. ( 5). NGD(u,v)=max{logf(u),logf(v)}− logf(u,v) logN−min{logf(u),logf(v)}(1) H(X|Y)=−/summationdisplay n i,jP/parenleftbig xi,yj/parenrightbig logp(xi,yj) p(yj)(2) DKL(P/bardblQ)=/summationdisplay x/epsilon1χP(x)log(P(x) Q(x)) (3) sim Lin(X,Y)=logP(comman (X,Y)) logP(description (X,Y))(4) sim/parenleftbig Ci,Cj/parenrightbig =α∗sim/parenleftbig Ci,Cj/parenrightbig dist+β∗sim/parenleftbig Ci,Cj/parenrightbig const+γ∗sim/parenleftbig Ci,Cj/parenrightbig cdepth(5) 5 Results Data is collected from Freebase and wiki data, Crowd sources community ontology, Blogs and social networks API and LODC cloud which it then formulated into knowledgegraph. The formulated graph is then converted to RDF format from OWL format. Jellyﬁsh algorithm is used for RDF conversion. RCVI dataset is preprocessed into custom XML format then converted to RDF' metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}
670	page_content='format then converted to RDF format. Then using KL divergence both the convertedRDF mapping is re ranked in increasing order of semantic similarity (Fig. 2). Table 1compares the performance of the proposed model with the base model approach and other approaches. Figure 3compares the precision percentage of the baseline models with DRHTG. It is evident from Table 1that the proposed framework DRHTG operates better than LSI+Cosine +Jaccard, MLAP , STM+Cosine, DRDLC, and LSI+Fuzzy C-means Clustering. Precision, F-measure, FDR, nDGC, and accuracy have all improved in the proposed DRHTG. The F-measure value of DRHTG is greater than LSI+Cosine +Jaccard, MLAP , STM+Cosine, DRDLC, and LSI+Fuzzy C-means Clustering by 14.22% 12.37%, DRHTG: A Knowledge-Centric Approach for Document Retrieval 421 Fig. 2. Precision percentage vs No. of recommendations Ta b l e 1 . Comparison of Performance of the proposed DRHTG with other approaches Search Technique Average Precision %Average Recall%Accuracy F-Measure FDR nDCG' metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}
671	page_content='F-Measure FDR nDCG LSI+Cosine+Jaccard 77.32 79.81 78.56 78.54 0.23 0.79 MLAP [ 2] 78.71 82.15 80.43 80.39 0.22 0.69 STM+Cosine 79.11 83.15 81.13 81.07 0.21 0.86 DRDLC [ 1] 74.93 78.18 76.55 76.52 0.26 0.86 LSI+Fuzzy C-Means Clustering81.18 84.17 82.675 82.64 0.19 0.87 Proposed DRHTG 91.78 93.78 92.78 92.76 0.09 0.95 11.69%, 16.24%, and 10.12%, respectively. The proposed model’s precision is 91.78%, while LSI+Cosine +Jaccard, MLAP , STM+Cosine, DRDLC, and LSI+Fuzzy C-means Clustering are 77.32%, 78.71%, 79.11%, 74.93%, and 81.18, respectively. The accuracy of DRHTG is greater than that of LSI+Cosine +Jaccard, MLAP , STM+Cosine, DRDLC, and LSI+Fuzzy C-means Clustering by 14.22%, 12.35%, 11.65%, 16.23%,and 10.12%. The recall of the proposed approach is better than LSI+Cosine +Jaccard, MLAP , STM+Cosine, DRDLC, and LSI+Fuzzy C-means Clustering in percentage by13.97, 11.63, 10.63, 15.6, and 9.61. The nDGC of the proposed approach is lower thanLSI+Cosine +Jaccard, MLAP , STM+Cosine, DRDLC, and LSI+Fuzzy C-means' metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}
672	page_content='DRDLC, and LSI+Fuzzy C-means Clustering by 0.16, 0.26, 0.09, 0.09, and 0.08, respectively. The FDR values of LSI+Cosine + Jaccard, MLAP , STM+Cosine, DRDLC, and LSI+Fuzzy C-means Clustering are greaterthan DRHTG by 0.14, 0.13, 0.11, 0.17, and 0.1. 422 M. Arulmozhi V arman and G. Deepak Fig. 3. Pictorial depiction of the proposed DRHTG and other baseline models 6 Conclusion The results’ efﬁcacy validates the proposed framework’s ability to be used for document retrieval. The RCVI dataset obtained is preprocessed to obtain custom RDF map-ping. Blogs and social networks API, Crowdsource community ontology, wiki data, free base, and LODC cloud are incorporated into the RDF conversion to improve classiﬁcation accuracy. Upon classiﬁcation, Jellyﬁsh Optimization is employed on the classiﬁedresults to re-rank the documents in increasing order. The proposed DRHTG framework yields an average accuracy of 92.78%, with a very low FDR of 0.09. Also, the Jellyﬁsh Optimization algorithm has been employed on the classiﬁed' metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}
673	page_content='employed on the classiﬁed results to yield more accu-rate results. The results validate that DRHTG is the best-in-class approach to re-rank documents by semantic similarity and yield it to the user. References 1. Ramya, R.S., Sejal, D., V enugopal, K.R., Iyengar, S.S., Patnaik, L.M.: DRDLC: discovering relevant documents using latent dirichlet allocation and cosine similarity. In: Proceedings of the 2018 VII International Conference on Network, Communication and Computing, pp. 87– 91, 14 Dec 2018 DRHTG: A Knowledge-Centric Approach for Document Retrieval 423 2. Deka, H., Sarma, P .: Machine learning approach for text and document mining. Int. J. Comput. Sci. Eng. (IJCSE). 6(5) (2017) 3. Hershey, J.R., Olsen, P .A.: Approximating the Kullback Leibler divergence between Gaussian mixture models. In: 2007 IEEE International Conference on Acoustics, Speech and Signal Processing-ICASSP2007. V ol. 4, pp. IV-317. IEEE 15 Apr 2007 4. Chou, J.S., Truong, D.N.: A novel metaheuristic optimizer inspired by behavior of' metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}
674	page_content='inspired by behavior of jellyﬁsh in ocean. Appl. Math. Comput. 15(389), 125535 (2021) 5. Li, W., Xia, Q.: A method of concept similarity computation based on semantic distance. Procedia Eng. 1(15), 3854–3859 (2011) 6. Shannon, C.E.: A mathematical theory of communication. Bell Syst. Tech. J. 27(3), 379–423 (1948) 7. Cilibrasi, R.L., Vitanyi, P .M.: The google similarity distance. IEEE Trans. Knowl. Data Eng. 19(3), 370–383 (2007) 8. Kuzi, S., Zhang, M., Li, C., Bendersky, M., Najork, M.: Leveraging semantic and lexical matching to improve the recall of document retrieval systems: a hybrid approach. arXivpreprint arXiv:2010.01195 . 2 Oct 2020 9. Karami, A., Lundy, M., Webb, F., Dwivedi, Y .K.: Twitter and research: a systematic literature review through text mining. IEEE Access. 26(8), 67698–67717 (2020) 10. Antons, D., Grünwald, E., Cichy, P ., Salge, T.O.: The application of text mining methods in innovation research: current state, evolution patterns, and development priorities. R&D Manage. 50(3), 329–351' metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}
675	page_content='R&D Manage. 50(3), 329–351 (2020) 11. Liu, Y ., Hong, Z.: Mapping XML to RDF: an algorithm based on element classiﬁcation and aggregation. In: Journal of Physics: Conference Series. V ol. 1848, no. 1, p. 012012. 1 Apr 2021 IOP Publishing 12. Arulmozhivarman, M., Deepak, G.: OWLW: ontology focused user centric architecture for web service recommendation based on LSTM and whale optimization. In: Musleh Al-Sartawi, A.M.A., Razzaque, A., Kamal, M.M. (eds.) EAMMIS 2021. LNNS, vol. 239, pp. 334–344.Springer, Cham (2021).  13. Surya, D., Deepak, G., Santhanavijayan, A.: KSTAR: a knowledge based approach for socially relevant term aggregation for web page recommendation. In: Motahhir, S., Bossouﬁ, B. (eds.) ICDTA 2021. LNNS, vol. 211, pp. 555–564. Springer, Cham (2021).  978-3-030-73882-2_50 14. Surya, D., Deepak, G., Santhanavijayan, A.: QFRDBF: query facet recommendation using knowledge centric DBSCAN and ﬁreﬂy optimization. In: Motahhir, S., Bossouﬁ, B. (eds.) ICDTA 2021. LNNS, vol. 211, pp. 801–811. Springer,' metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}
676	page_content='211, pp. 801–811. Springer, Cham (2021).  978-3-030-73882-2_73 15. Surya, D., Deepak, G., Santhanavijayan, A.: Ontology-based knowledge description model for climate change. In: Abraham, A., Piuri, V ., Gandhi, N., Siarry, P ., Kaklauskas, A., Madureira,A. (eds.) ISDA 2020. AISC, vol. 1351, pp. 1124–1133. Springer, Cham (2021).  org/10.1007/978-3-030-71187-0_104 424 M. Arulmozhi V arman and G. Deepak 16. Deepak, G., Santhanavijayan, A.: QGMS: a query growth model for personalization and diversiﬁcation of semantic search based on differential ontology semantics using artiﬁcial intelligence. Comput. Intell. 1–30 (2022) 17. Deepak, G., Santhanavijayan, A.: OntoDynS: expediting personalization and diversiﬁcation in semantic search by facilitating cognitive human interaction through ontology bagging and dynamic ontology alignment. J. Ambient Intell. Humanized Comput. 1–25 (2022)' metadata={'title': 'DRHTG: A Knowledge-Centric Approach for Document Retrieval Based on Heterogeneous Entity Tree Generation and RDF Mapping', 'author': 'M. Arulmozhi Varman', 'publish_date': '2023-03-18', 'subject': 'Innovations in Bio-Inspired Computing and Applications', 'doi': 'doi:10.1007/978-3-031-27499-2_39', 'keywords': 'Jellyfish; KL divergence; Optimization; RDF mapping; Text mining'}
677	page_content='Chatbots Technology and its Challenges: An Overview Hajar Zerouani1(B), Abdelhay Haqiq1,2, and Bouchaib Bounabat1 1ALQUALSADI Team, Rabat IT Center, ENSIAS, Mohammed V University in Rabat, Rabat, Morocco hajar zerouani@um5.ac.ma ,ahaqiq@esi.ac.ma ,b.bounabat@um5.ac.net 2ITQAN Team, LyRICA Laboratory, ESI, Rabat, Morocco Abstract. A chatbot is a conversational agent that uses Artiﬁcial Intelligence (AI) to interpret the text of the chat using Natural LanguageProcessing (NLP) in particular, instead of making direct contact with a live person, users can make conversation via text or voice. Chatbots are a fast-growing AI trend that involves the use of applications com-municating with users in a conversational style and imitating human conversation using human language. Many industries are attempting to include solutions based on artiﬁcial intelligence like chatbots to improvetheir customer service in order to deliver better service to their customers with faster and less expensive support. This paper is a survey' metadata={'title': 'Chatbots Technology and its Challenges: An Overview', 'author': 'Hajar Zerouani', 'publish_date': '2023-05-23', 'subject': 'International Conference on Advanced Intelligent Systems for Sustainable Development', 'doi': 'doi:10.1007/978-3-031-26384-2_6', 'keywords': 'Chatbots; Artificial Intelligence; Natural Language Processing; Deep Learning'}
678	page_content='This paper is a survey of the published chatbots to discover knowledge gaps and indicate areasthat require additional investigation and study, starting from history and how it evolves during the past, then chatbots architectures to understand how it works, and to identify application of chatbots in many domains,and ﬁnish by chatbots limitations that shorten its lifespan and how can future work improve the chatbot for best performance. Keywords: Chatbots ·Artiﬁcial Intelligence ·Natural Language Processing ·Deep Learning 1 Introduction Interactive Agent, Artiﬁcial Conversational Entity, talk bot, chatterbot, humancomputer dialogue system, digital assistants, those expressions mean the same term called chatbot. The recent is composed of two words ‘’chat” and ‘’bot” torefer to a bot for messaging that provides a human computer interaction (HCI)  which can perform three types of communication’s forms: speech [ 2], text and image. Over the past decade, AI has transformed the world subtly, machines nowcan learn' metadata={'title': 'Chatbots Technology and its Challenges: An Overview', 'author': 'Hajar Zerouani', 'publish_date': '2023-05-23', 'subject': 'International Conference on Advanced Intelligent Systems for Sustainable Development', 'doi': 'doi:10.1007/978-3-031-26384-2_6', 'keywords': 'Chatbots; Artificial Intelligence; Natural Language Processing; Deep Learning'}
679	page_content='subtly, machines nowcan learn and think through without the intervention of humans. Moreover, the number of chatbots has grown especially in the last two years as shown in Fig. 1 the development of research in this ﬁeld according to Google Scholar. Thanks to AI that can solve the most serious issue that chatbots face today is their inability to understand and produce natural expression. The AI-Chatbots c/circlecopyrtThe Author(s), under exclusive license to Springer Nature Switzerland AG 2023 J. Kacprzyk et al. (Eds.): AI2SD 2022, LNNS 637, pp. 56–64, 2023. _6 Chatbots Technology and its Challenges: An Overview 57 Fig. 1. Development of research in chatbots over the time by counting the number of papers according to Google Scholar. overcomes the limitations of rule based chatbots using NLP, Machine Translation (MT), Image Recognition (IR), Neural Networks (NNs)...and many branches of AI to reach the best user experience [ 3]. According to industry analysts, the worldwide chatbot market will be worth USD' metadata={'title': 'Chatbots Technology and its Challenges: An Overview', 'author': 'Hajar Zerouani', 'publish_date': '2023-05-23', 'subject': 'International Conference on Advanced Intelligent Systems for Sustainable Development', 'doi': 'doi:10.1007/978-3-031-26384-2_6', 'keywords': 'Chatbots; Artificial Intelligence; Natural Language Processing; Deep Learning'}
680	page_content='market will be worth USD 2485.7 million by 2028 and chatbot adoption will save businesses $11 billion a year in the healthcare, banking, and retail sectors by 2023 [ 4]. Nowadays many industries are in the race to develop their chatbots of customer services that oﬀerrapid and smart development in many domains such as businesses, education, healthcare and governance... It allows users to receive answers to their questions in a timely manner without having to wait in phone lines or send several emailsor search online for responses. Hence there are a variety of areas that a chatbot can serve, and they are often regarded as the key to a company’s long-term success and competitiveness. This paper covers a survey of chatbot design, architecture types and suggests steps to choose suitable architecture. This paper is structured as follows: 2 History Back to 1950, “can machines think?” was a question posed by Alan Turing [ 5] that reveal the rise of chatbot concept, 16 years later especially in psychology domain ﬁrst' metadata={'title': 'Chatbots Technology and its Challenges: An Overview', 'author': 'Hajar Zerouani', 'publish_date': '2023-05-23', 'subject': 'International Conference on Advanced Intelligent Systems for Sustainable Development', 'doi': 'doi:10.1007/978-3-031-26384-2_6', 'keywords': 'Chatbots; Artificial Intelligence; Natural Language Processing; Deep Learning'}
681	page_content='in psychology domain ﬁrst chatbot named ELIZA [ 6] permit to encourage the patient to talk but the chatbot’s capability is too inﬂexible, hereafter in 1970 [ 7]P A R R Yw a s created to imitate a paranoid patient [ 8], Later in 1988, this chatbot named JABBERWACKY, its objective was to switch from a text-based system to a completely voice-operated or verbal chatbot, this chatbot has so far achievedonly second place in the annual Loebner Prize [ 9]. The human-computer communication system’s development process is shifting from “adapting people to computers” to “adapting computers to people” 58 H. Zerouani et al. , In 1990 the prototype of chatbot JULIA was created [ 11] by the creator of the term ‘chatterbot’ Michael Mauldin [ 12], and it was a famous once upon time, thenceforward in 1992 an AI speech synthesis called DR. SBAITSO in psychotherapy [ 13], then ALICE the name is acronym of Artiﬁcial Linguistic Internet Computer Entity, this chatbot is inspired from ELIZE and designed withpattern matching or rule' metadata={'title': 'Chatbots Technology and its Challenges: An Overview', 'author': 'Hajar Zerouani', 'publish_date': '2023-05-23', 'subject': 'International Conference on Advanced Intelligent Systems for Sustainable Development', 'doi': 'doi:10.1007/978-3-031-26384-2_6', 'keywords': 'Chatbots; Artificial Intelligence; Natural Language Processing; Deep Learning'}
682	page_content='withpattern matching or rule based which we are going to talk in following section; this chatbot is implemented in Artiﬁcial Intelligence Markup Language (AIML) created in 1995 [ 14]. This language is used to specify the pattern-matching rules that connect words and phrases submitted by users to associated subject areas . In 2001 a chatbot named SmarterChild [ 16], which ran on MSN Messenger, used for entertainment [ 17], later in 2007 IBM launched his question-answering (QA) system named Waston [ 18] it still alive for now, designed for businesses, automating responses to customer inquiries [ 19], That revolution push big tech companies like Google, Apple and Microsoft to launch their chatbots named virtual personal assistants [ 20], in 2010 SIRI chatbot was created by Apple [ 21], then Google developed GOOGLE NOW in 2012 [ 22], then ALEXA in 2015 by Amazon [ 23], one year later Microsoft crafted CORTANA [ 24]. The Fig. 2shows a brief chronological sequence of previous chatbots. Fig. 2. Chronological' metadata={'title': 'Chatbots Technology and its Challenges: An Overview', 'author': 'Hajar Zerouani', 'publish_date': '2023-05-23', 'subject': 'International Conference on Advanced Intelligent Systems for Sustainable Development', 'doi': 'doi:10.1007/978-3-031-26384-2_6', 'keywords': 'Chatbots; Artificial Intelligence; Natural Language Processing; Deep Learning'}
683	page_content='Fig. 2. Chronological sequences of chatbots. 3 Architectures and Types of Chatbots 3.1 Architectures A chatbot also known as a conversational agent or an artiﬁcial dialogue system . It is a computer system that acts as an interface between human users and software applications, communicating mostly through natural language (spokenor written). Chatbots are frequently portrayed, conceived, and developed as a ﬂow of communication between multiple components as shown in Fig. 3However, it also has all of the necessary details: Chatbots Technology and its Challenges: An Overview 59 User Interface Component: the chatbot’s service starts when it receives a request from a user via text or speech-based application [ 26], such as Facebook Messenger, Slack, WhatsApp, WeChat, Viber, or Skype. User Message Analysis Component: The User Interface Controller sends the user’s request to the User Message Analysis Component, which analyzes it to detect the user’s intent and extracts entities using machine learning techniques or' metadata={'title': 'Chatbots Technology and its Challenges: An Overview', 'author': 'Hajar Zerouani', 'publish_date': '2023-05-23', 'subject': 'International Conference on Advanced Intelligent Systems for Sustainable Development', 'doi': 'doi:10.1007/978-3-031-26384-2_6', 'keywords': 'Chatbots; Artificial Intelligence; Natural Language Processing; Deep Learning'}
684	page_content='learning techniques or pattern matching [ 26]. Dialog Management Component: this Component manages the conversation background and keeps it up to date. It saves the current purpose as well asthe speciﬁed individuals until the conversation reaches that stage. If the chatbot is unable to gather the requisite context information, it will ask the user for additional context information to ﬁll in the gaps [ 26]. Backend: when rule-based chatbots are used, a Knowledge Base is developed (KB). It also contains a list of handwritten answers to the user’s inputs [ 26]. Response Generation Component: uses one or more of the three possible models to produce responses: Rule-based, Retrieval-based, or Generative-based . Fig. 3. General Chatbot Architecture [ 26]. In , the authors proposed an architecture composed of layers, and they added a security layer, elseways another work [ 28] attempt a complete syntactical and semantic study of user inputs as part of the system design, [ 29] works on architecture too, but no' metadata={'title': 'Chatbots Technology and its Challenges: An Overview', 'author': 'Hajar Zerouani', 'publish_date': '2023-05-23', 'subject': 'International Conference on Advanced Intelligent Systems for Sustainable Development', 'doi': 'doi:10.1007/978-3-031-26384-2_6', 'keywords': 'Chatbots; Artificial Intelligence; Natural Language Processing; Deep Learning'}
685	page_content='on architecture too, but no architectural design is provided. Depending on the type of chatbot, the developer may choose the components to implement [ 26]. 60 H. Zerouani et al. 3.2 Type of Chatbots Chatbots are classiﬁed depending on knowledge: particular knowledge domain or more than one Knowledge Domain (KD), Generic chatbots (G) can answer any user query from any domain, while Domain-Speciﬁc (DS) chatbots can onlyrespond to questions about a speciﬁc information domain, and chatbots that work through multiple domains are known as Cross or Open-Domain (OD) chatbots, also there is a classiﬁcation based on response generation: Rule based(RLB), Retrieval based (RB) and Generative based (GB) Chatbot, and Hybrid based (see Fig. 4) Though Generative-based chatbots are useful for engaging an individual in informal open-domain conversations, based on the previous andpreceding inputs, they use NLG to answer in a natural language that resembles humans. Without creating new text responses, RLB chatbots select an' metadata={'title': 'Chatbots Technology and its Challenges: An Overview', 'author': 'Hajar Zerouani', 'publish_date': '2023-05-23', 'subject': 'International Conference on Advanced Intelligent Systems for Sustainable Development', 'doi': 'doi:10.1007/978-3-031-26384-2_6', 'keywords': 'Chatbots; Artificial Intelligence; Natural Language Processing; Deep Learning'}
686	page_content='RLB chatbots select an answer from a collection of rules; this type is better for closed-domain communications.The RB model is more adaptable because it chooses the best solution based on a review and examination of available resources. If none of the rules ﬁt [ 26], hybrid chatbots that weigh the retrieved information against the created response to determine which is better [ 26]. When the chatbot has completed an answer, it displays it to the user and waits for feedback. Fig. 4. Diﬀerent types of chatbots. A chatbot’s operation can be combined with human interaction in certain cases where more ﬂexibility is needed. Human computation is used in at least one aspect of a human-mediated (HM) chatbot. Staﬀ working to incorporate their intelligence into fully Autonomous (A) chatbots will be able to resolvetheir ﬂaws, chatbots may be classiﬁed as Open-source (OS) or Commercial (C), depending on the Permissions granted by the development platform, furthermore another classiﬁcation is based on the type of' metadata={'title': 'Chatbots Technology and its Challenges: An Overview', 'author': 'Hajar Zerouani', 'publish_date': '2023-05-23', 'subject': 'International Conference on Advanced Intelligent Systems for Sustainable Development', 'doi': 'doi:10.1007/978-3-031-26384-2_6', 'keywords': 'Chatbots; Artificial Intelligence; Natural Language Processing; Deep Learning'}
687	page_content='is based on the type of Communication Channel (CC) usedby chatbots, which can be text, speech, image, or all three. Intrapersonal chatbots (RA) (Fig. 5) are close friends who live in the user’s domain and are aware of his requirements, they are often connected to messagingapps such as Slack and WhatsApp. Interpersonal chatbots (ER) are those that provide services such as restaurant reservations, airline reservations, or FAQ searches without being a friendly companion. Finally, Inter-agent chatbots allow Chatbots Technology and its Challenges: An Overview 61 bots to communicate with one another like Alexa and Cortana are two chatbots that have been linked together to converse [ 26]. Fig. 5. Diﬀerence between Intrapersonal/ Interpersonal/Inter-agent chatbots. 4 Discussion Every paper customizes its features and numbers of layers needed for a good architecture of the chatbot that responds to all user’s needs. The choice of suitable chatbot approach, types, languages, and platforms follows the intelligence level' metadata={'title': 'Chatbots Technology and its Challenges: An Overview', 'author': 'Hajar Zerouani', 'publish_date': '2023-05-23', 'subject': 'International Conference on Advanced Intelligent Systems for Sustainable Development', 'doi': 'doi:10.1007/978-3-031-26384-2_6', 'keywords': 'Chatbots; Artificial Intelligence; Natural Language Processing; Deep Learning'}
688	page_content='the intelligence level of the chatbot and tasks of this chatbot, as shown in Fig. 6Chatbot owner can answer the following questions to check satisfaction: 1Will the Chatbot Respond to New Questions or Not? This question will help to choose the suitable approach, as mentioned in Fig. 7. Pattern matching for rule based chatbots and the other approach for chatbots which needs to learnfrom old conversations. 2-What are the Tasks Chatbot Can Do? The answer of this question will classify the chatbot type: KD, Service Provided (SP), Response Generation Method (RGM), Human Aid (HA) and Goals as detailed in examples of available chatbots in Table 1. 3-Which Language Will the Chatbot Speak and How Many? This question will reveal the needs of translation and to check the availability of corpus, datasetsand models in this language. 4-Will the Chatbot be Connected to Many Platforms Like Facebook, WhatsApp, Skype...? This question helps to know which CC must be integrated (speech, text, image); the beneﬁt of those' metadata={'title': 'Chatbots Technology and its Challenges: An Overview', 'author': 'Hajar Zerouani', 'publish_date': '2023-05-23', 'subject': 'International Conference on Advanced Intelligent Systems for Sustainable Development', 'doi': 'doi:10.1007/978-3-031-26384-2_6', 'keywords': 'Chatbots; Artificial Intelligence; Natural Language Processing; Deep Learning'}
689	page_content='image); the beneﬁt of those platforms is that the user is already familiar with the messaging applications, and it has a big population. 62 H. Zerouani et al. Fig. 6. Flowchart to build suitable architecture for chatbot. The Table 1and Table 2presents a list of chatbots in diﬀerent domains using a set of metrics: KD, SP, RGM, HA, P, CC, Goals (if chatbot is Informative (IF),Task Based (TB) or Chat Based (CB)), Languages used and links of project. There has been a major increase in the production and usage of chatbots in recent years, with signiﬁcant beneﬁts in a variety of domains. They work 24 ha day, 7/7 in customer service centers, handling many clients at the same time, lowering pay-roll costs signiﬁcantly. In education, they also serve a growing numTable 1. Goals and Languages of existing Chatbots in diﬀerent domains. References Chatbot’s name Domain Languages Goals  Suve: Covid-19 symptom checker Health English /Estonia IF+TB  English practice (CSIEC) Education English CB+TB  Chatbot platform for B2B' metadata={'title': 'Chatbots Technology and its Challenges: An Overview', 'author': 'Hajar Zerouani', 'publish_date': '2023-05-23', 'subject': 'International Conference on Advanced Intelligent Systems for Sustainable Development', 'doi': 'doi:10.1007/978-3-031-26384-2_6', 'keywords': 'Chatbots; Artificial Intelligence; Natural Language Processing; Deep Learning'}
690	page_content='Chatbot platform for B2B services Business English CB+TB  the LvivCityHelper bot Governance Ukrainian IF+TB Table 2. Type of existing chatbots in diﬀerent domains. References KD SP RGM HA P CC Link  DS RA RLB+GB A OS Text   G RA RLB None OS Text/voice   OD RA None A C Text/voice/image   OD RA None A OS Text  Chatbots Technology and its Challenges: An Overview 63 ber of students by providing educational material and personal assistance. They also outperform human teachers in some situations, such as when they reducelanguage anxiety in foreign language students. They oﬀer a variety of services to patients in the area of healthcare, but there is a risk when patients receive a less precise answer, that is why it is necessary to measure the eﬀectiveness ofchatbots especially in the health domain. 5 Conclusion This survey aims to present a comprehensive view of chatbots to reduce time ofresearchers to understand chatbots and its architectures and types, help devel-opers to choose which approach is best and show' metadata={'title': 'Chatbots Technology and its Challenges: An Overview', 'author': 'Hajar Zerouani', 'publish_date': '2023-05-23', 'subject': 'International Conference on Advanced Intelligent Systems for Sustainable Development', 'doi': 'doi:10.1007/978-3-031-26384-2_6', 'keywords': 'Chatbots; Artificial Intelligence; Natural Language Processing; Deep Learning'}
691	page_content='approach is best and show examples of available chatbots in diﬀerent domains with languages used and link of project. Future work will concentrate on challenges and good practices of chatbots, also its performanceindicators in terms of customer relations, how can we be sure that a bot is working at full capacity? and how to improve the performance of a chatbot over time? References 1. Følstad, A., Brandtzæg, P.B.: Chatbots and the new world of HCI. Interactions 24(4), 38-42 (2017) 2. Nass, C.I., Brave, S.: Wired for Speech: How Voice Activates and Advances the Human-computer Relationship, p. 9. MIT Press, Cambridge (2005) 3. Nirala, K.K., Singh, N.K., Purani, V.S.: A survey on providing customer and public administration based services using AI: chatbot. Multimedia Tools Appl., 1–32 (2022) 4. Nguyen, Q.N., Sidorova, A., Torres, R.: User interactions with chatbot interfaces vs. menu-based interfaces: an empirical study. Comput. Hum. Behav. 128, 107093 (2022) 5. Dennett, D.C.: Can machines think?. In:' metadata={'title': 'Chatbots Technology and its Challenges: An Overview', 'author': 'Hajar Zerouani', 'publish_date': '2023-05-23', 'subject': 'International Conference on Advanced Intelligent Systems for Sustainable Development', 'doi': 'doi:10.1007/978-3-031-26384-2_6', 'keywords': 'Chatbots; Artificial Intelligence; Natural Language Processing; Deep Learning'}
692	page_content='Can machines think?. In: Teuscher, C. (eds.) Alan Turing: Life and Legacy of a Great Thinker, pp. 295–316. Springer, Heidelberg (2004).  org/10.1007/978-3-662-05642-4 12 6. Sharma, V., Goyal, M., Malik, D.: An intelligent behaviour shown by chatbot system. Int. J. New Technol. Res. 3(4), 263312 (2017) 7. Mezzi, R., Yahyaoui, A., Krir, M.W., Boulila, W., Koubaa, A.: Mental health intent recognition for Arabic-speaking patients using the mini international neuropsychi-atric interview (MINI) and BERT model. Sensors 22(3), 846 (2022) 8. AbuShawar, B., Atwell, E.: ALICE chatbot: trials and outputs. Computaci´ on y Sistemas 19(4), 625–632 (2015) 9. Carpenter, R., Freeman, J.: Computing machinery and the individual: the personal turing test. Computing (2005). Accessed 22 Sept 2009 10. Akgun, M., Cagiltay, K., Zeyrek, D.: The eﬀect of apologetic error messages and mood states on computer users’ self-appraisal of performance. J. Pragmat. 42(9), 2430–2448 (2010) 11. Curry, C.: Design, evolution & production of a' metadata={'title': 'Chatbots Technology and its Challenges: An Overview', 'author': 'Hajar Zerouani', 'publish_date': '2023-05-23', 'subject': 'International Conference on Advanced Intelligent Systems for Sustainable Development', 'doi': 'doi:10.1007/978-3-031-26384-2_6', 'keywords': 'Chatbots; Artificial Intelligence; Natural Language Processing; Deep Learning'}
693	page_content='evolution & production of a storytelling chatbot (2011) 12. Deryugina, O.V.: Chatterbots. Sci. Tech. Inf. Process. 37(2), 143–147 (2010) 64 H. Zerouani et al. 13. Zemˇ c´ık, M.T.: A brief history of chatbots. DEStech Trans. Comput. Sci. Eng. 10 (2019) 14. Marietto, M.D.G.B., et al.: Artiﬁcial intelligence markup language: a brief tutorial. arXiv preprint arXiv:1307.3091 (2013) 15. Singh, J., Joesph, M.H., Jabbar, K.B.A.: Rule-based chabot for student enquiries. J. Phys. Conf. Ser. 1228(1), 012060 (2019) 16. Adamopoulou, E., Moussiades, L.: An overview of chatbot technology. In: Maglogiannis, I., Iliadis, L., Pimenidis, E. (eds.) AIAI 2020. IFIP AICT, vol. 584, pp. 373–383. Springer, Cham (2020).  31 17. Bhute, A.N., Meshram, B.B.: IntelligentWeb Agent for Search Engines. arXiv preprint arXiv:1310.4774 (2013) 18. Ferrucci, D.A.: Introduction to “this is Watson”. IBM J. Res. Dev. 56(3.4), 1 (2012) 19. High, R.: The Era of Cognitive Systems: An Inside Look at IBM Watson and How it Works. IBM Corporation,' metadata={'title': 'Chatbots Technology and its Challenges: An Overview', 'author': 'Hajar Zerouani', 'publish_date': '2023-05-23', 'subject': 'International Conference on Advanced Intelligent Systems for Sustainable Development', 'doi': 'doi:10.1007/978-3-031-26384-2_6', 'keywords': 'Chatbots; Artificial Intelligence; Natural Language Processing; Deep Learning'}
694	page_content='it Works. IBM Corporation, Redbooks, pp. 1–16 (2012) 20. Cahn, J.: CHATBOT: architecture, design, & development. University of Pennsylvania School of Engineering and Applied Science Department of Computer andInformation Science (2017) 21. Ait-Mlouk, A., Jiang, L.: KBot: a Knowledge graph based chatBot for natural language understanding over linked data. IEEE Access 8, 149220–149230 (2020) 22. Ehrenbrink, P., Osman, S., M¨ oller, S.: Google now is for the extraverted, Cortana for the introverted: investigating the inﬂuence of personality on IPA preference. In: Proceedings of the 29th Australian Conference on Computer-Human Interaction, pp. 257–265, November 2017 23. Chung, H., Park, J., Lee, S.: Digital forensic approaches for Amazon Alexa ecosystem. Digit. Investig. 22, S15–S25 (2017) 24. Vadhera, A., Thute, A., Mala, S., Shankar, A.: Chatbot on COVID-19 for sustaining good health during the pandemic. In: Vadhera, S., Umre, B.S., Kalam, A. (eds.)Latest Trends in Renewable Energy Technologies. LNEE, vol. 760,' metadata={'title': 'Chatbots Technology and its Challenges: An Overview', 'author': 'Hajar Zerouani', 'publish_date': '2023-05-23', 'subject': 'International Conference on Advanced Intelligent Systems for Sustainable Development', 'doi': 'doi:10.1007/978-3-031-26384-2_6', 'keywords': 'Chatbots; Artificial Intelligence; Natural Language Processing; Deep Learning'}
695	page_content='Technologies. LNEE, vol. 760, pp. 271–284. Springer, Singapore (2021).  23 25. Shah, H., Warwick, K., Vallverd´ u, J., Wu, D.: Can machines talk? Comparison of Eliza with modern dialogue systems. Comput. Hum. Behav. 58, 278–295 (2016) 26. Adamopoulou, E., Moussiades, L.: Chatbots: history, technology, and applications. Mach. Learn. Appl. 2, 100006 (2020) 27. Wu, C., Szep, J., Hariri, S., Agarwal, N.K., Agarwal, S.K., Nevarez, C.: SeVA: an AI solution for age friendly care of hospitalized older adults. In: HEALTHINF, pp. 583–591 (2021) 28. Jia, J.: CSIEC: a computer assisted English learning chatbot based on textual knowledge and reasoning. Knowl. Based Syst. 22(4), 249–255 (2009) 29. Zahour, O., Eddaoui, A., Ouchra, H., Hourrane, O.: A system for educational and vocational guidance in Morocco: chatbot E-orientation. Procedia Comput. Sci.175, 554–559 (2020) 30. H¨ ohn, S., Bongard-Blanchy, K.: Heuristic evaluation of COVID-19 chatbots. In: Følstad, A., et al. (eds.) CONVERSATIONS 2020. LNCS, vol. 12604, pp.' metadata={'title': 'Chatbots Technology and its Challenges: An Overview', 'author': 'Hajar Zerouani', 'publish_date': '2023-05-23', 'subject': 'International Conference on Advanced Intelligent Systems for Sustainable Development', 'doi': 'doi:10.1007/978-3-031-26384-2_6', 'keywords': 'Chatbots; Artificial Intelligence; Natural Language Processing; Deep Learning'}
696	page_content='2020. LNCS, vol. 12604, pp. 131– 144. Springer, Cham (2021).  9 31. Aarthi, N.G., Keerthana, G., Pavithra, A., Pavithra, K.: Chatbot for retail shop evaluation. Int. J. Comput. Sci. Mob. Comput. 9(3), 69–77 (2020) 32. Smith, B., Gorsuch, G.J.: Synchronous computer mediated communication captured by usability lab technologies: new interpretations. System 32(4), 553–575 (2004)' metadata={'title': 'Chatbots Technology and its Challenges: An Overview', 'author': 'Hajar Zerouani', 'publish_date': '2023-05-23', 'subject': 'International Conference on Advanced Intelligent Systems for Sustainable Development', 'doi': 'doi:10.1007/978-3-031-26384-2_6', 'keywords': 'Chatbots; Artificial Intelligence; Natural Language Processing; Deep Learning'}
697	page_content='Chapter 9  Knowledge Representation Learning  and Knowledge-Guided NLP  Xu Han, Weize Chen, Zhiyuan Liu, Yankai Lin, and Maosong Sun  Abstract Knowledge is an important characteristic of human intelligence and  reﬂects the complexity of human languages. To this end, many efforts have been  devoted to organizing various human knowledge to improve the ability of machines  in language understanding, such as world knowledge, linguistic knowledge, commonsense knowledge, and domain knowledge. Starting from this chapter, our view  turns to representing rich human knowledge and using knowledge representations  to improve NLP models. In this chapter, taking world knowledge as an example,  we present a general framework of organizing and utilizing knowledge, including  knowledge representation learning, knowledge-guided NLP, and knowledge acquisition. For linguistic knowledge, commonsense knowledge, and domain knowledge,  we will introduce them in detail in subsequent chapters considering their unique  knowledge' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
698	page_content='their unique  knowledge properties.  9.1 Introduction  The discussion of knowledge is far earlier than the exploration of NLP and is  highly related to the study of human languages, which can be traced back to Plato  in the Classical Period of ancient Greece [ 15]. Over the next thousand years, the  discussion of knowledge gradually leads to many systematic philosophical theories,  such as epistemology [ 146] and ontology [ 140], reﬂecting the long-term analysis  and exploration of human intelligence.  X. Han · W. Chen · Z. Liu ( /envelopeback)·M .S u n  Department of Computer Science and Technology, Tsinghua University, Beijing, China  e-mail: hanxu2022@tsinghua. edu.cn; chenwz21@mails. tsinghua. edu.cn; liuzy@tsinghua. edu.cn;  sms@tsinghua. edu.cn  Y. L i n  Gaoling School of Artiﬁcial Intelligence, Renmin University of China, Beijing, China  e-mail: yankailin@ruc. edu.cn  © The Author(s) 2023  Z. Liu et al. (eds.), Representation Learning for Natural Language Processing ,  https:// doi.org/10.1007/' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
699	page_content=',  https:// doi.org/10.1007/ 97898199-16009_9273 274 X. Han et al. Although the question what is knowledge is a controversial philosophical  question with no deﬁnitive and generally accepted answer, we deeply touch on the  concept of knowledge in every aspect of our lives. At the beginning of the twentieth  century, analytic philosophy, which is advocated by Gottlob Frege, Bertrand Russell,  and Ludwig Wittgenstein [ 131], inspires the establishment of symbolic systems to  formalize human knowledge [ 68], signiﬁcantly contributing to the later development  of mathematical logic and philosophy of language.  As NLP is associated with human intelligence, the basic theory of NLP is  also highly related to the above knowledge-related theories. As shown in Fig. 9.1,  since the Dartmouth Summer Research Project on AI in 1956 [ 104], knowledge  has played a signiﬁcant role in the development history of NLP. Inﬂuenced by  mathematical logic and linguistics, early NLP studies [ 2, 24, 25, 64] mainly focus  on' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
700	page_content='24, 25, 64] mainly focus  on exploring symbolic knowledge representations and using symbolic systems to  enable machines to understand and reason languages.  Due to the generalization and coverage problems of symbolic representations,  ever since the 1990s, data-driven methods [ 63] are widely applied to represent  human knowledge in a distributed manner. Moreover, after 2010, with the boom of  deep learning [ 83], distributed knowledge representations are increasingly expressive from shallow to deep, providing a powerful tool of leveraging knowledge to  understand complex semantics.  Making full use of knowledge is crucial to achieving better language understanding. To this end, we describe the general framework of organizing and utilizing  knowledge, including knowledge representation learning, knowledge-guided NLP,  and knowledge acquisition. With this knowledgeable NLP framework, we show  how knowledge can be represented and learned to improve the performance of  NLP models and how to acquire rich' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
701	page_content='and how to acquire rich knowledge from text. As shown in Fig. 9.2,  knowledge representation learning aims to encode symbolic knowledge into distributed representations so that knowledge can be more accessible to machines.  Then, knowledge-guided NLP is explored to leverage knowledge representations to  improve NLP models. Finally, based on knowledge-guided models, we can perform  knowledge acquisition to extract more knowledge from plain text to enrich existing  knowledge systems.  In the real world, people organize many kinds of knowledge, such as world  knowledge, linguistic knowledge, commonsense knowledge, and domain knowledge. In this chapter, we focus on introducing the knowledgeable framework from  the perspective of world knowledge since world knowledge is well-deﬁned and  general enough. Then, in the following chapters, we will show more details about  other kinds of knowledge.  In Sect. 9.2, we will brieﬂy introduce the important properties of symbolic  knowledge and distributed model knowledge,' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
702	page_content='distributed model knowledge, aiming to indicate the core motivation  for transforming symbolic knowledge into model knowledge. In Sects. 9.3 and 9.4,  we will present typical approaches to encoding symbolic knowledge into distributed  representations and show how to use knowledge representations to improve NLP 9 Knowledge Representation Learning and Knowledge-Guided NLP 275 Distributed Knowledge  Representations  Symbolic Knowledge  Representations 1960 1980  1990 2010  Tom coughs today and may get  infected by COVID-19 Model  Deep neural models are widely  used in NLP after 2010, which  can bring deep understanding  with structured knowledge. COVID-19  cough, fever, headache communicable disease  symptoms instance of  Expert systems represent facts  and rules with knowledge  bases, and conduct inference  with inference engines.  The data-driven models  proposed in 1990s  encode knowledge into  shallow embeddings. COVID-19 communicable disease  cough fever  headache S  NP VP CC VP  NNP VBZ NP MD VP  and' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
703	page_content='CC VP  NNP VBZ NP MD VP  and today coughs Tom may VBZ VP  VBN PP  IN NP  NNP  gets infected by COVID-10 COVID-19 get Infected by mayand today coughs Tom  Modern grammar (linguistics)  theory has been introduced in  NLP but cannot cover complex  language usage. Probabilistic graphical models  represent conditional dependence structure, empowering  Bayesian networks COVID-19  Cough Fever Tiredness Insomnia  Fig. 9.1 Typical ways to organize and utilize knowledge in the development of NLP 276 X. Han et al. Massive Data Symbolic Knowledge  Model Knowledge  Transform symbolic knowledge  to model knowledge Knowledge Representation  Learning 1  Improve the performance on  NLP tasks by using model  knowledge Knowledge-guided NLP2  Knowledge Acquisition3  Extract knowledge from  massive data and organize the  knowledge in a symbolic form  Fig. 9.2 The framework for organizing and utilizing knowledge for NLP tasks includes knowledge  representation learning, knowledge-guided NLP, and knowledge acquisition  models,' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
704	page_content='acquisition  models, respectively. In Sect. 9.5, we will detail several scenarios for acquiring  knowledge to ensure that we can acquire sufﬁcient knowledge to help various NLP  models.  9.2 Symbolic Knowledge and Model Knowledge  Before detailing the framework of knowledge representation learning, knowledgeguided NLP, and knowledge acquisition, we brieﬂy present the necessary background information, especially various effective systems to organize knowledge.  In this section, we will ﬁrst introduce typical symbolic knowledge systems,  which are the common way of organizing knowledge. Then, we will present  more details of model knowledge obtained by projecting knowledge into machine  learning models via distributed representation learning, providing a more machinefriendly way of organizing knowledge. Finally, we will show the recent trend in  fusing symbolic knowledge and model knowledge, and indicate the importance of  knowledge representation learning as well as knowledge-guided NLP in this fusion  trend.' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
705	page_content='NLP in this fusion  trend.  9.2.1 Symbolic Knowledge  During the two decades from the 1950s to 1970s, the efforts orienting NLP are  mainly committed to symbolic computation systems. In 1956, Allen Newell and 9 Knowledge Representation Learning and Knowledge-Guided NLP 277 Herbert A. Simon write the ﬁrst AI program Logic Theorist that can perform  automated reasoning [ 113]. The Logic Theorist can prove 38 of the ﬁrst 52  theorems given by Bertrand Russell in Principia Mathematica , by using logic and  heuristic rules to prune the search tree of reasoning. Over the same period, Noam  Chomsky proposes syntactic structures [ 24] and transformational grammars [ 25],  using formal languages with precise mathematical notations to drive machine  processing of natural languages. Inspired by the Logic Theorist and syntactic  structures, Herbert A. Simon and John McCarthy develop information processing  language (IPL) [ 114] and list processing (LISP) [ 105], respectively, and these two  programming languages' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
706	page_content='two  programming languages signiﬁcantly support computer programming for machine  intelligence.  Since neither logic nor grammar rules can well solve complex and diverse  problems in practical scenarios, the direction of deriving general intelligence from  symbolic systems held by early researchers has gradually fallen into a bottleneck.  After the 1970s, researchers turn to designing domain-speciﬁc intelligence systems  for each speciﬁc application. The representative work of this period is the expert  system [ 2] initiated by Edward Feigenbaum. An expert system generally consists  of a knowledge base (KB) and an inference engine. KBs store a wealth of human  knowledge, including domain-speciﬁc expertise and rules established by experts in  various ﬁelds. Inference engines can leverage expertise and rules in KBs to solve  speciﬁc problems.  Compared with the early AI methods entirely based on mathematical systems,  expert systems work well in some practical ﬁelds such as business and medicine.  Edward' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
707	page_content='and medicine.  Edward Feigenbaum further proposes knowledge engineering [ 42] in the 1980s,  indicating the importance of knowledge acquisition, knowledge representation, and  knowledge application to machine intelligence. As shown in Fig. 9.3, inspired by  knowledge engineering, various KBs have emerged, such as the commonsense base  Cyc [ 84] and Semantic Web [ 7]. The most notable achievement of expert systems  is the Watson system developed by IBM. IBM Watson beats two human contestants  on the quiz show Jeopardy, demonstrating the potential effectiveness of a KB with  rich knowledge.  With the Internet thriving in the twenty-ﬁrst century, massive messages have  ﬂooded into the World Wide Web, and knowledge is transferred to the semistructured textual information on the Web. However, due to the information  explosion, extracting the knowledge we want from the signiﬁcant but noisy plain  text on the Internet is not easy. During seeking effective ways to organize knowlExpert System  (Edward Feigenbaum)' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
708	page_content='System  (Edward Feigenbaum) Commonsense Base  Cyc (Douglas Lenat)  Semantic Web  (Tim Berners-Lee) Waston  (IBM) Knowledge Graph  (Google)  1980 1984  2006 2011 2012  Fig. 9.3 The development of symbolic knowledge systems 278 X. Han et al. edge, Google proposes the concept of knowledge graphs (KGs) in 2012 [ 37]. KGs  arrange the structured multi-relational data of both concrete and abstract entities  in the real world, which can be regarded as graph-structured KBs. In addition to  describing world knowledge in conventional forms such as strings, the emergence  of KGs provides a new tool to organize world knowledge from the perspective  of entities and relations. Since KGs are very suitable for organizing the massive  amount of knowledge stored in the Web corpora for faster knowledge retrieval,  the construction of KGs has been blooming in recent years and has attracted wide  attention from academia and industry.  KGs are usually constructed from existing Semantic Web datasets in resource  description' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
709	page_content='in resource  description framework (RDF) [ 81] with the help of manual annotation. At the same  time, KGs can also be automatically enriched by extracting knowledge from the  massive plain text on the Web. As shown in Fig. 9.4, a typical KG usually contains  two elements: entities and relations. Both concrete objects and abstract concepts in  the real world are deﬁned as entities, while complex associations between entities  are deﬁned as relations. Knowledge is usually represented in the triplet form of  . /angbracketlefthead entity , relation , tail entity . /angbracketright, and we abridge this as ./angbracketlefth,r,t/angbracketright. For example,  Mark Twain is a famous American writer, and The Million Pound Bank Note is one  of his masterpieces. In a KG, this knowledge will be represented as . /angbracketleftThe Million  Pound Bank Note , Author , Mark Twain . /angbracketright. Owing to the well-structured form, KGs  are widely used in various applications to improve system performance. There  are' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
710	page_content='performance. There  are several KGs widely utilized nowadays in NLP, such as Freebase [ 8], DBpedia [ 106], YAGO [ 147], and Wikidata [ 156]. There are also many comparatively  smaller KGs in speciﬁc domains whose knowledge can function in domain-speciﬁc  tasks.  9.2.2 Model Knowledge  For grammar rules, expert systems, and even KGs, one of the pain points of these  symbolic knowledge systems is their weak generalization. In addition, it is also  difﬁcult to process symbolic knowledge using the numerical computing operations  that machines are good at. Therefore, it becomes important to establish a knowledge  framework based on numerical computing and with a strong generalization ability  to serve the processing of natural languages. To this end, statistical learning [ 80]  has been widely applied after the 1990s, including support vector machines [ 14],  decision trees [ 16], conditional random ﬁelds [ 79], and so on. These data-driven  statistical learning methods can acquire knowledge from data, use' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
711	page_content='knowledge from data, use numerical  features to implicitly describe knowledge, use probability models to represent  rules behind knowledge implicitly, and perform knowledge reasoning based on  probability computing. 9 Knowledge Representation Learning and Knowledge-Guided NLP 279 Citizenship  U.S.A New York  City Of Olivia Langdon Clemens Spous e  Mark Twain  Wahington D.C. City Of Author The Million Pound Bank Note  NY k  Fig. 9.4 An example of knowledge graphs. The graphics in the ﬁgure come from Vecteezy  or Wikidata (Vecteezy: https:// www. vecteezy. com; Wikidata: https:// www. wikidata. org). And all  these graphics are available for free or under the Creative Commons CC0 license  Different from symbolic knowledge, which is abstracted by human beings and  regarded as human-friendly knowledge, the intrinsic nature of statistical learning is  to capture the distribution patterns of data from statistics and uses these patterns to  abstract implicit knowledge that can be used to solve speciﬁc problems.' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
712	page_content='to solve speciﬁc problems. Although  such implicit knowledge captured by statistical learning methods may not directly  satisfy human intuition, the knowledge is adept at describing correlation information  in data and is easy to compute numerically. In other words, this kind of knowledge  based on numerical features and continuous probability models is more machinefriendly . Considering that the structure of probability models is also a kind of prior  knowledge, here we introduce the concept of model knowledge to describe this  machine-friendly knowledge.2  2 There are also some works [ 22]u s i n g continuous knowledge to refer to this machine-friendly  implicit knowledge. 280 X. Han et al. Q: Who was president of the United  States in 1801?  A: Thomas Jefferson was president  of the United States in 1801.  Q: What city is in the northwest  corner of Ohio?  A: Toledo is in the northwest corner  of Ohio.  Q: Who won the World Series in  2021?  A: The New York Yankees won the  World Series in 2021.  Q: How' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
713	"page_content=""World Series in 2021.  Q: How many Super Bowls do the  Cincinnati Bengals win in the 2030s?  A: The Cincinnati Bengals win two  Super Bowls in the 2030s. World Knowledge  Q: How many eyes does a giraffe  have?  A: A giraffe has two eyes.  Q: How many legs does a frog  have?  A: A frog has four legs.  Q: Are there any animals with three  legs?  A: No, there are no animals with  three legs.  Q: Why don't animals have three  legs?  A: Animals don't have three legs  because they would fall over. Commonsense Knowledge  Q: If I have a marble and a paper  clip in a box, put a pencil in the box,  and remove the marble, what is left?  A: A paper clip.  Q: If I have two shoes in a box, put  a pencil in the box, and remove one  shoe, what is left?  A: A shoe.  Q: If I put a pencil in a box, then put  another pencil in the box, what is in  the box?  A: Two pencils.  Q: Then if I take out a pencil and  put in a frog, what is in the box?  A: A frog. Knowledge Reasoning  Fig. 9.5 Some question-answering examples of GPT-3."" metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}"
714	page_content='examples of GPT-3. All these examples come from Kevin  Lacker’s blog Giving GPT-3 a Turing Test (https:// lacker. io/ai/2020/ 07/06/givinggpt-3-a-turingtest.html). These examples are also shown in the survey of PTMs [ 59]  In recent years, the boom of neural networks has provided a more powerful tool to  capture model knowledge from data. Compared to conventional statistical models,  neural networks are more expressive and can obtain more complex patterns from  data. After the success of representing words as distributed representations [ 107],  using shallow neural networks to learn low-dimensional continuous representations for concerned objects, such as words [ 123], graphs [ 152], sentences, and  documents [ 82], has become a standard paradigm for accomplishing various NLP  tasks. With the emergence of techniques that support increasing network depth  and parameter size, such as Transformers [ 154], large-scale pre-trained models  (PTMs) [ 33, 99, 206] based on deep neural networks are proposed. Recent' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
715	page_content='networks are proposed. Recent works  show that PTMs can capture rich lexical knowledge[ 69], syntactic knowledge[ 66],  semantic knowledge[ 192], and factual knowledge[ 126] from data during the selfsupervised pre-training stage. As shown in Fig. 9.5, we can ﬁnd that GPT-3 (a PTM  with 175 billion parameters) holds a certain amount of facts and commonsense  and can perform logical reasoning [ 17]. By stimulating the task-speciﬁc model  knowledge distributed in PTMs via various tuning methods [ 34], PTMs achieve  state-of-the-art results on many NLP tasks.  9.2.3 Integrating Symbolic Knowledge and Model Knowledge  In the previous sections, we have brieﬂy described many efforts made by researchers  to enhance the processing of natural languages with knowledge. Brieﬂy, symbolic  knowledge is suited for reasoning and modeling causality, and model knowledge is  suited for integrating information and modeling correlation. Symbolic knowledge  and model knowledge have their own strengths, and utilizing both is' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
716	page_content='and utilizing both is crucial to drive  the language understanding of machines. Over the past few decades, the practice has 9 Knowledge Representation Learning and Knowledge-Guided NLP 281 also shown that NLP models with deep language understanding cannot be achieved  by using a certain kind of knowledge alone.  The early explorations of NLP researchers relied entirely on handcrafted rules  and systems, the limitations of which have been revealed over the two AI winters [ 54]. These AI winters have shown that it is challenging to make machines  master versatile language abilities using only symbolic knowledge. In recent years,  researchers have devoted great attention to deep neural networks and automatically  learning model knowledge from massive data, leading to breakthroughs such as  word representations and PTMs. However, these data-driven methods that focus  on model knowledge still have some obvious limitations and face the challenges  of robustness and interpretability [ 83]. In terms of robustness,' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
717	page_content='83]. In terms of robustness, for neural-based  NLP models, it is not difﬁcult to build adversarial examples to induce model  errors [ 157], considering the knowledge automatically summarized by models may  be a shortcut [ 48] or even a bias [ 148]. In terms of interpretability, the predictions  given by models are also based on black-box correlations. Moreover, current datadriven methods may suffer from data-hungry issues. Model knowledge needs to be  learned based on massive data, but obtaining high-quality data itself is very difﬁcult.  Humans can learn skills with a few training examples, which is challenging for  machines. Therefore, relying solely on data-driven methods and model knowledge  to advance NLP also seems unsustainable.  We have systematically discussed the symbolic and distributed representations  of text in the previous chapters, and here we have made a further extension to form  a broader discussion of representing knowledge. From these discussions, we can  observe that taking full' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
718	page_content='can  observe that taking full advantage of knowledge, i.e., utilizing both symbolic or  model knowledge, is an important way to obtain better language understanding.  Some recent works [ 60, 193] have also shown a trend toward the integration of  symbolic and model knowledge and, more speciﬁcally, a trend of using symbolic  knowledge to improve deep neural models that already have strong model knowledge. In order to integrate both symbolic and model knowledge, three challenges  have to be addressed:  1. How to represent knowledge (especially symbolic knowledge) in a machinefriendly form so that current NLP models can utilize the knowledge?  2. How to use knowledge representations to guide speciﬁc NLP models?  3. How to continually acquire knowledge from large-scale plain text instead of  handcrafted efforts?  We will next introduce knowledge representation learning, knowledge-guided  NLP, and knowledge acquisition for these challenges.  9.3 Knowledge Representation Learning  As we mentioned before, we can' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
719	page_content='we mentioned before, we can organize knowledge using symbolic systems.  However, as the scale of knowledge increases, using these symbolic systems 282 X. Han et al. naturally faces two challenges: data sparsity and computational inefﬁciency. Despite  the importance of symbolic knowledge for NLP, these challenges indicate that  symbolic systems are not an inherently machine-friendly form of knowledge  organization. Speciﬁcally, data sparsity is a common problem in many ﬁelds. For  example, when we use KGs to describe general world knowledge, the number of  entities (nodes) in KGs can be enormous, while the number of relations (edges)  in KGs is typically few, i.e., there are often no relations between two randomly  selected entities in the real world, resulting in the sparsity of KGs. Computational  inefﬁciency is another challenge we have to overcome since computers are better  suited to handle numerical data and less adept at handling symbolic knowledge in  KGs. As the size of KGs continues to grow, this' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
720	page_content='KGs continues to grow, this efﬁciency challenge may become  more severe.  To solve the above problems, distributed knowledge representations are introduced, i.e., low-dimensional continuous embeddings are used to represent symbolic  knowledge. The sparsity problem is alleviated owing to using these distributed  representations, and the computational efﬁciency is also improved. In addition,  using embeddings to represent knowledge makes it more feasible and convenient to  integrate symbolic knowledge into neural NLP models, motivating the exploration  of knowledge-guided NLP. Up to now, distributed knowledge representations have  been widely used in many applications requiring the support of human knowledge.  Moreover, distributed knowledge representations can also signiﬁcantly improve the  ability of knowledge completion, knowledge fusion, and knowledge reasoning.  In this section, we take KGs that organize rich world knowledge as an example  to introduce how to obtain distributed knowledge representations.' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
721	page_content='knowledge representations. Hereafter, we use  .G=(E,R,T)to denote a KG, in which .E={e1,e2,...}is the entity set, . R= {r1,r2,...}is the relation set, and . Tis the fact set. We use .h,t∈Eto represent  the head and tail entities, and .h,tto represent their entity embeddings. A triplet  ./angbracketlefth,r,t/angbracketright∈Tis a factual record, where .h,tare entities and r is the relation between  h and t.  Given a triplet ./angbracketlefth,r,t/angbracketright, a score function .f( h ,r ,t) is used by knowledge  representation learning methods to measure whether ./angbracketlefth,r,t/angbracketrightis a fact or a fallacy.  Generally, the larger the value of .f( h ,r ,t) , the higher the probability that . /angbracketlefth,r,t/angbracketright is true.3 Based on .f( h ,r ,t) , knowledge representations can be learned with  .arg min θ/summationdisplay /angbracketlefth,r,t/angbracketright∈T/summationdisplay /angbracketleft˜h,˜r,˜t/angbracketright∈˜Tmax/braceleftBig 0,f(˜h,˜r,˜t)+γ−f( h ,r ,t)/bracerightBig ,' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
722	page_content='h ,r ,t)/bracerightBig , (9.1)  where . θis the learnable embeddings of entities and relations, ./angbracketlefth,r,t/angbracketrightindicates  positive facts (i.e., triplets in . T), and ./angbracketleft˜h,˜r,˜t/angbracketrightindicates negative facts (triplets that 3 For some methods, the smaller the value of .f( h ,r ,t) , the higher the probability that ./angbracketlefth, r, t/angbracketrightis  true. We re-formalize the score functions of these methods by taking the opposite of the score  functions so that we can present all knowledge representation learning methods within a uniﬁed  framework.  9 Knowledge Representation Learning and Knowledge-Guided NLP 283 do not exist in KGs). .γ> 0is a hyper-parameter used as a margin. A bigger . γ means to learn a wider gap between .f( h ,r ,t) and.f(˜h,˜r,˜t). Considering that there  are no explicit negative triplets in KGs, . ˜Tis usually deﬁned as  .˜T={ /angbracketleft˜h,r,t/angbracketright|˜h∈E,/angbracketlefth,r,t/angbracketright∈T}∪{ /angbracketleft' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
723	page_content='/angbracketleft h,˜r,t/angbracketright|˜r∈R,/angbracketlefth,r,t/angbracketright∈T} ∪{/angbracketlefth,r,˜t/angbracketright|˜t∈E,/angbracketlefth,r,t/angbracketright∈T}−T,(9.2)  which means . ˜Tis built by corrupting the entities and relations of the triplets in . T.  Different from the margin-based loss function in Eq. ( 9.1), some methods apply a  likelihood-based loss function to learn knowledge representations as  . arg min θ/summationdisplay /angbracketlefth,r,t/angbracketright∈Tlog/bracketleftbig 1+exp(−f( h ,r ,t) )/bracketrightbig +/summationdisplay /angbracketleft˜h,˜r,˜t/angbracketright∈˜Tlog/bracketleftbig 1+exp(f (˜h,˜r,˜t))/bracketrightbig . (9.3)  Next, we present some typical knowledge representation learning methods as  well as their score functions, including (1) linear representation methods that  formalize relations as linear transformations between entities, (2) translation representation methods that formalize relations as translation operations between entities,  (3) neural' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
724	page_content='between entities,  (3) neural representation methods that apply neural networks to represent entities  and relations, and (4) manifold representation methods that use complex manifold  spaces instead of simple Euclidean spaces to learn representations.  9.3.1 Linear Representation  Linear representation methods formalize relations as linear transformations between  entities, which is a simple and basic way to learn knowledge representations.  Structured Embeddings (SE) SE [ 13] is a typical linear method to represent KGs.  In SE, all entities are embedded into a d-dimensional space. SE designs two relationspeciﬁc matrices .Mr,1, .Mr,2∈Rd×dfor each relation r, and these two matrices are  used to transform the embeddings of entities. The score function of SE is deﬁned as  .f( h ,r ,t) =− /bardbl Mr,1h−Mr,2t/bardbl, (9.4)  where ./bardbl·/bardblis the vector norm. The assumption of SE is that the head and tail embeddings should be as close as possible after being transformed into a relation-speciﬁc  space.' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
725	page_content='a relation-speciﬁc  space. Therefore, SE uses the margin-based loss function to learn representations.  Semantic Matching Energy (SME) SME [ 11] builds more complex linear transformations than SE. Given a triplet ./angbracketlefth,r,t/angbracketright,. hand. rare combined using a projection  function to get a new embedding . lh,r. Similarly, given . tand. r, we can get . lt,r. Then, 284 X. Han et al. a point-wise multiplication function is applied on .lh,rand. lt,rto get the score of this  triplet. SME introduces two different projection functions to build .f( h ,r ,t) : one is  in the linear form  . f( h ,r ,t) =l/latticetop h,rlt,r,lh,r=M1h+M2r+b1,lt,r=M3t+M4r+b2, (9.5)  and the other is in the bilinear form  . f( h ,r ,t) =l/latticetop h,rlt,r,lh,r=(M1h⊙M2r)+b1,lt,r=(M3t⊙M4r)+b2, (9.6)  where . ⊙is the element-wise (Hadamard) product. . M1, . M2, . M3, and .M4are learnable transformation matrices, and . b1and . b2are learnable bias vectors. Empirically,  the margin-based loss function is suitable for' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
726	page_content='loss function is suitable for dealing with the score functions  built with vector norm operations, while the likelihood-based loss function is more  usually used to process the score functions built with inner product operations. Since  SME uses the inner product operation to build its score function, the likelihoodbased loss function is thus used to learn representations.  Latent Factor Model (LFM) LFM [ 70] aims to model large KGs based on a  bilinear structure. By modeling entities as embeddings and relations as matrices,  the score function of LFM is deﬁned as  .f( h ,r ,t) =h/latticetopMrt, (9.7)  where the matrix .Mris the representation of the relation r. Similar to SME, LFM  adopts the likelihood-based loss function to learn representations. Based on LFM,  DistMult [ 186] further restricts .Mrto be a diagonal matrix. As compared with LFM,  DistMult not only reduces the parameter size but also reduces the computational  complexity and achieves better performance.  RESCAL RESCAL [ 118, 119] is a' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
727	page_content='RESCAL [ 118, 119] is a representation learning method based on  matrix factorization. By modeling entities as embeddings and relations as matrices,  RESCAL adopts a score function the same to LFM. However, RESCAL employs  neither the margin-based nor the likelihood-based loss function to learn knowledge  representations. Instead, in RESCAL, a three-way tensor .− →X∈R|E|×|E|×|R|is  adopted. In the tensor . − →X, two modes respectively stand for head and tail entities,  while the third mode stands for relations. The entries of . − →Xare determined by the  existence of the corresponding triplet facts. That is, .− →Xijk=1if the triplet ./angbracketlefti-th  entity , k-th relation , j-th entity . /angbracketrightexists in the training set, and otherwise .− →Xijk=0.  To capture the inherent structure of all triplets, given .− →X={ X1,···,X|R|}, for each  slice .Xn=− →X[:,:,n], RESCAL assumes the following factorization for . Xnholds  .Xn≈EMrnE/latticetop, (9.8) 9 Knowledge Representation Learning and' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
728	page_content='Representation Learning and Knowledge-Guided NLP 285 where .E∈R|E|×dstands for the d-dimensional entity representations of all entities  and .Mrn∈Rd×drepresents the interactions between entities speciﬁc to the n-th  relation . rn. Following this tensor factorization assumption, the learning objective of  RESCAL is deﬁned as  .arg min E,M1 2⎛ ⎝|R|/summationdisplay n=1/bardblXn−EMrnE/latticetop/bardbl2 F⎞ ⎠+1 2λ⎛ ⎝/bardblE/bardbl2 F+|R|/summationdisplay n=1/bardblMrn/bardbl2 F⎞ ⎠, (9.9)  where .M={ Mr1,Mr2,···,Mr|R|}is the collection of all relation matrices, . /bardbl·/bardblF is the Frobenius vector norm, and . λis a hyper-parameter to control the second  regularization term.  Holographic Embeddings (HolE) HolE [ 117] is proposed as an enhanced version  of RESCAL. RESCAL works well with multi-relational data but suffers from a  high computational complexity. To achieve high effectiveness and efﬁciency at  the same time, HolE employs an operation named circular correlation to generate  representations. The' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
729	page_content='representations. The circular correlation operation .⋆:Rd×Rd→Rdbetween two  entities h and t is  .[h⋆t]k=d/summationdisplay i=1[h]i[t](k+i)modd+1, (9.10)  where .[·]imeans the i-th vector element. The score function is deﬁned as  .f( h ,r ,t) =− r/latticetop(h⋆t). (9.11)  HolE adopts the likelihood-based loss function to learn representations.  The circular correlation operation brings several advantages. First, the circular  correlation operation is noncommutative (i.e., .h⋆t/negationslash=t⋆h), which makes it capable  of modeling asymmetric relations in KGs. Second, the circular correlation operation  has a lower computational complexity compared to the tensor product operation in  RESCAL. Moreover, the circular correlation operation could be further accelerated  with the help of fast Fourier transform (FFT), which is formalized as  .h⋆t=F−1(F(h)⊙F(t)), (9.12)  where .F(·)and .F(·)−1represent the FFT operation and its inverse operation,  respectively, .F(·)denotes the complex conjugate of .F(·), and .' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
730	page_content='conjugate of .F(·), and . ⊙stands for the  element-wise (Hadamard) product. Due to the FFT operation, the computational  complexity of the circular correlation operation is .O(dlogd), which is much lower  than that of the tensor product operation. 286 X. Han et al. 9.3.2 Translation Representation  Translation methods are another effective way to obtain distributed representations  of KGs. To help readers better understand different translation representation  methods, we ﬁrst introduce their motivations.  The primary motivation is that it is natural to consider relations between entities  as translation operations. For distributed representations, entities are embedded  into a low-dimensional space, and ideal representations should embed entities with  similar semantics into the nearby regions, while entities with different meanings  should belong to distinct clusters. For example, William Shakespeare and Jane  Austen may be in the same cluster of writers, Romeo and Juliet and Pride and  Prejudice may be in' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
731	page_content='and  Prejudice may be in another cluster of books. In this case, they share the same  relation Notable Work , and the translations from writers to their books in the  embedding space are similar.  The secondary motivation of translation methods derives from the breakthrough  in word representation learning. Word2vec [ 108] proposes two simple models, skipgram and CBOW, to learn distributed word representations from large-scale corpora.  The learned word embeddings perform well in measuring word similarities and  analogies. And these word embeddings have some interesting phenomena: if the  same semantic or syntactic relations are shared by two word pairs, the translations  within the two word pairs are similar. For instance, we have  .w(king)−w(man)≈w(queen)−w(woman ), (9.13)  where .w(·)represents the embedding of the word. We know that the semantic  relation between king and man is similar to the relation between queen and woman ,  and the above case shows that this relational knowledge is successfully' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
732	page_content='knowledge is successfully embedded  into word representations. Apart from semantic relations, syntactic relations can  also be well represented by word2vec, as shown in the following example:  .w(bigger )−w(big)≈w(smaller )−w(small). (9.14)  Since word2vec implies that the implicit relations between words can be seen  as translations, it is reasonable to assume that relations in KGs can also be  modeled as translation embeddings. More intuitively, if we represent a word pair  and its implicit relation using a triplet, e.g., . /angbracketleftbig, Comparative , bigger . /angbracketright,w e  can obviously observe the similarity between word representation learning and  knowledge representation learning.  The last motivation comes from the consideration of the computational complexity. On the one hand, the substantial increase in the model complexity will  result in high computational costs and obscure model interpretability, and a complex  model may lead to overﬁtting. On the other hand, the experimental' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
733	page_content='other hand, the experimental results on the  model complexity demonstrate that the simpler models perform almost as well as  more expressive models in most knowledge-related applications [ 117, 186], in the 9 Knowledge Representation Learning and Knowledge-Guided NLP 287 Embedding of Relation Notable Work  Embedding of Head Entity  William Shakespeare Embedding of Tail Entity  h t  r  Fig. 9.6 The architecture of TransE [ 12]  condition that large-scale datasets and a relatively large amount of relations can  be used for training models. As KG size increases, the computational complexity  becomes the primary challenge for knowledge representation learning. The intuitive  assumption of modeling relations as translations rather than matrices leads to a  better trade-off between effectiveness and efﬁciency.  Since the translation-based methods are all extended from TransE [ 12], we thus  ﬁrst introduce TransE in detail and then introduce its extensions.  TransE As illustrated in Fig. 9.6, TransE embeds entities' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
734	page_content='9.6, TransE embeds entities as well as relations into  the same space. In the embedding space, relations are considered as translations  from head entities to tail entities. With this translation assumption, given a triplet  ./angbracketlefth,r,t/angbracketrightin . T, we want .h+rto be the nearest neighbor of the tail embedding . t.T h e  score function of TransE is then deﬁned as  .f( h ,r ,t) =− /bardbl h+r−t/bardbl. (9.15)  TransE uses the margin-based loss function for training. Although TransE is  effective and efﬁcient, it still has several challenges to be further explored.  First, considering that there may be multiple correct answers given two elements  in a triplet, under the translation assumption in TransE, each entity has only one  embedding in all triplets, which may lead to reducing the discrimination of entity  embeddings. In TransE, according to the entity cardinalities of relations, all relations  are classiﬁed into four categories, 1-to-1, 1-to-Many, Many-to-1, and Many-toMany. A relation' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
735	page_content='and Many-toMany. A relation is considered as 1-to-1 if one head appears with only one tail and  vice versa, 1-to-Many if a head can appear with many tails, Many-to-1 if a tail can  appear with many heads, and Many-to-Many if multiple heads appear with multiple  tails. Statistics demonstrate that the 1-to-Many, Many-to-1, and Many-to-Many 288 X. Han et al. relations occupy a large proportion. TransE performs well on 1-to-1 relations, but  has problems when handling 1-to-Many, Many-to-1, and Many-to-Many relations.  For instance, given the head entity William Shakespeare and the relation Notable  Work , we can get a list of masterpieces, such as Hamlet , A Midsummer Night’s  Dream , and Romeo and Juliet . These books share the same writer information while  differing in many other ﬁelds such as theme, background, and famous roles in the  book. Due to the entity William Shakespeare and the relation Notable Work ,  these books may be assigned similar embeddings and become indistinguishable.  Second, although the' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
736	page_content='Second, although the translation operation is intuitive and effective, only considering the simple one-step translation may limit the ability to model KGs. Taking  entities and relations as nodes and edges, the nodes that are not directly connected  may be linked by a path of more than one edge. However, TransE focuses on  minimizing ./bardblh+r−t/bardbl, which only utilizes the one-step relation information in KGs,  regardless of the latent relationships located in long-distance paths. For example, if  we know . /angbracketleftThe forbidden city , Located in , Beijing . /angbracketrightand. /angbracketleftBeijing , Capital of ,  China . /angbracketright, we can infer that The forbidden city locates in China . TransE can be further  enhanced with the favor of multistep information.  Third, the representation and the score function in TransE are oversimpliﬁed  for the consideration of efﬁciency. Therefore, TransE may not be capable enough  of modeling those complex entities and relations in KGs. There are' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
737	page_content='relations in KGs. There are still some  challenges in how to balance effectiveness and efﬁciency as well as avoid overﬁtting  and underﬁtting.  After TransE, there are lots of subsequent methods addressing the above challenges. Speciﬁcally, TransH [ 165], TransR [ 90], TransD [ 102], and TranSparse [ 71]  are proposed to solve the challenges in modeling complex relations, PTransE  is proposed to encode long-distance information located in multistep paths, and  CTransR, TransG, and KG2E further extend the oversimpliﬁed model of TransE.  Next, we will discuss these subsequent methods in detail.  TransH TransH [ 165] enables an entity to have multiple relation-speciﬁc representations to address the issue that TransE cannot well model 1-to-Many, Many-to-1,  and Many-to-Many relations. As we mentioned before, in TransE, entities are  embedded to the same semantic embedding space and similar entities tend to be  in the same cluster. However, it seems that William Shakespeare should be in the  neighborhood of Isaac' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
738	page_content='in the  neighborhood of Isaac Newton when talking about Nationality , while it should  be close to Mark Twain when talking about Occupation . To accomplish this,  entities should have multiple representations in different triplets.  As illustrated in Fig. 9.7, TransH proposes a hyperplane .wrfor each relation,  and computes the translation on the hyperplane . wr. Given a triplet ./angbracketlefth,r,t/angbracketright, TransH  projects . hand. tto the corresponding hyperplane . wrto get the projection . h⊥and. t⊥,  and . ris used to connect . h⊥and . t⊥:  .h⊥=h−w/latticetop rhwr,t⊥=t−w/latticetop rtwr, (9.16) 9 Knowledge Representation Learning and Knowledge-Guided NLP 289 t h  Entity Space Hyperplane of Relation r hr tr r Orthogonal Projection  Orthogonal Projection  Fig. 9.7 The architecture of TransH [ 165]  where . wris a vector and ./bardblwr/bardbl2is restricted to 1. The score function is  .f( h ,r ,t) =− /bardbl h⊥+r−t⊥/bardbl. (9.17)  As for training, TransH also minimizes the margin-based loss' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
739	page_content='the margin-based loss function with negative  sampling, which is similar to TransE.  TransR TransR [ 90] takes full advantage of linear methods and translation methods. As in Eq. ( 9.16), TransH enables entities to have multiple relation-speciﬁc  representations by projecting them to different hyperplanes, while entity embeddings and relation embeddings are still restricted in the same space, which may  limit the ability for modeling entities and relations. TransR assumes that entity  embeddings and relation embeddings should be in different spaces.  As illustrated in Fig. 9.8, For a triplet ./angbracketlefth,r,t/angbracketright, TransR projects . hand . tto the  relation space of r, and this projection is deﬁned as  .hr=hMr,tr=tMr, (9.18)  where .Mris the projection matrix. . hrand . trstand for the relation-speciﬁc entity  representations in the relation space of r, respectively. This means that each entity  has a relation-speciﬁc representation for each relation, and all translation operations  are' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
740	page_content='translation operations  are processed in the relation-speciﬁc space. The score function of TransR is  .f( h ,r ,t) =− /bardbl hr+r−tr/bardbl. (9.19)  TransR constrains the norms of the embeddings and has ./bardblh/bardbl2≤1, ./bardblt/bardbl2≤1,  ./bardblr/bardbl2≤1, ./bardblhr/bardbl2≤1, ./bardbltr/bardbl2≤1. As for training, TransR uses the same marginbased loss function as TransE. 290 X. Han et al. t h  Entity Space Relation Space of Relation r hr tr ×Mr  ×Mr r  Fig. 9.8 The architecture of TransR [ 90]  Furthermore, a relation should also have multiple representations since the  meanings of a relation with different head and tail entities differ slightly. For  example, the relation Contains the Location has head-tail patterns like citystreet , country-city , and even country-university , each conveys different attribute  information. To handle these subtle differences, entities for a same relation should  also be projected differently.  To this end, cluster-based TransR (CTransR) is then proposed, which' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
741	page_content='is then proposed, which is an  enhanced version of TransR by taking the nuance in meaning for a same relation  with different entities into consideration. More speciﬁcally, for each relation, all  entity pairs of the relation are ﬁrst clustered into several groups. The clustering  process depends on the result of .t−hfor each entity pair .(h,t) , and . hand . tare the  embeddings learned by TransE. Then, we assign a distinct sub-relation embedding  . rcfor each cluster of the relation r according to cluster-speciﬁc entity pairs, and the  original score function of TransR is modiﬁed as  .f( h ,r ,t) =− /bardbl hr+rc−tr/bardbl−λ/bardblrc−r/bardbl, (9.20)  where . λis a hyper-parameter to control the regularization term and ./bardblrc−r/bardblis to  make the sub-relation embedding . rcand the uniﬁed relation embedding . rnot too  distinct.  TransD TransD [ 102] is an extension of TransR that uses dynamic mapping  matrices to project entities into relation-speciﬁc spaces. TransR focuses on learning  multiple' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
742	page_content='focuses on learning  multiple relation-speciﬁc entity representations. However, TransR projects entities  according to only relations, ignoring the entity diversity. Moreover, the projection  operations based on matrix-vector multiplication lead to a higher computational  complexity compared to TransE, which is time-consuming when applied on largescale KGs. 9 Knowledge Representation Learning and Knowledge-Guided NLP 291 Entity Space Relation Space of Relation r t1r t2r  h2  h1  h1r h2r  t1 t2 Mrh i  Mrt i Mrh i Mrt i  r  r  Fig. 9.9 The architecture of TransD [ 102]  For each entity and relation, TransD deﬁnes two vectors: one is used as the  embedding, and the other is used to construct projection matrices to map entities  to relation spaces. As illustrated in Fig. 9.9,W eu s e . h,. t,. rto denote the embeddings  of entities and relations, and . hp, . tp, . rpto represent the projection vectors. There  are two projection matrices .Mrh,.Mrtused to project entities to relation spaces, and  these projection' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
743	page_content='spaces, and  these projection matrices are dynamically constructed as  .Mrh=rph/latticetop p+I,M rt=rpt/latticetop p+I, (9.21)  which means the projection vectors of both entities and relations are combined to  determine dynamic projection matrices. The score function is  .f( h ,r ,t) =− /bardbl Mrhh+r−Mrtt/bardbl. (9.22)  These projection matrices are initialized with identity matrices by setting all the  projection vectors to . 0at initialization, and the normalization constraints in TransR  are also used for TransD.  TransD proposes a dynamic method to construct projection matrices by considering the diversities of both entities and relations, achieving better performance  compared to existing methods in knowledge completion. Moreover, TransD lowers  both computational and spatial complexity compared to TransR.  TranSparse TranSparse [ 71] is also a subsequent work of TransR. Although  TransR has achieved promising results, there are still two challenges remained.  One is the heterogeneity challenge.' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
744	page_content='the heterogeneity challenge. Relations in KGs differ in granularity. Some  relations express complex semantics between entities, while some other relations  are relatively simple. The other is the imbalance challenge. Some relations have  more valid head entities and fewer valid tail entities, while some are the opposite. 292 X. Han et al. If we consider these challenges rather than merely treating all relations equally, we  can obtain better knowledge representations.  Existing methods such as TransR build projection matrices for each relation, and  these projection matrices have the same parameter scale, regardless of the variety  in the complexity of relations. TranSparse is proposed to address this issue. The  underlying assumption of TranSparse is that complex relations should have more  parameters to learn while simple relations should have fewer parameters, where the  relation complexity is judged from the number of triplets or entities linked to the  relation. To accomplish this, two models are' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
745	page_content='this, two models are proposed, including TranSparse-share  and TranSparse-separate.  Inspired by TransR, given a relation r, TranSparse-share builds a relation-speciﬁc  projection matrix .Mr(θr)for the relation. .Mr(θr)is sparse and the sparse degree . θr mainly depends on the number of entity pairs linked to r. Suppose . Nris the number  of linked entity pairs, .N∗ rrepresents the maximum number of . Nr, and .θmindenotes  the minimum sparse degree of projection matrices that .0≤θmin≤1. The sparse  degree of relation r is deﬁned as  .θr=1−(1−θmin)Nr N∗r. (9.23)  Both head and tail entities share the same sparse projection matrix . Mr(θr).T h e  score function is  .f( h ,r ,t) =− /bardbl Mr(θr)h+r−Mr(θr)t/bardbl. (9.24)  Different from TranSparse-share, TranSparse-separate builds two different sparse  matrices .Mrh(θrh)and .Mrt(θrt)for head and tail entities, respectively. Then, the  sparse degree .θrh(or . θrt) depends on the number of head (or tail) entities linked to  r.W eh a v e .Nrh(or . Nrt) to' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
746	page_content='eh a v e .Nrh(or . Nrt) to represent the number of head (or tail) entities, as well as  .N∗ rh(or . N∗ rt) to represent the maximum number of .Nrh(or . Nrt). And .θminwill also  be set as the minimum sparse degree of projection matrices that .0≤θmin≤1.W e  have  .θrh=1−(1−θmin)Nrh/N∗ rh,θ rt=1−(1−θmin)Nrt/N∗ rt. (9.25)  The ﬁnal score function of TranSparse-separate is  .f( h ,r ,t) =− /bardbl Mrh(θrh)h+r−Mrt(θrt)t/bardbl. (9.26)  Through sparse projection matrices, TranSparse solves the heterogeneity challenge  and the imbalance challenge simultaneously.  PTransE PTransE [ 89] is an extension of TransE that considers multistep relational  paths. All abovementioned translation methods only consider simple one-step  paths (i.e., relation) to perform the translation operation, ignoring the rich global 9 Knowledge Representation Learning and Knowledge-Guided NLP 293 information located in the whole KGs. For instance, if we notice the multistep  relational path that . /angbracketleftThe forbidden city, Located' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
747	page_content='forbidden city, Located in, Beijing . /angbracketright.→. /angbracketleftBeijing,  Capital of, China . /angbracketright, we can inference with conﬁdence that the triplet . /angbracketleftThe  forbidden city, Located in, China . /angbracketrightmay exist. Relational paths provide us a  powerful way to build better representations for KGs and even help us better  understand knowledge reasoning.  There are two main challenges when encoding the information in multistep  relational paths. First, how to select reliable and meaningful relational paths among enormous path candidates in KGs, since there are lots of paths that cannot indicate reasonable relations. Consider two triplet facts  . /angbracketleftThe forbidden city, Located in,  Beijing . /angbracketright.→. /angbracketleftBeijing, held, 2008 Summer Olympics . /angbracketright, it is hard to describe the  relation between The forbidden city and 2008 Summer Olympics. Second, how to  model the meaningful relational paths? It is not easy to handle the problem' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
748	page_content='easy to handle the problem of  semantic composition in relational paths.  To select meaningful relational paths, PTransE uses a path-constraint resource  allocation (PCRA) algorithm to judge the path reliability. Suppose there is informa-tion (or resource) in the head entity h which will ﬂow to the tail entity t through  some certain paths. The basic assumption of PCRA is that the reliability of the  path  . /lscriptdepends on the amount of resource that eventually ﬂows from head to  tail. Formally, we denote a certain path between h and t as ./lscript=(r 1,...,r l).  The resource that travels from h to t following the path could be represented as  .S0/hr1− →S 1r2− →...rl− →S l/t. For an entity .m∈S i, the amount of resource that  belongs to m is deﬁned as  .R/lscript(m)=/summationdisplay n∈Si−1(·,m)1 |Si(n,·)|R/lscript(n), (9.27)  where .Si−1(·,m) indicates all direct predecessors of the entity m along with the  relation . riin .Si−1and .Si(n,·) indicates all direct successors of .n∈S i−1with the  relation' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
749	page_content='of .n∈S i−1with the  relation . ri. Finally, the amount of resource that ﬂows to the tail .R/lscript(t)is used to  measure the reliability of . /lscript, given the triplet ./angbracketlefth,/lscript,t/angbracketright .  Once we ﬁnish selecting those meaningful relational path candidates, the next  challenge is to model the semantic composition of these multistep paths. PTransE  proposes three composition operations, namely, addition, multiplication, and recurrent neural networks, to get the path representation . lbased on the relations in  ./lscript=(r 1,...,r l). The score function is  .f( h ,/lscript ,t)=− /bardbll−(t−h)/bardbl≈−/bardbll−r/bardbl=f (/lscript,r), (9.28)  where r indicates the golden relation between h and t. Since PTransE also wants to  meet the assumption in TransE that .r≈t−h , PTransE directly utilizes . rin training.  The optimization objective of PTransE is  .arg min θ/summationdisplay (h,r,t)∈T[L(h,r ,t)+1 Z/summationdisplay /lscript∈P(h,t)R(/lscript|h,t)L(/lscript,r)], (9.29) 294 X.' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
750	page_content='(9.29) 294 X. Han et al. where .L(h,r ,t) is the margin-based loss function with .f( h ,r ,t) , .L(/lscript,r) is the  margin-based score function with .f( /lscript ,r) , and .Z=/summationtext /lscript∈P(h,t)R(/lscript|h,t) is a  normalization factor. The reliability .R(/lscript|h,t) of . /lscriptin .(h,/lscript,t) is well considered in  the overall loss function. For the path . /lscript, the initial resource is set as .R/lscript(h)=1.B y  recursively performing PCRA from h to t through . /lscript, the resource .R/lscript(t)can indicate  how much information can be well translated, and .R/lscript(t)is thus used to measure  the reliability of the path . /lscript, i.e., .R(/lscript|h,t)=R/lscript(t). Besides PTransE, similar  ideas [ 47, 50] also consider multistep relational paths and demonstrate that there is  plentiful information located in multistep relational paths which could signiﬁcantly  improve knowledge representation.  KG2E KG2E [ 65] introduces multidimensional Gaussian distributions to represent' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
751	page_content='distributions to represent  KGs. Existing translation methods usually consider entities and relations as vectors  embedded in low-dimensional spaces. However, as explained above, entities and  relations in KGs are diverse at different granularities. Therefore, the margin in the  margin-based loss function that is used to distinguish positive triplets from negative  triplets should be more ﬂexible due to the diversity, and the uncertainties of entities  and relations should be taken into consideration.  KG2E represents entities and relations with Gaussian distributions. Speciﬁcally,  the mean vector denotes the central position of an entity or a relation, and the covariance matrix denotes its uncertainties. Following the score function proposed in  TransE, for ./angbracketlefth,r,t/angbracketright, the Gaussian distributions of entities and relations are deﬁned as  .h∼N(μh,Σh),t∼N(μt,Σt),r∼N(μr,Σr). (9.30)  Note that the covariances are diagonal for efﬁcient computation. KG2E  hypothesizes that head and tail' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
752	page_content='that head and tail entities are independent with speciﬁc relations;  then, the translation could be deﬁned as  .e∼N(μh−μt,Σh+Σt). (9.31)  To measure the dissimilarity between . eand . r, KG2E considers both asymmetric  similarity and symmetric similarity, and then proposes two methods.  The asymmetric similarity is based on the KL divergence between . eand. r, which  is a typical method to measure the similarity between two distributions. The score  function is  . f( h ,r ,t) =−DKL(e/bardblr) =−/integraldisplay x∈RdN(x;μr,Σr)logN(x;μe,Σe) N(x;μr,Σr)dx =−1 2{tr(Σ−1 rΣr)+(μr−μe)/latticetopΣ−1 r(μr−μe)−logdet(Σe) det(Σr)−d}, (9.32)  where .tr(Σ)indicates the trace of . Σand .Σ−1indicates the inverse of . Σ. 9 Knowledge Representation Learning and Knowledge-Guided NLP 295 The symmetric similarity is built on the expected likelihood and probability  product kernel. KE2G takes the inner product between the probability density  functions of . eand . ras the measurement of similarity. The logarithm of score' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
753	page_content='The logarithm of score  function deﬁned is  .f( h ,r ,t) =−/integraldisplay x∈RdN(x;μe,Σe)N(x;μr,Σr)dx =− logN(0;μe−μr,Σe+Σr) =−1 2{(μe−μr)/latticetop(Σe+Σr)−1(μe−μr) +log det (Σe+Σr)+dlog(2π)}.(9.33)  The optimization objective of KG2E is also margin-based similar to TransE. Both  asymmetric and symmetric similarities are constrained by some regularizations to  avoid overﬁtting:  .∀l∈E∪R,/bardblμl/bardbl2≤1,c minI≤Σl≤cmaxI,c min>0, (9.34)  where .cminand .cmaxare the hyper-parameters as the restriction values for covariance.  TransG TransG [ 174] discusses the problem that some relations in KGs such  as Contains the Location or Part of may have multiple sub-meanings,  which is also discussed in TransR. In fact, these complex relations could be divided  into several more precise sub-relations. To address this issue, CTransR is proposed  with a preprocessing that clusters sub-relation according to entity pairs.  As illustrated in Fig. 9.10, TransG assumes that the embeddings containing several semantic' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
754	page_content='containing several semantic components should follow a Gaussian mixture model. The generative  process is:  1. For each entity .e∈E, TransG sets a standard normal distribution: .μe∼N(0,I).  2. For a triplet ./angbracketlefth,r,t/angbracketright, TransG uses the Chinese restaurant process (CRP) to  automatically detect semantic components (i.e., sub-meanings in a relation):  .πr,n∼CRP(β). .πr,nis the weight of the i-th component generated by the  Chinese restaurant process from the data.  3. Draw the head embedding from a standard normal distribution: .h∼N(μh,σ2 hI).  4. Draw the tail embedding from a standard normal distribution: .t∼N(μt,σ2 tI).  5. Calculate the relation embedding for this semantic component: .μr,n=t−h.  Finally, the score function is  .f( h ,r ,t) ∝Nr/summationdisplay n=1πr,nN(μr,n;μt−μh,(σ2 h+σ2 t)I), (9.35)  in which . Nris the number of semantic components of the relation r. 296 X. Han et al. Learning Relations Learning Sub-relations h h r r  r  Fig. 9.10 The architecture of TransG [' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
755	page_content='The architecture of TransG [ 174]. The ﬁgure is redrawn according to Fig. 2 from TransG  paper [ 174]  9.3.3 Neural Representation  With the development of neural networks, several efforts have been devoted to  exploring neural networks for modeling KGs. Next, we will introduce how to  represent KGs with neural networks.  Single Layer Model (SLM) Inspired by the previous works in representing KGs,  SLM represents both entities and relations in low-dimensional spaces, and uses  relation-speciﬁc matrices to project entities to relation spaces. Similar to the linear  method SE, the score function of SLM is  .f( h ,r ,t) =r/latticetoptanh(Mr,1h+Mr,2t), (9.36)  where . h, .t∈Rderepresent head and tail embeddings, .r∈Rdrrepresents relation  embedding, and .Mr,1, .Mr,2∈Rde×drstand for the relation-speciﬁc matrices.  Neural Tensor Network (NTN) Although SLM has introduced relation embeddings as well as a nonlinear neural layer to build the score function, the representation capability is still restricted. NTN [ 143]' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
756	page_content='still restricted. NTN [ 143] is then proposed by introducing  tensors into the SLM framework, which can be seen as an enhanced version of  SLM. Besides the original linear neural network layer that projects entities to the  relation space, NTN adds another tensor-based neural layer which combines head  and tail embeddings with a relation-speciﬁc tensor. The score function of NTN is  .f( h ,r ,t) =r/latticetoptanh(h/latticetop− →Mrt+Mr,1h+Mr,2t+br), (9.37) 9 Knowledge Representation Learning and Knowledge-Guided NLP 297 where .− →Mr∈Rde×de×dris a three-way relation-speciﬁc tensor, . bris the bias, and  .Mr,1, .Mr,2∈Rde×drare the relation-speciﬁc matrices. Note that SLM can be seen  as a simpliﬁed version of NTN if the tensor and the bias are set to zero.  Besides improving the score function, NTN also attempts to utilize the latent  textual information located in entity names and successfully achieves signiﬁcant  improvements. Differing from previous methods that provide each entity with  a vector, NTN' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
757	page_content='entity with  a vector, NTN represents each entity as the average of its entity name’s word  embeddings. For example, the entity Bengal tiger will be represented as the average  word embeddings of Bengal and tiger. It is apparent that the entity name will provide  valuable information for understanding an entity, since Bengal tiger may come from  Bengal and be related to other tigers.  NTN utilizes tensor-based neural networks to model triplet facts and achieves  excellent success. However, the overcomplicated method leads to high computational complexity compared to other methods, and the vast number of parameters  limits the performance on sparse and large-scale KGs.  Neural Association Model (NAM) NAM [ 94] adopts multilayer nonlinear activation to model relations. More speciﬁcally, two structures are used by NAM to  represent KGs: deep neural network (DNN) and relation modulated neural network  (RMNN).  NAM-DNN adopts a MLP with L layers to operate knowledge embeddings:  .zk=Sigmoid (Mkzk−1+bk),' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
758	page_content='.zk=Sigmoid (Mkzk−1+bk), k=1,···,L, (9.38)  where .z0=[ h;r]is the concatenation of . hand . r, .Mkis the weight matrix of the  k-th layer, and . bkis the bias vector of the k-th layer. Finally, NAM-DNN deﬁnes the  score function as  .f( h ,r ,t) =Sigmoid (t/latticetopzL). (9.39)  As compared with NAM-DNN, NAM-RMNN additionally feeds the relation  embedding . rinto the model:  .zk=Sigmoid (Mkzk−1+Bkr), k=1,···,L, (9.40)  where .Mkand .Bkindicate the weight and bias matrices. Finally, NAM-RMNN  deﬁnes the score function as  .f( h ,r ,t) =Sigmoid (t/latticetopzL+BL+1r). (9.41)  Convolutional 2D Embeddings (ConvE) ConvE [ 32] uses 2D convolutional  operations over embeddings to model KGs. Speciﬁcally, ConvE uses convolutional  and fully connected layers to model interactions between entities and relations. After  that, the obtained features are ﬂattened and transformed by a fully connected layer, 298 X. Han et al. and the inner product between the ﬁnal feature and the tail entity embeddings is  used to build' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
759	page_content='embeddings is  used to build the score function:  .f( h ,r ,t) =N/parenleftbig vec(N([¯h;¯r]∗ω))W/parenrightbig ·t, (9.42)  where .[¯h;¯r]is the concatenation of . ¯hand . ¯r, .N(·)is a neural layer, . ∗denotes the  convolution operator, and .vec(·)means compressing a matrix into a vector. . ¯hand  . ¯rdenote the 2D-reshaping versions of . hand . r, respectively: if .h,r∈Rd, then  .¯h,¯r∈Rda×db, where .d=dadb.  To some extent, ConvE can be seen as an improvement model based on HolE.  Compared with HolE, ConvE adopts multiple neural layers to learn nonlinear  features and is thus more expressive than HolE.  Relational Graph Convolutional Networks (RGCN) RGCN [ 136] is an extension of GCNs to model KGs. The core idea of RGCN is to formalize modeling  KGs as message passing. Therefore, in RGCN, the representations of entities and  relations are the results of information propagation and fusion at multiple layers.  Speciﬁcally, given an entity h, its embedding at the .(k+1)-th layer is  .hk+1=Sigmoid⎛' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
760	page_content='layer is  .hk+1=Sigmoid⎛ ⎝/summationdisplay r∈R/summationdisplay t∈Nr h1 cr hWk rtk+˜Wktk⎞ ⎠, (9.43)  where .Nr hdenotes the neighbor set of h under the relation r and . cr his the  normalization factor. . cr hcan be either learned or preset, and normally .cr h=|Nr h|.  Note that RGCN only aims to obtain more expressive features for entities and  relations. Therefore, based on the output features of RGCN, any score function  mentioned above can be used here, such as combining the features of RGCN and  the score function of TransE to learn knowledge representations.  9.3.4 Manifold Representation  So far, we have introduced linear methods, translation methods, and neural methods  for knowledge representation. All these methods project entities and relations  into low-dimensional embedding spaces, and seek to improve the ﬂexibility and  variety of entity and relation representations. Although these methods have achieved  promising results, they assume that the geometry of the embedding spaces for  entities and' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
761	page_content='spaces for  entities and relations are all Euclidean. However, the basic Euclidean geometry  may not be the optimal geometry to model the complex structure of KGs. Next,  we will introduce several typical manifold methods that aim to use more ﬂexible  and powerful geometric spaces to carry representations. 9 Knowledge Representation Learning and Knowledge-Guided NLP 299 ManifoldE ManifoldE [ 173] considers the possible positions of golden candidates  for representations in spaces as a manifold rather than a point. The overall score  function of ManifoldE is  .f( h ,r ,t) =− /bardbl M(h,r,t) −D2 r/bardbl, (9.44)  in which .D2 ris a relation-speciﬁc manifold parameter. Two kinds of manifolds are  then proposed in ManifoldE. ManifoldE-Sphere is a straightforward manifold that  supposes . tshould be located in the sphere which has .h+rto be the center and . Dr to be the radius. We have:  .M(h,r,t) =/bardbl h+r−t/bardbl. (9.45)  A tail may correspond to many different head-relation pairs, and the manifold' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
762	page_content='pairs, and the manifold  assumption requires that the tail lays in all the manifolds of these head-relation  pairs, i.e., lays in the intersection of these manifolds. However, two spheres can only  intersect only under some strict conditions. Therefore, the hyperplane is utilized  because it is easier for two hyperplanes to intersect. The function of ManifoldEHyperplane is  .M(h,r,t) =(h+rh)/latticetop(t+rt), (9.46)  in which . rhand . rtrepresent the two entity-speciﬁc embeddings of the relation  r. This indicates that for a triplet ./angbracketlefth,r,t/angbracketright, the tail entity . tshould locate in the  hyperplane whose normal vector is .h+rhand intercept is . D2 r. Furthermore,  ManifoldE-Hyperplane considers absolute values in .M(h,r,t) as.|h+rh|/latticetop|t+rt|to  double the solution number of possible tail entities. For both manifolds, ManifoldE  applies a kernel form on the reproducing kernel Hilbert space.  ComplEx ComplEx [ 153] employs an eigenvalue decomposition model which  makes use of' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
763	page_content='model which  makes use of complex-valued embeddings, i.e., .h,r,t∈Cd. Complex embeddings  can well handle binary relations, such as the symmetric and antisymmetric relations.  The score function of ComplEx is  . f( h ,r ,t) =Re(/angbracketleftr,h,t/angbracketright) =/angbracketleftRe(r),Re(h),Re(t)/angbracketright+/angbracketleft Re(r),Im(h),Im(t)/angbracketright −/angbracketleftIm(r),Re(h),Im(t)/angbracketright−/angbracketleft Im(r),Im(h),Re(t)/angbracketright, where ./angbracketleftx,y,z/angbracketright=/summationtext ixiyizidenotes the trilinear dot product, .Re(x)is the real part  of x, and .Im(x)is the imaginary part of x. In fact, ComplEx can be viewed as a  generalization of RESCAL that uses complex embeddings to model KGs.  RotatE Similar to ComplEx, RotatE [ 149] also represents KGs with complexvalued embeddings. RotatE deﬁnes relations as rotations from head entities to tail  entities, which makes it easier to learn various relation patterns such as symmetry, 300 X. Han et al. antisymmetry,' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
764	page_content='X. Han et al. antisymmetry, inversion, and composition. The element-wise (Hadamard) product  can naturally represent the rotation process in the complex-valued space. Therefore,  the score function of RotatE is  .f( h ,r ,t) =− /bardbl h⊙r−t/bardbl, (9.47)  where .h,r,t∈Cdand . ⊙denotes the element-wise (Hadamard) product. RotatE  is simple and achieves quite good performance. Compared with previous methods,  it is the ﬁrst model that is theoretically able to model all the above four patterns  (symmetry, antisymmetry, inversion, and composition). On the basis of RotatE,  Zhang et al. [ 203] further introduce hypercomplex spaces to represent entities and  relations, and achieves better performance.  MuRP MuRP [ 4] proposes to embed the entities in the hyperbolic space since  hyperbolic space is shown to be more suitable to represent hierarchical data than  Euclidean space. Speciﬁcally, they embed the entities to the Poincaré model [ 130]  (a typical geometric model in hyperbolic space), and exploit the Mobiüs' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
765	page_content='and exploit the Mobiüs transformations in the Poincaré model as the alternatives to vector-matrix multiplication and  vector addition in Euclidean space. The score function of MuRP is  .f( h ,r ,t) =dP(h(r),t(r))2−bh−bt =dP(expc 0(Mrlogc 0(h)),t⊕r)−bh−bt,(9.48)  where .dP(·,·)calculates the distance between two points in the Poincaré model, . Mr is the transform matrix for the relation r, . ris the translation vector of the relation  r, and . bhand . btare biases for the head and tail entities respectively. .expc 0is the  exponential mapping at . 0in the Poincaré model of the curvature c, and it maps  points in the tangent space at . 0(an Euclidean subspace) to the Poincaré model. . logc 0 is the logarithmic mapping at . 0in the Poincaré model of the curvature c, and is the  inverse mapping for .expc 0. MuRP with a dimension as low as 40 achieves comparable  results to the Euclidean models with dimension greater than 100, showing the  effectiveness of hyperbolic space in encoding relational knowledge.' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
766	page_content='relational knowledge.  HyboNet HyboNet [ 23] argues that previous hyperbolic methods such as MuRP  only introduce the hyperbolic geometric for embeddings, but still perform linear  transformations in tangent spaces (Euclidean subspaces), signiﬁcantly limiting the  capability of hyperbolic models. Inspired by the Lorentz transformation in Physics,  HyboNet proposes a linear transformation in the Lorentz model [ 130] (another  typical geometric model to build hyperbolic spaces) to avoid the introduction of  exponential mapping and logarithmic mapping when transforming embeddings,  signiﬁcantly speeding up the network and stabilizing the computation. The score  function of HyboNet is  .f( h ,r ,t) =d2 L(gr(h),t)−bh−bt−δ, (9.49) 9 Knowledge Representation Learning and Knowledge-Guided NLP 301 where . d2 Lis the squared Lorentzian distance between two points in Lorentz model,  . gris the relation-speciﬁc Lorentz linear transformation, .bh,btare the biases for  the head and tail entities, respectively, and . δis a' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
767	page_content='respectively, and . δis a hyper-parameter used to make the  training process more stable.  9.3.5 Contextualized Representation  We live in a complicated pluralistic real world where we can get information from  different senses. Due to this, we can learn knowledge not only from structured  KGs but also from text, schemas, images, and rules. Despite the massive size  of existing KGs, there is a large amount of knowledge in the real world that  may not be included in the KGs. Integrating multisource information provides a  novel approach for learning knowledge representations not only from the internal  structured information of KGs but also from other external information. Moreover,  exploring multisource information can help further understand human cognition  with different senses in the real world. Next, we will introduce typical methods  that utilize multisource information to enhance knowledge representations.  Knowledge Representation with Text Textual information is one of the most  common and widely' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
768	page_content='the most  common and widely used information for knowledge representation. Wang et  al.  attempt to utilize textual information by jointly learning representations  of entities, relations, and words within the same low-dimensional embedding space.  The method contains three parts: the knowledge model, the text model, and the  alignment model. The knowledge model is learned on the triplets of KGs using  TransE, while the text model is learned on the text using skip-gram. As for the  alignment model, two methods are proposed to align entity and word representations  by utilizing Wikipedia anchors and entity names, respectively.  Modeling entities and words into the same embedding space has the merit  of encoding the information in both KGs and plain text in a uniﬁed semantic  space. However, Wang’s joint model mainly depends on the completeness of  Wikipedia anchors and suffers from the ambiguities of many entity names. To  address these issues, Zhong et al. [ 207] further improve the alignment model with' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
769	page_content='the alignment model with  entity descriptions, assuming that entities should have similar semantics to their  corresponding descriptions.  Different from the above joint models that merely consider the alignments  between KGs and textual information, description-embodied knowledge representation learning (DKRL) [ 176] can directly build knowledge representations  from entity descriptions. Speciﬁcally, DKRL provides two kinds of knowledge  representations: for each entity h, the ﬁrst is the structure-based representation  . hS, which can be learned based on the structure of KGs, and the second is the 302 X. Han et al. Notable WorkNoNoNototNN aabablblle ee WWWoororkrkWWW  William Shakespeare is CNN / CBOW  Text Description of Head  Entity A Midsummer CNN / CBOW  Text Description of Tail Entity hD  hD tD tD Knowledge Graph  tS hS Embedding of Relation (r)  Notable Work EEEmmbbebeedddddiing oof RReelattiioonn ((r) NNoNotabblble WoorkWW  Fig. 9.11 The architecture of DKRL [ 176]. The ﬁgure is redrawn according to' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
770	page_content='ﬁgure is redrawn according to Fig. 3 from DKRL  paper [ 176]  description-based representation .hDthat derives from its description. The score  function of DKRL derives from translation methods, and we have:  . f( h ,r ,t) =−(/bardblhS+r−tS/bardbl+/bardbl hS+r−tD/bardbl+/bardbl hD+r−tS/bardbl+/bardbl hD+r−tD/bardbl). (9.50)  As shown in Fig. 9.11, the description-based representations are constructed via  CBOW or CNNs that can encode rich textual information from plain text into  representations.  Compared with conventional non-contextualized methods, the representations  learned by DKRL are built with both structured and textual information and thus  could perform better. Besides, DKRL can represent an entity even if it is not in the  training set as long as there are a few sentences to describe this entity. Therefore,  with millions of new entities emerging every day, DKRL can handle these new  entities based on the setting of zero-shot learning.  Knowledge Representation with Types Entity types, as' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
771	page_content='with Types Entity types, as hierarchical schemas,  can provide rich structured information to understand entities. Generally, there are 9 Knowledge Representation Learning and Knowledge-Guided NLP 303 two paths for using entity types for knowledge representations: type-constrained  methods and type-augmented methods.  Type-Constrained Methods Krompaß et al. [ 78] take type information as constraints to improve existing methods like RESCAL and TransE via type constraints.  It is intuitive that for a particular relation, the head and tail entities associated with  this relation can only be of some speciﬁc types. For example, the head entity of the  relation Writes Books should be a person (more precisely, an author), and the  tail entity should be a book.  With type constraints, in RESCAL, the original factorization .Xn≈EM rnE/latticetopin  Eq.( 9.8) can be modiﬁed to  .X/primen≈E[Hrn,:]MrnE/latticetop [Trn,:], (9.51)  where .Hrn, .Trnare the entity sets ﬁtting the type constraints of the n-th relation . rn in' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
772	page_content='of the n-th relation . rn in . R, and .X/primenis a sparse adjacency matrix of the shape .|Hrn|×|Trn|. Intuitively,  only the entities that ﬁt type constraints will be considered during the factorization  process.  With type constraints, in TransE, negative samples with higher quality can be  generated. Learning knowledge representations need negative samples, and negative  samples are often generated by randomly replacing triplets’ head or tail entities.  Given a triplet ./angbracketlefth,r,t/angbracketright, with type constraints, its negative samples ./angbracketleft˜h,˜r,˜t/angbracketrightneed to  satisfy  .˜h∈Hr⊆E,˜t∈Tr⊆E. (9.52)  Intuitively, for an entity whose type does not match the relation r, it will not be  used to construct negative samples. The negative samples constructed with type  constraints are more confusing, which is beneﬁcial for learning more robust and  effective representations.  Type-Augmented Methods In addition to the simplicity and effectiveness of using  the type information as' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
773	page_content='the type information as constraints, the representation can be further enhanced  by using the type information directly as additional information in the learning.  Instead of merely viewing type information as type constraints, type-embodied  knowledge representation learning (TKRL) is proposed [ 177], utilizing hierarchical  type structures to instruct the construction of projection matrices. Inspired by  TransR that every entity should have multiple representations in different relation  spaces, the score function of TKRL is  .f( h ,r ,t) =− /bardbl Mrhh+r−Mrtt/bardbl, (9.53)  in which .Mrhand .Mrtare two projection matrices for h and t that depend on  their corresponding hierarchical types in this triplet. Two hierarchical encoders  are proposed to learn the above projection matrices, regarding all sub-types in the  hierarchy as projection matrices, where the recursive hierarchical encoder (RHE) is 304 X. Han et al. .  .  .  RHE WHE  h t  r h t  r i βiMc(i)  h i βiMc(i)  t Mc(m)  t Mc(m)  h  Mc(m−1)  t' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
774	page_content='Mc(m)  t Mc(m)  h  Mc(m−1)  t Mc(m−1)  h  Mc(1)  h Mc(1)  t  hch tct  hch tct  Fig. 9.12 The architecture of TKRL [ 177]. The ﬁgure is redrawn according to Fig. 2 from TKDL  paper [ 177]  based on the matrix multiplication operation, and the weighted hierarchical encoder  (WHE) is based on the matrix summation operation.  Figure 9.12 shows a simple illustration of TKRL. Taking a type hierarchy c with  m layers for instance, .c(i)is the i-th sub-type. Considering the sub-type at the ﬁrst  layer is the most precise and the sub-type at the last layer is the most general, TKRL  can get type-speciﬁc entity representations at different granularities following the  hierarchical structure, and the projection matrices can be formalized as  .MRHE c=m/productdisplay i=1Mc(i)=Mc(1)Mc(2)...Mc(m), MWHE c=m/summationdisplay i=1βiMc(i)=β1Mc(1)+···+ βmMc(m),(9.54)  where .Mc(i)stands for the projection matrix of the i-th sub-type of the hierarchical  type c and . βiis the corresponding weight of the sub-type. Taking RHE as' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
775	page_content='the sub-type. Taking RHE as an  example, given the entity William Shakespeare , it is ﬁrst projected to a general sub9 Knowledge Representation Learning and Knowledge-Guided NLP 305 Suit of armour  Armet Has a Part  Fig. 9.13 Examples of entity images. These examples come from the original paper of  TKRL [ 175]. All these images come from ImageNet [ 31]  type space like human and then sequentially projected to a more precise sub-type  like author or English author .  Knowledge Representation with Images Human cognition is highly related to  the visual information of objects in the real world. For entities in KGs, their corresponding images can provide intuitive visual information about their appearance,  which may give important hints about some attributes of the entities. For instance,  Fig.9.13 shows the images of Suit of armour and Armet . From these images, we can  easily infer the fact . /angbracketleftSuit of armour , Has a Part , Armet . /angbracketrightdirectly.  Image-embodied knowledge' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
776	page_content='Image-embodied knowledge representation learning (IKRL) [ 175] is proposed  to consider visual information when learning knowledge representations. Inspired  by the abovementioned DKRL, for each entity h, IKRL also proposes the imagebased representation . hIbesides the original structure-based representation . hS, and  jointly learns these entity representations simultaneously within the translationbased framework:  .f( h ,r ,t) =−(/bardblhS+r−tS/bardbl+/bardblhS+r−tI/bardbl+/bardblhI+r−tS/bardbl+/bardbl hI+r−tI/bardbl). (9.55)  More speciﬁcally, IKRL uses CNNs to obtain the representations of all entity  images, and then uses a matrix to project image representations from the image  embedding space to the entity embedding space. Since one entity may have multiple  images, IKRL uses an attention-based method to highlight those most informative  images. IKRL not only shows the importance of visual information for representing  entities but also shows the possibility of ﬁnding a uniﬁed space to represent' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
777	page_content='a uniﬁed space to represent  heterogeneous and multimodal information. 306 X. Han et al. Knowledge Representation with Logic Rules Typical KGs store knowledge in  the form of triplets with one relation linking two entities. Most existing knowledge  representation methods only consider the information of triplets independently,  ignoring the possible interactions and relations between different triplets. Logic  rules, which are certain kinds of summaries derived from human prior knowledge,  could help us with knowledge reasoning. For instance, given the triplet . /angbracketleftBeijing ,  Capital of , China . /angbracketright, we can easily infer the triplet . /angbracketleftBeijing , Located in ,  China . /angbracketrightwith high conﬁdence, since we know the logic rule Capital of . ⇒ Located in . To this end, various efforts have been devoted to exploring logic  rules for KGs [ 5, 127, 162]. Here we introduce a typical translation method that  jointly learns knowledge representations and logic rules – KALE' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
778	page_content='and logic rules – KALE [ 52]. KALE can  rank all possible logic rules based on the results pre-trained by TransE, and then  manually ﬁlter useful rules to improve knowledge representations.  The joint learning of KALE consists of two parts: triplet modeling and rule  modeling. For the triplet modeling, KALE deﬁnes its score function following the  translation assumption as  .f( h ,r ,t) =1−1 3√ d/bardblh+r−t/bardbl, (9.56)  in which d stands for the dimension of knowledge embeddings. .f( h ,r ,t) takes  a value in ., aiming to map discrete Boolean values (false or true) into a  continuous space ( .). For the rule modeling, KALE uses the t-norm fuzzy  logics [ 55] that compute the truth value of a complex formula from the truth values  of its constituents. Especially, KALE focuses on two typical types of logic rules.  The ﬁrst rule is .∀h,t:/angbracketlefth,r1,t/angbracketright⇒/angbracketleft h,r2,t/angbracketright(e.g., given . /angbracketleftBeijing , Capital of ,  China . /angbracketright, we can infer' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
779	page_content='we can infer that . /angbracketleftBeijing , Located in , China . /angbracketright). KALE represents the  score function of this logic rule . l1via speciﬁc t-norm logical connectives as  .f( l1)=f( h ,r 1,t)f (h,r 2,t)−f( h ,r 1,t)+1. (9.57)  The second rule is .∀h,e,t:/angbracketlefth,r1,e/angbracketright∧/angbracketlefte,r2,t/angbracketright⇒/angbracketleft h,r3,t/angbracketright(e.g., given . /angbracketleftTsinghua ,  Located in , Beijing . /angbracketrightand . /angbracketleftBeijing , Located in , China . /angbracketright, we can infer that  . /angbracketleftTsinghua , Located in , China . /angbracketright). And the second score function is deﬁned as  .f( l2)=f( h ,r 1,e)f (e,r 2,t)f (h,r 3,t)−f( h ,r 1,e)f (e,r 2,t)+1. (9.58)  The joint training contains all positive formulas, including triplet facts and logic  rules. Note that for the consideration of rule qualities, KALE ranks all possible  logic rules by their truth values with pre-trained TransE and manually ﬁlters some  rules. 9 Knowledge' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
780	page_content='some  rules. 9 Knowledge Representation Learning and Knowledge-Guided NLP 307 9.3.6 Summary  Knowledge representation learning is the cornerstone of applying knowledge for  NLP tasks. Knowledge can be incorporated into NLP tasks in a high-quality  manner only with good knowledge representations. In this section, we introduce  ﬁve directions of existing efforts to obtain distributed knowledge representations:  (1) linear methods , where relations are represented as linear transformations  between entities, (2) translation methods , where relations are represented as  additive translations between entities, (3) neural methods , where neural networks  parameterize the interactions between entities and relations, (4) manifold methods ,  where representations are learned in more ﬂexible and powerful geometric spaces  instead of the basic Euclidean geometry, and (5) contextualized methods , where  representations are learned under complex contexts.  In summary, from simple methods like SE and TransE, to more' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
781	page_content='like SE and TransE, to more sophisticated  methods that use neural networks (e.g., ConvE), the hyperbolic geometry (e.g.,  HyboNet), and textual information (e.g., DKRL), all these methods can provide  effective knowledge representations. These methods lay a solid foundation for further knowledge-guided NLP and knowledge acquisition, which will be introduced  in later sections. Note that more sophisticated methods do not necessarily lead to a  better application in NLP tasks. Researchers still need to choose the appropriate  knowledge representation learning method according to the characteristics of  speciﬁc tasks and the balance between computational efﬁciency and representation  quality.  9.4 Knowledge-Guided NLP  An effective NLP agent is expected to accurately and deeply understand user  demands, and appropriately and ﬂexibly give responses and solutions. Such kind  of work can only be done supported by certain forms of knowledge. To this end,  knowledge-guided NLP has been widely explored in recent' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
782	page_content='widely explored in recent years. Figure 9.14  shows a brief pipeline of utilizing knowledge for NLP tasks. In this pipeline,  we ﬁrst need to extract knowledge from heterogeneous data sources and store  the extracted knowledge with knowledge systems (e.g., KGs). Next, we need to  project knowledge systems into low-dimensional continuous spaces with knowledge  representation learning methods to manipulate the knowledge in a machine-friendly  way. Finally, informative knowledge representations can be applied to handle  various NLP tasks. After introducing how to learn knowledge representations,  we will detailedly show in this section how to use knowledge representations for  speciﬁc NLP tasks. 308 X. Han et al. Knowledge  Acquisition Knowledge  Representation  Learning Knowledge  Guidance Hamlet is a tragedy  written  by Willianm  Shakespeare  at an  uncertain date  between  1599 and 1602,...  Heterogeneous  Information KGs Information Retrieval  Question Answering  Dialogue System  Knowledge  Representations' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
783	page_content='Knowledge  Representations Knowledge  Applications  Fig. 9.14 The pipeline of utilizing knowledge for NLP tasks  The performance of NLP models (more generally, machine learning models)  depends on four critical factors: input data, model architecture, learning objective,  and hypothesis space. And the whole goal is to minimize the structural risk  .min f∈F1 NN/summationdisplay i=1L(yi,f(x i))+λJ(f ), (9.59)  where . xiis the input data, f is the model function, . Lis the learning objective, . Fis  the hypothesis space, and .J(f ) is the regularization term. By applying knowledge  to each of these four factors, we can form four directions to perform knowledgeguided NLP: (1) knowledge augmentation, which aims to augment the input data . xi with knowledge; (2) knowledge reformulation, which aims to reformulate the model  function f with knowledge; (3) knowledge regularization, which aims to regularize  or modify the learning objectives . Lwith knowledge; (4) knowledge transfer, which  aims to transfer the' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
784	page_content='which  aims to transfer the pre-trained parameters as prior knowledge to constrain the  hypothesis space . F.  Some works [ 60, 61] have brieﬂy introduced this knowledge-guided NLP  framework, while in this section, we will further present more details around the  four knowledge-guided directions. In addition, to make this section clearer and  more intuitive, we will also introduce some speciﬁc application cases of knowledgeguided NLP.  9.4.1 Knowledge Augmentation  Knowledge augmentation aims at using knowledge to augment the input features of  models. Formally, after using knowledge . kto augment the input, the original risk  function is changed to  .min f∈F1 NN/summationdisplay i=1L(yi,f( x i,k))+λJ(f ). (9.60) 9 Knowledge Representation Learning and Knowledge-Guided NLP 309 In order to achieve this kind of knowledge augmentation at the input level, existing  efforts focus on adopting two mainstream approaches.  Augmentation with Knowledge Context One approach is to directly add knowledge to the input as' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
785	page_content='add knowledge to the input as additional context. Augmenting language modeling with  retrieval is a representative method, such as REALM [ 53] and RAG [ 86]. These  methods retrieve background knowledge from additional corpora and then use the  retrieved knowledge to provide more information for language modeling. Since  the retrieved knowledge can signiﬁcantly improve the performance of language  understanding and generation, this approach to achieving knowledge augmentation  is widely applied by question answering [ 76, 111] and dialogue systems [ 139, 168].  Next, we will take RAG as an example to show how to perform knowledge  augmentation with knowledge context.  Example: Knowledge Augmentation for the Generation of PTMs In recent years,  PTMs have achieved state-of-the-art results on a variety of NLP tasks, but these  PTMs still face challenges in precisely accessing and manipulating knowledge  and cannot well handle various knowledge-intensive tasks, especially for various  text generation tasks that' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
786	page_content='text generation tasks that require extensive knowledge. To help PTMs utilize more  knowledge for text generation, retrieval-augmented generation (RAG) [ 86] has been  proposed with the aim of using the retrieved external knowledge as additional  context to generate text with higher quality.  Given the input sequence x to generate the output sequence y, the overall process  of the typical autoregressive generation method can be formalized as . P(y|x)=/producttextN i=1Pθ(yi|x,y 1:i−1), where . θis the parameters of the generator, N is the length  of y, and . yiis the i-th token of y. To use more knowledge to generate y, RAG ﬁrst  retrieves the external information z according to the input x and then generates the  output sequence y based on both x and z. To ensure that the retrieved contents can  cover the crucial knowledge required to generate y, the topK contents retrieved by  the retriever are all used to help generate the output sequence y, and thus the overall  generation process is  .PRAG-Sequence' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
787	page_content='process is  .PRAG-Sequence (y|x)≈/summationdisplay z∈top−K[Pη(·|x)]Pη(z|x)Pθ(y|x,z) =/summationdisplay z∈top-K[Pη(·|x)]Pη(z|x)N/productdisplay i=1Pθ(yi|x,z,y 1:i−1),(9.61)  where . ηis the parameters of the retriever.  In addition to applying knowledge augmentation at the sequence level, tokenlevel RAG is also introduced to provide ﬁner-grained augmentation. Speciﬁcally,  token-level RAG ﬁrst retrieves the top K external information according to the  input x, which is the same as RAG-Sequence. When generating text, token-level  RAG considers all the retrieved information together to generate the distribution for  the next output token, instead of sequence-level RAG which separately generates 310 X. Han et al. sequences based on the retrieved content and then merges the generated sequences.  Formally, the token-level RAG is  .PRAG-Token (y|x)≈N/productdisplay i=1/summationdisplay z∈top-K[P(·|x)]Pη(z|x)Pθ(yi|x,z,y 1:i−1). (9.62)  To sum up, RAG adds the retrieved knowledge to the input as additional context,' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
788	page_content='input as additional context,  which is a typical example of knowledge augmentation with knowledge context.  Augmentation with Knowledge Embeddings Another approach is to design special modules to fuse the original input features and knowledge embeddings and then  use the knowledgeable features as the input to solve NLP tasks. Since this approach  can help to fully utilize heterogeneous knowledge from multiple sources, many  works follow this approach to integrate unstructured text and structured symbolic  knowledge in KGs, leading to knowledge-guided information retrieval [ 87, 100] and  knowledge-guided PTMs [ 96, 124, 128, 163, 185, 205]. Next, we will ﬁrst introduce  word-entity duet, an effective information retrieval method, and then take a typical  knowledge-guided information retrieval method EDRM as an example to show how  to perform knowledge augmentation with knowledge embeddings.  Example: Knowledge Augmentation for Information Retrieval Information  retrieval focuses on obtaining informative' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
789	page_content='on obtaining informative representations of queries and documents,  and then designing effective metrics to compute the similarities between queries  and documents. The emergence of large-scale KGs has motivated the development  of entity-oriented information retrieval, which aims to leverage KGs to improve  the retrieval process. Word-entity duet [ 179] is a typical method for entity-oriented  information retrieval. Speciﬁcally, given a query q and a document d, word-entity  duet ﬁrst constructs bag-of-words . qwand . dw. By annotating the entities mentioned  by the query q and the document d, word-entity duet then constructs bag-of-entities  . qeand . de. Based on bag-of-words and bag-of-entities, word-entity duet utilizes the  duet representations of bag-of-words and bag-of-entities to match the query q and  the document d. The word-entity duet method consists of a four-way interaction:  query words to document words ( .qw-. dw), query words to document entities ( .qw. de), query entities to document' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
790	page_content='query entities to document words ( .qe-. dw), and query entities to document  entities ( .qe-. de).  On the basis of the word-entity duet method, EDRM [ 100] further uses distributed representations instead of bag-of-words and bag-of-entities to represent  queries and documents for ranking. As shown in Fig. 9.15, EDRM ﬁrst learns  the distributed representations of entities according to entity-related information in  KGs, such as entity descriptions and entity types. Then, EDRM uses interactionbased neural models [ 28] to match the query and documents with word-entity duet  distributed representations. More speciﬁcally, EDRM uses a translation layer that  calculates the similarity between query-document terms: ( .vi wqor . vi eq) and ( . vj wd or . vj ed). It constructs the interaction matrix .M={ Mww,Mwe,Mew,Mee},b y 9 Knowledge Representation Learning and Knowledge-Guided NLP 311 wv  t wo  tzt  Kernal  Pooling Soft Match  Feature Φ( M) Φ( M)  Interaction Matrix M Obama  Family  Tree Bigrams Unigrams' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
791	page_content='Tree Bigrams Unigrams  Trigrams  Obama  Description  Type  Family Tree  Description  Type  Enriched-entity  Embedding Enriched-entity  Embedding N-gram  Embedding Query Document  Final  Ranking  Score Text  KG Vwq  Veq Ved Vwd  Mww Mwe  Mew Mee  Fig. 9.15 The architecture of EDRM [ 100]. The ﬁgure is redrawn according to Fig. 1 from EDRM  paper [ 100]  denoting .Mww,Mwe,Mew,Meeas the interactions of .qw-. dw, .qw-. de, .qe-. dw, .qe. de, respectively. And the elements in these matrices are the cosine similarities of  corresponding terms:  .Mij ww=cos(vi wq,vj wd);Mij we=cos(vi wq,vj ed), Mij ew=cos(vi eq,vj wd);Mij ee=cos(vi eq,vj ed).(9.63)  The ﬁnal ranking feature .Φ(M)is a concatenation of four cross matches:  .Φ(M)=[φ(Mww);φ(Mwe);φ(Mew);φ(Mee)], (9.64)  where .φ(·)can be any function used in interaction-based neural ranking models,  such as using Gaussian kernels to extract the matching feature from the matrix  . Mand then pool into a feature vector .φ(M). For more details of designing . φ(·) and using' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
792	page_content='of designing . φ(·) and using .Φ(M)to compute ranking scores, we suggest referring to some typical  interaction-based information retrieval models [ 28, 180].  To sum up, EDRM introduces distributed knowledge representations to improve  the representations of queries and documents for information retrieval, which is a  typical example of knowledge augmentation with knowledge embeddings.  9.4.2 Knowledge Reformulation  Knowledge reformulation aims at using knowledge to enhance the model processing  procedure. Formally, after using knowledge to reformulate the model function, the 312 X. Han et al. original risk function is changed to  .min fk∈F1 NN/summationdisplay i=1L(yi,fk(xi))+λJ(fk), (9.65)  where .fk(·)is the model function reformulated by knowledge. Considering the  complexity of the model function .f(·), it is difﬁcult for us to comprehensively  discuss the construction process of . fk. To introduce this section more clearly and  give readers a more intuitive understanding of knowledge reformulation,' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
793	page_content='of knowledge reformulation, we here  focus on introducing two relatively simple knowledge reformulation scenarios:  knowledgeable preprocessing and post-processing.  Knowledgeable Preprocessing On the one hand, we can use the underlying  knowledge-guided model layer for preprocessing to make features more informative [ 160, 167, 194]. Formally, . xiis ﬁrst input to the function k and then input to the  function f as  .fk(xi)=f( k(xi)), (9.66)  where .k(·)is the knowledge-guided model function used for preprocessing and . f(·) is the original model function. The knowledge-guided attention mechanism is a representative approach that usually leverages informative knowledge representations  to enhance model feature processing. Next, we will take two typical knowledgeguided attention mechanisms [ 58, 178] as examples to show how to use knowledge  for model preprocessing.  Example: Knowledge Reformulation for Knowledge Acquisition Knowledge acquisition includes two main approaches. One is knowledge graph' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
794	page_content='One is knowledge graph completion (KGC),  which aims to perform link prediction on KGs. The other is relation extraction (RE)  to predict relations between entity pairs based on the sentences containing entity  pairs. Formally, given sentences .s1,s2,···containing the entity pair . h,t,R Ea i m s  to evaluate the likelihood that a relation r and .h,tcan form a triplet based on the  semantics of these sentences. Different from RE, KGC only uses the representations  of .h,r,t learned by knowledge representation learning methods to compute the  score function .f( h ,r ,t) , and the score function serves knowledge acquisition.  Generally, RE and KGC models are learned separately, and these models cannot  fully integrate text and knowledge to acquire more knowledge. To this end, Han et  al.  propose a joint learning framework for knowledge acquisition, which can  jointly learn knowledge and text representations within a uniﬁed semantic space  via KG-text alignments. Figure 9.16 shows the brief framework of the' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
795	page_content='the brief framework of the joint model.  For the text part, the sentence with two entities (e.g., Mark Twain and Florida )i s  regarded as the input to the encoder, and the output is considered to potentially  describe speciﬁc relations (e.g., Place of Birth ). For the KG part, entity and  relation representations are learned via a knowledge representation learning method 9 Knowledge Representation Learning and Knowledge-Guided NLP 313 Place of Birth Florida Mark Twain  Encoder  was [Mark Twain] born in [Florida] Word  Position + = Mark Twain (h) Place of Birth (r) Florida (t)  Text Fact KG  Fig. 9.16 The joint learning framework for knowledge acquisition [ 58]. The ﬁgure is redrawn  according to Fig. 1 from the paper of Han et al. [ 58]  such as TransE. The learned representations of the KG and text parts are aligned  during the training process.  Given sentences .{s1,s2,···} containing the same entity pair . h,t, not all of these  sentences can help predict the relation between h and t. For a given' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
796	page_content='between h and t. For a given relation r,  there are many triplets .{(h1,r ,t 1),(h 2,r ,t 2),···} containing the relation, but not  all triplets are important enough for learning the representation of r. Therefore,  as shown in Fig. 9.17, Han et al. further adopt mutual attention to reformulate  the preprocessing of both the text and knowledge models, to select more useful  sentences for RE and more important triplets for KGC. Speciﬁcally, we use  knowledge representations to highlight the more valuable sentences for predicting  the relation between h and t. This process can be formalized as  .α=Softmax (r/latticetop htWKAS),ˆs=Sα/latticetop, (9.67)  where .WKAis a bilinear matrix of the knowledge-guided attention, . S=[ s1,s2,···] are the hidden states of the sentences .s1,s2,···. .r/latticetop htis a representation that 314 X. Han et al. Fig. 9.17 The mutual attention to reformulate both the text and knowledge models [ 58]. The ﬁgure is redrawn according to Fig. 1 from the paper of Han et  al.  9 Knowledge' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
797	page_content='of Han et  al.  9 Knowledge Representation Learning and Knowledge-Guided NLP 315 can indicate the latent relation between h and t, computed based on knowledge  representations. . ˆsis the feature after synthesizing the information of all sentences,  which is used to predict the relation between h and t ﬁnally.  Similar to using knowledge representations to select high-quality sentences, we  can also use semantic information to select triples conducive to learning relations.  This process can be formalized as  .α=Softmax (r/latticetop TextWSAR),r KG=Rα/latticetop, (9.68)  where .WSAis a bilinear matrix of the semantics-guided attention, . R= [rh1t1,rh2h2,···] are the triplet-speciﬁc relation representations of the triplets  .{(h1,r ,t 1),(h 2,r ,t 2),···}. .rTextis the semantic representation of the relation r  used by the RE model. .rKGis the ﬁnal relation representation enhanced with  semantic information.  This work is a typical attempt to apply knowledge representations of existing  KGs to reformulate' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
798	page_content='existing  KGs to reformulate knowledge acquisition models. In Sect. 9.5, we will introduce  knowledge acquisition in more detail.  Example: Knowledge Reformulation for Entity Typing Entity typing is the task of  detecting semantic types for a named entity (or entity mention) in plain text. For  example, given a sentence Jordan played 15 seasons in the NBA , entity typing aims  to infer that Jordan in this sentence is a person ,a nathlete , and even a basketball  player . Entity typing is important for named entity disambiguation since it can  narrow down the range of candidates for an entity mention [ 21]. Moreover, entity  typing also beneﬁts massive NLP tasks such as relation extraction [ 98], question  answering [ 184], and knowledge base population [ 20].  Neural models [ 36, 138] have achieved state-of-the-art performance for ﬁnegrained entity typing. However, these methods only consider the textual information  of named entity mentions for entity typing while ignoring the rich information that  KGs can' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
799	page_content='information that  KGs can provide for determining entity types. For example, in the sentence In  1975, Gates . . . Microsoft . . . company , even though we have no type information  of Microsoft in KGs, other entities similar to Microsoft (e.g., IBM ) in KGs can  also provide supplementary information to help us determine the type of Microsoft .  To take advantage of KGs for entity typing, knowledge-guided attention for neural  entity typing (KNET) has been proposed [ 178].  As illustrated in Fig. 9.18, KNET mainly consists of two parts. Firstly, KNET  builds a neural network, including a bidirectional LSTM and a fully connected  layer, to generate context and named entity mention representations. Secondly,  KNET introduces a knowledge-guided attention mechanism to emphasize those  critical words and improve the quality of context representations. Here, we introduce  the knowledge-guided attention in detail. KNET employs the translation method  TransE to obtain entity embedding . efor each entity e in KGs.' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
800	page_content='. efor each entity e in KGs. During the training  process, given the context words .c={ wi,···,wj}, a named entity mention m 316 X. Han et al. Entity  Representation  Word  Representations Bidirectional  LSTM States Knowledge-guided  Attention Context and Mention  Representations Final Representation  for Entity Typing  Chaplin and Julie Christie Concentrating  Context Entity Mention ContextEntity Embeddings Julie  Christie  Fig. 9.18 The architecture of KNET [ 178]. The ﬁgure is redrawn according to Fig. 1 from KNET paper [ 178] 9 Knowledge Representation Learning and Knowledge-Guided NLP 317 and its corresponding entity embedding . e, KNET computes the knowledge-guided  attention as  .α=Softmax (e/latticetopWKAH),c=Hα/latticetop, (9.69)  where .WKAis a bilinear matrix of the knowledge-guided attention and . H= [hi,···,hj]are the bidirectional LSTM states of .{wi,···,wj}. The context  representation . cis used as an important feature for the subsequent process of type  classiﬁcation.  Through the above two' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
801	page_content='Through the above two examples of knowledge acquisition and entity typing,  we introduce how to highlight important features based on knowledge in the  model preprocessing stage, so as to output better features to help improve model  performance.  Knowledgeable Post-Processing Apart from reformulating model functions for  pre-processing, on the other hand, knowledge can be used as an expert at the end of  models for post-processing, guiding models to obtain more accurate and effective  results [ 1, 51, 124]. Formally, . xiis ﬁrst input to the function f and then input to the  function k as  .fk(xi)=k(f( xi)), (9.70)  where .k(·)is the knowledge-guided model function used for post-processing and  .f(·)is the original model function. Knowledgeable post-processing is widely  used by knowledge-guided language modeling to improve the word prediction  process [ 1, 51]. Next, we will take a typical knowledge-guided language modeling  method NKLM [ 1] as an example to show how to use knowledge representations to' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
802	page_content='knowledge representations to  improve model post-processing (Fig. 9.19).  Example: Knowledge Post-Processing on Language Modeling NKLM [ 1]a i m s  to perform language modeling by considering both semantics and knowledge to  generate text. Speciﬁcally, NKLM designs two ways to generate each word in the  text. The ﬁrst is the same as conventional auto-regressive models that generate a  vocabulary word according to the probabilities over the vocabulary. The second  is to generate a knowledge word according to external KGs. Speciﬁcally, NKLM  uses the LSTM architecture as the backbone to generate words. For external KGs,  NKLM stores knowledge representations to build a knowledgeable module . K= {(a1,O1),(a2,O2),···,(an,On)}, in which . Oidenotes the description of the i-th  fact, . aidenotes the concatenation of the representations of the head entity, relation  and tail entity of the i-th fact.  Given the context .{w1,w2,···,wt−1}, NKLM takes both the vocabulary  word representation .wv t−1, the knowledge word' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
803	page_content='.wv t−1, the knowledge word representation .wo t−1, and the  knowledge-guided representation .at−1at the step .t−1as LSTM’s input  .xt={ wv t−1,wo t−1,at−1}. . xtis then fed to LSTM together with the hidden state  .ht−1to get the output state . ht. Next, a two-layer multilayer perceptron .f(·)is  applied to the concatenation of . htand . xtto get the fact key .kt=f(ht,xt). . ktis 318 X. Han et al. at−1 wv  t−1 wo  t−1 LSTM ht−1 a1  a2  a3  a4  ...  an ... O1  O2  O3  O4  ht Fact Search kt at ht wv  t wo  tzt  External Knowledge Copy  NaF  xt On  Fig. 9.19 T h ea r c h i t e c t u r eo fN K L M[ 1]. A special entry .(NaF,)is included in the knowledgable  module to allow the absence of knowledge when the currently generated word is not included in  the knowledgable module. NaF is short for not a fact . The ﬁgure is redrawn according to Fig. 1  from NKLM paper [ 1]  then used to extract the most relevant fact representation . atfrom the knowledgeable  module. Finally, the selected fact . atis combined with the' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
804	page_content='fact . atis combined with the hidden state . htto output  a vocabulary word .wv tand knowledge word .wo t(which is copied from the entity  name in the t-th fact), and then determine which word to generate at the step t.  Overall, by using KGs to enhance the post-processing of language modeling,  NKLM can generate sentences that are highly related to world knowledge, which  are often difﬁcult to model without considering external knowledge. 9 Knowledge Representation Learning and Knowledge-Guided NLP 319 9.4.3 Knowledge Regularization  Knowledge regularization aims to use knowledge to modify the objective functions  of models:  .min f∈F1 NN/summationdisplay i=1L(yi,f( x i))+λkLk(k,f (x i))+λJ(f ), (9.71)  where .Lk(k,f (x i))is the additional predictive targets and learning objectives  constructed based on knowledge and .λkis a hyper-parameter to control the  knowledgeable loss term.  Distant supervision [ 109] is a representative method that uses external knowledge  to heuristically annotate corpora as' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
805	page_content='annotate corpora as additional supervision signals. For many vital  information extraction tasks, such as RE [ 58, 72, 91, 196] and entity typing [ 36, 138,  178], distant supervision is widely applied for model training. As we will introduce  distant supervision in Sect. 9.5 to show how to build additional supervision signals  with knowledge, we do not introduce concrete examples here.  Knowledge regularization is also widely used by knowledge-guided PTMs [ 124,  163, 205]. To fully integrate knowledge into language modeling, these knowledgeguided PTMs design knowledge-speciﬁc tasks as their pre-training objectives and  use knowledge representations to build additional prediction objectives. Next, we  will take the typical knowledge-guided PTM ERNIE [ 205] as an example to show  how knowledge regularization can help the learning process of models.  Example: Knowledge Regularization for PTMs PTMs like BERT [ 33] have great  abilities to extract features from text. With informative language representations,' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
806	page_content='language representations,  PTMs obtain state-of-the-art results on various NLP tasks. However, the existing  PTMs rarely consider incorporating external knowledge, which is essential in  providing related background information for better language understanding. For  example, given a sentence Bob Dylan wrote Blowin’ in the Wind and Chronicles:  Volume One , without knowing Blowin’ in the Wind is a song and Chronicles: Volume  One is a book , it is not easy to know the occupations of Bob Dylan , i.e., songwriter  and writer .  To this end, an enhanced language representation model with informative entities  (ERNIE) is proposed [ 205]. Figure 9.20 is the overall architecture of ERNIE.  ERNIE ﬁrst augments the input data using knowledge augmentation as we have  mentioned in Sect. 9.4.1 . Speciﬁcally, ERNIE recognizes named entity mentions  and then aligns these mentions to their corresponding entities in KGs. Based  on the alignments between text and KGs, ERNIE takes the informative entity  representations as' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
807	page_content='entity  representations as additional input features.  Similar to conventional PTMs, ERNIE adopts masked language modeling and  next sentence prediction as the pre-training objectives. To better fuse textual and  knowledge features, ERNIE proposes denoising entity auto-encoding (DAE) by  randomly masking some mention-entity alignments in the text and requiring models 320 X. Han et al. e(i−1)  1 e(i−1)  2  bob dylan wrote w(i−1)  1w(i−1)  2w(i−1)  3w(i−1)  n  1962 Multi-Head Attention Multi-Head Attention Information Fusion w(i)  1w(i)  2 e(i)  1  w(i)  n e(i)  2  w(i)  3 e(i)  1 e(i)  2  ˜e(i)  1 ˜e(i)  2 ˜w(i)  1 ˜w(i)  2˜w(i)  3 ˜w(i)  n  Token Input Entity Input Token Output Entity Output  Bob Dylan wrote in 1962 blow w(i−1)  4 ˜w(i)  4 w(i)  4  Multi-Head  Attention Feed  Forward  Nx Multi-Head  Attention Information  Fusion  Token Input Multi-Head  Attention  Entity Input Mx Token Output Entity Output  Bob Dylan Aggregator  Transformer Aggregator  (a) Model Achitecture (b) Aggregator K-Encoder' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
808	page_content='(b) Aggregator K-Encoder  T-Encoder ˜e(i)  1˜e(i)  2  Fig. 9.20 The architecture of ERNIE [ 205]. The ﬁgure is redrawn according to Fig. 2 from ERNIE paper [ 205] 9 Knowledge Representation Learning and Knowledge-Guided NLP 321 to select appropriate entities to complete the alignments. Different from the existing  PTMs that predict tokens with only using local context, DAE requires ERNIE to  aggregate both text and knowledge to predict both tokens and entities, leading  to knowledge-guided language modeling. DAE is clearly a knowledge-guided  objective function.  In addition to ERNIE, there are other representative works on knowledge  regularization. For example, KEPLER [ 163] incorporates structured knowledge into  its pre-training. Speciﬁcally, KEPLER encodes the textual description of entities  as entity representations and predicts the relation between entities based on these  description-based representations. In this way, KEPLER can learn the structured  information of entities and relations in KGs in' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
809	page_content='and relations in KGs in a language-modeling manner.  WKLM [ 181] proposes a pre-training objective type-constrained entity replacement.  Speciﬁcally, WKLM randomly replaces the named entity mentions in the text with  other entities of the same type and requires the model to identify whether an entity  mention is replaced or not. Based on the new pre-training objective, WKLM can  accurately learn text-related knowledge and capture the type information of entities.  From Fig. 9.20, we can ﬁnd that ERNIE also adopts knowledge reformulation  by adding the new aggregator layers designed for knowledge integration to the  original Transformer architecture. To a large extent, the success of knowledgeguided PTMs comes from the fact that these models use knowledge to enhance  important factors of model learning. Up to now, we have introduced knowledge  augmentation, knowledge reformulation, and knowledge regularization. Next, we  will further introduce knowledge transfer.  9.4.4 Knowledge Transfer  Knowledge transfer' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
810	page_content='Transfer  Knowledge transfer aims to use knowledge to obtain a knowledgeable hypothesis  space, reducing the cost of searching optimal parameters and making it easier  to train an effective model. There are two typical approaches to transferring  knowledge: (1) transfer learning [ 120] that focuses on transferring model knowledge learned from labeled data to downstream task-speciﬁc models and (2) selfsupervised learning [ 97] that focuses on transferring model knowledge learned from  unlabeled data to downstream task-speciﬁc models. More generally, the essence of  knowledge transfer is to use prior knowledge to constrain the hypothesis space:  .min f∈Fk1 NN/summationdisplay i=1L(yi,f(x i))+λJ(f ), (9.72)  where . Fkis the knowledge-guided hypothesis space.  Knowledge transfer is widely used in NLP. The ﬁne-tuning stage of PTMs is a  typical scenario of knowledge transfer, which aims to transfer the versatile knowledge acquired in the pre-training stage to speciﬁc tasks. Intuitively, after pre-training 322 X.' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
811	page_content='after pre-training 322 X. Han et al. Mark Twain was born in  _____ PTM Florida  A frog has  _____  legs PTM four  I like eating apples. It is    _____ PTM great  This smells stinky. It is    _____ PTM terrible Class: Positive Class: Negative  It is It is Prompt Learning Knowledge Probing  Fig. 9.21 By using prompts, we can stimulate the knowledge of PTMs to handle speciﬁc tasks  such as sentiment classiﬁcation and predicting symbolic knowledge  a PTM, ﬁne-tuning this PTM can be seen as narrowing down searching task-speciﬁc  parameters to a local hypothesis space around the pre-trained parameters rather than  the global hypothesis space.  As we mentioned in Chap. 5, in addition to ﬁne-tuning PTMs, prompt learning  has also been widely explored. Despite the success of ﬁne-tuning PTMs, it still  faces two challenges. On the one hand, there is a gap between the objectives of  pre-training and ﬁne-tuning, since most PTMs are learned with language modeling  objectives, yet downstream tasks may have quite different' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
812	page_content='may have quite different objective forms such as  classiﬁcation, regression, and labeling. On the other hand, as the parameter size of  PTMs increases rapidly, ﬁne-tuning PTMs has become resource-intensive. In order  to alleviate these issues, prompts have been introduced to utilize the knowledge of  PTMs in an effective and efﬁcient manner [ 93].  A ss h o w ni nF i g . 9.21, prompt learning aims at converting downstream tasks into  a cloze-style task similar to pre-training objectives so that we can better transfer  the knowledge of PTMs to downstream tasks. Taking prompt learning for sentiment  classiﬁcation as an example, a typical prompt consists of a template (e.g., ...I tw a s  [MASK] .) and a label word set (e.g., great and terrible ) as candidates for predicting  [MASK] . By changing the input using the template to predict [MASK] and mapping  the prediction to corresponding labels, we can apply masked language modeling for  sentiment classiﬁcation. For example, given the sentence I like eating' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
813	page_content='the sentence I like eating apples. ,w e  ﬁrst use the prompt template to get the new input sentence I like eating apples. It was  [MASK] . According to PTMs predicting great or terrible at the masked position,  we can determine whether this sentence is positive or negative.  The recently proposed large-scale PTM GPT-3 [ 17] shows the excellent performance of prompt learning in various language understanding and generation tasks.  In prompt learning, all downstream tasks are transformed to be the same as the pretraining tasks. And since the parameters of PTMs are frozen during prompt learning,  the size of hypothesis space is much smaller compared to ﬁne-tuning, making more  efﬁcient knowledge transfer possible.  Overall, PTMs play an important role in driving the use of model knowledge. And to some extent, PTMs also inﬂuence the paradigm of using symbolic  knowledge in NLP. As shown in Fig. 9.21, many knowledge probing works [ 74,  125, 126] show that by designing prompt, PTMs can even complete structured' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
814	page_content='can even complete structured  knowledge information. These studies show that PTMs, as good carriers of symbolic 9 Knowledge Representation Learning and Knowledge-Guided NLP 323 knowledge, can memorize symbolic knowledge well. Moreover, these studies also  indicate one factor that may contribute to the power of PTMs: knowledge can be  spontaneously abstracted by PTMs from large-scale unstructured data and then used  to solve concrete problems, and the abstracted knowledge matches well with the  knowledge formed by human beings. Inspired by this, we can further delve into  how PTMs abstract knowledge and how PTMs store knowledge in their parameters, which is very meaningful for further advancing the integration of symbolic  knowledge and model knowledge. On the other hand, all these studies also show  the importance of knowledge-guided NLP. Compared with letting models slowly  abstract knowledge from large-scale data, directly injecting symbolic knowledge  into models is a more effective solution.  The success' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
815	page_content='solution.  The success of PTMs demonstrates the clear advantages of fully transferring  existing model knowledge in terms of computing efﬁciency and effectiveness, as  compared to learning a model from scratch. Since we have introduced the details  of PTMs in Chap. 5, in this section, we mainly discuss the valuable properties of  knowledge transfer owned by PTMs.  9.4.5 Summary  In this section, we present several ways in which knowledge is used to guide  NLP models. Depending on the location of model learning where knowledge steps  in, we group the guidance from knowledge into four categories: (1) knowledge  augmentation , where knowledge is introduced to augment the input data, (2)  knowledge reformulation , where special model modules are designed to interact  with knowledge, (3) knowledge regularization , where knowledge does not directly  intervene the forward pass of the model but acts as a regularizer, and (4) knowledge  transfer , where knowledge helps narrow down the hypothesis space to achieve more' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
816	page_content='space to achieve more  efﬁcient and effective model learning.  These approaches enable effective integration of knowledge into deep models,  allowing models to leverage sufﬁcient knowledge (especially symbolic knowledge)  to better perform NLP tasks. Since knowledge is essential for models to understand  and complete the NLP tasks, knowledge-guided NLP is a worthwhile area for  researchers to continue to explore.  9.5 Knowledge Acquisition  The KBs used in early expert systems and the KGs built in recent years both have  long relied on manual construction. Manually organizing knowledge ensures that  knowledge systems are constructed with high quality but suffers from inefﬁciency,  incompleteness, and inconsistency in the annotation process. As shown in Fig. 9.22, 324 X. Han et al. 23M  2017 46M  2018 80M  2020 65M  2019 The number of entities The development of Wikidata  100M  2022 90M  2021  Fig. 9.22 The development trend of Wikidata from 2017 to 2022  the number of entities in the popular open-source KG' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
817	page_content='in the popular open-source KG Wikidata4 grew at a rate of  over 15 million per year from 2017 to 2022. At this rate of growth, it is unrealistic  to rely solely on human annotation to organize large-scale human knowledge.  Therefore, it is crucial to explore automatic knowledge acquisition, which can  signiﬁcantly better support knowledge representation learning and knowledgeguided NLP. In this section, taking KGs that store rich world knowledge as an  example, we describe how to perform automatic knowledge acquisition to enrich  the amount of knowledge for KGs.  Generally, we have several approaches to acquiring knowledge. Knowledge  graph completion (KGC) and RE are two typical approaches. As shown in Fig. 9.23,  KGC aims to obtain new knowledge by reasoning over the internal structure of  KGs. For example, given the triplet . /angbracketleftMark Twain , Place of Birth , Florida . /angbracketright and the triplet . /angbracketleftFlorida , City of , U.S.A . /angbracketright, we can easily infer the fact .' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
818	page_content='can easily infer the fact . /angbracketleftMark  Twain , Citizenship , U.S.A . /angbracketright. Different from KGC that infers new knowledge  based on the internal information of KGs, RE focuses on detecting relations  between entities from external plain text. For example, given the sentence Mark  Twain was an American author and humorist , we can get the triplet . /angbracketleftMark  Twain , Citizenship , U.S.A . /angbracketrightfrom the semantic information of the sentence.  Since the text is the core carrier of human knowledge, RE can obtain more and  broader knowledge than KGC. Moreover, KGC highly relies on the knowledge  representation learning methods that we have introduced in the previous Sect. 9.3.  Therefore, in this section, we only introduce knowledge acquisition by using RE as  an example.  As RE is an important way to acquire knowledge, many researchers have devoted  extensive efforts to this ﬁeld in the past decades. Various statistical RE methods  based on feature engineering [ 75, 208],' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
819	page_content='engineering [ 75, 208], kernel models [ 18, 27], and probabilistic 4 https:// www. wikidata. org.  9 Knowledge Representation Learning and Knowledge-Guided NLP 325 Mark Twain U.S.A  Florida Citizenship  Place of Birth City of Mark Twain U.S.A  Mark Twain was an American author and humorist Citizenship Knowledge Graph Completion Relation Extraction  Fig. 9.23 An example of knowledge graph completion and relation extraction  graphical models [ 133, 134] have been proposed and achieved promising results.  With the development of deep learning, neural networks as a powerful tool for  encoding semantics have further advanced the development of RE, including recursive neural networks [ 110, 144], convolutional neural networks [ 92, 197], recurrent  neural networks [ 115, 201], and graph neural networks [ 204, 210]. Considering that  neural networks have become the backbone of NLP research in recent years, we  focus on introducing knowledge acquisition with neural RE models in this section.  For those statistical' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
820	page_content='For those statistical methods, some surveys [ 121, 195] can provide sufﬁcient details  about them. Next, we present how to acquire knowledge in various complex textual  scenarios around neural RE, including sentence-level methods, bag-level methods,  document-level methods, few-shot methods, and contextualized methods.  9.5.1 Sentence-Level Relation Extraction  Sentence-level RE is the basis for acquiring knowledge from text to enrich KGs.  As shown in Fig. 9.24, sentence-level RE is based on the sentence-level semantics  to extract relations between entities. Formally, given an input sentence . s= {w1,w2,···,wn}consisting of n words and an entity pair ( . e1, . e2) in the sentence,  sentence-level RE aims to obtain the probability distribution .P(r|s,e1,e2)over the  relation set . R(.r∈R). Based on .P(r|s,e1,e2), we can infer all relations between  . e1and . e2.  Mark Twain  was born in Florida 0.05  0.01 0.89  ... Citizenship  CityOf PlaceOfBirth  Model 0.05 Citizenshi p  0.01 ...  CityOf  Fig. 9.24 An' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
821	page_content='...  CityOf  Fig. 9.24 An example of sentence-level relation extraction 326 X. Han et al. Fig. 9.25 The process of encoding sentence-level semantic information to detect the relations  expressed by a given sentence  Learning an effective model to measure .P(r|s,e1,e2)requires efforts of three  different aspects. As shown in Fig. 9.25, the ﬁrst is to encode the input words into  informative word-level features .{w1,w2,···,wn}that can well serve the relation  classiﬁcation process. The second is to train a sentence encoder, which can well  encode the word-level features .{w1,w2,···,wn}into the sentence-level feature . s with respect to the entity pair ( . e1, . e2). The third is to train a classiﬁer that can well  compute the conditional probability distribution .P(r|s,e1,e2)over all relations in  . Rbased on the sentence-level feature . s. Next, we will present some typical works  in each of these three aspects.  Word-Level Semantics Encoding Given the sentence .s={w1,w2,···,wn}and  the entity pair ( . e1, .' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
822	page_content='the entity pair ( . e1, . e2), before encoding sentence semantics and further classifying  relations, we have to project the discrete words of the source sentence s into a  continuous vector space to get the input representation .w={ w1,w2,···,wn}.I n  general, widely used word-level features include the following components:  Word Embeddings Word embeddings aim to encode the syntactic and semantic  information of words into distributed representations, i.e., each word is represented  by a vector. Word embeddings are the basis for encoding word-level semantics,  and word2vec [ 108] and GloVe [ 123] are the most common ways to obtain word  embeddings.  Position Embeddings Position embeddings aim to encode which input words  belong to the target entities and how close each word is to the target entities. Specifically, for each word . wi, its position embedding is formalized as the combination of  the relative distances from . wito . e1and . e2. For instance, given the sentence Mark  Twain was an American' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
823	page_content='Mark  Twain was an American author and humorist , the relative distance from the word  was to the entity Mark Twain is. −1, and the distance to the entity American is 2. The  relative distances .−1and 2 are then encoded into the position embedding to provide  a positional representation for the word was. Since RE highly relies on word-level 9 Knowledge Representation Learning and Knowledge-Guided NLP 327 positional information to capture entity-speciﬁc semantics, position embeddings are  w i d e l yu s e di nR E[ 135, 197, 201].  Part-of-Speech (POS) Tag Embeddings POS Tag Embeddings aim to encode the  word-level lexical information (e.g., nouns, verbs, etc.) of the sentence. Formally, all  words in the sentence are encoded into embeddings according to their POS tags, and  these POS tag embeddings can serve as lexical complements for word embeddings  and position embeddings [ 19, 183, 209].  Hypernym Embeddings Hypernym embeddings aim to leverage the prior knowledge of hypernyms in WordNet [ 43]. Compared to' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
824	page_content='in WordNet [ 43]. Compared to POS tags, hypernyms are  ﬁner-grained. WordNet is a typical linguistic KG. In WordNet, all words are  grouped into sets of cognitive synonyms (synsets), and each synset can express a  distinct concept. Hypernyms are deﬁned among these synsets. Here is just a brief  introduction to WordNet, and we will introduce linguistic knowledge in detail in  Chap. 10. When given the hypernym information of each word in WordNet (e.g.,  noun.food, verb.motion, etc), it is easy to connect this word with other words  that are different but conceptually similar. Similar to POS tag embeddings, each  hypernym tag in WordNet has a tag-speciﬁc embedding, and each word in a sentence  is encoded into a hypernym embedding based on the word-speciﬁc hypernym tag.  The above embeddings are usually concatenated together to obtain the ﬁnal input  features .w={ w1,w2,···,wn}, and. wis used to support further encoding sentencelevel semantics.  Sentence-Level Semantics Encoding Based on word-level features, we' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
825	page_content='on word-level features, we introduce  different sentence encoders to encode sentence-level semantic information for RE:  Convolutional Neural Network Encoders CNN encoders [ 135, 197] use convolutional layers to extract local features and then use pooling operations to encode all  local features into a ﬁxed-sized vector.  Here we take an encoder with only one convolutional layer and one max-pooling  operation as an example. Given the word-level features .{w1,w2,···,wn},t h e  convolutional layer can be formalized as  .{h1,h2,···,hn}=CNN({w1,w2,···,wn}), (9.73)  where .CNN(·)indicates the convolution operation inside the convolutional layer, . hi is the hidden state of the i-th word, and we have introduced this part in Chap. 4.  Then, the sentence representation . sis obtained by using the max-pooling operation,  where the i-th element of . sis given as  .[s]i=max 1≤j≤n[hj]i, (9.74)  where .[·]iis the i-th element of the vector.  Further, PCNN [ 196], which is a variant of CNN, adopts a piecewise maxpooling' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
826	page_content='adopts a piecewise maxpooling operation. All hidden states .{p1,p2,···pn}are divided into three parts by 328 X. Han et al. the positions of . e1and . e2. The max-pooling operation is performed on the three  segments respectively, and . sis the concatenation of the three pooling results.  Recurrent Neural Network Encoders RNN encoders [ 201] use recurrent layers  to learn temporal features on the input sequence. Given the word-level features  .{w1,w2,···,wn}, each input word feature is fed into recurrent layers step by step.  For the i-th step, the network takes . wiand the hidden state of the last step .hi−1as  input, and the whole process is given as  .hi=RNN(wi,hi−1), (9.75)  where .RNN(·)indicates the RNN function, which can be a LSTM unit or a GRU  unit mentioned in Chap. 4.  The conventional recurrent models typically encode sequences from start to  end and build the hidden state of each step only considering its preceding steps.  Besides unidirectional RNNs, bidirectional RNNs [ 137] are also adopted' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
827	page_content='RNNs [ 137] are also adopted to encode  sentence-level semantics, and the whole process is given as  .← −hi=← − −RNN(wi,← −hi+1),− →hi=− − →RNN(wi,− →hi−1),hi=[← −hi;− →hi], (9.76)  where .[·;·] is the concatenation of two vectors.  Similar to the abovementioned convolutional models, the recurrent models also  use pooling operations to extract the global sentence feature . s, which forms the  representation of the whole input sentence. For example, we can use a max-pooling  operation to obtain . s:  .[s]i=max 1≤j≤n[hj]i. (9.77)  Besides pooling operations, attention operations [ 3] can also combine all local  features. Speciﬁcally, given the output states .H=[ h1,h2,···,hn]produced by  a recurrent models, . scan be formalized as  .α=Softmax (q/latticetopf(H)),s=Hα/latticetop, (9.78)  where . qis a learnable query vector and .f(·)is an attention transformation function.  Moreover, some works [ 110] propose to encode semantics from both the word  sequence and tree-structured dependency of a sentence by' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
828	page_content='dependency of a sentence by stacking bidirectional  path-based recurrent neural networks. More speciﬁcally, these path-based methods  mainly consider the shortest path between entities in the dependency tree, and utilize  stacked layers to encode the path as the sentence representation. Some preliminary  works [ 182] have shown that these paths are informative in RE and proposed various  recursive neural models for this. Next, we will introduce these recursive models in  detail. 9 Knowledge Representation Learning and Knowledge-Guided NLP 329 Recursive Neural Network Encoders Recursive encoders aim to extract features  based on syntactic parsing trees, considering that the syntactic information between  target entities in a sentence can beneﬁt classifying their relations. Generally, these  encoders utilize the parsing tree structure as the composition direction to integrate  word-level features into sentence-level features. Socher et al. [ 144] introduce a  recursive matrix-vector model that can capture the' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
829	page_content='model that can capture the structure information by assigning a matrix-vector representation for each constituent in parsing trees. In Socher’s  model, the vector can represent the constituent, and the matrix can represent how  the constituent modiﬁes the word meaning it is combined with.  T a ie ta l .[ 151] further propose two tree-structured models, the Child-Sum  Tree-LSTM and the N-ary Tree-LSTM. Given the parsing tree of a sentence, the  transition equations of the Child-Sum Tree-LSTM are deﬁned as  .ht=/summationdisplay k∈C(t)TLSTM (hk), (9.79)  where .C(t) is the children set of the node t,.TLSTM (·)indicates a Tree-LSTM cell,  which is simply modiﬁed from the LSTM cell, and the hidden states of the leaf  nodes are the input features. The transition equations of the N-ary Tree-LSTM are  similar to the transition equations of Child-Sum Tree-LSTM. The main difference  is that the N-ary Tree-LSTM limits the tree structures to have at most N branches.  More details of recursive neural networks can be' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
830	page_content='neural networks can be found in Chap. 4.  Sentence-Level Relation Classiﬁcation After obtaining the representation . sof  the input sentence s, we require a relation classiﬁer to compute the conditional  probability .P(r|s,e1,e2). Generally, .P(r|s,e1,e2)can be obtained with  .P(r|s,e1,e2)=Softmax (Ms+b), (9.80)  where . Mis the relation matrix consisting of relation embeddings and . bis a bias  vector. Intuitively, using a Softmax layer to compute the conditional probability  means that an entity pair has only one corresponding relation. However, sometimes  multiple relations may exist between an entity pair. To this end, for each relation  .r∈R, some works perform relation-speciﬁc binary classiﬁcation:  .P(r|s,e1,e2)=Sigmoid (r/latticetops+br), (9.81)  where . ris the relation embedding of r and . bris a relation-speciﬁc bias value.  9.5.2 Bag-Level Relation Extraction  Although existing neural methods have achieved promising results in sentence-level  RE, these neural methods still suffer from the problem' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
831	page_content='still suffer from the problem of data scarcity since manu330 X. Han et al. New York City is the most populous city in the United  States  New York City was the capital of the United States  from 1785 until 1790  New York City is the premier gateway for legal  immigration to the United States U.S.A New York City of  Distant Supervision  Model Knowledge Graph  Fig. 9.26 An example of bag-level relation extraction  ally annotating training data is time-consuming and labor-intensive. To alleviate this  problem, distant supervision [ 109] has been introduced to automatically annotate  training data by aligning existing KGs and plain text. The main idea of distant  supervision is that sentences containing two entities may describe the relations of the  two entities recorded in KGs. As shown in Fig. 9.26,g i v e n( New York , City of ,  U.S.A ), the distant supervision assumption regards all sentences that contain New  York and U.S.A as positive instances for the relation City of . Besides providing  massive' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
832	page_content='. Besides providing  massive training data, distant supervision also naturally provides a way to detect the  relations between two given entities based on multiple sentences (bag-level) rather  than a single sentence (sentence-level).  Therefore, bag-level RE aims to predict the relations between two given entities  by considering all sentences containing these entities, by highlighting those informative examples and ﬁltering out noisy ones. As shown in Fig. 9.26, given the input  sentence set .S={ s1,s2,···,sm}and an entity pair ( . e1, . e2) contained by these  sentences, bag-level RE methods aim to obtain the probability .P(r|S,e1,e2)over  the relation set.  As shown in Fig. 9.27, learning an effective model to measure . P(r|S,e1,e2) requires efforts from three different aspects: encoding sentence-level semantics  (including encoding word-level semantics), encoding bag-level semantics, and  ﬁnally classifying relations. Since encoding word-level semantics and sentencelevel semantics have been already' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
833	page_content='semantics have been already introduced in sentence-level RE, we mainly focus  on introducing how to encode bag-level semantics here.  Bag-Level Semantics Encoding For bag-level RE, we need to encode bag-level  semantics based on sentence-level representations. Formally, given a sentence bag  .S={s1,s2,···,sm}, each sentence . sihas its own sentence representation . si; a baglevel encoder encodes all sentence representations into a single bag representation  . ˆs. Next, we will introduce some typical bag-level encoders as follows:  Max Encoders Max encoders aim to select the most conﬁdent sentence in the bag  . Sand use the representation of the selected sentence as the bag representation, 9 Knowledge Representation Learning and Knowledge-Guided NLP 331 Fig. 9.27 The process of obtaining bag-level semantic information to detect the relations  described by a given sentence bag  considering not all sentences containing an entity pair can express the relations  between the entity pair. For instance, given New' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
834	page_content='pair. For instance, given New York City is the premier gateway  for legal immigration to the United States , the sentence does not highly express  the relation City of . To this end, the at-least-one assumption [ 196] has been  proposed, assuming that at least one sentence containing target entities can express  their relations. With the at-least-one assumption, the sentence with the highest  probability for a speciﬁc relation is selected to represent the bag . S. Formally, the  bag representation is given as  .ˆs=si∗,i∗=arg max iP(r|si,e1,e2). (9.82)  Average Encoders Average encoders use the average of all sentence vectors  to represent the bag. Max encoders use only one sentence in the bag as the  bag representation, ignoring the rich information and correlation among different  sentences in the bag. To take advantage of all sentences, Lin et al. [ 91] make the  bag representation . ˆsdepends on the representations of all sentences in the bag. The  average encoder assumes all sentences contribute equally' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
835	page_content='sentences contribute equally to the bag representation . ˆs:  .ˆs=/summationdisplay i1 msi. (9.83)  Attentive Encoders Attentive encoders use attention operations to aggregate all  sentence vectors. Considering the inevitable mislabeling problem introduced by distant supervision, average encoders may be affected by those mislabeled sentences.  To address this problem, Lin et al. [ 91] further propose a sentence-level selective 332 X. Han et al. attention to reduce the side effect of mislabeled data. Formally, with the attention  operation, the bag representation . ˆsis deﬁned as  .α=Softmax (q/latticetop rf(S)),ˆs=Sα/latticetop, (9.84)  where .S={ s1,s2,···,sm}, .f(·)is an attention transformation function and  and . qris the query vector of the relation r used for the attention operation. To  further improve the attention operation, more sophisticated mechanisms, such as  knowledge-enhanced strategies [ 58,72,199], soft-labeling strategies [ 95], reinforcement learning [ 44, 200], and adversarial training [' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
836	page_content='and adversarial training [ 171], have been explored to build  more effective attention operations.  Bag-Level Relation Classiﬁcation Similar to sentence-level methods, when  obtaining the bag representation . ˆs, the probability .P(r|S,e1,e2)is computed  as  .P(r|S,e1,e2)=Softmax (Mˆs+b), (9.85)  where . Mis the relation matrix consisting of relation embeddings and . bis a bias  vector. For those methods performing relation-speciﬁc binary classiﬁcation, the  relation-speciﬁc conditional probability is given by  .P(r|S,e1,e2)=Sigmoid (r/latticetopˆs+br), (9.86)  where . ris the relation embedding of r and . bris a relation-speciﬁc bias value.  9.5.3 Document-Level Relation Extraction  For RE, not all relational facts can be acquired by sentence-level or bag-level  methods. Many facts are expressed across multiple sentences in a document. As  shown in Fig. 9.28, a document may contain multiple entities that interact with each  other in a complex way. If we want to get the fact that . /angbracketleftRiddarhuset' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
837	page_content='. /angbracketleftRiddarhuset , City of ,  Sweden . /angbracketright, we ﬁrst have to detect Riddarhuset is located in Stockholm from the fourth  sentence, and then detect Stockholm is the capital of Sweden and Sweden is a country  from the ﬁrst sentence. From these three facts, we can ﬁnally infer that the sovereign  state of Riddarhuset is Sweden .  Performing reading and reasoning over multiple sentences becomes important, which is intuitively hard to reach for both sentence-level and bag-level  methods. According to the statistics of a human-annotated dataset sampled from  Wikipedia [ 188], more than .40% facts require considering the semantics of multiple  sentences for their extraction, which is not negligible. Some works [ 150, 155] that  focus on document-level RE also report similar observations. Hence, it is crucial to  advance RE from the sentence level to the document level. 9 Knowledge Representation Learning and Knowledge-Guided NLP 333  Kungliga Hovkapellet (The Royal Court Orchestra )i s a' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
838	"page_content=""Royal Court Orchestra )i s a  Swedish orchestra, originally part of the Royal Court in Sweden 's  capital Stockholm .   The orchestra originally consisted of both musicians and singers.   It had only male members until 1727 ,w h e n Sophia  and Judith Fischer were employed as vocalists; in the 1850s ,t h e  harpist Marie Pauline hman became the first female  instrumentalist.   From 1731 , public concerts were performed at Riddarhuset in  Stockholm .   Since 1773 , when the Royal Swedish Opera was founded by  Gustav III of Sweden ,t h e Kungliga Hovkapellet has been part of  the opera's company. Kungliga Hovkapellet  Kungliga Hovkapellet Royal Swedish Opera Part of  Royal Court Orchestra Royal Swedish Opera Part of  Riddarhuset Sweden Country Supporting Evidence: ,  Supporting Evidence:   Fig. 9.28 An example of document-level relation extraction from the dataset DocRED [ 188]  Due to being much more complex than sentence-level and bag-level RE,  document-level RE remains an open problem in terms of"" metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}"
839	page_content='an open problem in terms of benchmarking and  methodology. For benchmarks that can evaluate the performance of document-level  RE, existing datasets either only have a few manually annotated examples [ 88],  or have noisy distantly supervised annotations [ 122, 129], or serve only a speciﬁc  domain [ 85]. To address this issue, Yao et al. [ 188] manually annotate a largescale and general-purpose dataset to support the evaluation of document-level RE  methods, named DocRED. DocRED is built based on Wikipedia and Wikidata, and  it has two main features. First, DocRED is the largest human-annotated documentlevel RE dataset, containing .132,375 entities and .56,354 facts. Second, nearly  half of the facts in DocRED can only be extracted from multiple sentences. This  makes it necessary for models to read multiple sentences in a document to identify  entities and infer their relations by considering the holistic semantic information of  the document.  Document-Level RE Methods The preliminary results on DocRED' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
840	page_content='preliminary results on DocRED show that  existing sentence-level methods cannot work well on DocRED, indicating that 334 X. Han et al. document-level RE is more challenging than sentence-level RE. Many efforts have  been devoted to document-level RE based on DocRED.  PTM-Based Methods Wang et al. [ 158] use PTMs as a backbone to build an  effective document-level RE model, considering that recently proposed PTMs show  the ability to encode long sequences. Although PTMs can effectively capture  contextual semantic information from plain text for document-level RE, PTMs still  cannot explicitly handle coreference, which is critical for modeling interactions  between entities. Ye et al. [ 190] introduce a PTM that captures coreference relations  between entities to improve document-level RE.  Graph-Based Methods Nan et al. [ 112] construct document-level graphs based  on syntactic trees, coreferences, and some human-designed heuristics to model  dependencies in documents. To better model document-level graphs,' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
841	page_content='model document-level graphs, Zeng et  al.  construct a path reasoning mechanism using graph neural networks to infer  relations between entities.  Document-Level Distant Supervision Some works [ 128, 172] also propose to leverage document-level distant supervision to learn entity and relation representations.  Based on well-designed heuristic rules, these distantly supervised methods perform  effective data augmentation for document-level RE.  Cross-Document RE In addition to abovementioned methods for RE within  one document, Yao et al. [ 187] further propose CodRED which aims to acquire  knowledge from multiple documents. Cross-document RE presents two main  challenges: (1) Given an entity pair, models need to retrieve relevant documents  to establish multiple reasoning paths. (2) Since the head and tail entities come  from different documents, models need to perform cross-document reasoning via  bridging entities to resolve the relations. To support the research, CodRED provides  a large-scale' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
842	page_content='provides  a large-scale human-annotated dataset, which contains 30,504 relational facts, as  well as the associated reasoning text paths and evidence. Experiments show that  CodRED is challenging for existing RE methods. In summary, acquiring knowledge  from documents has drawn increasing attention from the community, and is still a  promising direction worth further exploration.  9.5.4 F ew-Shot Relation Extraction  As we mentioned before, the performance of conventional RE methods heavily relies on annotated data. Annotating large-scale data is time-consuming and  labor-intensive. Although distant supervision can alleviate this issue, the distantly  supervised data also exhibits a long-tail distribution, i.e., most relations have very  limited instances. In addition, distant supervision suffers from mislabeling, which  makes the classiﬁcation of long-tail relations more difﬁcult. Hence, it is necessary  to study training RE models with few-shot training instances. Figure 9.29 is an  example of few-shot RE.' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
843	page_content='an  example of few-shot RE. 9 Knowledge Representation Learning and Knowledge-Guided NLP 335 iPhone is designed by Apple Inc.  Steve Jobs is the co-founder of Apple Inc.  Tim Cook is current CEO Product  Founder  CEO  Bill Gates founded Microsoft. ? Supporting Set  Query Instance  Model  Fig. 9.29 An example of few-shot relation extraction  Few-Shot RE Methods FewRel [ 62] is a large-scale supervised dataset for fewshot RE, which requires models to handle relation classiﬁcation with limited  training instances. Based on FewRel, some works explore few-shot RE and achieve  promising results.  Meta Learning and Metric Learning Methods Han et al. [ 62] demonstrate that  meta learning and metric learning can be well used for few-shot RE. Following the  direction of meta learning, Dong et al. [ 35] propose to leverage meta-information  of relations (e.g., relation names and aliases) to guide the initialization and fast  adaptation of meta learning for few-shot RE. Following the direction of metric  learning, based' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
844	page_content='of metric  learning, based on the prototypical neural network [ 141], which is a typical metric  learning approach, many more effective metric learning methods [ 45, 191]a r e  proposed for few-shot RE.  PTM-Based Methods Soares et al. [ 142] utilize PTMs to handle few-shot RE  and show surprising results. On the one hand, the use of PTMs can transfer the  knowledge captured from unlabeled data to help solve the problem of data scarcity.  On the other hand, Soares et al. introduce contrastive learning based on PTMs,  which can be seen as a more effective metric learning method. On FewRel, Soares’  model can achieve comparable results to human performance.  Domain Adaptation and Out-of-Distribution Detection After FewRel, Gao et  al.  propose some more challenging few-shot scenarios, including domain  adaptation and out-of-distribution detection. Gao et al. build a more challenging  dataset FewRel 2.0 and use sufﬁcient experimental results on FewRel 2.0 to show  that the state-of-the-art few-shot methods' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
845	page_content='few-shot methods struggle in these two scenarios, and the  commonly used techniques for domain adaptation and out-of-distribution detection  cannot handle the two challenges well. These ﬁndings call for more attention and  further efforts to few-shot RE, which is still a challenging open problem. 336 X. Han et al. 9.5.5 Open-Domain Relation Extraction  Most RE systems regard the task as relation classiﬁcation and can only deal with  pre-deﬁned relation types. However, relation types in the real-world corpora are  typically in rapid growth. For example, the number of relation types in Wikidata  grows to over 10,000 in 6 years from 2017 to 2022 [ 202]. Therefore, handling  emerging relations in the open-domain scenario is a challenging problem for  RE. Existing methods for open-domain RE can be divided into three categories:  extracting open relation phrases, clustering open relation types, and learning with  increasing relation types.  Extracting Open Relation Phrases Open information extraction (OpenIE) aims' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
846	page_content='extraction (OpenIE) aims  to extract semi-structured relation phrases [ 39, 40]. Since the relations are treated  as free-form text from the sentences, OpenIE can deal with relations that are  not pre-deﬁned. For OpenIE, the traditional statistical methods typically design  heuristic rules (e.g., syntactic and lexical constraints) to identify relation phrase  candidates and ﬁlter out noisy ones via a relation discriminator [ 41, 169, 189].  Neural OpenIE methods typically learn to generate relation phrases in an encoderdecoder architecture [ 26, 77], or identify relation phrases in the sentence via  sequence labeling [ 145]. The supervision for neural OpenIE models typically comes  from the high-conﬁdence results from the statistical methods. The advantage of  OpenIE is that minimal human efforts are required in both relation type design and  relation instance annotation. The relational phrases also exhibit good readability to  humans. However, due to the diversity of natural language, the same relation type' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
847	page_content='the same relation type  can have different surface forms in different sentences. Therefore, linking various  surface forms of relation phrases to the standardized relation types could be difﬁcult.  Clustering Open Relation Types Open relation extraction (OpenRE) aims to  discover new relation types by clustering relational instances into groups. OpenRE  methods typically learn discriminative representations for relational instances and  cluster these open-domain instances into groups. Compared with OpenIE, OpenRE  aims at clustering new types that are out of existing relation types, yet OpenIE only  focuses on representing relations with language phrases to get rid of pre-deﬁned  types. Generally, the results of OpenIE can be used to support the clustering of  OpenRE. Elsahar et al. [ 38] make an initial attempt to obtain relational instance  representations through rich features, including entity types and re-weighted word  embeddings, and cluster these handcrafted representations to discover new relation' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
848	page_content='to discover new relation types. Then, some works [ 67, 103] propose to improve the learning and  clustering of relational instance representations by using effective self-supervised  signals. Notably, Wu et al. [ 170] propose to transfer relational knowledge from the  supervised data of existing relations to the unsupervised data of open relations.  Given labeled relational instances of existing relations, Wu et al. use a relational  Siamese network to learn a metric space. Then, the metric space is transferred to  measure the similarities of unlabeled sentences, based on which the clustering is  performed. Inspired by Wu et al. [ 170], Zhang et al. [ 202] further leverage relation 9 Knowledge Representation Learning and Knowledge-Guided NLP 337 hierarchies to learn more discriminative metric space for the clustering of relational  instance representations, where the instances of the nearby relations on hierarchies  are encouraged to share similar representations. Moreover, since relational instance' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
849	page_content='since relational instance  representations contain rich hierarchical information, the newly discovered relations  can be directly appended to the existing relation hierarchy. OpenRE can deal with  the diversity of relation surface forms by clustering. However, the speciﬁc semantics  of relation clusters still needs to be summarized through human efforts.  Learning with Increasing Relation Types After discovering novel relations from  the open corpora, the relation classiﬁer needs to be updated to deal with both  existing and new relations. A straightforward approach is to re-train the relation  classiﬁer using all the instances of existing and new relations together from scratch  whenever new relations emerge. However, the approach is not feasible due to the  high computational cost. Continual relation learning aims to utilize the instances of  novel relations to update a relation classiﬁer continually. A signiﬁcant challenge  of continual relation learning is the catastrophic forgetting [ 159], where the' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
850	page_content='forgetting [ 159], where the  performance on the existing relations can degrade signiﬁcantly after training with  new relations. To address this problem, some works propose saving several instances  for existing classes and re-training the classiﬁer with these memorized instances  and new data together [ 30, 159]. This learning process based on memorized  instances is named memory replay . However, repeatedly updating the classiﬁer  with several memorized instances may cause overﬁtting of existing relations.  Drawing inspirations from the study of mammalian memory in neuroscience [ 10],  EMAR [ 56] proposes episodic memory activation and reconsolidation mechanism  to prevent the overﬁtting problem. The key idea is that the prototypes of the existing  relations should remain discriminative after each time of replaying and activating  memorized relation instances. In this way, EMAR can ﬂexibly handle new relations  without forgetting or overﬁtting existing relations.  9.5.6 Contextualized Relation Extraction' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
851	page_content='Relation Extraction  As mentioned above, RE systems have been signiﬁcantly improved in supervised  and distantly supervised scenarios. To further improve RE performance, many  researchers are working on the contextualized RE by integrating multisource information. In this section, we will describe some typical approaches to contextualized  RE in detail.  Utilizing External Information Most existing RE systems stated above only  concentrate on the text, regardless of the rich external text-related heterogeneous  information, like world knowledge in KGs, visual knowledge in images, and  structured or semi-structured knowledge on the Web. Text-related heterogeneous  information could provide rich additional context. As mentioned in Sect. 9.4.2 ,  Han et al. [ 58] propose a joint learning framework for RE, the key idea of which  is to jointly learn knowledge and text representations within a uniﬁed semantic 338 X. Han et al. space via KG-text alignments. In Han’s work, for the text part, word and sentence' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
852	page_content='text part, word and sentence  representations are learned via a CNN encoder. For the KG part, entity and relation  representations are learned via translation-based methods mentioned in Sect. 9.3.2 .  The learned representations of the KG and text parts are aligned during the training  process, by using entity anchors to share word and entity representations as well  as adopting mutual attention to make sentence representations and knowledge  representations enhance each other. Apart from this preliminary attempt, many  efforts have been devoted to this direction [ 72, 132, 164, 166].  Incorporating Relational Paths Although existing RE systems have achieved  promising results, they still suffer from a major problem: the models can only  directly learn from sentences containing both target entities. However, those  sentences containing only one of the target entities could also provide helpful  information and help build inference chains. For example, if we know that Alexandre  Dumas ﬁls is the son of' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
853	page_content='Dumas ﬁls is the son of Alexandre Dumas and Alexandre Dumas is the son of  Thomas-Alexandre Dumas , we can infer that Alexandre Dumas ﬁls is the grandson  of Thomas-Alexandre Dumas . Zeng et al. [ 199] introduce a path-based RE model  incorporating textual relational paths so as to utilize the information of both direct  and indirect sentences. The model employs an encoder to represent the semantics of  multiple sentences and then builds a relation path encoder to measure the probability  distribution of relations given the inference path in text. Finally, the model combines  information from both sentences and relational paths and predicts each relation’s  conﬁdence. This work is the preliminary effort to consider the knowledge of relation  paths in text RE. There are also several methods later to consider the reasoning paths  of sentence semantic meanings for RE, such as using effective neural models like  RNNs to learn relation paths [ 29], and using distant supervision to annotate implicit  relation' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
854	page_content='annotate implicit  relation paths [ 49] automatically.  9.5.7 Summary  In this section, we elaborate on the approaches to acquiring knowledge. Typically,  we focus on RE, and classify RE methods into six groups according to their  application scenarios: (1) sentence-level RE , which focuses on extracting relations  from sentences, (2) bag-level RE , which focuses on extracting relations from the  bags of sentences annotated by distant supervision, (3) document-level RE , which  focuses on extracting relations from documents, (4) few-shot RE , which focuses  on low-resource scenarios, (5) open-domain RE , which focuses on continually  extracting open-domain relations that are not pre-deﬁned, and (6) contextualized  RE, which focuses on integrating multisource information for RE.  Note that knowledge acquisition does not just mean RE and includes many other  methods, such as KGC, event extraction, etc. Moreover, not all human knowledge  is represented in a textual form, and there is also a large amount of' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
855	page_content='is also a large amount of knowledge in  images, audio, and other knowledge carriers. How to obtain knowledge from these 9 Knowledge Representation Learning and Knowledge-Guided NLP 339 carriers to empower models is also a problem worthy of further consideration by  researchers.  9.6 Summary and Further Readings  We have now overviewed the current progress of using knowledge for NLP  tasks, including knowledge representation learning, knowledge-guided NLP, and  knowledge acquisition. In this last section, we will summarize the contents of this  chapter and then provide more readings for reference.  Knowledge representation learning is a critical component of using knowledge  since it bridges the gap between knowledge systems that store knowledge and  applications that require knowledge. We systemically describe existing methods for knowledge representation learning. Further, we discuss several advanced  approaches that deal with the current challenges of knowledge representation learning. For further' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
856	page_content='learning. For further understanding of knowledge graph representation learning, more  related papers can be found in this paper list.5 There are also some recommended  surveys and books [ 6, 73, 102, 116, 161].  After introducing knowledge representation learning, we introduce the framework of knowledge-guided learning, aiming to improve NLP models with knowledge representations. The framework includes four important directions: knowledge  augmentation, knowledge reformulation, knowledge regularization, and knowledge  transfer. All these four directions of knowledge-guided learning have been widely  advanced in the past few years. Following these four directions, we review typical  cases to clarify this knowledge-guided framework, covering information extraction,  information retrieval, language modeling, and text generation. Considering the  breakthroughs of PTMs, we also use prompts as an example to show the recent  trend of knowledge transfer in the era of PTMs. We suggest readers to ﬁnd further  insights' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
857	page_content='to ﬁnd further  insights from the recent surveys and books about knowledge and PTMs [ 9, 60, 193].  Based on knowledge representation learning and knowledge-guided learning,  we introduce how to acquire more knowledge from plain text to enrich existing  knowledge systems. We systematically review knowledge acquisition methods in  various textual scenarios, including sentence-level, bag-level, document-level, fewshot, and open-domain acquisition. In this ﬁeld, we refer further readings to the  paper list6 and the typical surveys [ 57, 73].  Acknowledgments The contributions of all authors for the second edition are the following:  Zhiyuan Liu, Yankai Lin, and Maosong Sun designed the overall architecture of this chapter;  Xu Han and Weize Chen drafted the chapter; Zhengyan Zhang and Yuan Yao participated in and  proofread some parts of Sects. 9.4 and 9.5. Zhiyuan Liu and Yankai Lin proofread and revised this  chapter. 5 https:// github. com/ thunlp/ KRLPapers .  6 https:// github. com/ thunlp/ NREPapers .' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
858	page_content='com/ thunlp/ NREPapers .  340 X. Han et al. We thank Ruobing Xie for providing initial materials in the ﬁrst edition and also thank Ning  Ding, Chaojun Xiao, Shengding Hu, Xinrong Zhang, Qimin Zhan, Bowen Li, and Shihao Liang  for proofreading this chapter.  This chapter is the knowledge representation learning chapter of the second edition of the book  Representation Learning for Natural Language Processing , with its ﬁrst edition published in 2020  . As compared to the ﬁrst edition of this chapter, the main changes include the following: (1)  we added the section Knowledge-guided NLP and the section Knowledge Acquisition, and (2) we  comprehensively supplemented and updated the information, discussions, examples, and ﬁgures in  other existing sections.  References  1. Sungjin Ahn, Heeyoul Choi, Tanel Pärnamaa, and Yoshua Bengio. A neural knowledge  language model. arXiv preprint arXiv:1608.00318 , 2016.  2. Barr Avron and Edward A Feigenbaum. The handbook of artiﬁcial intelligence . AddisonWesley, 1981.' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
859	page_content='. AddisonWesley, 1981.  3. Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by  jointly learning to align and translate. In Proceedings of ICLR , 2015.  4. Ivana Balaževi ´c, Carl Allen, and Timothy Hospedales. Multi-relational poincaré graph  embeddings. In Proceedings of NeurIPS , 2019.  5. Islam Beltagy and Raymond J Mooney. Efﬁcient markov logic inference for natural language  semantics. In Proceedings of AAAI Workshop , 2014.  6. Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A review and  new perspectives. IEEE Transactions on Pattern Analysis and Machine Intelligence , 2013.  7. Tim Berners-Lee, James Hendler, and Ora Lassila. The semantic web. Scientiﬁc american ,  284(5):34–43, 2001.  8. Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. Freebase: a  collaboratively created graph database for structuring human knowledge. In Proceedings of  KDD , 2008.  9. Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman,' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
860	page_content='Ehsan Adeli, Russ Altman, Simran Arora, Sydney von  Arx, Michael S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, et al. On the  opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258 , 2021.  10. Bruno Bontempi, Catherine Laurent-Demir, Claude Destrade, and Robert Jaffard. Timedependent reorganization of brain circuitry underlying long-term memory storage. Nature ,  400(6745):671–675, 1999.  11. Antoine Bordes, Xavier Glorot, Jason Weston, and Yoshua Bengio. Joint learning of words  and meaning representations for open-text semantic parsing. In Proceedings of AISTATS ,  2012.  12. Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana  Yakhnenko. Translating embeddings for modeling multi-relational data. In Proceedings of  NeurIPS , 2013.  13. Antoine Bordes, Jason Weston, Ronan Collobert, and Yoshua Bengio. Learning structured  embeddings of knowledge bases. In Proceedings of AAAI , 2011.  14. Bernhard E Boser, Isabelle M Guyon, and Vladimir N' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
861	page_content='M Guyon, and Vladimir N Vapnik. A training algorithm for  optimal margin classiﬁers. In Proceedings of COLT , 1992.  15. David Bostock. Plato’s theaetetus . Oxford University Press, 1988.  16. Leo Breiman, Jerome Friedman, Charles J Stone, and Richard A Olshen. Classiﬁcation and  regression trees . CRC Press, 1984.  17. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language  models are few-shot learners. In Proceedings of NeurIPS , 2020. 9 Knowledge Representation Learning and Knowledge-Guided NLP 341 18. Razvan C Bunescu and Raymond J Mooney. A shortest path dependency kernel for relation  extraction. In Proceedings of EMNLP, 2005.  19. Rui Cai, Xiaodong Zhang, and Houfeng Wang. Bidirectional recurrent convolutional neural network for relation classiﬁcation. In Proceedings of ACL, 2016.  20. Andrew Carlson, Justin Betteridge, Richard C Wang, Estevam R Hruschka Jr, and Tom M Mitchell. Coupled' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
862	page_content='and Tom M Mitchell. Coupled semi-supervised learning for information extraction. In Proceedings of WSDM, 2010.  21. Mohamed Chabchoub, Michel Gagnon, and Amal Zouaq. Collective disambiguation and semantic annotation for entity linking and typing. In Proceedings of SWEC, 2016.  22. Gang Chen, Maosong Sun, and Yang Liu. Towards a universal continuous knowledge base. AI Open, 2:197–204, 2021.  23. Weize Chen, Xu Han, Yankai Lin, Hexu Zhao, Zhiyuan Liu, Peng Li, Maosong Sun, and Jie Zhou. Fully hyperbolic neural networks. In Proceedings of ACL, 2022.  24. Noam Chomsky. Syntactic structures. De Gruyter, 1957.  25. Noam Chomsky. Aspects of the Theory of Syntax. MIT Press, 1965.  26. Lei Cui, Furu Wei, and Ming Zhou. Neural open information extraction. In Proceedings of ACL, 2018.  27. Aron Culotta and Jeffrey Sorensen. Dependency tree kernels for relation extraction. In Proceedings of ACL, 2004.  28. Zhuyun Dai, Chenyan Xiong, Jamie Callan, and Zhiyuan Liu. Convolutional neural networks for soft-matching n-grams' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
863	page_content='for soft-matching n-grams in ad-hoc search. In Proceedings of WSDM, 2018.  29. Rajarshi Das, Arvind Neelakantan, David Belanger, and Andrew McCallum. Chains of  reasoning over entities, relations, and text using recurrent neural networks. In Proceedings  of EACL, 2017.  30. Cyprien de Masson D’Autume, Sebastian Ruder, Lingpeng Kong, and Dani Yogatama. Episodic memory in lifelong language learning. In Proceedings of NeurIPS, 2019.  31. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. ImageNet: A large-scale hierarchical image database. In Proceedings of CVPR, 2009.  32. Tim Dettmers, Pasquale Minervini, Pontus Stenetorp, and Sebastian Riedel. Convolutional 2d knowledge graph embeddings. In Proceedings of AAAI, 2018.  33. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: pre-training of deep bidirectional transformers for language understanding. In Proceedings of NAACL-HLT,  2019.  34. Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
864	page_content='Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, et al. Delta tuning: A comprehensive study of param-eter efﬁcient methods for pre-trained language models. arXiv preprint arXiv:2203.06904,  2022.  35. Bowen Dong, Yuan Yao, Ruobing Xie, Tianyu Gao, Xu Han, Zhiyuan Liu, Fen Lin, Leyu Lin, and Maosong Sun. Meta-information guided meta-learning for few-shot relation classiﬁcation. In Proceedings of COLING, 2020.  36. Li Dong, Furu Wei, Hong Sun, Ming Zhou, and Ke Xu. A hybrid neural model for type classiﬁcation of entity mentions. In Proceedings of IJCAI, 2015.  37. Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko Horn, Ni Lao, Kevin Murphy, Thomas Strohmann, Shaohua Sun, and Wei Zhang. Knowledge vault: A web-scale approach to probabilistic knowledge fusion. In Proceedings of KDD, 2014.  38. Hady Elsahar, Elena Demidova, Simon Gottschalk, Christophe Gravier, and Frederique Laforest. Unsupervised open relation extraction. In Proceedings of ESWC, 2017.  39. Oren Etzioni, Michele Banko,' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
865	page_content='Oren Etzioni, Michele Banko, Stephen Soderland, and Daniel S Weld. Open information extraction from the web. Communications of the ACM, 51(12):68–74, 2008.  40. Oren Etzioni, Anthony Fader, Janara Christensen, Stephen Soderland, et al. Open information extraction: The second generation. In Proceedings of IJCAI, 2011.  41. Anthony Fader, Stephen Soderland, and Oren Etzioni. Identifying relations for open informa-tion extraction. In Proceedings of EMNLP, 2011. 342 X. Han et al. 42. Edward A Feigenbaum. Knowledge engineering: The applied side of artiﬁcial intelligence.  Technical report, Computer Science Department of Stanford University, 1980.  43. Christiane Fellbaum. Wordnet. The encyclopedia of applied linguistics, 2012.  44. Jun Feng, Minlie Huang, Li Zhao, Yang Yang, and Xiaoyan Zhu. Reinforcement learning for relation classiﬁcation from noisy data. In Proceedings of AAAI, 2018.  45. Tianyu Gao, Xu Han, Zhiyuan Liu, and Maosong Sun. Hybrid attention-based prototypical networks for noisy few-shot relation' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
866	page_content='for noisy few-shot relation classiﬁcation. In Proceedings of AAAI, 2019.  46. Tianyu Gao, Xu Han, Hao Zhu, Zhiyuan Liu, Peng Li, Maosong Sun, and Jie Zhou. FewRel 2.0: Towards more challenging few-shot relation classiﬁcation. In Proceedings of EMNLP-IJCNLP, 2019.  47. Alberto García-Durán, Antoine Bordes, and Nicolas Usunier. Composing relationships with translations. In Proceedings of EMNLP, 2015.  48. Robert Geirhos, Jörn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, and Felix A Wichmann. Shortcut learning in deep neural networks. Nature Machine Intelligence, 2(11):665–673, 2020.  49. Michael Glass, Alﬁo Gliozzo, Oktie Hassanzadeh, Nandana Mihindukulasooriya, and Gae-tano Rossiello. Inducing implicit relations from text using distantly supervised deep nets. In Proceedings of ISWC, 2018.  50. Kelvin Gu, John Miller, and Percy Liang. Traversing knowledge graphs in vector space. In Proceedings of EMNLP, 2015.  51. Yihong Gu, Jun Yan, Hao Zhu, Zhiyuan Liu, Ruobing Xie,' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
867	page_content='Zhiyuan Liu, Ruobing Xie, Maosong Sun, Fen Lin, and Leyu Lin. Language modeling with sparse product of sememe experts. In Proceedings of EMNLP,  2018.  52. Shu Guo, Quan Wang, Lihong Wang, Bin Wang, and Li Guo. Jointly embedding knowledge graphs and logical rules. In Proceedings of EMNLP, 2016.  53. Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Mingwei Chang. Retrieval augmented language model pre-training. In Proceedings of ICML, 2020.  54. Michael Haenlein and Andreas Kaplan. A brief history of artiﬁcial intelligence: On the past, present, and future of artiﬁcial intelligence. California management review, 61(4):5–14, 2019.  55. Petr Hájek. Metamathematics of fuzzy logic. Springer Science & Business Media, 1998.  56. Xu Han, Yi Dai, Tianyu Gao, Yankai Lin, Zhiyuan Liu, Peng Li, Maosong Sun, and Jie Zhou. Continual relation learning via episodic memory activation and reconsolidation. In Proceedings of ACL, 2020.  57. Xu Han, Tianyu Gao, Yankai Lin, Hao Peng, Yaoliang Yang, Chaojun Xiao, Zhiyuan' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
868	page_content='Yang, Chaojun Xiao, Zhiyuan Liu, Peng Li, Jie Zhou, and Maosong Sun. More data, more relations, more context and more openness: A review and outlook for relation extraction. In Proceedings of AACL-IJCNLP,  2020.  58. Xu Han, Zhiyuan Liu, and Maosong Sun. Neural knowledge acquisition via mutual attention between knowledge graph and text. In Proceedings of AAAI, 2018.  59. Xu Han, Zhengyan Zhang, Ning Ding, Yuxian Gu, Xiao Liu, Yuqi Huo, Jiezhong Qiu, Yuan Yao, Ao Zhang, Liang Zhang, et al. Pre-trained models: Past, present and future. AI Open,  2021.  60. Xu Han, Zhengyan Zhang, and Zhiyuan Liu. Knowledgeable machine learning for natural language processing. Communications of the ACM, 64(11):50–51, 2021.  61. Xu Han, Zhengyan Zhang, and Zhiyuan Liu. Knowledge-guided pre-trained language models. ZTE CommunicationsM, 28(2):10–15, 2022.  62. Xu Han, Hao Zhu, Pengfei Yu, Ziyun Wang, Yuan Yao, Zhiyuan Liu, and Maosong Sun.  FewRel: A large-scale supervised few-shot relation classiﬁcation dataset with' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
869	page_content='classiﬁcation dataset with state-of-the-art  evaluation. In Proceedings of EMNLP, 2018.  63. Trevor Hastie, Robert Tibshirani, Jerome H Friedman, and Jerome H Friedman. The elements of statistical learning: data mining, inference, and prediction, volume 2. Springer, 2009.  64. Frederick Hayes-Roth, Donald A Waterman, and Douglas B Lenat. Building expert system.  Addison-Wesley, 1983. 9 Knowledge Representation Learning and Knowledge-Guided NLP 343 65. Shizhu He, Kang Liu, Guoliang Ji, and Jun Zhao. Learning to represent knowledge graphs  with gaussian embedding. In Proceedings of CIKM, 2015.  66. John Hewitt and Christopher D. Manning. A structural probe for ﬁnding syntax in word representations. In Proceedings of NAACL-HLT, 2019.  67. Xuming Hu, Lijie Wen, Yusong Xu, Chenwei Zhang, and S Yu Philip. Selfore: Self-supervised relational feature learning for open relation extraction. In Proceedings of EMNLP,  2020.  68. Peter Hylton. Russell, idealism, and the emergence of analytic philosophy. Oxford University' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
870	page_content='philosophy. Oxford University  Press, 1990.  69. Ganesh Jawahar, Benoît Sagot, and Djamé Seddah. What does BERT learn about the structure of language? In Proceedings of ACL, 2019.  70. Rodolphe Jenatton, Nicolas L Roux, Antoine Bordes, and Guillaume R Obozinski. A latent factor model for highly multi-relational data. In Proceedings of NeurIPS, 2012.  71. Guoliang Ji, Kang Liu, Shizhu He, and Jun Zhao. Knowledge graph completion with adaptive sparse transfer matrix. In Proceedings of AAAI, 2016.  72. Guoliang Ji, Kang Liu, Shizhu He, and Jun Zhao. Distant supervision for relation extraction with sentence-level attention and entity descriptions. In Proceedings of AAAI, 2017.  73. Shaoxiong Ji, Shirui Pan, Erik Cambria, Pekka Marttinen, and S Yu Philip. A survey on knowledge graphs: Representation, acquisition, and applications. IEEE Transactions on Neural Networks and Learning Systems, 33(2):494–514, 2021.  74. Zhengbao Jiang, Frank F Xu, Jun Araki, and Graham Neubig. How can we know what language models know?' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
871	page_content='what language models know? Transactions of the Association for Computational Linguistics,  8:423–438, 2020.  75. Nanda Kambhatla. Combining lexical, syntactic, and semantic features with maximum entropy models for extracting relations. In Proceedings of ACL, 2004.  76. Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. Dense passage retrieval for open-domain question answering. In Proceedings of EMNLP, 2020.  77. Keshav Kolluru, Samarth Aggarwal, Vipul Rathore, Soumen Chakrabarti, et al. Imojie: Iterative memory-based joint open information extraction. In Proceedings of ACL, 2020.  78. Denis Krompaß, Stephan Baier, and V olker Tresp. Type-constrained representation learning in knowledge graphs. In Proceedings of ISWC, 2015.  79. John Lafferty, Andrew McCallum, Fernando Pereira, et al. Conditional random ﬁelds: Probabilistic models for segmenting and labeling sequence data. In Proceedings of ICML,  2001.  80. Thomas K Landauer and Susan T Dumais.' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
872	page_content='Landauer and Susan T Dumais. A solution to Plato’s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge. Psychological Review, 1997.  81. Ora Lassila, Ralph R. Swick, World Wide, and Web Consortium. Resource description framework (rdf) model and syntax speciﬁcation, 1998.  82. Quoc V Le and Tomas Mikolov. Distributed representations of sentences and documents. In Proceedings of ICML, 2014.  83. Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature, 521(7553):436,  2015.  84. Douglas B Lenat. CYC: A large-scale investment in knowledge infrastructure. Communica-tions of the ACM, 38(11):33–38, 1995.  85. Omer Levy, Minjoon Seo, Eunsol Choi, and Luke Zettlemoyer. Zero-shot relation extraction  via reading comprehension. In Proceedings of CoNLL, 2017.  86. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman  Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. Retrieval-augmented generation' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
873	page_content='generation for knowledge-intensive nlp tasks. In Proceedings of NeurIPS, 2020.  87. Diya Li, Lifu Huang, Heng Ji, and Jiawei Han. Biomedical event extraction based on knowledge-driven tree-LSTM. In Proceedings of NAACL-HLT, 2019. 344 X. Han et al. 88. Jiao Li, Yueping Sun, Robin J. Johnson, Daniela Sciaky, Chih-Hsuan Wei, Robert Leaman,  Allan Peter Davis, Carolyn J. Mattingly, Thomas C. Wiegers, and Zhiyong Lu. BioCreative V CDR task corpus: a resource for chemical disease relation extraction. Database, 2016, 05  2016.  89. Yankai Lin, Zhiyuan Liu, Huanbo Luan, Maosong Sun, Siwei Rao, and Song Liu. Modeling relation paths for representation learning of knowledge bases. In Proceedings of EMNLP,  2015.  90. Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and Xuan Zhu. Learning entity and relation embeddings for knowledge graph completion. In Proceedings of AAAI, 2015.  91. Yankai Lin, Shiqi Shen, Zhiyuan Liu, Huanbo Luan, and Maosong Sun. Neural relation extraction with selective attention over instances. In' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
874	page_content='attention over instances. In Proceedings of ACL, 2016.  92. Chunyang Liu, Wenbo Sun, Wenhan Chao, and Wanxiang Che. Convolution neural network for relation extraction. In Proceedings of ICDM, 2013.  93. Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. arXiv preprint arXiv:2107.13586, 2021.  94. Quan Liu, Hui Jiang, Andrew Evdokimov, Zhen-Hua Ling, Xiaodan Zhu, Si Wei, and Yu Hu. Probabilistic reasoning via deep learning: Neural association models. arXiv preprint arXiv:1603.07704, 2016.  95. Tianyu Liu, Kexiang Wang, Baobao Chang, and Zhifang Sui. A soft-label method for noise-tolerant distantly supervised relation extraction. In Proceedings of EMNLP, 2017.  96. Weijie Liu, Peng Zhou, Zhe Zhao, Zhiruo Wang, Qi Ju, Haotang Deng, and Ping Wang. KBERT: Enabling language representation with knowledge graph. In Proceedings of AAAI,  2020.  97. Xiao Liu, Fanjin Zhang,' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
875	page_content='97. Xiao Liu, Fanjin Zhang, Zhenyu Hou, Li Mian, Zhaoyu Wang, Jing Zhang, and Jie Tang. Selfsupervised learning: Generative or contrastive. IEEE Transactions on Knowledge and Data Engineering, 2021.  98. Yang Liu, Kang Liu, Liheng Xu, Jun Zhao, et al. Exploring ﬁne-grained entity type constraints for distantly supervised relation extraction. In Proceedings of COLING, 2014.  99. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. RoBERTa: A robustly optimized BERT pretraining approach. arXiv preprint arXiv:1907.11692, 2019.  100. Zhenghao Liu, Chenyan Xiong, Maosong Sun, and Zhiyuan Liu. Entity-duet neural ranking: Understanding the role of knowledge graph semantics in neural information retrieval. In Proceedings of ACL, 2018.  101. Zhiyuan Liu, Yankai Lin, and Maosong Sun. Representation Learning for Natural Language Processing. Springer, 2020.  102. Zhiyuan Liu, Maosong Sun, Yankai Lin, and Ruobing Xie. Knowledge' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
876	page_content='and Ruobing Xie. Knowledge representation learning: A review. JCRD, 53(2):247–261, 2016.  103. Diego Marcheggiani and Ivan Titov. Discrete-state variational autoencoders for joint dis-covery and factorization of relations. Transactions of the Association for Computational Linguistics, 4:231–244, 2016.  104. J McCarthy, ML Minsky, and N Rochester. A proposal for the dartmouth summer research project on artiﬁcial intelligence. 1955.  105. John McCarthy. History of lisp. ACM SIGPLAN Notices, 13(8):217–223, 1978.  106. Pablo N Mendes, Max Jakob, Andrés García-Silva, and Christian Bizer. DBpedia spotlight: shedding light on the web of documents. In Proceedings of ICSS, 2011.  107. T Mikolov and J Dean. Distributed representations of words and phrases and their composi-tionality. In Proceedings of NeurIPS, 2013.  108. Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efﬁcient estimation of word representations in vector space. In Proceedings of ICLR, 2013.  109. Mike Mintz, Steven Bills, Rion Snow, and Dan' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
877	page_content='Bills, Rion Snow, and Dan Jurafsky. Distant supervision for relation extraction without labeled data. In Proceedings of ACL-IJCNLP, 2009. 9 Knowledge Representation Learning and Knowledge-Guided NLP 345 110. Makoto Miwa and Mohit Bansal. End-to-end relation extraction using LSTMs on sequences  and tree structures. In Proceedings of ACL, 2016.  111. Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al. WebGPT: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332, 2021.  112. Guoshun Nan, Zhijiang Guo, Ivan Sekuli ´c, and Wei Lu. Reasoning with latent structure  reﬁnement for document-level relation extraction. In Proceedings of ACL, 2020.  113. Allen Newell, John Clifford Shaw, and Herbert A Simon. Empirical explorations of the logic theory machine: a case study in heuristic. In Proceedings of Western Computer, 1957.  114. Allen Newell and Fred M Tonge. An introduction' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
878	page_content='Fred M Tonge. An introduction to information processing language v. Communications of the ACM, 3(4):205–211, 1960.  115. Thien Huu Nguyen and Ralph Grishman. Combining neural networks and log-linear models to improve relation extraction. arXiv preprint arXiv:1511.05926, 2015.  116. Maximilian Nickel, Kevin Murphy, V olker Tresp, and Evgeniy Gabrilovich. A review of relational machine learning for knowledge graphs. In Proceedings of the IEEE, 2015.  117. Maximilian Nickel, Lorenzo Rosasco, and Tomaso Poggio. Holographic embeddings of knowledge graphs. In Proceedings of AAAI, 2016.  118. Maximilian Nickel, V olker Tresp, and Hans-Peter Kriegel. A three-way model for collective learning on multi-relational data. In Proceedings of ICML, 2011.  119. Maximilian Nickel, V olker Tresp, and Hans-Peter Kriegel. Factorizing YAGO: scalable machine learning for linked data. In Proceedings of WWW, 2012.  120. Sinno Jialin Pan and Qiang Yang. A survey on transfer learning. TKDE, 22(10):1345–1359,  2009.  121. Sachin Pawar,' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
879	page_content='2009.  121. Sachin Pawar, Girish K Palshikar, and Pushpak Bhattacharyya. Relation extraction: A survey. arXiv preprint arXiv:1712.05191, 2017.  122. Nanyun Peng, Hoifung Poon, Chris Quirk, Kristina Toutanova, and Wen-tau Yih. Cross-sentence n-ary relation extraction with graph LSTMs. Transactions of the Association for Computational Linguistics, 5:101–115, 2017.  123. Jeffrey Pennington, Richard Socher, and Christopher Manning. GloVe: Global vectors for word representation. In Proceedings of EMNLP, 2014.  124. Matthew E Peters, Mark Neumann, Robert Logan, Roy Schwartz, Vidur Joshi, Sameer Singh, and Noah A Smith. Knowledge enhanced contextual word representations. In Proceedings of EMNLP-IJCNLP, 2019.  125. Fabio Petroni, Patrick Lewis, Aleksandra Piktus, Tim Rocktäschel, Yuxiang Wu, Alexander H Miller, and Sebastian Riedel. How context affects language models’ factual predictions. In Proceedings of AKBC, 2020.  126. Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu,' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
880	page_content='Anton Bakhtin, Yuxiang Wu, and Alexander Miller. Language models as knowledge bases? In Proceedings of EMNLP-IJCNLP, 2019.  127. Jay Pujara, Hui Miao, Lise Getoor, and William W Cohen. Knowledge graph identiﬁcation. In Proceedings of ISWC, 2013.  128. Yujia Qin, Yankai Lin, Ryuichi Takanobu, Zhiyuan Liu, Peng Li, Heng Ji, Minlie Huang, Maosong Sun, and Jie Zhou. Erica: Improving entity and relation understanding for pre-trained language models via contrastive learning. In Proceedings of ACL-IJCNLP, 2021.  129. Chris Quirk and Hoifung Poon. Distant supervision for relation extraction beyond the sentence boundary. In Proceedings of EACL, 2017.  130. Arlan Ramsay and Robert D Richtmyer. Introduction to hyperbolic geometry. Springer  Science & Business Media, 1995.  131. Erich H Reck. From Frege to Wittgenstein: Perspectives on Early Analytic Philosophy. Oxford  University Press, 2001.  132. Sebastian Riedel, Limin Yao, Andrew McCallum, and Benjamin M Marlin. Relation extrac-tion with matrix factorization and' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
881	page_content='with matrix factorization and universal schemas. In Proceedings of NAACL-HLT, 2013. 346 X. Han et al. 133. Dan Roth and Wen-tau Yih. Probabilistic reasoning for entity & relation recognition. In  Proceedings of COLING, 2002.  134. Dan Roth and Wen-tau Yih. A linear programming formulation for global inference in natural language tasks. In Proceedings of CoNLL, 2004.  135. Cicero Nogueira dos Santos, Bing Xiang, and Bowen Zhou. Classifying relations by ranking with convolutional neural networks. In Proceedings of ACL-IJCNLP, 2015.  136. Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne van den Berg, Ivan Titov, and Max Welling. Modeling relational data with graph convolutional networks. In Proceedings of ESWC, 2018.  137. Mike Schuster and Kuldip K Paliwal. Bidirectional recurrent neural networks. IEEE Transac-tions on Signal Processing, 45(11):2673–2681, 1997.  138. Sonse Shimaoka, Pontus Stenetorp, Kentaro Inui, and Sebastian Riedel. An attentive neural architecture for ﬁne-grained entity type' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
882	page_content='for ﬁne-grained entity type classiﬁcation. In Proceedings of AKBC Workshop,  2016.  139. Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and Jason Weston. Retrieval augmen-tation reduces hallucination in conversation. In Findings of EMNLP, 2021.  140. Barry Smith. Ontology. In The furniture of the world, pages 47–68. Brill, 2012.  141. Jake Snell, Kevin Swersky, and Richard Zemel. Prototypical networks for few-shot learning. In Proceedings of NeurIPS, 2017.  142. Livio Baldini Soares, Nicholas FitzGerald, Jeffrey Ling, and Tom Kwiatkowski. Matching the Blanks: Distributional similarity for relation learning. In Proceedings of ACL, pages 2895– 2905, 2019.  143. Richard Socher, Danqi Chen, Christopher D Manning, and Andrew Ng. Reasoning with neural tensor networks for knowledge base completion. In Proceedings of NeurIPS, 2013.  144. Richard Socher, Brody Huval, Christopher D Manning, and Andrew Y Ng. Semantic compositionality through recursive matrix-vector spaces. In Proceedings of EMNLP, 2012.  145.' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
883	page_content='of EMNLP, 2012.  145. Gabriel Stanovsky, Julian Michael, Luke Zettlemoyer, and Ido Dagan. Supervised open information extraction. In Proceedings of NAACL-HLT, 2018.  146. Matthias Steup and Ram Neta. Epistemology. 2005.  147. Fabian M Suchanek, Gjergji Kasneci, and Gerhard Weikum. YAGO: a core of semantic knowledge. In Proceedings of WWW, 2007.  148. Tony Sun, Andrew Gaut, Shirlyn Tang, Yuxin Huang, Mai ElSherief, Jieyu Zhao, Diba Mirza, Elizabeth Belding, Kai-Wei Chang, and William Yang Wang. Mitigating gender bias in natural language processing: Literature review. In Proceedings of ACL, 2019.  149. Zhiqing Sun, Zhi-Hong Deng, Jian-Yun Nie, and Jian Tang. RotatE: Knowledge graph embedding by relational rotation in complex space. In Proceedings of ICLR, 2019.  150. Kumutha Swampillai and Mark Stevenson. Inter-sentential relations in information extraction corpora. In Proceedings of LREC, 2010.  151. Kai Sheng Tai, Richard Socher, and Christopher D. Manning. Improved semantic representa-tions from' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
884	page_content='representa-tions from tree-structured long short-term memory networks. In Proceedings of ACL, 2015.  152. Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. LINE: Large-scale information network embedding. In Proceedings of WWW, 2015.  153. Théo Trouillon, Johannes Welbl, Sebastian Riedel, Éric Gaussier, and Guillaume Bouchard. Complex embeddings for simple link prediction. In Proceedings of ICML, 2016.  154. Ashish Vaswani, Noam Shazeer, Niki Parmar, Llion Jones, Jakob Uszkoreit, Aidan N Gomez, and Lukasz Kaiser. Attention is all you need. In Proceedings of NeurIPS, 2017.  155. Patrick Verga, Emma Strubell, and Andrew McCallum. Simultaneously self-attending to  all mentions for full-abstract biological relation extraction. In Proceedings of NAACL-HLT,  2018.  156. Denny Vrande ˇci´c and Markus Krötzsch. Wikidata: A free collaborative knowledge base.  Communications of the ACM, 57(10):78–85, 2014.  157. Eric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, and Sameer Singh. Universal' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
885	page_content='and Sameer Singh. Universal  adversarial triggers for attacking and analyzing nlp. In Proceedings of EMNLP-IJCNLP,  2019. 9 Knowledge Representation Learning and Knowledge-Guided NLP 347 158. Hong Wang, Christfried Focke, Rob Sylvester, Nilesh Mishra, and William Wang. Fine-tune  BERT for DocRED with two-step process. arXiv preprint arXiv:1909.11898, 2019.  159. Hong Wang, Wenhan Xiong, Mo Yu, Xiaoxiao Guo, Shiyu Chang, and William Yang Wang. Sentence embedding alignment for lifelong relation extraction. In Proceedings of NAACL-HLT, 2019.  160. Qingyun Wang, Lifu Huang, Zhiying Jiang, Kevin Knight, Heng Ji, Mohit Bansal, and Yi Luan. PaperRobot: Incremental draft generation of scientiﬁc ideas. In Proceedings of ACL,  2019.  161. Quan Wang, Zhendong Mao, Bin Wang, and Li Guo. Knowledge graph embedding: A survey of approaches and applications. IEEE Transactions on Knowledge and Data Engineering,  29(12):2724–2743, 2017.  162. Quan Wang, Bin Wang, and Li Guo. Knowledge base completion using embeddings and' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
886	page_content='using embeddings and rules. In Proceedings of IJCAI, 2015.  163. Xiaozhi Wang, Tianyu Gao, Zhaocheng Zhu, Zhengyan Zhang, Zhiyuan Liu, Juanzi Li, and Jian Tang. KEPLER: A uniﬁed model for knowledge embedding and pre-trained language representation. Transactions of the Association for Computational Linguistics, 9:176–194,  2021.  164. Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. Knowledge graph and text jointly embedding. In Proceedings of EMNLP, 2014.  165. Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. Knowledge graph embedding by translating on hyperplanes. In Proceedings of AAAI, 2014.  166. Zhigang Wang and Juan-Zi Li. Text-enhanced representation learning for knowledge graph.  In Proceedings of IJCAI, 2016.  167. Jason Weston, Sumit Chopra, and Antoine Bordes. Memory networks. arXiv preprint  arXiv:1410.3916, 2014.  168. Jason Weston, Emily Dinan, and Alexander H Miller. Retrieve and reﬁne: Improved sequence generation models for dialogue. In Proceedings of EMNLP, 2018.  169. Fei Wu' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
887	page_content='of EMNLP, 2018.  169. Fei Wu and Daniel S Weld. Open information extraction using wikipedia. In Proceedings of ACL, 2010.  170. Ruidong Wu, Yuan Yao, Xu Han, Ruobing Xie, Zhiyuan Liu, Fen Lin, Leyu Lin, and Maosong Sun. Open relation extraction: Relational knowledge transfer from supervised data to unsupervised data. In Proceedings of EMNLP-IJCNLP, 2019.  171. Yi Wu, David Bamman, and Stuart Russell. Adversarial training for relation extraction. In Proceedings of EMNLP, 2017.  172. Chaojun Xiao, Yuan Yao, Ruobing Xie, Xu Han, Zhiyuan Liu, Maosong Sun, Fen Lin, and Leyu Lin. Denoising relation extraction from document-level distant supervision. In Proceedings of EMNLP, 2020.  173. Han Xiao, Minlie Huang, and Xiaoyan Zhu. From one point to a manifold: Knowledge graph embedding for precise link prediction. In Proceedings of IJCAI, 2016.  174. Han Xiao, Minlie Huang, and Xiaoyan Zhu. TransG: A generative model for knowledge graph embedding. In Proceedings of ACL, 2016.  175. Ruobing Xie, Zhiyuan Liu, Tat-seng' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
888	page_content='Xie, Zhiyuan Liu, Tat-seng Chua, Huanbo Luan, and Maosong Sun. Image-embodied knowledge representation learning. In Proceedings of IJCAI, 2016.  176. Ruobing Xie, Zhiyuan Liu, Jia Jia, Huanbo Luan, and Maosong Sun. Representation learning of knowledge graphs with entity descriptions. In Proceedings of AAAI, 2016.  177. Ruobing Xie, Zhiyuan Liu, and Maosong Sun. Representation learning of knowledge graphs with hierarchical types. In Proceedings of IJCAI, 2016.  178. Ji Xin, Yankai Lin, Zhiyuan Liu, and Maosong Sun. Improving neural ﬁne-grained entity typing with knowledge attention. In Proceedings of AAAI, 2018.  179. Chenyan Xiong, Jamie Callan, and Tie-Yan Liu. Word-entity duet representations for document ranking. In Proceedings of SIGIR, 2017.  180. Chenyan Xiong, Zhuyun Dai, Jamie Callan, Zhiyuan Liu, and Russell Power. End-to-end neural ad-hoc ranking with kernel pooling. In Proceedings of SIGIR, 2017. 348 X. Han et al. 181. Wenhan Xiong, Jingfei Du, William Yang Wang, and Veselin Stoyanov. Pretrained' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
889	page_content='Veselin Stoyanov. Pretrained encyclopedia: Weakly supervised knowledge-pretrained language model. In Proceedings of ICLR,  2020.  182. Kun Xu, Yansong Feng, Songfang Huang, and Dongyan Zhao. Semantic relation classiﬁ-cation via convolutional neural networks with simple negative sampling. In Proceedings of EMNLP, 2015.  183. Yan Xu, Ran Jia, Lili Mou, Ge Li, Yunchuan Chen, Yangyang Lu, and Zhi Jin. Improved rela-tion classiﬁcation by deep recurrent neural networks with data augmentation. In Proceedings of COLING, 2016.  184. Mohamed Yahya, Klaus Berberich, Shady Elbassuoni, and Gerhard Weikum. Robust question answering over the web of linked data. In Proceedings of CIKM, 2013.  185. Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, and Yuji Matsumoto. Luke: Deep contextualized entity representations with entity-aware self-attention. In Proceedings of EMNLP, 2020.  186. Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, and Li Deng. Embedding entities and relations for learning and inference in' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
890	page_content='for learning and inference in knowledge bases. In Proceedings of ICLR, 2015.  187. Yuan Yao, Jiaju Du, Yankai Lin, Peng Li, Zhiyuan Liu, Jie Zhou, and Maosong Sun. Codred: A cross-document relation extraction dataset for acquiring knowledge in the wild. In Proceedings of EMNLP, 2021.  188. Yuan Yao, Deming Ye, Peng Li, Xu Han, Yankai Lin, Zhenghao Liu, Zhiyuan Liu, Lixin Huang, Jie Zhou, and Maosong Sun. DocRED: A large-scale document-level relation extraction dataset. In Proceedings of ACL, 2019.  189. Alexander Yates, Michele Banko, Matthew Broadhead, Michael J Cafarella, Oren Etzioni, and Stephen Soderland. Textrunner: open information extraction on the web. In Proceedings of NAACL-HLT, 2007.  190. Deming Ye, Yankai Lin, Jiaju Du, Zhenghao Liu, Peng Li, Maosong Sun, and Zhiyuan Liu. Coreferential reasoning learning for language representation. In Proceedings of EMNLP,  2020.  191. Zhi-Xiu Ye and Zhen-Hua Ling. Multi-level matching and aggregation network for few-shot relation classiﬁcation. In Proceedings' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
891	page_content='classiﬁcation. In Proceedings of ACL, 2019.  192. David Yenicelik, Florian Schmidt, and Yannic Kilcher. How does BERT capture semantics? a closer look at polysemous words. In Proceedings of BlackboxNLP, 2020.  193. Wenhao Yu, Chenguang Zhu, Zaitang Li, Zhiting Hu, Qingyun Wang, Heng Ji, and Meng Jiang. A survey of knowledge-enhanced text generation. ACM Computing Surveys (CSUR),  54(11):1–38, 2022.  194. Yuan Zang, Fanchao Qi, Chenghao Yang, Zhiyuan Liu, Meng Zhang, Qun Liu, and Maosong Sun. Word-level textual adversarial attacking as combinatorial optimization. In Proceedings of ACL, 2020.  195. Dmitry Zelenko, Chinatsu Aone, and Anthony Richardella. Kernel methods for relation extraction. JMLR, 3:1083–1106, 2003.  196. Daojian Zeng, Kang Liu, Yubo Chen, and Jun Zhao. Distant supervision for relation extraction via piecewise convolutional neural networks. In Proceedings of EMNLP, 2015.  197. Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou, and Jun Zhao. Relation classiﬁcation via convolutional deep neural' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
892	page_content='via convolutional deep neural network. In Proceedings of COLING, 2014.  198. Shuang Zeng, Runxin Xu, Baobao Chang, and Lei Li. Double graph based reasoning for document-level relation extraction. In Proceedings of EMNLP, 2020.  199. Wenyuan Zeng, Yankai Lin, Zhiyuan Liu, and Maosong Sun. Incorporating relation paths in  neural relation extraction. In Proceedings of EMNLP, 2017.  200. Xiangrong Zeng, Shizhu He, Kang Liu, and Jun Zhao. Large scaled relation extraction with  reinforcement learning. In Proceedings of AAAI, 2018.  201. Dongxu Zhang and Dong Wang. Relation classiﬁcation via recurrent neural network. arXiv preprint arXiv:1508.01006, 2015.  202. Kai Zhang, Yuan Yao, Ruobing Xie, Xu Han, Zhiyuan Liu, Fen Lin, Leyu Lin, and Maosong Sun. Open hierarchical relation extraction. In Proceedings of NAACL-HLT, 2021. 9 Knowledge Representation Learning and Knowledge-Guided NLP 349 203. Shuai Zhang, Yi Tay, Lina Yao, and Qi Liu. Quaternion knowledge graph embeddings. In  Proceedings of NeurIPS , 2019.  204.' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
893	page_content='of NeurIPS , 2019.  204. Yuhao Zhang, Peng Qi, and Christopher D Manning. Graph convolution over pruned  dependency trees improves relation extraction. In Proceedings of EMNLP , 2018.  205. Zhengyan Zhang, Xu Han, Zhiyuan Liu, Xin Jiang, Maosong Sun, and Qun Liu. ERNIE:  Enhanced language representation with informative entities. In Proceedings of ACL , 2019.  206. Zhengyan Zhang, Xu Han, Hao Zhou, Pei Ke, Yuxian Gu, Deming Ye, Yujia Qin, Yusheng  Su, Haozhe Ji, Jian Guan, et al. CPM: A large-scale generative chinese pre-trained language  model. AI Open , 2:93–99, 2021.  207. Huaping Zhong, Jianwen Zhang, Zhen Wang, Hai Wan, and Zheng Chen. Aligning knowledge  and text embeddings by entity descriptions. In Proceedings of EMNLP , 2015.  208. Guodong Zhou, Jian Su, Jie Zhang, and Min Zhang. Exploring various knowledge in relation  extraction. In Proceedings of ACL , 2005.  209. Peng Zhou, Wei Shi, Jun Tian, Zhenyu Qi, Bingchen Li, Hongwei Hao, and Bo Xu.  Attention-based bidirectional long short-term memory' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
894	page_content='long short-term memory networks for relation classiﬁcation.  In Proceedings of ACL , 2016.  210. Hao Zhu, Yankai Lin, Zhiyuan Liu, Jie Fu, Tat-Seng Chua, and Maosong Sun. Graph neural  networks with generated parameters for relation extraction. In Proceedings of ACL , 2019.  Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0  International License ( http:// creativecommons. org/licenses/ by/4.0/), which permits use, sharing,  adaptation, distribution and reproduction in any medium or format, as long as you give appropriate  credit to the original author(s) and the source, provide a link to the Creative Commons license and  indicate if changes were made.  The images or other third party material in this chapter are included in the chapter’s Creative  Commons license, unless indicated otherwise in a credit line to the material. If material is not  included in the chapter’s Creative Commons license and your intended use is not permitted by  statutory regulation or' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
895	page_content='by  statutory regulation or exceeds the permitted use, you will need to obtain permission directly from  the copyright holder.' metadata={'title': 'Chapter 9 Knowledge Representation Learning and Knowledge-Guided NLP', 'author': 'Unknown author', 'publish_date': '2023-06-23', 'subject': '', 'doi': 'No DOI available', 'keywords': ''}
896	page_content='Vol.:(0123456789)1 3Annals of Biomedical Engineering   LETTER TO\xa0THE\xa0EDITOR Potential for\xa0GPT Technology to\xa0Optimize Future Clinical  Decision‑Making Using Retrieval‑Augmented Generation Calvin\xa0Wang1 \xa0· Joshua\xa0Ong2\xa0· Chara\xa0Wang3\xa0· Hannah\xa0Ong4\xa0· Rebekah\xa0Cheng5\xa0· Dennis\xa0Ong6 Received: 14 July 2023 / Accepted: 17 July 2023  © The Author(s) under exclusive licence to Biomedical Engineering Society 2023 Abstract Advancements in artificial intelligence (AI) provide many helpful tools for healthcare, one of which includes AI chatbots that  use natural language processing to create humanlike, conversational dialog. These chatbots have general cognitive skills and  are able to engage with clinicians and patients to discuss patients’ health\xa0conditions and what they may be at risk for. While  chatbot engines have access to a wide range of medical texts and research papers, they currently provide high-level, generic  responses and are limited in their ability to provide diagnostic guidance and clinical advice to patients' metadata={'title': 'Potential for GPT Technology to Optimize Future Clinical Decision-Making Using Retrieval-Augmented Generation', 'author': 'Calvin Wang', 'publish_date': '2023-08-01', 'subject': 'Annals of Biomedical Engineering', 'doi': 'https://doi.org/10.1007/s10439-023-03327-6', 'keywords': 'GPT; Patient; Clinical; Large language model'}
897	page_content='clinical advice to patients on an individual  level. The essay discusses the use of retrieval-augmented generation (RAG), which can be used to improve the specificity of  user-entered prompts and thereby enhance the detail in AI chatbot responses. By embedding more recent clinical data and  trusted medical sources, such as clinical guidelines, into the chatbot models, AI chatbots can provide more patient-specific  guidance, faster diagnoses and treatment recommendations,\xa0and greater improvement of patient outcomes. Keywords GPT\xa0· Patient\xa0· Clinical\xa0· Large language model Introduction Developments in artificial intelligence (AI) research continue to unearth key applications wherein AI can transform  modern medicine. For example, prior studies have demonstrated AI’s potential for analyzing medical images [1 ], coding medical notes [2 ], identifying high-risk patient groups  , and summarizing clinical trials [4 ]. Another aspect  where AI can revolutionize medicine is through AI chatbots, such as OpenAI’s' metadata={'title': 'Potential for GPT Technology to Optimize Future Clinical Decision-Making Using Retrieval-Augmented Generation', 'author': 'Calvin Wang', 'publish_date': '2023-08-01', 'subject': 'Annals of Biomedical Engineering', 'doi': 'https://doi.org/10.1007/s10439-023-03327-6', 'keywords': 'GPT; Patient; Clinical; Large language model'}
898	page_content='AI chatbots, such as OpenAI’s ChatGPT (OpenAI, San Francisco, CA)  and Google’s Language Model for Dialog Applications  (LaMDA) (Google, Mountain View, CA). While ChatGPT is not programmed for specific functions  such as medical image interpretation and note generation,  it holds general cognitive skills to engage in a conversation  with chatbot users. Users can input “prompts” for the engine  to respond to, which can take on many different forms such  as a question (e.g., “How many layers exist within human  skin?”) or a directive (e.g., “Please summarize the following  article into 3 main points.”) [5 ]. AI chatbots are typically trained by publicly available  sources on the Internet; for example, ChatGPT3.5 contains  data up to September 2021. While ChatGPT has not been  specifically trained for healthcare applications, it has the  ability to access and reference a broad array of medical texts,  research papers, health system websites, and clinical guidelines when prompted with a medical question [5 ]. In' metadata={'title': 'Potential for GPT Technology to Optimize Future Clinical Decision-Making Using Retrieval-Augmented Generation', 'author': 'Calvin Wang', 'publish_date': '2023-08-01', 'subject': 'Annals of Biomedical Engineering', 'doi': 'https://doi.org/10.1007/s10439-023-03327-6', 'keywords': 'GPT; Patient; Clinical; Large language model'}
899	page_content='a medical question [5 ]. In fact,  ChatGPT is capable of exceeding the United States Medical  Licensing Examination (USMLE) Step One passing score by  approximately 20 points simply by leveraging its dataset [6 ]. However, while ChatGPT performs well in answering  questions related to scientific knowledge, it is less useful  in analyzing risk factors and characteristics of a patient to  provide individualized diagnostic guidance and clinical BIOMEDICAL ENGINEERING  SOCIETY Associate Editor Stefan M. Duma oversaw the review of this  article.  * Calvin Wang   cw1028@rutgers.edu 1 College of\xa0Medicine Robert Wood Johnson Medical  School, Rutgers University, New\xa0Brunswick, NJ\xa008901, USA 2 Michigan Medicine, University of\xa0Michigan, Ann\xa0Arbor, MI,  USA 3 Biotechnology High School, Freehold, NJ, USA 4 College of\xa0Medicine, The Ohio State University, Columbus,  OH, USA 5 Department of\xa0Physical Therapy, Virginia Commonwealth  University, Richmond, VA, USA 6 Amazon Web Services, Amazon, Seattle, WA, USA  C.\xa0Wang et al.' metadata={'title': 'Potential for GPT Technology to Optimize Future Clinical Decision-Making Using Retrieval-Augmented Generation', 'author': 'Calvin Wang', 'publish_date': '2023-08-01', 'subject': 'Annals of Biomedical Engineering', 'doi': 'https://doi.org/10.1007/s10439-023-03327-6', 'keywords': 'GPT; Patient; Clinical; Large language model'}
900	page_content='WA, USA  C.\xa0Wang et al. 1 3 advice. In these circumstances, ChatGPT typically responds  to prompts with less specificity [7 ]. For example, Fig.\xa0 1 illustrates ChatGPT’s response to  a hypothetical patient with respiratory issues, wherein the  application suggests potential diseases and conditions that  may be affecting the patient. Although the engine returns  a comprehensive answer, it is generic and does not drive  toward understanding more specific information about the  patient (e.g., biomarkers) to provide a patient-specific recommendation or diagnosis. Enabling this functionality within AI chatbots would  increase the scale and speed at which patients can be diagnosed. This would be greatly helpful for clinicians across  all specialties, but specifically within oncology where  every delayed month in treatment can raise the risk of death  by 6–13% [8 ]. Thus, ChatGPT would create an immense  value-add by providing efficient and accurate diagnostic  advice on a one-to-one basis for patients based on' metadata={'title': 'Potential for GPT Technology to Optimize Future Clinical Decision-Making Using Retrieval-Augmented Generation', 'author': 'Calvin Wang', 'publish_date': '2023-08-01', 'subject': 'Annals of Biomedical Engineering', 'doi': 'https://doi.org/10.1007/s10439-023-03327-6', 'keywords': 'GPT; Patient; Clinical; Large language model'}
901	page_content='basis for patients based on clinical  characteristics. One method through which ChatGPT can improve its  response specificity is through retrieval-augmented generation (RAG), as shown in Fig.\xa0 2A. To allow RAG to  occur, knowledge sources (e.g., document repositories,  APIs) outside the limits of the model must first be added to expand the model’s database. This addition of outside data  is completed through embedding, or the process by which  text is given numerical representation to be understood  within a vector space. As a result, user prompts and queries (step 1) can draw upon these new knowledge sources  (steps 2 and 3) in order to acquire “enhanced context”  which can be used to augment the prompt and make it  more specific (step 4). The augmented prompt may thereby  generate a more detailed response from the large language  model (step 5) [9 ]. As an additional example, Fig.\xa0 2B demonstrates how the  RAG process works with the hypothetical question from  Fig.\xa01. In the example, the original question' metadata={'title': 'Potential for GPT Technology to Optimize Future Clinical Decision-Making Using Retrieval-Augmented Generation', 'author': 'Calvin Wang', 'publish_date': '2023-08-01', 'subject': 'Annals of Biomedical Engineering', 'doi': 'https://doi.org/10.1007/s10439-023-03327-6', 'keywords': 'GPT; Patient; Clinical; Large language model'}
902	page_content='the original question (step 1) is asked  as a prompt by the user and subsequently entered as a query  in the system (step 2). The query is sourced through all  available knowledge resources embedded within the model  via RAG (step 3). In this case, additional context suggests  that the patient’s baseline condition resembles common risk  factors for lung cancer. This context can then be used to  augment the user’s original prompt to be more focused on  lung cancer (step 4), and thus the large language model can  provide a more specific answer regarding biomarkers, procedures, and other diagnostic processes used to evaluate the  disease. This level of retrieval-augmented generation, paired  with prompt engineering, holds the potential to offer medical insights to clinicians and patients at a quick rate to guide  clinical decision-making. Figure\xa0 3 provides a bare, preliminary glimpse on what  RAG-assisted ChatGPT responses could look like. Based  on the same original question in Fig.\xa0 1, the prompt inputted' metadata={'title': 'Potential for GPT Technology to Optimize Future Clinical Decision-Making Using Retrieval-Augmented Generation', 'author': 'Calvin Wang', 'publish_date': '2023-08-01', 'subject': 'Annals of Biomedical Engineering', 'doi': 'https://doi.org/10.1007/s10439-023-03327-6', 'keywords': 'GPT; Patient; Clinical; Large language model'}
903	page_content='Fig.\xa0 1, the prompt inputted  below includes the enhanced context in step 3 of Fig.\xa0 2B.  As displayed, this additional context allows ChatGPT to  generate a response that is more detailed than that of Fig.\xa0 1.  Here, ChatGPT lists additional symptoms, risk factors, and  diagnostic tests that can be used to confirm a case of lung  cancer. Via RAG, future ChatGPT engines would automatically retrieve this enhanced context to augment the original  prompt and generate a more specific response. However, one  can notice that the current\xa0response in Fig.\xa0 3 still does not  contain advice to assist with diagnoses and treatments for  patients on an individualized level, and future use of RAG  with patient-specific data may help bridge this gap. Therefore, the many advancements within healthcare  from artificial intelligence can be brought one step forward  through the embedding of more recent, detailed clinical  data in chatbots to assist with retrieval-augmented generation. Clinical guidelines released after' metadata={'title': 'Potential for GPT Technology to Optimize Future Clinical Decision-Making Using Retrieval-Augmented Generation', 'author': 'Calvin Wang', 'publish_date': '2023-08-01', 'subject': 'Annals of Biomedical Engineering', 'doi': 'https://doi.org/10.1007/s10439-023-03327-6', 'keywords': 'GPT; Patient; Clinical; Large language model'}
904	page_content='guidelines released after ChatGPT’s cutoff of  September 2021 and trusted medical sources (e.g., NCCN,  UptoDate) can be added to models to augment user prompts  and improve the specificity of ChatGPT’s responses, in order  to provide more patient-specific guidance to improve diagnostic and treatment efficiency.  Fig. 1  Current ChatGPT4 conversation providing clinical advice for a  hypothetical patient Potential for\xa0GPT Technology to\xa0Optimize Future Clinical Decision‑Making Using… 1 3Funding Not applicable. Declarations   Conflict of interest This submission does not contain any conflicts of  interest or competing interests with prior submitted papers. References  1. Ker, J., L. Wang, J. Rao, and T. Lim. Deep learning applications  in medical image analysis. IEEE Access. 6:9375–9389, 2018.  2. Milosevic, N., and W. Thielemann. Comparison of biomedical  relationship extraction methods and models for knowledge graph  creation. J. Web Semant.  2022. https://  doi. org/ 10. 1016/j. websem.   2022. 100756.Fig. 2' metadata={'title': 'Potential for GPT Technology to Optimize Future Clinical Decision-Making Using Retrieval-Augmented Generation', 'author': 'Calvin Wang', 'publish_date': '2023-08-01', 'subject': 'Annals of Biomedical Engineering', 'doi': 'https://doi.org/10.1007/s10439-023-03327-6', 'keywords': 'GPT; Patient; Clinical; Large language model'}
905	page_content='websem.   2022. 100756.Fig. 2  A Illustration of  retrieval-augmented generation (RAG) in a large language  model, wherein knowledge  sources are used to augment a  prompt in order to generate a  more accurate response from  the model . B Example of  retrieval-augmented generation  using the prompt from Fig.\xa01 Fig. 3  Extension of ChatGPT conversation in Fig.\xa0 1, wherein the  enhanced context from Fig.\xa0 2B is added to increase ChatGPT  response specificity.  C.\xa0Wang et al. 1 3  3. Beaulieu-Jones, B. K., W. Yuan, G. A. Brat, et\xa0al. Machine learning for patient risk stratification: standing on, or looking over, the  shoulders of clinicians? NPJ Digit. Med. 4:62–62, 2021.  4. Waisberg, E., J. Ong, M. Masalkhi, et\xa0al. GPT-4: a new era of  artificial intelligence in medicine. Ir J. Med. Sci. 2023. https://   doi. org/ 10. 1007/ s1184502303377-8.  5. Lee, P., S. Bubeck, and J. Petro. Benefits, limits, and risks  of GPT-4 as an AI chatbot for medicine. N. Engl. J. Med.   388(13):1233–1239, 2023. https:// doi. org/' metadata={'title': 'Potential for GPT Technology to Optimize Future Clinical Decision-Making Using Retrieval-Augmented Generation', 'author': 'Calvin Wang', 'publish_date': '2023-08-01', 'subject': 'Annals of Biomedical Engineering', 'doi': 'https://doi.org/10.1007/s10439-023-03327-6', 'keywords': 'GPT; Patient; Clinical; Large language model'}
906	page_content='2023. https:// doi. org/ 10. 1056/ nejms r2214   184.  6. Nori, H., N. King, S. M. McKinney, D. Carignan, and E. Horvitz.  Capabilities of GPT-4 on medical challenge problems. arXiv:  https:// arxiv. org/ abs/ 2303. 13375, 2023.  7. Hanna, T. P., W. D. King, S. Thibodeau, M. Jalink, G. A. Paulin,  E. Harvey-Jones, D. E. O’Sullivan, C. M. Booth, R. Sullivan, and  A. Aggarwal. Mortality due to cancer treatment delay: systematic  review and meta-analysis. BMJ. 2020. https:// doi. org/ 10. 1136/   bmj. m4087. 8. Homolak, J. Opportunities and risks of chatgpt in medicine, Science, and Academic Publishing: a modern promethean dilemma.  Croat. Med. J. 64(1):1–3, 2023. https:// doi. org/ 10. 3325/ cmj. 2023.   64.1.  9. Lewis, P., E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal,  H. Küttler, M. Lewis, W. Yih, T. Rocktäschel, S. Riedel, and D.  Kiela. Retrieval-augmented generation for knowledge-intensive  NLP tasks. Adv. Neural Inf. Process. Syst. 33:9459–9474, 2021.  10. Mishra, A. Machine Learning in the' metadata={'title': 'Potential for GPT Technology to Optimize Future Clinical Decision-Making Using Retrieval-Augmented Generation', 'author': 'Calvin Wang', 'publish_date': '2023-08-01', 'subject': 'Annals of Biomedical Engineering', 'doi': 'https://doi.org/10.1007/s10439-023-03327-6', 'keywords': 'GPT; Patient; Clinical; Large language model'}
907	"page_content=""A. Machine Learning in the AWS Cloud: Add Intellegence to Applications with Amazon Sagemaker and Amazon  Rekognition. Amazon, 2019. https:// docs. aws. amazon. com/ sagem   aker/ latest/ dg/ jumps  tartfound ationmodelscusto mizerag. html. Publisher's Note Springer Nature remains neutral with regard to  jurisdictional claims in published maps and institutional affiliations."" metadata={'title': 'Potential for GPT Technology to Optimize Future Clinical Decision-Making Using Retrieval-Augmented Generation', 'author': 'Calvin Wang', 'publish_date': '2023-08-01', 'subject': 'Annals of Biomedical Engineering', 'doi': 'https://doi.org/10.1007/s10439-023-03327-6', 'keywords': 'GPT; Patient; Clinical; Large language model'}"
